{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arnobzzz/Inverter-RL-agent/blob/main/inverter2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e70c995f",
        "outputId": "0f22cab6-b7d9-454d-af35-dbb709d1eca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Installing Dependencies ---\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/664.8 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# FINAL MASTER SCRIPT: TRAIN, COMPARE, AND GENERATE ALL PLOTS\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Part 1: Installation ---\n",
        "print(\"--- Installing Dependencies ---\")\n",
        "!pip install gymnasium stable-baselines3[extra] torch tensorboard -q\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "from gymnasium import spaces # Import spaces for defining observation space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baf71a6e"
      },
      "outputs": [],
      "source": [
        "# Save the controller classes to a Python file\n",
        "%%writefile controllers.py\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class SPWMController:\n",
        "    \"\"\"A simple open-loop controller with a fixed modulation index.\"\"\"\n",
        "    def __init__(self, modulation_index=0.8):\n",
        "        self.m = modulation_index\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "class PIController:\n",
        "    \"\"\"A standard Proportional-Integral (PI) controller.\"\"\"\n",
        "    def __init__(self, Kp, Ki, target_rms, ac_freq=50.0):\n",
        "        self.Kp = Kp\n",
        "        self.Ki = Ki\n",
        "        self.target_rms = target_rms\n",
        "        self.ac_period = 1.0 / ac_freq\n",
        "        self.integral_error = 0.0\n",
        "        self.m = 0.8 # Initial modulation index\n",
        "\n",
        "    def update_modulation_index(self, v_c_history_tensor):\n",
        "        if v_c_history_tensor.numel() < 2: return\n",
        "        measured_rms = torch.sqrt(torch.mean(v_c_history_tensor**2))\n",
        "        error = self.target_rms - measured_rms.item()\n",
        "        self.integral_error += error * self.ac_period\n",
        "        self.integral_error = np.clip(self.integral_error, -10.0, 10.0)\n",
        "        self.m = (self.Kp * error) + (self.Ki * self.integral_error)\n",
        "        self.m = np.clip(self.m, 0.0, 1.0)\n",
        "\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c591fd17"
      },
      "outputs": [],
      "source": [
        "# Save the InverterModelGPU class to a Python file\n",
        "%%writefile inverter_model_gpu.py\n",
        "import numpy as np\n",
        "import torch\n",
        "# Removed solve_ivp as it's not used in this version and might cause import issues\n",
        "# from scipy.integrate import solve_ivp\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \"\"\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    # Using a simple step function instead of batch_step_rk4 for this script's structure\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # Custom RK4 Solver Step\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d70d396"
      },
      "outputs": [],
      "source": [
        "# Save the InverterEnvGPU class to a Python file\n",
        "%%writefile rl_environment_gpu.py\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import torch\n",
        "from inverter_model_gpu import InverterModelGPU # Import from the file saved above\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    \"\"\"A GPU-accelerated Gymnasium environment for the inverter.\"\"\"\n",
        "    def __init__(self, device): # Accept device here\n",
        "        super().__init__()\n",
        "        self.device = device # Use the passed device\n",
        "        self.inverter = InverterModelGPU(device=self.device) # Use the class defined above\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        # Observation: [V_rms, I_rms, Power, PF, THD] - Shape (5,)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        if v_history_gpu.numel() < 2:\n",
        "            return torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        # Handle case where fft might be short\n",
        "        if fft.numel() > 10:\n",
        "            harmonics = torch.abs(fft[1:11]) # Look at fundamental + 10 harmonics\n",
        "            fundamental = harmonics[0]\n",
        "            higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "            thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        else:\n",
        "            thd = torch.tensor(1.0, device=self.device, dtype=torch.float32) # Assume high distortion\n",
        "\n",
        "\n",
        "        obs = torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "        obs[~torch.isfinite(obs)] = 0.0\n",
        "        # Ensure obs is shape (5,)\n",
        "        if obs.shape != (5,):\n",
        "             # Pad with zeros if necessary (shouldn't happen with correct stacking)\n",
        "             padded_obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "             padded_obs[:obs.numel()] = obs\n",
        "             obs = padded_obs\n",
        "\n",
        "\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        # Initial observation (zeros as no history yet), ensure it's on the correct device and shape (5,)\n",
        "        obs = torch.zeros(5, device=self.device, dtype=torch.float32) # Initialize with 5 zeros\n",
        "        return obs.cpu().numpy(), {} # Return numpy array for SB3 compatibility\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            # Pass load_resistance as a scalar tensor\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance, 1e-5) # Use constant dt\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu # Unpack 5 elements\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3b32ca5"
      },
      "outputs": [],
      "source": [
        "# Save the controller classes to a Python file\n",
        "%%writefile controllers.py\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class SPWMController:\n",
        "    \"\"\"A simple open-loop controller with a fixed modulation index.\"\"\"\n",
        "    def __init__(self, modulation_index=0.8):\n",
        "        self.m = modulation_index\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "class PIController:\n",
        "    \"\"\"A standard Proportional-Integral (PI) controller.\"\"\"\n",
        "    def __init__(self, Kp, Ki, target_rms, ac_freq=50.0):\n",
        "        self.Kp = Kp\n",
        "        self.Ki = Ki\n",
        "        self.target_rms = target_rms\n",
        "        self.ac_period = 1.0 / ac_freq\n",
        "        self.integral_error = 0.0\n",
        "        self.m = 0.8 # Initial modulation index\n",
        "\n",
        "    def update_modulation_index(self, v_c_history_tensor):\n",
        "        if v_c_history_tensor.numel() < 2: return\n",
        "        measured_rms = torch.sqrt(torch.mean(v_c_history_tensor**2))\n",
        "        error = self.target_rms - measured_rms.item()\n",
        "        self.integral_error += error * self.ac_period\n",
        "        self.integral_error = np.clip(self.integral_error, -10.0, 10.0)\n",
        "        self.m = (self.Kp * error) + (self.Ki * self.integral_error)\n",
        "        self.m = np.clip(self.m, 0.0, 1.0)\n",
        "\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "764d19dd"
      },
      "outputs": [],
      "source": [
        "# Save the InverterModelGPU class to a Python file\n",
        "%%writefile inverter_model_gpu.py\n",
        "import numpy as np\n",
        "import torch\n",
        "# Removed solve_ivp as it's not used in this version and might cause import issues\n",
        "# from scipy.integrate import solve_ivp\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \"\"\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    # Using a simple step function instead of batch_step_rk4 for this script's structure\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # Custom RK4 Solver Step\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0c9958d"
      },
      "outputs": [],
      "source": [
        "# Save the InverterEnvGPU class to a Python file\n",
        "%%writefile rl_environment_gpu.py\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import torch\n",
        "from inverter_model_gpu import InverterModelGPU # Import from the file saved above\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    \"\"\"A GPU-accelerated Gymnasium environment for the inverter.\"\"\"\n",
        "    def __init__(self, device): # Accept device here\n",
        "        super().__init__()\n",
        "        self.device = device # Use the passed device\n",
        "        self.inverter = InverterModelGPU(device=self.device) # Use the class defined above\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        # Observation: [V_rms, I_rms, Power, PF, THD] - Shape (5,)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        if v_history_gpu.numel() < 2:\n",
        "            return torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        # Handle case where fft might be short\n",
        "        if fft.numel() > 10:\n",
        "            harmonics = torch.abs(fft[1:11]) # Look at fundamental + 10 harmonics\n",
        "            fundamental = harmonics[0]\n",
        "            higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "            thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        else:\n",
        "            thd = torch.tensor(1.0, device=self.device, dtype=torch.float32) # Assume high distortion\n",
        "\n",
        "\n",
        "        obs = torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "        obs[~torch.isfinite(obs)] = 0.0\n",
        "        # Ensure obs is shape (5,)\n",
        "        if obs.shape != (5,):\n",
        "             # Pad with zeros if necessary (shouldn't happen with correct stacking)\n",
        "             padded_obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "             padded_obs[:obs.numel()] = obs\n",
        "             obs = padded_obs\n",
        "\n",
        "\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        # Initial observation (zeros as no history yet), ensure it's on the correct device and shape (5,)\n",
        "        obs = torch.zeros(5, device=self.device, dtype=torch.float32) # Initialize with 5 zeros\n",
        "        return obs.cpu().numpy(), {} # Return numpy array for SB3 compatibility\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            # Pass load_resistance as a scalar tensor\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance, 1e-5) # Use constant dt\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu # Unpack 5 elements\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}\n",
        "\n",
        "# --- Part 2: Import Your Custom Modules ---\n",
        "try:\n",
        "    # Import from the files saved above\n",
        "    from rl_environment_gpu import InverterEnvGPU\n",
        "    from inverter_model_gpu import InverterModelGPU\n",
        "    from controllers import SPWMController, PIController\n",
        "    print(\"--- All custom modules imported successfully! ---\")\n",
        "except ImportError as e:\n",
        "    print(f\"\\n--- ERROR: Could not import a required file. ---\")\n",
        "    print(\"Please make sure all .py files are uploaded to this Colab session.\")\n",
        "    raise\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 3: Train the RL Agent\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Starting RL Agent Training ---\")\n",
        "if __name__ == '__main__':\n",
        "    num_cpu = max(1, os.cpu_count() - 1)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    log_dir = \"./ppo_inverter_tensorboard/\" # Define log directory\n",
        "    print(f\"Creating {num_cpu} parallel environments. Using device: {device}\")\n",
        "\n",
        "    # Use the InverterEnvGPU defined in this cell, passing the device\n",
        "    env = make_vec_env(lambda: InverterEnvGPU(device=device), n_envs=num_cpu) # Pass device to constructor\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=1, device=device, n_steps=1024, batch_size=64, tensorboard_log=log_dir)\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.learn(total_timesteps=100000)\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(\"--- Training Complete ---\")\n",
        "    print(f\"Total Training Time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    rl_model_filename = \"ppo_inverter_final_model.zip\"\n",
        "    model.save(rl_model_filename)\n",
        "    print(f\"--- Model Saved as {rl_model_filename} ---\")\n",
        "    env.close()\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 4: Generate RL Learning Curve Plot (IMMEDIATELY AFTER TRAINING)\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Generating RL Performance Plots ---\")\n",
        "\n",
        "def get_learning_curve(log_path):\n",
        "    try:\n",
        "        ea = event_accumulator.EventAccumulator(log_path, size_guidance={event_accumulator.SCALARS: 0})\n",
        "        ea.Reload()\n",
        "        if 'rollout/ep_rew_mean' in ea.Tags()['scalars']:\n",
        "            reward_data = ea.Scalars('rollout/ep_rew_mean')\n",
        "            return [e.step for e in reward_data], [e.value for e in reward_data]\n",
        "        return None, None\n",
        "    except Exception: return None, None\n",
        "\n",
        "subdirs = [os.path.join(log_dir, d) for d in os.listdir(log_dir)]\n",
        "latest_log_dir = max(subdirs, key=os.path.getmtime)\n",
        "steps, rewards = get_learning_curve(latest_log_dir)\n",
        "\n",
        "if steps and rewards:\n",
        "    plt.figure(figsize=(12, 8), dpi=100)\n",
        "    plt.plot(steps, rewards, color='darkgreen')\n",
        "    plt.title('Reinforcement Learning Curve', fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Training Timesteps'); plt.ylabel('Mean Reward per Episode')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"rl_learning_curve.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Could not generate learning curve. Log file might be missing or corrupted.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 5: Run the Head-to-Head Comparison\n",
        "# ==============================================================================\n",
        "\n",
        "def run_simulation(controller_type, model_path=None, duration=0.2, dt=1e-5):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    if controller_type == \"RL\":\n",
        "        try:\n",
        "            # Load the model onto the correct device\n",
        "            sim_controller = PPO.load(model_path, device=device)\n",
        "            controller_name = \"RL Controller (Proposed)\"\n",
        "        except FileNotFoundError:\n",
        "            print(f\"\\nFATAL ERROR: Model file not found at '{model_path}'\")\n",
        "            print(\"Please make sure your trained model .zip file is uploaded and the name is correct.\")\n",
        "            return None\n",
        "    elif controller_type == \"PI\":\n",
        "        sim_controller = PIController(Kp=0.05, Ki=2.5, target_rms=30.0)\n",
        "        controller_name = \"PI Controller\"\n",
        "    elif controller_type == \"SPWM\":\n",
        "        sim_controller = SPWMController(modulation_index=0.65)\n",
        "        controller_name = \"SPWM Controller\"\n",
        "    else:\n",
        "        raise ValueError(\"Unknown controller type.\")\n",
        "\n",
        "    print(f\"\\n--- Running simulation for: {controller_name} ---\")\n",
        "\n",
        "    # Instantiate the GPU Inverter Model (used for all controllers now)\n",
        "    inverter = InverterModelGPU(device=device)\n",
        "    num_steps = int(duration / dt)\n",
        "\n",
        "    time_hist = np.zeros(num_steps)\n",
        "    v_c_hist = np.zeros(num_steps)\n",
        "    i_l_hist = np.zeros(num_steps)\n",
        "\n",
        "    ac_period_steps = int((1.0 / inverter.ac_freq.item()) / dt)\n",
        "\n",
        "    # Initialize observation for RL controller (shape (5,)) to match the env used for training\n",
        "    obs = np.zeros(5, dtype=np.float32) # Initialize with 5 zeros\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in range(num_steps):\n",
        "        t = i * dt\n",
        "\n",
        "        # Load scheduling (applied directly in the simulation step)\n",
        "        r_load_val = 50.0\n",
        "        if 0.08 <= t < 0.16:\n",
        "            r_load_val = 25.0\n",
        "        r_load_tensor = torch.tensor(r_load_val, device=device, dtype=torch.float32)\n",
        "\n",
        "        if controller_type == \"RL\":\n",
        "            # Get action from the RL controller\n",
        "            # Pass the observation with an added batch dimension (expected by SB3 models trained on VecEnvs)\n",
        "            action, _ = sim_controller.predict(np.expand_dims(obs, axis=0), deterministic=True)\n",
        "            m_numpy = (action[0][0] + 1.0) / 2.0\n",
        "\n",
        "        else: # PI and SPWM controllers\n",
        "            if isinstance(sim_controller, PIController) and i > 0 and i % ac_period_steps == 0:\n",
        "                 # PI update logic (using history collected so far)\n",
        "                 v_cycle_tensor = torch.from_numpy(v_c_hist[max(0, i - ac_period_steps):i]).to(device)\n",
        "                 sim_controller.update_modulation_index(v_cycle_tensor)\n",
        "\n",
        "            m_numpy = sim_controller.get_modulation_index(t)\n",
        "\n",
        "        # Step the *inverter model* directly for all controllers\n",
        "        modulation_index = torch.tensor(m_numpy, device=device)\n",
        "        state_gpu = inverter.step(modulation_index, r_load_tensor, dt)\n",
        "        state_cpu = state_gpu.cpu().numpy()\n",
        "\n",
        "        # Store history\n",
        "        time_hist[i], v_c_hist[i], i_l_hist[i] = t, state_cpu[1], state_cpu[0]\n",
        "\n",
        "        # Update the observation for the next step if using the RL controller and at the end of a cycle\n",
        "        if controller_type == \"RL\" and (i + 1) % ac_period_steps == 0:\n",
        "            v_cycle = torch.from_numpy(v_c_hist[max(0, i-ac_period_steps+1):i+1]).to(device)\n",
        "            i_cycle = torch.from_numpy(i_l_hist[max(0, i-ac_period_steps+1):i+1]).to(device)\n",
        "\n",
        "            # Calculate the 5-element observation vector (V_rms, I_rms, Power, PF, THD)\n",
        "            v_rms = torch.sqrt(torch.mean(v_cycle**2))\n",
        "            i_rms = torch.sqrt(torch.mean(i_cycle**2))\n",
        "            power = torch.mean(v_cycle * i_cycle)\n",
        "            pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "            thd = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "            if len(v_cycle) > 1:\n",
        "                fft = torch.fft.fft(torch.from_numpy(v_c_hist[max(0, i-ac_period_steps+1):i+1]).to(device)) # Convert to tensor for FFT\n",
        "                # Attempt to find the fundamental frequency index based on the number of points in the cycle\n",
        "                freq_resolution = (1.0 / (len(v_cycle) * dt))\n",
        "                fundamental_freq_idx = int(inverter.ac_freq.item() / freq_resolution)\n",
        "                if fundamental_freq_idx > 0 and fundamental_freq_idx < len(fft) and torch.abs(fft[fundamental_freq_idx]).item() > 1e-6:\n",
        "                   harmonics_abs = torch.abs(fft[1: fundamental_freq_idx + 11]) # Consider fundamental + 10 harmonics\n",
        "                   # Adjust fundamental index based on slice\n",
        "                   fundamental_in_slice_idx = fundamental_freq_idx - 1\n",
        "                   if fundamental_in_slice_idx < len(harmonics_abs):\n",
        "                       fundamental_abs = harmonics_abs[fundamental_in_slice_idx]\n",
        "                       # Sum of squares of higher harmonics magnitudes from the fundamental onwards in the slice\n",
        "                       if fundamental_in_slice_idx + 1 < len(harmonics_abs):\n",
        "                           higher_harmonics_sum_sq = torch.sum(harmonics_abs[fundamental_in_slice_idx + 1 :]**2)\n",
        "                           thd = torch.sqrt(higher_harmonics_sum_sq) / (fundamental_abs + 1e-6)\n",
        "                       else:\n",
        "                           thd = torch.tensor(0.0, device=device, dtype=torch.float32) # No higher harmonics in slice\n",
        "                   else:\n",
        "                       thd = torch.tensor(0.0, device=device, dtype=torch.float32) # Fundamental index outside slice\n",
        "\n",
        "                else:\n",
        "                    thd = torch.tensor(1.0, device=device, dtype=torch.float32) # Assume high distortion if fundamental is zero or not found\n",
        "\n",
        "            # Construct obs as a NumPy array of shape (5,)\n",
        "            obs = torch.stack([v_rms, i_rms, power, pf, thd]).cpu().numpy()\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Simulation finished in {end_time - start_time:.2f} seconds.\")\n",
        "    return time_hist, v_c_hist, i_l_hist\n",
        "\n",
        "def analyze_and_plot(results):\n",
        "    print(\"\\n--- Analyzing results and generating plots... ---\")\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    # Create a figure with a single subplot for the RMS voltage plot\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(12, 6), dpi=150) # Removed the second subplot\n",
        "\n",
        "    # Plot RMS Voltage\n",
        "    for name, data in results.items():\n",
        "        # Check if data is valid before processing\n",
        "        if data is not None and len(data) == 3:\n",
        "            time, v_c, _ = data\n",
        "            # Ensure history arrays have sufficient length\n",
        "            if len(time) > 1 and len(v_c) > 1:\n",
        "                dt = time[1] - time[0]\n",
        "                window_size = int(0.02 / dt) if dt > 0 else 0\n",
        "                # Ensure we have enough data points for the sliding window\n",
        "                if len(v_c) >= window_size and window_size > 0:\n",
        "                    rms_voltage = [np.sqrt(np.mean(v_c[i-window_size:i]**2)) for i in range(window_size, len(v_c))]\n",
        "                    ax.plot(time[window_size:], rms_voltage, label=name, linewidth=2.5)\n",
        "                else:\n",
        "                    print(f\"Warning: Not enough data ({len(v_c)} points) for RMS calculation for {name}. Required at least {window_size} points.\")\n",
        "            else:\n",
        "                print(f\"Warning: Insufficient data ({len(time)} time points, {len(v_c)} voltage points) for plotting RMS voltage for {name}. Skipping plot.\")\n",
        "        else:\n",
        "            print(f\"Warning: Invalid or missing data for {name}. Skipping plot.\")\n",
        "\n",
        "\n",
        "    ax.set_title('Dynamic Voltage Response to Load Step', fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel('Time (s)', fontsize=12)\n",
        "    ax.set_ylabel('RMS Voltage (V)', fontsize=12)\n",
        "    ax.axvspan(0.08, 0.16, color='gray', alpha=0.2, label='Heavy Load Applied')\n",
        "    ax.legend(fontsize=12); ax.grid(True, which='both', linestyle='--')\n",
        "\n",
        "    # Removed the THD calculation and plotting section\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"final_comparison_results.png\")\n",
        "    print(\"\\n--- Plots generated and saved as 'final_comparison_results.png' ---\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Part 6: Main Execution Block ---\n",
        "if __name__ == '__main__':\n",
        "    results = {}\n",
        "    # !!! IMPORTANT !!!\n",
        "    # Make sure this name matches the name of your best trained model file!\n",
        "    # For example, \"ppo_final_model.zip\" or \"ppo_my_model.zip\"\n",
        "    rl_model_filename = \"ppo_inverter_final_model.zip\" # This is the filename used in Part 3\n",
        "\n",
        "    print(\"\\n--- Running SPWM Simulation ---\")\n",
        "    results[\"SPWM Controller\"] = run_simulation(controller_type=\"SPWM\")\n",
        "    if results[\"SPWM Controller\"] is not None:\n",
        "        print(f\"SPWM Simulation Data Lengths: time={len(results['SPWM Controller'][0])}, v_c={len(results['SPWM Controller'][1])}, i_l={len(results['SPWM Controller'][2])}\")\n",
        "    else:\n",
        "        print(\"SPWM Simulation Failed.\")\n",
        "\n",
        "    print(\"\\n--- Running PI Simulation ---\")\n",
        "    results[\"PI Controller\"] = run_simulation(controller_type=\"PI\")\n",
        "    if results[\"PI Controller\"] is not None:\n",
        "        print(f\"PI Simulation Data Lengths: time={len(results['PI Controller'][0])}, v_c={len(results['PI Controller'][1])}, i_l={len(results['PI Controller'][2])}\")\n",
        "    else:\n",
        "        print(\"PI Simulation Failed.\")\n",
        "\n",
        "\n",
        "    print(\"\\n--- Running RL Simulation ---\")\n",
        "    results[\"RL Controller (Proposed)\"] = run_simulation(controller_type=\"RL\", model_path=rl_model_filename)\n",
        "    if results[\"RL Controller (Proposed)\"] is not None:\n",
        "         print(f\"RL Simulation Data Lengths: time={len(results['RL Controller (Proposed)'][0])}, v_c={len(results['RL Controller (Proposed)'][1])}, i_l={len(results['RL Controller (Proposed)'][2])}\")\n",
        "    else:\n",
        "        print(\"RL Simulation Failed.\")\n",
        "\n",
        "\n",
        "    # Check if all simulations were successful before plotting\n",
        "    if all(res is not None and len(res[0]) > 1 for res in results.values()):\n",
        "        analyze_and_plot(results)\n",
        "    else:\n",
        "        print(\"\\n--- Skipping analysis due to simulation failures or insufficient data. ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d24efb1e"
      },
      "outputs": [],
      "source": [
        "# --- Part 1: Installation ---\n",
        "print(\"--- Installing Dependencies ---\")\n",
        "!pip install gymnasium stable-baselines3[extra] torch tensorboard -q\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "from gymnasium import spaces # Import spaces for defining observation space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "291960d4"
      },
      "outputs": [],
      "source": [
        "# Save the controller classes to a Python file\n",
        "%%writefile controllers.py\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class SPWMController:\n",
        "    \"\"\"A simple open-loop controller with a fixed modulation index.\"\"\"\n",
        "    def __init__(self, modulation_index=0.8):\n",
        "        self.m = modulation_index\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "class PIController:\n",
        "    \"\"\"A standard Proportional-Integral (PI) controller.\"\"\"\n",
        "    def __init__(self, Kp, Ki, target_rms, ac_freq=50.0):\n",
        "        self.Kp = Kp\n",
        "        self.Ki = Ki\n",
        "        self.target_rms = target_rms\n",
        "        self.ac_period = 1.0 / ac_freq\n",
        "        self.integral_error = 0.0\n",
        "        self.m = 0.8 # Initial modulation index\n",
        "\n",
        "    def update_modulation_index(self, v_c_history_tensor):\n",
        "        if v_c_history_tensor.numel() < 2: return\n",
        "        measured_rms = torch.sqrt(torch.mean(v_c_history_tensor**2))\n",
        "        error = self.target_rms - measured_rms.item()\n",
        "        self.integral_error += error * self.ac_period\n",
        "        self.integral_error = np.clip(self.integral_error, -10.0, 10.0)\n",
        "        self.m = (self.Kp * error) + (self.Ki * self.integral_error)\n",
        "        self.m = np.clip(self.m, 0.0, 1.0)\n",
        "\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03e63ab1"
      },
      "outputs": [],
      "source": [
        "# Save the InverterModelGPU class to a Python file\n",
        "%%writefile inverter_model_gpu.py\n",
        "import numpy as np\n",
        "import torch\n",
        "# Removed solve_ivp as it's not used in this version and might cause import issues\n",
        "# from scipy.integrate import solve_ivp\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \"\"\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    # Using a simple step function instead of batch_step_rk4 for this script's structure\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # Custom RK4 Solver Step\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eb242b7"
      },
      "outputs": [],
      "source": [
        "# Save the InverterEnvGPU class to a Python file\n",
        "%%writefile rl_environment_gpu.py\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import torch\n",
        "from inverter_model_gpu import InverterModelGPU # Import from the file saved above\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    \"\"\"A GPU-accelerated Gymnasium environment for the inverter.\"\"\"\n",
        "    def __init__(self, device): # Accept device here\n",
        "        super().__init__()\n",
        "        self.device = device # Use the passed device\n",
        "        self.inverter = InverterModelGPU(device=self.device) # Use the class defined above\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        # Observation: [V_rms, I_rms, Power, PF, THD] - Shape (5,)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        if v_history_gpu.numel() < 2:\n",
        "            return torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        # Handle case where fft might be short\n",
        "        if fft.numel() > 10:\n",
        "            harmonics = torch.abs(fft[1:11]) # Look at fundamental + 10 harmonics\n",
        "            fundamental = harmonics[0]\n",
        "            higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "            thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        else:\n",
        "            thd = torch.tensor(1.0, device=self.device, dtype=torch.float32) # Assume high distortion\n",
        "\n",
        "\n",
        "        obs = torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "        obs[~torch.isfinite(obs)] = 0.0\n",
        "        # Ensure obs is shape (5,)\n",
        "        if obs.shape != (5,):\n",
        "             # Pad with zeros if necessary (shouldn't happen with correct stacking)\n",
        "             padded_obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "             padded_obs[:obs.numel()] = obs\n",
        "             obs = padded_obs\n",
        "\n",
        "\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        # Initial observation (zeros as no history yet), ensure it's on the correct device and shape (5,)\n",
        "        obs = torch.zeros(5, device=self.device, dtype=torch.float32) # Initialize with 5 zeros\n",
        "        return obs.cpu().numpy(), {} # Return numpy array for SB3 compatibility\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            # Pass load_resistance as a scalar tensor\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance, 1e-5) # Use constant dt\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu # Unpack 5 elements\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a9bfd8b"
      },
      "outputs": [],
      "source": [
        "# --- Part 1: Installation and Initial Imports ---\n",
        "print(\"--- Installing Dependencies ---\")\n",
        "!pip install gymnasium stable-baselines3[extra] torch tensorboard -q\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "from gymnasium import spaces # Import spaces for defining observation space\n",
        "import importlib # Import importlib for module reloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "194ed8f0"
      },
      "outputs": [],
      "source": [
        "# Save the controller classes to a Python file\n",
        "%%writefile controllers.py\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class SPWMController:\n",
        "    \"\"\"A simple open-loop controller with a fixed modulation index.\"\"\"\n",
        "    def __init__(self, modulation_index=0.8):\n",
        "        self.m = modulation_index\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "class PIController:\n",
        "    \"\"\"A standard Proportional-Integral (PI) controller.\"\"\"\n",
        "    def __init__(self, Kp, Ki, target_rms, ac_freq=50.0):\n",
        "        self.Kp = Kp\n",
        "        self.Ki = Ki\n",
        "        self.target_rms = target_rms\n",
        "        self.ac_period = 1.0 / ac_freq\n",
        "        self.integral_error = 0.0\n",
        "        self.m = 0.8 # Initial modulation index\n",
        "\n",
        "    def update_modulation_index(self, v_c_history_tensor):\n",
        "        if v_c_history_tensor.numel() < 2: return\n",
        "        measured_rms = torch.sqrt(torch.mean(v_c_history_tensor**2))\n",
        "        error = self.target_rms - measured_rms.item()\n",
        "        self.integral_error += error * self.ac_period\n",
        "        self.integral_error = np.clip(self.integral_error, -10.0, 10.0)\n",
        "        self.m = (self.Kp * error) + (self.Ki * self.integral_error)\n",
        "        self.m = np.clip(self.m, 0.0, 1.0)\n",
        "\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84bbe477"
      },
      "outputs": [],
      "source": [
        "# Save the InverterModelGPU class to a Python file\n",
        "%%writefile inverter_model_gpu.py\n",
        "import numpy as np\n",
        "import torch\n",
        "# Removed solve_ivp as it's not used in this version and might cause import issues\n",
        "# from scipy.integrate import solve_ivp\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \"\"\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    # Using a simple step function instead of batch_step_rk4 for this script's structure\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # Custom RK4 Solver Step\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5b837ed"
      },
      "outputs": [],
      "source": [
        "# Save the InverterEnvGPU class to a Python file\n",
        "%%writefile rl_environment_gpu.py\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import torch\n",
        "from inverter_model_gpu import InverterModelGPU # Import from the file saved above\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    \"\"\"A GPU-accelerated Gymnasium environment for the inverter.\"\"\"\n",
        "    def __init__(self, device): # Accept device here\n",
        "        super().__init__()\n",
        "        self.device = device # Use the passed device\n",
        "        self.inverter = InverterModelGPU(device=self.device) # Use the class defined above\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        # Observation: [V_rms, I_rms, Power, PF, THD] - Shape (5,)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        if v_history_gpu.numel() < 2:\n",
        "            return torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        # Handle case where fft might be short\n",
        "        if fft.numel() > 10:\n",
        "            harmonics = torch.abs(fft[1:11]) # Look at fundamental + 10 harmonics\n",
        "            fundamental = harmonics[0]\n",
        "            higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "            thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        else:\n",
        "            thd = torch.tensor(1.0, device=self.device, dtype=torch.float32) # Assume high distortion\n",
        "\n",
        "\n",
        "        obs = torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "        obs[~torch.isfinite(obs)] = 0.0\n",
        "        # Ensure obs is shape (5,)\n",
        "        if obs.shape != (5,):\n",
        "             # Pad with zeros if necessary (shouldn't happen with correct stacking)\n",
        "             padded_obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "             padded_obs[:obs.numel()] = obs\n",
        "             obs = padded_obs\n",
        "\n",
        "\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        # Initial observation (zeros as no history yet), ensure it's on the correct device and shape (5,)\n",
        "        obs = torch.zeros(5, device=self.device, dtype=torch.float32) # Initialize with 5 zeros\n",
        "        return obs.cpu().numpy(), {} # Return numpy array for SB3 compatibility\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            # Pass load_resistance as a scalar tensor\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance, 1e-5) # Use constant dt\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu # Unpack 5 elements\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cdda19c"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CORRECTED inverter_model_gpu.py file\n",
        "# ==============================================================================\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \"\"\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch) # Corrected typo here, dvC_dt instead of dvC_C\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # Custom RK4 Solver Step\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjgBsgmbHClm"
      },
      "outputs": [],
      "source": [
        "# --- Step 1: Define and Save the Inverter Model ---\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "inverter_model_code = \"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \\\"\\\"\\\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \\\"\\\"\\\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state\n",
        "\"\"\"\n",
        "\n",
        "# Create the file\n",
        "print(\"--- Creating inverter_model_gpu.py for testing ---\")\n",
        "with open(\"inverter_model_gpu.py\", \"w\") as f:\n",
        "    f.write(inverter_model_code)\n",
        "print(\"Saved inverter_model_gpu.py\")\n",
        "\n",
        "# --- Step 2: Run a simple simulation test ---\n",
        "print(\"\\n--- Starting simple simulation test ---\")\n",
        "try:\n",
        "    from inverter_model_gpu import InverterModelGPU\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    inverter = InverterModelGPU(device=device)\n",
        "    inverter.reset()\n",
        "\n",
        "    # Simulation parameters\n",
        "    duration = 0.2\n",
        "    dt = 1e-5\n",
        "    num_steps = int(duration / dt)\n",
        "    modulation_index = 0.7  # Fixed modulation index for open-loop test\n",
        "    load_resistance = 50.0\n",
        "\n",
        "    time_hist = np.zeros(num_steps)\n",
        "    v_c_hist = np.zeros(num_steps)\n",
        "    i_l_hist = np.zeros(num_steps)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in range(num_steps):\n",
        "        state_gpu = inverter.step(\n",
        "            modulation_index=torch.tensor(modulation_index, device=device, dtype=torch.float32),\n",
        "            r_load=torch.tensor(load_resistance, device=device, dtype=torch.float32),\n",
        "            dt=dt\n",
        "        )\n",
        "        state_cpu = state_gpu.cpu().numpy()\n",
        "        time_hist[i], v_c_hist[i], i_l_hist[i] = i * dt, state_cpu[1], state_cpu[0]\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Test simulation finished in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "    # --- Step 3: Plot the results to visually confirm it worked ---\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(time_hist, v_c_hist, label='Capacitor Voltage $v_c$')\n",
        "    plt.title('Open-Loop Inverter Output Voltage Test')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Voltage (V)')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.savefig(\"inverter_test_plot.png\")\n",
        "    plt.show()\n",
        "    print(\"Test successful. Plot saved as 'inverter_test_plot.png'.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred during the test: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac-VQUbdJqLj"
      },
      "outputs": [],
      "source": [
        "# --- Step 1: Define and Save the Inverter Model and RL Environment ---\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "\n",
        "# Define the content for inverter_model_gpu.py\n",
        "inverter_model_code = \"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \\\"\\\"\\\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \\\"\\\"\\\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state\n",
        "\"\"\"\n",
        "\n",
        "# Define the content for rl_environment_gpu.py\n",
        "rl_env_code = \"\"\"\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import torch\n",
        "from inverter_model_gpu import InverterModelGPU\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    \\\"\\\"\\\"A GPU-accelerated Gymnasium environment for the inverter.\\\"\\\"\\\"\n",
        "    def __init__(self, device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.inverter = InverterModelGPU(device=self.device)\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        if v_history_gpu.numel() < 2:\n",
        "            return torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        if fft.numel() > 10:\n",
        "            harmonics = torch.abs(fft[1:11])\n",
        "            fundamental = harmonics[0]\n",
        "            higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "            thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        else:\n",
        "            thd = torch.tensor(1.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        obs = torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "        obs[~torch.isfinite(obs)] = 0.0\n",
        "        if obs.shape != (5,):\n",
        "            padded_obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "            padded_obs[:obs.numel()] = obs\n",
        "            obs = padded_obs\n",
        "\n",
        "        return obs\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "        return obs.cpu().numpy(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "        dt = 1e-5\n",
        "\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance, dt)\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}\n",
        "\"\"\"\n",
        "\n",
        "# Create the files\n",
        "print(\"--- Creating custom Python files for RL environment test ---\")\n",
        "with open(\"inverter_model_gpu.py\", \"w\") as f:\n",
        "    f.write(inverter_model_code)\n",
        "print(\"Saved inverter_model_gpu.py\")\n",
        "with open(\"rl_environment_gpu.py\", \"w\") as f:\n",
        "    f.write(rl_env_code)\n",
        "print(\"Saved rl_environment_gpu.py\")\n",
        "\n",
        "\n",
        "# --- Step 2: Test the RL environment ---\n",
        "print(\"\\n--- Starting RL environment test ---\")\n",
        "try:\n",
        "    from rl_environment_gpu import InverterEnvGPU\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create an instance of the environment\n",
        "    env = InverterEnvGPU(device=device)\n",
        "\n",
        "    # Run for a few steps\n",
        "    obs, info = env.reset()\n",
        "    print(f\"Initial Observation: {obs}\")\n",
        "    for i in range(3):\n",
        "        # Action is a random value between -1 and 1\n",
        "        random_action = env.action_space.sample()\n",
        "        obs, reward, done, truncated, info = env.step(random_action)\n",
        "        print(f\"\\nStep {i+1}:\")\n",
        "        print(f\"  Action: {random_action}\")\n",
        "        print(f\"  Observation (V_rms, I_rms, Power, PF, THD): {obs}\")\n",
        "        print(f\"  Reward: {reward}\")\n",
        "        print(f\"  Done: {done}\")\n",
        "\n",
        "    print(\"\\nEnvironment test finished successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred during the RL environment test: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "291E-dV-K5G3"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# SINGLE-FILE, SELF-CONTAINED SCRIPT FOR ENVIRONMENT TEST\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Part 1: Installation and Initial Imports ---\n",
        "print(\"--- Installing Dependencies ---\")\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "# Function to safely install packages\n",
        "def install(package):\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
        "        print(f\"Successfully installed {package}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error installing {package}: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "install(\"gymnasium\")\n",
        "install(\"torch\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 2: Define Classes Directly\n",
        "# ==============================================================================\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \"\"\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state\n",
        "\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    \"\"\"A GPU-accelerated Gymnasium environment for the inverter.\"\"\"\n",
        "    def __init__(self, device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.inverter = InverterModelGPU(device=self.device)\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        if v_history_gpu.numel() < 2:\n",
        "            return torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        if fft.numel() > 10:\n",
        "            harmonics = torch.abs(fft[1:11])\n",
        "            fundamental = harmonics[0]\n",
        "            higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "            thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        else:\n",
        "            thd = torch.tensor(1.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        obs = torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "        obs[~torch.isfinite(obs)] = 0.0\n",
        "        if obs.shape != (5,):\n",
        "            padded_obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "            padded_obs[:obs.numel()] = obs\n",
        "            obs = padded_obs\n",
        "\n",
        "        return obs\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "        return obs.cpu().numpy(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "        dt = 1e-5\n",
        "\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance, dt)\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 3: Run the test\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Starting final RL environment test ---\")\n",
        "try:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    env = InverterEnvGPU(device=device)\n",
        "\n",
        "    obs, info = env.reset()\n",
        "    print(f\"Initial Observation: {obs}\")\n",
        "    for i in range(3):\n",
        "        random_action = env.action_space.sample()\n",
        "        obs, reward, done, truncated, info = env.step(random_action)\n",
        "        print(f\"\\nStep {i+1}:\")\n",
        "        print(f\"  Action: {random_action}\")\n",
        "        print(f\"  Observation (V_rms, I_rms, Power, PF, THD): {obs}\")\n",
        "        print(f\"  Reward: {reward}\")\n",
        "        print(f\"  Done: {done}\")\n",
        "\n",
        "    print(\"\\nEnvironment test finished successfully. You can now proceed to the full training and comparison script.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred during the final RL environment test: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Qjrkl15LBo2"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# FINAL MASTER SCRIPT: TRAIN, COMPARE, AND GENERATE ALL PLOTS\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Part 1: Installation and Initial Imports ---\n",
        "print(\"--- Installing Dependencies ---\")\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "from gymnasium import spaces\n",
        "\n",
        "# Function to safely install packages\n",
        "def install(package):\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
        "        print(f\"Successfully installed {package}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error installing {package}: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "install(\"gymnasium\")\n",
        "install(\"stable-baselines3[extra]\")\n",
        "install(\"torch\")\n",
        "install(\"tensorboard\")\n",
        "install(\"matplotlib\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 2: Define all Classes in a Single Script\n",
        "# ==============================================================================\n",
        "print(\"--- Defining all classes ---\")\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \"\"\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    \"\"\"A GPU-accelerated Gymnasium environment for the inverter.\"\"\"\n",
        "    def __init__(self, device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.inverter = InverterModelGPU(device=self.device)\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        if v_history_gpu.numel() < 2:\n",
        "            return torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        if fft.numel() > 10:\n",
        "            harmonics = torch.abs(fft[1:11])\n",
        "            fundamental = harmonics[0]\n",
        "            higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "            thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        else:\n",
        "            thd = torch.tensor(1.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        obs = torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "        obs[~torch.isfinite(obs)] = 0.0\n",
        "        if obs.shape != (5,):\n",
        "            padded_obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "            padded_obs[:obs.numel()] = obs\n",
        "            obs = padded_obs\n",
        "\n",
        "        return obs\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "        return obs.cpu().numpy(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "        dt = 1e-5\n",
        "\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance, dt)\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}\n",
        "\n",
        "class SPWMController:\n",
        "    \"\"\"A simple open-loop controller with a fixed modulation index.\"\"\"\n",
        "    def __init__(self, modulation_index=0.8):\n",
        "        self.m = modulation_index\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "class PIController:\n",
        "    \"\"\"A standard Proportional-Integral (PI) controller.\"\"\"\n",
        "    def __init__(self, Kp, Ki, target_rms, ac_freq=50.0):\n",
        "        self.Kp = Kp\n",
        "        self.Ki = Ki\n",
        "        self.target_rms = target_rms\n",
        "        self.ac_period = 1.0 / ac_freq\n",
        "        self.integral_error = 0.0\n",
        "        self.m = 0.8 # Initial modulation index\n",
        "\n",
        "    def update_modulation_index(self, v_c_history_tensor):\n",
        "        if v_c_history_tensor.numel() < 2: return\n",
        "        measured_rms = torch.sqrt(torch.mean(v_c_history_tensor**2))\n",
        "        error = self.target_rms - measured_rms.item()\n",
        "        self.integral_error += error * self.ac_period\n",
        "        self.integral_error = np.clip(self.integral_error, -10.0, 10.0)\n",
        "        self.m = (self.Kp * error) + (self.Ki * self.integral_error)\n",
        "        self.m = np.clip(self.m, 0.0, 1.0)\n",
        "\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Main Execution Block\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Starting Main Execution ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 3: Train the RL Agent\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Starting RL Agent Training ---\")\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    num_cpu = max(1, os.cpu_count() - 1)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    log_dir = \"./ppo_inverter_tensorboard/\"\n",
        "    print(f\"Creating {num_cpu} parallel environments. Using device: {device}\")\n",
        "\n",
        "    env = make_vec_env(InverterEnvGPU, n_envs=num_cpu, env_kwargs={'device': device})\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=1, device=device, n_steps=1024, batch_size=64, tensorboard_log=log_dir)\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.learn(total_timesteps=100000)\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(\"--- Training Complete ---\")\n",
        "    print(f\"Total Training Time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    rl_model_filename = \"ppo_inverter_final_model.zip\"\n",
        "    model.save(rl_model_filename)\n",
        "    print(f\"--- Model Saved as {rl_model_filename} ---\")\n",
        "    env.close()\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 4: Generate RL Learning Curve Plot (IMMEDIATELY AFTER TRAINING)\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Generating RL Performance Plots ---\")\n",
        "\n",
        "def get_learning_curve(log_path):\n",
        "    try:\n",
        "        ea = event_accumulator.EventAccumulator(log_path, size_guidance={event_accumulator.SCALARS: 0})\n",
        "        ea.Reload()\n",
        "        if 'rollout/ep_rew_mean' in ea.Tags()['scalars']:\n",
        "            reward_data = ea.Scalars('rollout/ep_rew_mean')\n",
        "            return [e.step for e in reward_data], [e.value for e in reward_data]\n",
        "        return None, None\n",
        "    except Exception: return None, None\n",
        "\n",
        "subdirs = [os.path.join(log_dir, d) for d in os.listdir(log_dir) if os.path.isdir(os.path.join(log_dir, d))]\n",
        "if subdirs:\n",
        "    latest_log_dir = max(subdirs, key=os.path.getmtime)\n",
        "    steps, rewards = get_learning_curve(latest_log_dir)\n",
        "\n",
        "    if steps and rewards:\n",
        "        plt.figure(figsize=(12, 8), dpi=100)\n",
        "        plt.plot(steps, rewards, color='darkgreen')\n",
        "        plt.title('Reinforcement Learning Curve', fontsize=16, fontweight='bold')\n",
        "        plt.xlabel('Training Timesteps'); plt.ylabel('Mean Reward per Episode')\n",
        "        plt.grid(True)\n",
        "        plt.savefig(\"rl_learning_curve.png\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Could not generate learning curve. Log file might be missing or corrupted.\")\n",
        "else:\n",
        "    print(\"Could not find any log directory to generate learning curve.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 5: Run the Head-to-Head Comparison\n",
        "# ==============================================================================\n",
        "\n",
        "def run_simulation(controller_type, model_path=None, duration=0.2, dt=1e-5):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    if controller_type == \"RL\":\n",
        "        try:\n",
        "            sim_controller = PPO.load(model_path, device=device)\n",
        "            controller_name = \"RL Controller (Proposed)\"\n",
        "        except FileNotFoundError:\n",
        "            print(f\"\\nFATAL ERROR: Model file not found at '{model_path}'\")\n",
        "            print(\"Please make sure your trained model .zip file is uploaded and the name is correct.\")\n",
        "            return None\n",
        "    elif controller_type == \"PI\":\n",
        "        sim_controller = PIController(Kp=0.05, Ki=2.5, target_rms=30.0)\n",
        "        controller_name = \"PI Controller\"\n",
        "    elif controller_type == \"SPWM\":\n",
        "        sim_controller = SPWMController(modulation_index=0.65)\n",
        "        controller_name = \"SPWM Controller\"\n",
        "    else:\n",
        "        raise ValueError(\"Unknown controller type.\")\n",
        "\n",
        "    print(f\"\\n--- Running simulation for: {controller_name} ---\")\n",
        "\n",
        "    inverter = InverterModelGPU(device=device)\n",
        "    num_steps = int(duration / dt)\n",
        "\n",
        "    time_hist = np.zeros(num_steps)\n",
        "    v_c_hist = np.zeros(num_steps)\n",
        "    i_l_hist = np.zeros(num_steps)\n",
        "\n",
        "    ac_period_steps = int((1.0 / inverter.ac_freq.item()) / dt)\n",
        "\n",
        "    obs = np.zeros(5, dtype=np.float32)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in range(num_steps):\n",
        "        t = i * dt\n",
        "\n",
        "        r_load_val = 50.0\n",
        "        if 0.08 <= t < 0.16:\n",
        "            r_load_val = 25.0\n",
        "        r_load_tensor = torch.tensor(r_load_val, device=device, dtype=torch.float32)\n",
        "\n",
        "        if controller_type == \"RL\":\n",
        "            action, _ = sim_controller.predict(np.expand_dims(obs, axis=0), deterministic=True)\n",
        "            m_numpy = (action[0][0] + 1.0) / 2.0\n",
        "        else:\n",
        "            if isinstance(sim_controller, PIController) and i > 0 and i % ac_period_steps == 0:\n",
        "                v_cycle_tensor = torch.from_numpy(v_c_hist[max(0, i - ac_period_steps):i]).to(device)\n",
        "                if v_cycle_tensor.numel() > 0:\n",
        "                    sim_controller.update_modulation_index(v_cycle_tensor)\n",
        "\n",
        "            m_numpy = sim_controller.get_modulation_index(t)\n",
        "\n",
        "        modulation_index = torch.tensor(m_numpy, device=device)\n",
        "        state_gpu = inverter.step(modulation_index, r_load_tensor, dt)\n",
        "        state_cpu = state_gpu.cpu().numpy()\n",
        "\n",
        "        time_hist[i], v_c_hist[i], i_l_hist[i] = t, state_cpu[1], state_cpu[0]\n",
        "\n",
        "        if controller_type == \"RL\" and (i + 1) % ac_period_steps == 0:\n",
        "            v_cycle = v_c_hist[max(0, i-ac_period_steps+1):i+1]\n",
        "            i_cycle = i_l_hist[max(0, i-ac_period_steps+1):i+1]\n",
        "\n",
        "            if len(v_cycle) > 1:\n",
        "                v_cycle_tensor = torch.from_numpy(v_cycle).to(device)\n",
        "                i_cycle_tensor = torch.from_numpy(i_cycle).to(device)\n",
        "\n",
        "                v_rms = torch.sqrt(torch.mean(v_cycle_tensor**2))\n",
        "                i_rms = torch.sqrt(torch.mean(i_cycle_tensor**2))\n",
        "                power = torch.mean(v_cycle_tensor * i_cycle_tensor)\n",
        "                pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "                fft = torch.fft.fft(v_cycle_tensor)\n",
        "                thd = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "                if len(fft) > 1:\n",
        "                    freq_resolution = (1.0 / (len(v_cycle) * dt))\n",
        "                    fundamental_freq_idx = int(inverter.ac_freq.item() / freq_resolution)\n",
        "                    if 0 < fundamental_freq_idx < len(fft) and torch.abs(fft[fundamental_freq_idx]).item() > 1e-9:\n",
        "                        fundamental_abs = torch.abs(fft[fundamental_freq_idx])\n",
        "                        harmonics_abs_sq = torch.sum(torch.abs(fft[1:int(len(fft)/2)])**2) - fundamental_abs**2\n",
        "                        thd = torch.sqrt(harmonics_abs_sq) / (fundamental_abs + 1e-6)\n",
        "                    else:\n",
        "                        thd = torch.tensor(1.0, device=device, dtype=torch.float32)\n",
        "\n",
        "                obs = torch.stack([v_rms, i_rms, power, pf, thd]).cpu().numpy()\n",
        "            else:\n",
        "                obs = np.zeros(5, dtype=np.float32)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Simulation finished in {end_time - start_time:.2f} seconds.\")\n",
        "    return time_hist, v_c_hist, i_l_hist\n",
        "\n",
        "def analyze_and_plot(results):\n",
        "    print(\"\\n--- Analyzing results and generating plots... ---\")\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(12, 6), dpi=150)\n",
        "\n",
        "    for name, data in results.items():\n",
        "        if data is not None and len(data) == 3:\n",
        "            time, v_c, _ = data\n",
        "            if len(time) > 1 and len(v_c) > 1:\n",
        "                dt = time[1] - time[0]\n",
        "                window_size = int(0.02 / dt) if dt > 0 else 0\n",
        "                if len(v_c) >= window_size and window_size > 0:\n",
        "                    rms_voltage = [np.sqrt(np.mean(v_c[i - window_size:i]**2)) for i in range(window_size, len(v_c))]\n",
        "                    ax.plot(time[window_size:], rms_voltage, label=name, linewidth=2.5)\n",
        "                else:\n",
        "                    print(f\"Warning: Not enough data ({len(v_c)} points) for RMS calculation for {name}. Required at least {window_size} points.\")\n",
        "            else:\n",
        "                print(f\"Warning: Insufficient data ({len(time)} time points, {len(v_c)} voltage points) for plotting RMS voltage for {name}. Skipping plot.\")\n",
        "        else:\n",
        "            print(f\"Warning: Invalid or missing data for {name}. Skipping plot.\")\n",
        "\n",
        "    ax.set_title('Dynamic Voltage Response to Load Step', fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel('Time (s)', fontsize=12)\n",
        "    ax.set_ylabel('RMS Voltage (V)', fontsize=12)\n",
        "    ax.axvspan(0.08, 0.16, color='gray', alpha=0.2, label='Heavy Load Applied')\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.grid(True, which='both', linestyle='--')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"final_comparison_results.png\")\n",
        "    print(\"\\n--- Plots generated and saved as 'final_comparison_results.png' ---\")\n",
        "    plt.show()\n",
        "\n",
        "# --- Part 6: Main Execution Block ---\n",
        "if __name__ == '__main__':\n",
        "    results = {}\n",
        "    rl_model_filename = \"ppo_inverter_final_model.zip\"\n",
        "\n",
        "    print(\"\\n--- Running SPWM Simulation ---\")\n",
        "    results[\"SPWM Controller\"] = run_simulation(controller_type=\"SPWM\")\n",
        "    if results[\"SPWM Controller\"] is not None:\n",
        "        print(f\"SPWM Simulation Data Lengths: time={len(results['SPWM Controller'][0])}, v_c={len(results['SPWM Controller'][1])}, i_l={len(results['SPWM Controller'][2])}\")\n",
        "    else:\n",
        "        print(\"SPWM Simulation Failed.\")\n",
        "\n",
        "    print(\"\\n--- Running PI Simulation ---\")\n",
        "    results[\"PI Controller\"] = run_simulation(controller_type=\"PI\")\n",
        "    if results[\"PI Controller\"] is not None:\n",
        "        print(f\"PI Simulation Data Lengths: time={len(results['PI Controller'][0])}, v_c={len(results['PI Controller'][1])}, i_l={len(results['PI Controller'][2])}\")\n",
        "    else:\n",
        "        print(\"PI Simulation Failed.\")\n",
        "\n",
        "    print(\"\\n--- Running RL Simulation ---\")\n",
        "    results[\"RL Controller (Proposed)\"] = run_simulation(controller_type=\"RL\", model_path=rl_model_filename)\n",
        "    if results[\"RL Controller (Proposed)\"] is not None:\n",
        "        print(f\"RL Simulation Data Lengths: time={len(results['RL Controller (Proposed)'][0])}, v_c={len(results['RL Controller (Proposed)'][1])}, i_l={len(results['RL Controller (Proposed)'][2])}\")\n",
        "    else:\n",
        "        print(\"RL Simulation Failed.\")\n",
        "\n",
        "    if all(res is not None and len(res[0]) > 1 for res in results.values()):\n",
        "        analyze_and_plot(results)\n",
        "    else:\n",
        "        print(\"\\n--- Skipping analysis due to simulation failures or insufficient data. ---\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "authorship_tag": "ABX9TyMqQIdoju1SJp7/ajp4fvs9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}