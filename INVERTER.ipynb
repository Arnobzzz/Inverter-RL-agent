{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arnobzzz/Inverter-RL-agent/blob/main/INVERTER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTU5Y6SQDg2c"
      },
      "source": [
        "\n",
        "\n",
        "# **Basic Circuit**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7oUMWwqAKxK",
        "outputId": "c58acc79-cfad-4f51-af5e-0bd8b6cd9b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting schemdraw\n",
            "  Downloading schemdraw-0.21-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading schemdraw-0.21-py3-none-any.whl (136 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/136.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m133.1/136.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.9/136.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: schemdraw\n",
            "Successfully installed schemdraw-0.21\n"
          ]
        }
      ],
      "source": [
        "!pip install schemdraw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "Og5_e3XBAB5I",
        "outputId": "eb075ffd-b2ea-480f-dad3-f73ac6bdce96"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABCcAAAFYCAYAAABgeZYXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVsVJREFUeJzt3Xt8z/X///H7e+fNZkI5bBo5rhDmkKg5RaOmj0jpo/mQY+FTIvrmFCUVpXJIydKBoj5RKBJCOY0c+phTE8Ycm9jMbO/n7w+/vT57t41tNi+b2/Vy2cX7/Xw/X6/X4/32Nnvf9zw4jDFGAAAAAAAANnGzuwAAAAAAAHBjI5wAAAAAAAC2IpwAAAAAAAC2IpwAAAAAAAC2IpwAAAAAAOAGN3/+fDVu3FgLFiyw5foOdusAAAAAAODGFhoaqtjYWNWqVUu7du265tdn5AQAAAAAADe4s2fPuvx5rRFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWxFOAAAAAAAAWzmMMcbuIgAAAAAAQOFLTEzUli1bFBMTo5iYGO3evVvJycnav3+/0tPT5eHhoQYNGqhu3boKCwtTWFiY6tSpIx8fn0Kti3ACAAAAAIBi7NChQ5o5c6bmzZunffv25fl4Dw8P1a9fXz179tTjjz+ugICAAq+RcAIAAAAAgGLG6XRqxYoVmjZtmhYtWiSn05ltPw8PD/n7++vs2bNKT0+Xm5ubjDHKKSoICAjQE088of79++uOO+4osHoJJwAAAAAAKEbWr1+vJ598Ur/99ptLu7u7uxo1aqSwsDA1bNhQYWFhCg0NlYeHhxYsWKDXX39dQ4cOVUREhLZt26aYmBht3rxZmzZt0q5du7JcJzIyUtOmTVNQUNBV10w4AQAAAABAMXD+/HmNGjVKkydPdhkpUbFiRfXp00dPPvlkvoOErVu3avr06fr000+VnJxstQcGBmrKlCl64okn5HA48l074QQAAAAAAEXc+vXr1aNHD+3evdtqCwsL04gRIxQZGSlPT88CuU5iYqLmzJmjCRMmKCEhwWrv0KGD3nvvvXyHH4QTAAAAAAAUYdHR0erVq5c1WsLLy0tjx47Vc889Jw8Pj0K55unTpzV48GB98sknVlvZsmX1/fffq0GDBnk+H+EEAAAAAABF1Ntvv63Bgwdb9xs1aqTZs2cX6GKVl7No0SL17dvXGkVRsmRJLV68WM2bN8/TeQgnAAAAAAAogqZPn64BAwZY959++mm9+eabhTZaIienTp1Sx44dtW7dOkmSv7+/fvzxRzVq1CjX5yCcAAAAAACgiJk3b566detmbfk5cuRIjR079qoWpbwaSUlJevjhh/X9999LkkqXLq21a9cqNDQ0V8cTTgAAAAAAUITExcWpTp06SkpKkiQNHz5cEyZMsLmqS7uFREREaPXq1ZKkevXqaePGjblajNOtsIsDAAAAAAAFw+l0qmfPnlYwERUVpVdeecXmqi7x9fXVokWLrPUufv3111zXxsgJAAAAAACKiGnTpumpp56SJN16663auXOnAgICbK7KVUxMjJo0aaL09HR5eHho8+bNuvPOOy97DCMnAAAAAAAoAuLi4jRs2DDr/qxZs667YEKSwsLCNGLECElSWlqaevTooYsXL172GMIJAAAAAACKgNGjR1vTOfr27as2bdrYXFHOXnzxRdWuXVvSpekdH3/88WX7M60DAAAAAIDr3MmTJxUUFKTU1FSVLl1aBw4cKNRRE8YYzZkzR9HR0Tp37pwefPBBPffcc/Lz88v1OdatW6fmzZtLkho2bKhNmzbl2JeREwAAAAAAXOc+/PBDpaamSpJ69uxZ6MHEv//9b/Xo0UOrVq3S5s2bNXr0aLVt21Z//fVXrs9z9913KywsTJK0efNmwgkAAAAAAIqq9PR0zZgxw7rfr1+/Qr3e+++/r7fffjtL+7p16/J0bYfDoQEDBlj3p02blnNfpnUAAAAAAHD9Wrp0qdq3by9Juv/++7V06dJCu1Z8fLxCQ0N19uxZSdLMmTN15513ql27dkpMTJQkffPNN3rggQdydb7k5GQFBQUpMTFRPj4+io+PV+nSpbP0Y+QEAAAAAMBFz5495XA4VKZMGV24cOGK/WNiYtSrVy9Vr15dJUqUkK+vr6pWraru3btr+fLleb7+f/7zH0VGRqpChQry8vLSzTffrDZt2ujDDz9Uenp6fp5SFi1atJDD4SiQc+XHmDFj5HA4tGrVqiv2XbZsmXW7d+/ehViVNG7cOCuY6Nmzp3r37q3GjRtrypQpVp/nn38+138Pfn5+6t69uyQpJSVFa9euzbYf4QQAAAAAwHL27Fl98cUXcjgcOn36tL7++usc+zqdTj377LNq2LCh5syZo9tuu039+vXT4MGDFRYWpsWLF6tt27YaN25crq6dlJSkjh07qlOnTlq7dq3atGmj5557Tg899JB27dqlXr16qXnz5jpx4kQBPduiISYmxrp97733Ftp1/vjjD3344YeSJH9/f7322mvWY927d1fTpk0lSf/97381f/78XJ/3nnvusW5nfi6ZeeSnYAAAAABA8fT5558rKSlJzz77rN566y3NmjVLXbt2zbbviy++qDfffFP16tXTggULVLVqVZfHz58/r3fffVenTp3K1bV79OihRYsWqUOHDvrkk09UqlQp67GUlBQNHDhQH3zwgR566CGtXr1aHh7F/yOt0+nU1q1bJUkhISEqW7ZsoV3rrbfe0sWLFyVJgwcPVpkyZazHHA6Hxo4dq7Zt20qSXnvtNXXt2jVXo08aNmxo3c4pnJABAAAAAOD/u+uuu4yHh4dJSEgwrVu3Nm5ububAgQNZ+u3du9e4u7ubMmXKmISEhMueMyUl5YrXXb58uZFkqlevbpKTk7Pt43Q6TfPmzY0kM2vWLKs9Li7OSDJRUVHZHifJhIeHu9zP7ivj+Mzn27lzp2nfvr0JDAw0JUqUMPfdd5/ZvHlzlmuEhISYkJCQbK8fHh5uMn/8zrj/96/sjt+1a5f1eKdOnbI9f0H466+/TMmSJY0k4+PjY06cOJGlj9PpNA0bNrTq+emnn3J1bqfTaW666SYjyZQvXz7bPkzrAAAAAABIujRcf/369Wrbtq3KlSunJ554Qk6nU7Nnz87SNzo6Wunp6erbt6/KlSt32fN6e3tf8doZ1xgyZIh8fX2z7eNwOPR///d/kmRNP8iP0aNHKyQkxLqd8fXQQw+59Pv999/VrFkznT9/Xv3791dkZKRWrlype++9Vxs2bMj39Xv06KHw8HBJUlRUlHX9f//731n6Zh5pkLEtZ2GYM2eOtU3oP//5z2xHaDgcDg0ePNi6/8477+Tq3A6Hw6o9ISFBR44cydKn+I+BAQAAAADkyqxZsyTJWsCwU6dOGjBggGbPnq1Ro0bJze1/v99et26dJKlVq1YFcu2ff/5ZktS6devL9gsPD5eHh4c2bdqk9PR0ubu75/laY8aM0apVq/THH39ozJgxOfZbs2aNhg8frgkTJlhtUVFRuv/++9W7d29t3749z9eWLoUTBw4c0OrVq9WjRw+1aNEix74JCQnW7erVq+freldijHHZqnTgwIE59u3SpYuGDBmi48eP6z//+Y+OHTt2xXBKulT7Dz/8IOnSc6pYsaLL44ycAAAAAADo4sWL+vjjj1WyZElrBIG/v7/+8Y9/6ODBg9YHywwZH5qDg4ML5PoZ56tUqdJl+/n6+qpMmTJKTU3N9VoW+VWqVClrpEaGdu3aqXXr1tqxY0fO6ycUoPPnz1u3cxpR8ndvv/227rrrLq1ZsyZX/X/55Rft3LlTktS0aVPVrVs3x77e3t7q2bOnJCktLS3bUTXZyVx75ueUgXACAAAAAKCFCxfqxIkT6tKli3x8fKz2J554QtL/RlXcSOrXry9/f/8s7Rm7T2QsVFmYUlNTrdteXl65Oubll1/Whg0bFBUVJafTecX+M2fOtG737dv3iv0zb2f666+/5qqmzLVntz0t4QQAAAAAwAofMsKIDK1bt1ZQUJAWLlyo06dPW+3ly5eXJMXHxxfI9TPOd+jQocv2O3/+vE6dOiUvLy+X3SQKQ07TFTLaz5w5U6jXl1w/1GcOKi6nXr16kqS4uLgsI17+7s8//9Tnn38u6dJIkS5dulzx/LfddpumTJmiJk2a6KmnnspVTZlrz24NEsIJAAAAALjBHTp0SMuWLZN0aU0Hh8Nhfbm7uys+Pl4XLlzQJ598Yh3TrFkzSdKKFSsKpIa77747V+dbvXq10tLS1KhRI2u9iYy1MNLS0rL0v5oA4dixY5dtDwwMtNrc3Nyyvf7V1nCl6RDZyTz6IfNaEtmZM2eOUlJSJF0Kpvz8/HJ1jUGDBmn9+vXWKJIrudL0FMIJAAAAALjBRUdHy+l0qnnz5urVq1eWr6ioKEmuUzt69Oghd3d3zZw5UydOnLjs+bMbxv93PXr0kCRNnjzZ+rD8d8YYa3HKjHUPpEu/8ZeyH8WR09SLjGAjPT09x5q2bt2qc+fOZWnPWMuhfv36VttNN92k48ePZwkokpKStHfv3nxdX/rfiBJJ2Z4nOw8++KAqVKgg6dJ0nT/++CPbfk6nU++++651v0+fPrk6f35krj3zc8pAOAEAAAAANzBjjGbPni2Hw6GPPvpIH3zwQZav6OhoNW3aVNu3b9fmzZslSdWqVdOwYcN08uRJRUREKC4uLsu5U1JSNHny5MvuiJHhvvvuU6dOnbRnzx498sgjWUYbXLhwQf3799dPP/2ku+++22X6ScmSJVWzZk2tXbtW+/bts9rPnj2rESNGZHu90qVLS7r8NJLExES9/PLLLm3ff/+9VqxYodq1a7ts7dmoUSNdvHhRn376qdVmjNGIESOUlJSUr+tLrtuH5nYBTk9PT/Xr10/SpQBi6tSp2fZbunSp9Xq1atVKd9xxR67On1fGGKv28uXLZ9mpQ5IcxhhTKFcHAAAAAFz3VqxYoTZt2ig8PFyrVq3Ksd/777+vPn36qF+/fpo+fbqkSx98n3vuOb355pvy9PRUq1atVLt2bXl6elrrHZw6dUrjx4/PsutFds6dO6euXbtqyZIlKl26tDp06KBKlSrpxIkTWrJkieLj49WkSRMtWrRIt9xyS7b1lS1bVl26dJHT6dTSpUvVqFEjffnll1me3/Tp0zVgwAA1aNBAERER8vHx0Z133qkHH3xQBw4cUJUqVXTPPfdo+/btatCgge666y4dOHBA8+fPl6enp1auXKkmTZpY59u5c6fCwsLkdDrVtWtX3XzzzVqzZo0SExPl7++vbdu2KfPH7//+97+qXbu2ypcvr8cff1yBgYEqVaqUnn76aZfn5XQ6FRgYqHPnzikkJEQHDhy44usoXZp6cuuttyo1NVUBAQE6cOCAFYhIlwKD5s2bW1u4Lly4UJGRkbk6d17FxcXptttukyR16NBB3377bdZOBgAAAABww3rssceMJDN79uzL9jtz5ozx9fU1gYGBJjk52eWxTZs2mZ49e5pq1aoZX19f4+3tbSpXrmy6detmli9fnqd6nE6nmT9/vunQoYMpV66c8fT0NGXKlDGtWrUyH3zwgbl48WKOx06dOtVUr17deHp6mltvvdWMGjXKpKamGkkmPDzcpe/FixfNsGHDzK233mo8PDyMJBMVFWWMMSYuLs66v3PnTtO+fXtTsmRJU6JECdOmTRuzefPmbK//448/miZNmhhvb29TpkwZ0717d3Ps2DETHh5usvv4HR0dberUqWO8vb2NJBMSEpLtee+55x4jyUgyJ06cyNXraIwxffv2tY574YUXXB77/vvvrcdCQ0NNWlpars+bV1988YV1rVGjRmXbh5ETAAAAAABkkjFyIioqStHR0XaXo2eeeUZvvfWWJOnLL79Up06dcnXcH3/8oerVq+vixYvy9vbWtm3bVLNmTaWkpKh+/fqKjY2VJM2bN09du3YtrPI1aNAgvfPOO5JyHqHBmhMAAAAAAFzH2rZta91+//33c31cSEiIBg4cKOnSmh2PPfaYDh8+rH79+lnBRKNGjdS5c+eCLTiT5ORkffzxx5IkHx8fNW/ePNt+hBMAAAAAAFzH2rZtqypVqkiSvvvuO+3fvz/Xx44bN05Vq1aVdGn3kUqVKumjjz6SdGnhzA8//NDaOaQwzJs3T4mJiZKkRx991GXdi8wIJwAAAAAAuI65u7tbu29I0owZM3J9rJ+fnxYtWpRl+04PDw998sknql27doHV+XfGGJedQgYMGJBjX9acAAAAAADgOnfy5EkFBwfrwoULKl26tA4cOKCAgIBcH3/w4EFNmDBBP//8s6pVq6ZnnnkmxykWBWXdunXWNRo2bKhNmzbl2JdwAgAAAACAIuCJJ56w1m/o27dvnkZQXGsXLlxQw4YNtXPnTknSrFmz1LNnzxz7E04AAAAAAFAExMXFqU6dOkpKSpIkLV++XG3atLG5quyNHDlS48ePlyTVq1dPGzdulKenZ479CScAAAAAACgipk2bpqeeekqSdOutt2rnzp15mt5xLcTExKhJkyZKT0+Xh4eHNm/erDvvvPOyx7AgJgAAAAAARUS/fv3UokULSZfWkRg4cKCupzEHf/31l6KiopSeni5JevHFF68YTEiMnAAAAAAAoEj5+/SO4cOHa8KECTZXJZ0/f14RERFavXq1pNxN58jAyAkAAAAAAIqQKlWq6IMPPpDD4ZAkvfrqqxo5cqStIyiSkpL00EMPWcFE6dKl9dlnn+UqmJAIJwAAAAAAKHIeffRRTZ061bo/fvx4DRo0SGlpade8llOnTqlt27ZatmyZJMnf31/fffedQkNDc30OwgkAAAAAAIqg/v37a8qUKdb9d999V3fffbd+++23a1bDokWLVLt2bf3888+SpJIlS2rp0qVq1KhRns5DOAEAAAAAQBE1aNAgRUdHy83t0sf7TZs2qUGDBpowYUKhjqI4ffq0unfvro4dOyohIUGSdPPNN2vVqlVq3rx5ns9HOAEAAAAAQBEWFRWldevWqWbNmpKk1NRUvfDCC2rSpIkWLFigixcvFti1EhMTNWXKFN1xxx365JNPrPYOHTpo69atql+/fr7Oy24dAAAAAAAUA+fPn9fo0aM1adIkOZ1Oq71ChQrq06ePevfuraCgoHyde+vWrZo2bZo+++wzJScnW+2BgYGaMmWKnnjiCWuBzvwgnAAAAAAAoBhZv369evfurZ07d7q0u7u7q2HDhgoLC7P+vP322+Xh4eHSLykpSb/++qtiYmK0efNmbd68Wbt27cpyncjISE2bNi3fgUdmhBMAAAAAABQzxhitWLFC06ZN08KFC11GUmTm4eGhEiVKyMfHR06nUykpKTp37lyO25IGBAQoKipK/fv31+23315g9RJOAAAAAABQjB06dEjvv/++5s2bp7179+b5eA8PDzVo0EA9e/bU448/Ln9//wKvkXACAAAAAIAbRGJiorZu3aqYmBjFxMRo9+7dSk5O1v79+5WWliYvLy/Vr19fdevWVVhYmMLCwlSnTh15e3sXal2EEwAAAAAA3OCCg4MVHx+voKAgHT58+Jpfn61EAQAAAACArQgnAAAAAACArQgnAMBmLVq0uKo9oa/E4XCoRYsWhXZ+AAAA4GoRTgBANpKSkvTKK6+oQYMG8vf3l7e3t4KDg3XPPfdoxIgR2r9/f6FePzo6Wg6HQ9HR0YV6HQAAAOB64GF3AQBwvTl79qyaN2+u7du3q1q1avrnP/+pMmXK6OTJk9q4caNeffVVVa1aVVWrVi2Q682ZM0fJyckFci4AAACgKCKcAIC/eeutt7R9+3Y9+eSTmjlzZpYpF3Fxcbpw4UKBXe/WW28tsHMBAAAARRHTOgDgb3755RdJ0lNPPZXtWhBVqlRRrVq1JEn/+Mc/5ObmphMnTrj0qVevnhwOh1588UWX9ozpGh999JHV9vc1J3r06KF//etfkqR//etfcjgc1ldmZ8+e1dixY1W3bl35+fkpMDBQ9evX18iRI3Xx4sUsdR87dkxRUVEqW7asfH19ddddd2nVqlV5eGUAAACAwsHICQD4mzJlykiS9uzZo3r16l22b8uWLfX1119r1apV6tKliyTp1KlT2r59uyRp5cqVLv0z7rds2TLHcz700ENKTEzUwoUL1bFjx2xrOH78uMLDwxUbG6t69eqpf//+cjqdio2N1cSJEzVkyBCVKlXK6p+YmKjmzZsrMDBQ3bt31/Hjx/X555+rXbt2iomJUe3ata/0sgAAAACFhnACAP6mS5cu+uSTT/Tkk09q48aNatu2rcLCwqzQIrOMkGHlypVWOLF69WoZY9S6dWv99NNPSkpKUokSJax+t91222WncmQOJx566CH16NEjS58BAwYoNjZWL7zwgl5++WWXx44dOyZ/f3+Xtm3btmnAgAF655135OZ2adBcq1at9OSTT+rdd9/VjBkzcv8CAQAAAAWMaR0A8DeRkZGaNGmSjDGaNGmS2rVrp7Jly6patWp6+umntXfvXqtv7dq1VbZsWf34449W28qVK+Xv769hw4bp4sWLWrNmjSRp//79OnTo0FVv65mQkKCvvvpKVatW1ZgxY7I8Xq5cOXl4uGbPJUqU0MSJE61gQpKioqLk4eGhTZs2XVU9AAAAwNUinACAbDz77LM6cuSIvvjiC/373/9W8+bNdfDgQU2dOlV169bVokWLJEkOh0MtWrTQ7t27dfToUUmXwol77rlH9957r7y9va2pHLmZ0pEbmzdvljFGLVu2lKenZ66OqVGjRpbRFB4eHipXrpwSExOvqh4AAADgahFOAEAOAgIC1KVLF7355ptas2aNTpw4oQEDBiglJUW9evVSamqqJNepHSdOnNBvv/2mVq1aycfHR02bNi3wcOLMmTOSpKCgoFwfU7JkyWzbPTw8lJ6eflX1AAAAAFeLcAIAcikwMFDvvvuuQkJCdPLkSe3YsUOSaziRsftFRlvLli21ZcsWnTlzRqtWrVL16tXzFCpkJ2Ohy/j4+Ks6DwBkWLVqlRwOR7ZTxQrK33cmAgpSjx495HA4dODAAbtLAZBPhBMAkAcOh8Na3DJDaGioypcvrx9//FErV67UTTfdpPr160u6tOhkenq6PvjgAx05ciTX6024u7tLUrajGho2bCg3NzetXLky2y1DAdy4Dhw44LL9sMPhkJ+fnypWrKjWrVtr1KhR2r9/v91l4hqLiYlRr169VL16dZUoUUK+vr6qWrWqunfvruXLl9tdXqG5FqEbgIJDOAEAf/Pee+/luEjk119/rV27dqlUqVIu22+2aNFCv//+uxYsWKDw8HBr4cnGjRvLz89PEydOlJT7KR2lS5eWJB06dCjLY+XKldPDDz+s/fv3a+zYsVkeP378uNLS0nJ1HQDFU9WqVTV69GiNHj1agwcPVkREhI4fP65x48apZs2aeuGFF2SMsfo3btxYu3bt0tNPP21j1ShoTqdTzz77rBo2bKg5c+botttuU79+/TR48GCFhYVp8eLFatu2rcaNG2d3qVdtwoQJ2rVr11WPTgRgH7YSBYC/Wbp0qfr166dq1aqpWbNmqlixopKSkrR161atWbNGbm5umjZtmry9va1jWrZsqXnz5unEiRMuAYSXl5eaNWtm/WYqtyMnmjZtKl9fX7311lv6888/dfPNN0uSXnzxRUnStGnTtHPnTr388stasmSJWrVqJWOM9uzZo2XLlunYsWPW9A8AN55q1apl+9vitWvXqnv37powYYLc3d2tD6V+fn6qVavWNa4She3FF1/Um2++qXr16mnBggWqWrWqy+Pnz5/Xu+++q1OnTtlUYcGpUKGCKlSoYHcZAK6GAQC4iI2NNa+99pq57777TJUqVYyPj4/x8fExVatWNVFRUWbz5s1ZjtmzZ4+RZCSZHTt2uDz2yiuvGEmmZs2a2V4vPDzcZPftePHixaZRo0bG19fXOndmZ86cMSNHjjS1atUy3t7eJjAw0NSrV8+MGjXKpKamWv0kmfDw8GyvHRISYkJCQq7wigAoKuLi4owk065duxz7xMbGGm9vb+Pl5WUOHjxojDFm5cqVRpIZPXp0lv47duwwXbp0MTfffLPx8vIylStXNoMHDzYnT57M9vxr1qwx9957r/Hz8zOlS5c2jzzyiDl48GCO3+ucTqeZNWuWufvuu01AQIDx9fU1YWFhZtasWfl7EWCMMWbv3r3G3d3dlClTxiQkJFy2b0pKijHGmN27d5uhQ4ea+vXrm9KlSxtvb29TvXp18/zzz5uzZ89mOS7j7/T8+fPm+eefN5UqVTLe3t6mVq1a5u233zZOp9Olf2Jionn11VfNvffeaypUqGA8PT1NhQoVTPfu3c2+ffuyrc3pdJoPP/zQNG/e3AQGBhpfX19TrVo106dPH/PHH39Y/aKioowkExcXZ4wxZvTo0db/nX//yuhjjDEnTpwwgwcPNpUrVzZeXl7m5ptvNl26dMnyf3nma+zfv9+88cYbJjQ01Hh5eZmoqKjLvr5AUREUFGQkmaCgIFuuz8gJAPibmjVraujQoRo6dGiuj6levbrLEOnMRowYoREjRuR4bMYimn/Xvn17tW/fPsfjSpYsqZdeekkvvfTSZWvLqS5JLBwG3IBq1qypRx55RB9//LG+/vprDRw4MMe+a9euVbt27ZSamqrOnTurcuXK+uWXXzRlyhR9++23Wr9+vcqWLWv1X7FihSIiIuTm5qauXbuqYsWKWrFihZo1a6abbropy/mNMXr88cc1d+5cVa9eXd26dZOXl5eWL1+uXr166b///a/eeOONQnkdirvo6Gilp6erb9++Kleu3GX7ZowE/OqrrzRr1iy1bNlSLVq0kNPp1Pr16zVx4kStXr1aP/30U7ZbWD/yyCPaunWrHn74YUnSl19+qUGDBunAgQOaNGmS1W/Xrl0aNWqUWrZsqX/84x8qUaKEYmNj9dlnn2nx4sXasmWLQkJCrP5Op1Ndu3bVggULFBQUpMcee0wlS5bUgQMH9MUXXygiIkK33nprts+pRYsWOnDggD766COFh4e7jFzMGFl44sQJNW3aVPv371eLFi306KOPKi4uTgsWLNDixYv1/fffq3nz5lnOPXDgQK1fv14dOnTQgw8+qFtuueWyry+AXLIlEgEAAECBy83ICWOMmTVrlpFkunfvbozJfuREenq6qVq1qpFkvvvuO5fjhw4daiSZnj17uvS/7bbbjMPhMGvWrLHanU6n6datW7YjwGbOnGkkmX/9618uI74uXLhgHnzwQSMp29FquLIWLVoYSeaHH37I9TGHDx82Fy5cyNI+duxYI8l88sknLu0ZIydq1qxpEhMTrfbExERTs2ZN43A4zKZNm1zaT506leX8P/74o3FzczNPPvmkS/s777xjJJnWrVub5ORkl8eSk5NdzvX3kRPGXH5EkDHG/Otf/zKSzIgRI1zaFy9ebCSZatWqmfT09CzXCA4Odhm1ARQXdo+cYEFMAACAG0zFihUlSSdPnsyxz7p167R//35FRESoXbt2Lo+NGjVKpUuX1meffabU1FRJl0ZZ/P7773rggQdcftvscDj0yiuvWLsQZfbuu++qRIkSmjp1qstv5L28vPTyyy9LkubOnZv/J3oDS0hIkCQFBwfn+pigoCB5eXllac9YKPWHH37I9riRI0cqMDDQuh8YGKgXX3xRxhh99NFHLu0ZCz5n1rJlS91xxx1Zzj9t2jS5u7tr+vTp8vX1dXnM19c323PlVmpqqubOnasyZcpY6zllaN++ve677z7t27dP69aty3Ls0KFDcxyxASD/mNYBAACALLZu3Sop+4V8/f391bBhQy1btky7d+9WnTp1tG3bNknSPffck6V/SEiIKlWq5DKVLDk5WTt27FDFihWtHY0yy9gqOTY2tgCeDXLDGKPZs2crOjpaO3fu1JkzZ+R0Oq3Hjxw5ku1x2f2dZ7RlvI8yrFq1Sm+99ZY2bNigkydPuuwulTkYOXfunHbt2qVq1aqpevXqV/W8shMbG6uUlBS1bNlSfn5+WR5v2bKlli9frl9//TXL82vcuHGB1wOAcAIAAOCGk/EhM2MnoOz89ddfkpTjegUZOyNk9Dtz5owk5Tj/vly5ci7hxJ9//iljjOLj47PdFjlDUlJSjo8hZ+XLl1dsbKzi4+NVs2bNXB0zaNAgvfvuu6pUqZIiIyNVoUIFaz2KsWPH6sKFC9kel917JKMt430hSfPnz1fXrl3l7++vdu3aqXLlyvLz85PD4VB0dLT++OMPq2/GcYW1NWhe39+ZXWkNDwD5QzgBAABwg8lYiLdRo0Y59ilZsqQk6dixY9k+njFtIKNfxrD+48ePZ9v/7+fJOC4sLEybN2/OZeXIrWbNmmnVqlVasWKFWrVqdcX+x48f19SpU1W3bl398ssvLqMJEhISLhsgHTt2LMs0h4y/78zTPcaMGSMfHx/FxMRkGQ0xb948l/sZx8XHx1+x9vzI6/s7M4fDUSg1ATc61pwAgCLO6XRqzZo12r17t92lACgC9uzZoy+++ELe3t76xz/+kWO/+vXrS8p+R6GkpCRt3rxZvr6+1m/l77zzTknSmjVrsvT/448/dOjQIZe2gIAAhYaGateuXUpMTMzns0FOevToIXd3d82cOVMnTpy4bN8LFy7o999/lzFGbdq0yTLNIbu/0ys9ntGW8T6SpP379ys0NDRLMHH06FH9/vvvLm3+/v66/fbbFRcXp7179172+jnJWOckPT09y2O1atWSj4+PNm3apOTk5CyPZ7zv69Wrl69rA8g7wgkAKMJ27NihZs2a6d5771W9evVy/I0lAEiXFrls166dLly4oOHDh192yHyzZs1UtWpVLV26NMtChePHj9epU6f02GOPWesENG/eXFWqVNG3336rtWvXWn2NMXrhhRey/YA4aNAgJScnq3fv3tlO34iLi2PL43yqVq2ahg0bppMnTyoiIkJxcXFZ+qSkpGjy5MkaM2aMtYXnzz//7LLOxOHDhy+7HbYkjRs3zmX6xpkzZzR+/Hg5HA5FRUVZ7SEhIdq3b5/LaIWUlBT179/fWmMks6eeekrp6ekaMGCAzp8/n6X206dPX7aujAUz/x6MSZfWt3jsscd08uRJTZgwweWx7777Tt9//72qVaumZs2aXfYaAAoO0zoAoAhKTk7WSy+9pEmTJlmLibm7u7ssLAbgxrVv3z6NGTNG0qVdCY4fP66NGzdqx44dcnd314svvqjRo0df9hxubm6Kjo5Wu3bt1L59e3Xp0kUhISH65ZdftGrVKlWtWlWvvvqqS/+ZM2eqffv2atOmjbp27aqKFSvqxx9/1NGjR1W3bl1t377d5Rp9+/bV+vXr9dFHH2ndunVq06aNKlasqGPHjik2NlYbNmzQZ599psqVKxf0S3RDGD9+vFJSUvTmm2+qZs2aatWqlWrXri1PT0/FxcXphx9+0KlTpzR+/HhVqFBBDz/8sL788ks1bNhQrVu31rFjx/Ttt9+qdevW2r9/f47XqVGjhmrXrq2HH35YkvTll1/q8OHDevbZZ9WwYUOr38CBAzVw4EDVr19fnTt3VlpampYvXy5jjO68805rUdUM/fv31+rVq/XFF1+oevXqioyMVMmSJXXw4EF9//33mjVrlh566KEc66pVq5YqVqyoefPmydvbW8HBwXI4HBo4cKACAwM1ceJErV69WuPHj9fPP/+sJk2a6MCBA5o/f778/Pw0e/Zsubnxu1zgmrFlA1MAQL4tWbLEVK5c2UiyvmrUqGF++uknu0sDYLO4uDiX7w2SjK+vr6lQoYJp2bKlGTlypNm3b1+W41auXGkkmdGjR2d5bPv27aZz586mbNmyxtPT04SEhJjBgwebEydOZFvDTz/9ZO69917j6+trSpcubbp06WL++OMPEx4ebnL60fPzzz83bdq0MTfddJPx9PQ0QUFBpkWLFmbSpEk5Xge5t2nTJtOzZ09TrVo14+vra7y9vU3lypVNt27dzPLly61+Z8+eNUOGDDGVK1c23t7epnr16mbcuHEmNTXVSDLh4eEu5834Oz1//rwZNmyYqVSpkvHy8jI1a9Y0b7/9tnE6nS79nU6nmTFjhrnjjjuMj4+PKV++vOnVq5c5fvx4ju8Pp9NpPvjgA3PXXXeZEiVKGD8/P1O9enXTr18/c/DgQatfVFSUkWTi4uJcjl+/fr0JDw83AQEB1r+JzH1OnDhhBg0aZEJCQoynp6cpW7as6dy5s9mxY0eWWnK6BlBcBAUFGUkmKCjIlus7jDHmmiciAIA8O3r0qJ555hl9/vnnVpuXl5deeOEFDR8+3FpRHQCAa6FFixZavXq1+DgBFA/BwcGKj49XUFCQDh8+fM2vz7QOALjOOZ1OzZw5U8OHD3eZ09uiRQvNmDEj11vEAQAAANcrwgkAuI7t2LFDffr00fr16622MmXKaNKkSXriiSfYzgwAAADFAiu8AMB1KDk5WcOHD1eDBg1cgokePXooNjZWUVFRBBMAAAAoNhg5AQDXmaVLl2rAgAEu2+fVqFFD7733nlq0aGFbXQAAZLZq1Sq7SwBQjDByAgCuE0ePHtWjjz6q9u3bW8GEl5eXxowZo+3btxNMAAAAoNhi5AQA2IwFLwFcT3bv3q2EhATdc889cnPj91gAgGuD/3EAwEY7duxQs2bN1L9/fyuYKFOmjKKjo/Xjjz8STAC4phISElS7dm21aNFCEREROnr0aL7PNX/+fDVu3FgLFiwowApRXOTm/cF7CLixOAwbEwPANZecnKyXXnpJkyZNUlpamtXeo0cPvf766ypbtqyN1QG4Uf3www+67777rPtly5bVhx9+qAcffDDP5woNDVVsbKxq1aqlXbt2FWSZKAZy8/7gPQRcW8HBwYqPj1dQUJAOHz58za/PyAkAuMaWLl2qO+64QxMnTrSCiRo1amjlypWaPXs2wQSA68bJkycVGRmpAQMGKDk5OU/Hnj171uVPILPcvD94DwE3FsIJALhGWPASQFESGBho3Z4+fboaNmyobdu22VgRAKA4I5wAgELmdDo1Y8YMhYaG6vPPP7faW7Rooe3bt2v06NHy9va2sUIAyOqpp57SjBkz5OvrK0natWuXGjdurDfffFNOp9Pm6gAAxQ3hBAAUIha8BFBUORwO9e3bVzExMapXr54kKTU1Vc8+++xVL5YJAMDfEU4AQB4lJiZqypQpuuuuu3TbbbepRo0auv/++7VgwQJdvHhR0qUFL4cPH64GDRpo/fr11rE9evRQbGysoqKi5HA4rnldAJBXoaGhWr9+vYYMGWK1LVu2THXr1tU333xjY2UAgOLEw+4CAKCoMMbo9ddf19ixY7MsDLd37159//33qlixot5880298MIL2r9/v/V4jRo19N577xXKuhK5rWv27Nlq27ZtgV8fQPHn7e2tN954Q+3atVNUVJSOHj1qLZbZv39/vfHGG/Lz87O7TABAEcbICQDIpWHDhun55593CQDKlCmjEiVKWPePHDmixx57zAomrsWCl7mtq0OHDlq4cGGh1ADgxnDfffdp+/btioyMtNpYLBMAUBAIJwAgF+bOnas33njDut+7d2/99ttvOnnypP766y8tX75cLVu2lHRpAUw3NzdFREQU+oKXeakrLS1Njz32mH7//fdCqQXAjaFs2bL6+uuvNX36dBbLBAAUGMIJALgCY4xLADB9+nTNnDlTt99+uyTJzc1Nbdq00fLly/Xoo49KuhRQ3H777YW64GV+6jp//rymTZtWaDUBuDE4HA7169ePxTIBAAWGcAIArmDjxo3asmWLJCksLEz9+vXLtp+7u7veeecda5TEhx9+qPPnz99wdQG4cVxuscyUlBQbKwMAFDUsiAmg0MTHxysqKkqxsbF2l3JVzp49a93u2bPnZfuWLVtWkZGRmj9/vv7880/997//VVhYWKHUtWbNmnzXFRISIi8vr0Kp61q5//779f777xf4ricA8ianxTIBAMgLwglYnn32WU2fPl1+fn7WHFLgapw7d05nzpyxu4wCddttt12xT5UqVazbmYONgnbu3Dnrdl7rOnHiRKHUdC3NmjVL3377rTw8+K8MBeP8+fM6d+6c/P39b9j/By9cuGDd3rVrV56Ove+++7RixQo1aNDAZdREfHy8goODC6zGoubUqVNKSUmRw+EgTM0kY22Sy70/4uPjrT/d3d2vWW1FQcbr5+PjozJlythcDYqLjCl5do2w5Sc6WKZPn66UlBSGYaJQeHp66pZbbrG7jHw5e/as/vrrL0nK1WKScXFx1u2AgIBCq8vf39+6nde6br755iI9cuL48eO6ePGijh07ZncpKIZOnz5tdwnXhfXr1+ep//Lly/XEE09k+3NExofMG5kxRsYYu8u4LuXm/cFCq9lLSUnh3xcK3N+3pr9WHIbvkvj/ypQpo9OnT8vNzU0VKlSwuxwUIwEBARo3bpw6d+5sdyn5smHDBt11112SLq3tsHnz5hz7njhxQsHBwUpNTdVNN92k+Pj4QvsN7PVa17WwYMECjRw5slBHpuDGw8iJSyMnMqZkdOrUSV9++WWujnnhhRc0efJkq61s2bIuUzuCgoIKvtgiIvMHRzc3lnvLkDlsyOn9wWuXs4zXz+FwqGLFijZXg+Li/PnzSk5O1oABAzRp0qRrfn1GTsCS8YNYhQoVdPjwYZurAa4fjRs3VoMGDbRlyxbFxMRo+vTp6t+/f5Z+6enpGjRokFJTUyVdWgeiMD/gXK91XQudO3cusmEXcD374YcfdN9990m6tNjllezatUvdunXTr7/+arW1a9dO0dHRatiwoeLj4xUUFHRD/1wRHBzM65CN3LwuvHY5y3htKlasyGuDYoMIEgCuwOFwaOjQodb9AQMGqE+fPvrtt98kXfrtxfLly3Xfffdp3rx5ki6FfQMGDLgh6wJQ/BljNH36dDVo0MAKJry8vPTmm29qyZIlKl++vL0FAgCKHEZOAEAuPProo4qJidEbb7whSXr//ff1/vvvq3Tp0rpw4YKSkpKsvh4eHpo7d26uFqksrnUBKL5OnjypXr16adGiRVbb7bffrs8++0x33nmnjZUBAIoyRk4AQC699tprmjhxovz8/Ky206dPuwQAFStW1OLFi9WxY8cbvi4Axc/y5ctVp04dl2BiwIAB2rx5M8EEAOCqEE4AQC45HA4NGzZM8fHxmjJliu666y5VqVJFNWrUULt27bRgwQIdOHBAbdu2pS4AxcqFCxc0ZMgQtW3bVgkJCZIuLXr5zTffaOrUqUV+HRsAgP2Y1gEAeVSqVCkNGjRIgwYNsrsUF9drXQCKtsstesnaEgCAgsLICQAAAGRhjNGMGTMUFhbGopcAgELHyAkAAABkMXXqVJ05c8a6z6KXAIDCxMgJAAAAZJE5mGDRSwBAYWPkBAAAALJVtmxZzZ49Ww888IDdpQAAijlGTgAAAECSVLt2bXl4XPrdVbt27bRjx458BxMBAQEufwKZ5eb9wXsIuLEQTgAAAECSVL58ee3cuVOrV6++6kUvx40bp8aNG2vcuHEFWCGKi9y8P3gPATcWhzHG2F0Erg/BwcGKj49XUFCQDh8+bHc5AAAARR4/X6Ew8L5CccTICQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCvCCQAAAAAAYCsPuwvAtZeYmKgtW7YoJiZGMTEx2r17t5KTk5WQkCBJOnbsmJo0aaK6desqLCxMYWFhqlOnjnx8fGyuHAAAAIAxRpJ08uRJzZ07Vw8//LC8vLxsrgq4Og6T8c5GsXbo0CHNnDlT8+bN0759+/J8vIeHh+rXr6+ePXvq8ccfV0BAQCFUCQAAULwEBwcrPj5eQUFBOnz4sN3loJioUKGC9YtFSbrlllv09ttvq2vXrjZWBVwdwolizOl0asWKFZo2bZoWLVokp9OZbT8PDw/5+/vr7NmzSk9Pl5ubm4wxyumtERAQoCeeeEL9+/fXHXfcUZhPAQAAoEgjnEBhuO222xQXF5elfcaMGerbt68NFQFXj3CimFq/fr2efPJJ/fbbby7t7u7uatSokcLCwtSwYUOFhYUpNDRUHh4eWrBggV5//XUNHTpUERER2rZtm2JiYrR582Zt2rRJu3btynKdyMhITZs2TUFBQdfqqQEAABQZhBMoDBk/t7dv316bNm3S4sWLJUlubm5asWKFWrRoYW+BQD4QThQz58+f16hRozR58mSXkRIVK1ZUnz599OSTT+Y7SNi6daumT5+uTz/9VMnJyVZ7YGCgpkyZoieeeEIOh+OqnwMAAEBxQTiBwmaM0XPPPafJkydLkiIiIrRkyRKbqwLyjnCiGFm/fr169Oih3bt3W21hYWEaMWKEIiMj5enpWSDXSUxM1Jw5czRhwgSXuW4dOnTQe++9xygKAACA/49wAtdCWlqaqlatqoMHD8rhcGjv3r2qWrWq3WUBecJWosVEdHS0mjVrZgUTXl5emjBhgtavX6+HH364wIIJSSpVqpQGDRqk3377Tf/85z+t9sWLF6tevXrasmVLgV0LAAAAwOV5eHiod+/eki6NpMiY5gEUJYQTxcDbb7+tf/3rX9Y0jkaNGmnLli0aPny4PDwKb7fY0qVL6+OPP9bChQtVvnx5SZe2M2rZsqXWrl1baNcFAAAA4KpBgwbW7T///NPGSoD8IZwo4qZPn67Bgwdb959++mn9/PPP+dpFY/78+WrcuLEWLFiQp+MiIyO1c+dONWvWTJL0119/KSIiQps2bcpzDQAAAADy7syZM9ZtHx8fGysB8odwogibN2+ennrqKev+yJEj9fbbb+d7tMSoUaO0adMmjRw5Ms/HlilTRt9//73atWsnSTp37pzuv//+bHf4AAAAAFCw5s+fb92uXr26jZUA+UM4UUTFxcXpySefVMZ6psOHD9dLL710VbtlnD171uXPvCpRooT+85//KDw8XJJ0+vRpdevWTRcvXsx3TQAAAAAub8eOHVq4cKEkqXz58nrwwQdtrgjIO8KJIsjpdKpnz55KSkqSJEVFRemVV16xuapLfH19tWjRImtaya+//nrd1AYAAAAUNxs3blRERIS1/lyfPn0KdDF84FohnCiCZsyYoVWrVkmSbr31Vr3zzjtXNWKioJUsWVIfffSR3N3dJUnjx4/Xtm3bbK4KAAAAKB6OHDmibt26qX79+mrSpIni4+MlXVoUc+jQoTZXB+QP4UQRExcXp2HDhln3Z82apYCAgDyfZ/78+QoNDVVwcLD1dfToUUnS0aNHXdpDQ0PzvEhmWFiYRowYIenSvss9evRgegcAAABQAPbt26e5c+fq119/tdrq16+vJUuWyN/f377CgKtAOFHEjB492prO0bdvX7Vp0yZf53n99dcVGxur+Ph46ytjKJjT6XRpj42N1euvv57na7z44ouqXbu2pEvTOz7++ON81QoAAADg8q6nkdRAfhBOFCEnT57U559/LkkqXbp0vgKDDMOGDVOtWrUUFBRkfbm5XXo7uLm5ubTXqlUrX8PDvL29NWPGDOv+9OnT810vAAAAgEuqVatmTevIsGXLFkVEROjcuXM2VgbkH+FEEfLhhx8qNTVVktSzZ898TefI0LlzZ+3atUuHDx+2vipUqCBJqlChgkv7rl271Llz53xd5+6771ZYWJgkafPmzdq0aVO+awYAAAAgVaxYUZ9++qm2bNmijRs3Kjg4WJK0devWq/oFJmAnwokiIj093WUUQr9+/WysJvccDocGDBhg3Z82bZqN1QAAAADFS6NGjbRkyRJrFPTMmTNZ6w1FEuFEEbFs2TLFxcVJku6//35VrVrV5opy79FHH1WpUqUkSfPmzdPp06ftLQgAAADFzqpVq+RwODRmzBi7S7nm6tSpo44dO0qSEhIS9M0339hcEZB3bpJ04MABORwOly8/Pz9VrFhRrVu31qhRo7R///4rnmzFihXq1q2bKleuLF9fX5UoUUKhoaHq27evNmzYkOuiDh48qAEDBqh69ery8fGRv7+/qlSpog4dOmjixInWgpA3kmXLllm3e/fuXSjXyJgmcjXTRbLj5+en7t27S5JSUlK0du3aAj0/AAAArn8Znznuv/9+u0spMA6HQy1atLC7DElSly5drNt79+61sRIgfzwy36latar++c9/SpIuXLig48ePa+PGjRo3bpxeeeUVDRs2TC+//HKWlWDPnz+vnj17at68efLz81ObNm1Uo0YNSdKePXv06aefaubMmZozZ471ITUn27ZtU4sWLZSYmKhmzZopIiJC/v7+OnjwoNasWaMlS5bo4YcfVrVq1QrydbjuxcTEWLfvvffeQrnGuHHj9PrrrxfK3sj33HOP3nnnHUmXnktkZGSBXwMAAAC4UQUGBlq3U1JSbKwEyB+XcKJatWrZDoNau3atunfvrgkTJsjd3V3jxo1zebxXr16aN2+e7rvvPn388ccqV66cy+OJiYmaMGGCEhMTr1jQs88+q8TExByDjF9++UVly5bNxVMrPpxOp7Zu3SpJCgkJKbTn37lz53wvfHklDRs2tG5nDloAAAAAXL0tW7ZYt2+66SYbKwHyJ1drTjRv3lzfffedvL299dprr+nQoUPWYytXrtTcuXNVo0YNff3111mCCUkqVaqUJk6cqD59+lzxWr/88otKlSqV4wiLpk2bWusXZPbNN9+oZcuWCgwMlK+vr+68805NnjxZaWlpLv0uNxctY6hZjx49XNorV66sypUrKzExUU8//bQqVaokDw8PRUdHW322bdumxx9/XMHBwfL29laFChV0//33Zzvfa+HChWrdurVuuukm+fj4qHbt2nrjjTeUnp6e7XPes2ePtSVQxs4XRU3lypWtb5KEEwAAAJCkHj16yOFwKC4uTm+//bZq1aolb29vhYSEaOzYsXI6nVmOOX/+vIYPH65KlSpZP0u///772Z4/p5/vM+Q0LePs2bMaO3as6tatKz8/PwUGBqp+/foaOXKkLl68aH2mkKTVq1e7TI/P/BkhLS1NkydP1p133ilfX18FBgaqZcuW2X5GiI6Oto7/5ptv1KxZMwUEBKhy5cpXfB3T0tKs18DhcKhDhw5XPAa43nhcucslNWvW1COPPKKPP/5YX3/9tQYOHChJmjVrliTpueeek5+f32XP4e3tfcXrlClTRgkJCTpy5IgqVqyYq9omT56sIUOGqHTp0urWrZtKlCihRYsWaciQIVqzZo2++uqrLFNR8urChQtq1aqVzp07p8jISHl4eFhBzJdffqlu3brJGKMHH3xQNWvW1PHjx7VhwwbNmjVLDz74oHWeESNG6NVXX1VQUJA6deqkwMBArVmzRkOHDtWGDRs0f/78LNfO/GG+qIYTDodDYWFh+uGHH/L89wsAAIDibejQoVq9erUeeOABtWvXTl9//bXGjBmj1NRUvfzyy1Y/p9OpyMhI/fDDD6pTp466deumU6dO6ZlnnlHLli0LpJbjx48rPDxcsbGxqlevnvr37y+n06nY2FhNnDhRQ4YMUeXKlTV69GiNHTtWISEhLuFHvXr1JEnGGHXu3FkLFy5UjRo19NRTTykpKUmff/65IiMjNXnyZD3zzDNZrj9//nwtW7ZMDzzwgAYMGKC//vrrsvUaY/T888/r4MGDkore4vmAxRhj4uLijCTTrl07czmzZs0ykkz37t2ttsqVKxtJZt++fZc9NreeffZZI8lUqVLFTJw40fz8888mKSkpx/779u0zHh4e5pZbbjEHDx602lNSUkzz5s2NJDNnzhyrfeXKlUaSGT16dJZzZbwOUVFRLu0hISHW65OcnOzyWEJCgilRooQpUaKE2bJlS5ZzHjp0yLq9bNky6zznzp2z2p1Op+nXr5+RZBYsWJDlHG+88YaRZCSZL774IsfX4nrXv39/63nExMTYXQ4AAEChCwoKMpJMUFCQ3aXYLrvPHFFRUdbP/keOHLHaT5w4YUqVKmUCAgLMhQsXrPbZs2cbSeb+++83aWlpVvv27duNl5dXlp/zc/r5PoMkEx4e7tL28MMPG0nmhRdeyNI/ISHBXLx48bLHZ/joo4+sxzM/hz/++MOULVvWeHh4mP3792d5bm5ubmb58uXZnjMzp9NpVq5cadq3b2/9jO3m5mZWrVp1xWOB61GethLN+E33yZMnrbaEhARJUnBwcF5zkWy9/PLL6tGjh/744w89//zzuvvuu1WyZEmFhYVp/PjxWdat+Oyzz5SWlqYhQ4aoUqVKVru3t7cmTpwoSS5Dq67Ga6+9Jl9fX5e2jz76SElJSRoyZIjq16+f5ZjMr8u7774r6dLewyVKlLDaHQ6HXn31VTkcDs2dOzfLOc6fP2/d/vv1i5LMtWd+TgAAALixjRw5UhUqVLDuly1bVh07dtTZs2e1e/duq33OnDmSLn1mcHd3t9rr1KlzxYX3cyMhIUFfffWVqlatmu008HLlysnDI3eDzz/66CNJlz5DeHl5We233nqrnnnmGaWlpenTTz/NclzHjh3Vpk2by577l19+kbu7u1q2bKklS5ZY7dOmTVN4eHiu6gOuN7me1nGt+Pj4aPbs2Ro3bpyWLFmijRs3auPGjdqyZYu2bNmi9957T6tXr9Ztt90mSdZCkdnNFWvatKl8fHz066+/FkhdderUydK+ceNGSVLbtm2veI7169erRIkS+vDDD7N93NfXV7GxsVnaU1NTrduZv7EVNZlrv3Dhgo2VAAAA4HqS3dTljF/yZf7l5LZt21SiRAk1aNAgS/977rnHmnKeX5s3b5YxRi1btpSnp+dVnWvr1q3y8/NT48aNszyWMQUlu88p2fX/u4sXL8oYY913OBwaOHCg+vbtm/+CAZvlKZw4cuSIJOnmm2+22sqXL68DBw4oPj7eCgwKQnBwsPr06WMtorl//3717NlTP/30k5555hktXLhQkqw5WNktxOlwOFSuXDnFx8dfdT233HJLtutWnDlzRpIUFBR0xXOcPn1aaWlpGjt2bI59kpKSsrRl/lCfOagoajLXnpv1RwAAAHBjKFmyZJa2jBEKmReNP3PmjMto6cyy+zyQV3n52f5K/vrrrxxrzRglkt16Erl5Hp6ennI4HFZAYYzR22+/rdtvv52AAkVWnqZ1rFq1SpLUqFEjq61Zs2aSpBUrVhRcVdmoWrWqNT3jxx9/tNozvpEdO3YsyzHGGB07dszlm52b26Wn/PddPKT/fTPKTk4LambsHJKbAKRkyZIqU6aMjDE5fsXFxWU5rrhMhygu01MAAABgj8DAQJ04cSLbx7L7PJDXn/3z8rP9lZQsWVLHjx/P9rGMqfHZhTK5Wci/adOmSk9P16pVq1x25hgwYID1mQ0oanIdTuzZs0dffPGFvL299Y9//MNq79WrlyRp0qRJV/zgfLVD+f39/bO0ZazzkN0/wg0bNiglJcVaMVf6356/2X3DyZgikhcZw66WLVt2xb5NmjTRqVOntHfv3jxdo3z58tbtvB57Pclce+bnBAAAAOTGnXfeqaSkJG3ZsiXLY2vWrMnSdrmwIbuf/Rs2bCg3NzetXLlSFy9evGI9bm5uLiM7Mqtfv76Sk5OtaeCZZXx2yfw5Ja8cDofCw8P1zTff6Nlnn5V0aTeT1157Ld/nBOyUq3Bi3bp1ateunS5cuKDhw4e7DHNq2bKlHnvsMe3evVudOnXKNh3866+/9MILL2jmzJlXvNZLL72kQ4cOZWk3xujVV1+VJDVv3txq79atmzw8PDR58mRr2ol0aQrB888/L0kuW/vUrFlTAQEBWrRokU6fPm21Hzt2TOPHj79ifX8XFRUlf39/TZo0Kds5Y5m/EQ4aNEiS1LNnT506dSpL34SEBO3atStLe+Y5eJm3FS1KjDFW7eXLl2cbUQAAAORZxqKX//d//+cSCuzYsUMff/xxlv4lS5ZUzZo1tXbtWu3bt89qP3v2rEaMGJGlf7ly5fTwww9r//792U7FPn78uMsojNKlS+vw4cPZ1hoVFSVJGjFihEvQcejQIU2ePFkeHh56/PHHr/SUr8jhcGjixIm69dZbJUnfffed9u/ff9XnBa41lzUn9u3bZ61Km5qaquPHj2vjxo3asWOH3N3d9eKLL2r06NFZTjJr1iwZYzRv3jxVqVJFbdu2VY0aNWSM0d69e7VixQqdPXs2228Yfzd58mSNGTNGDRs2VFhYmEqXLq1Tp05p5cqV2rNnj8qUKaNJkyZZ/atWrWrtN1y3bl098sgjKlGihL755hvt3r1bHTt21D//+U+rv5eXlwYOHKhXXnlFDRo0sFYB/uabbxQeHp7nf8i33HKL5syZo0cffVSNGzdWZGSkatasqZMnT2rDhg2qXLmyvv76a0mX9hweOXKkxo0bp2rVqun+++9XSEiITp06pX379mnNmjUaP368QkNDXa5Ro0YN+fv769y5c0U2nDhw4ID+/PNPSdkveAQAAABcSVRUlD777DN99913ql+/viIiInT69GnNnTtXbdu21bfffpvlmCFDhqhPnz5q2rSpunTpIqfTqaVLl7pMVc9s2rRp2rlzp15++WUtWbJErVq1kjFGe/bs0bJly3Ts2DFrREarVq30xRdf6KGHHlL9+vXl7u6uyMhI1a1bV927d9dXX32lhQsXqm7dunrggQeUlJSkzz//XKdPn9akSZMKbM0+Dw8P9e7dWyNHjpQxRosXL7Z+MQoUGcb8b//fzF++vr6mQoUKpmXLlmbkyJFm3759V9yXdPny5eaxxx4zISEhxsfHx/j4+Jjq1aubJ5980mzYsCFXe5v+9NNPZvjw4aZp06amYsWKxtPT0/j7+5u6deua5557zmX/48wWLlxowsPDTUBAgPH29jZ16tQxkyZNctmHOEN6eroZM2aMqVSpkvHy8jI1atQwU6ZMMb///nu2+yCHhISYkJCQy9a9detW88gjj5hy5coZT09PU6FCBRMREWG+/fbbbF+nBx980Nx8883G09PTlC9f3jRt2tSMGzfOHDx4MNvz33PPPdbfzYkTJy5by/Xoiy++sOofNWqU3eUAAABcE0FBQUaSCQoKsrsU22V85mjXrp3VFhUVZSSZuLi4LP1Hjx5tJJmVK1e6tCclJZlhw4aZoKAg4+3tbW6//XYzc+ZMs3LlSiPJjB49Osu5pk6daqpXr248PT3NrbfeakaNGmVSU1ONJBMeHp6l/5kzZ8zIkSNNrVq1jLe3twkMDDT16tWzjstw9OhR88gjj5iyZcsaNzc3I8nMnj3bevzixYvmjTfeMHXq1DHe3t4mICDAhIeHm4ULF2a55uzZs7McnxeLFy+2ft4eM2ZMvs4B2MlhTKY9aHDdeuaZZ/TWW29Jkr788kt16tTJ3oLyaNCgQXrnnXckSQsXLlRkZKTNFQEAABS+4OBgxcfHKygoKMfh/0BBmDt3rrp16yZJevXVV60p7kBRkafdOmCftm3bWrfff/99GyvJu+TkZGtKj4+Pj8uaIQAAAACu3vz5863b1atXt7ESIH8IJ4qItm3bqkqVKpKK3iI38+bNU2JioiTp0UcfVenSpe0tCAAAAChGduzYoYULF0q6tPj8gw8+aHNFQN4RThQR7u7u6tevn3V/xowZNlaTe8YYTZ061bo/YMAAG6sBAAAAipeNGzcqIiJCTqdTktSnTx95enraXBWQd6w5UYScPHlSwcHBunDhgkqXLq0DBw4oICDA7rIua926ddY0joYNG2rTpk02VwQAAHDtsOYECsORI0f03HPPadeuXfr111+t9gYNGmj16tXy9/e3rzggnxg5UYSULVtWjzzyiCTp9OnTGjp0aL7PNX/+fIWGhio4OPiKX6GhoVqwYEGer3HhwgWX0R79+/fPd70AAAAALtm3b5/mzp3rEkzUr19fS5YsIZhAkeVhdwHIm7Fjx+qrr75SUlKS3nvvPXXu3Flt2rTJ83lef/11xcbG5ql/586d83SN8ePHa+fOnZKkevXqqXv37nk6HgAAAEDuOBwOu0sArgojJ4qYKlWq6LXXXrPu9+rVS2fPns3zeYYNG6ZatWopKCjoil+1atXK8yiNmJgYTZgwQZLk4eGh6Oho5r4BAAAABaBatWrq1q2b6tevb7Vt2bJFEREROnfunI2VAfnHmhNFkNPpVOvWrbVq1SpJUlRUlGbPnn3dpKV//fWX7r77bv3222+SpDFjxmj06NE2VwUAAHDtseYECtumTZvUqVMn6/01atQojR071uaqgLwjnCii4uLiVKdOHSUlJUmShg8fbo1UsNP58+cVERGh1atXS7o0nWPjxo2MmgAAADckwglcCzt27FC9evXkdDpVvnx5HTx4kJ+/UeQwraOIqlKlij744ANrtMSrr76qkSNHys6sKSkpSQ899JAVTJQuXVqfffYZ3xgBAACAQlSnTh117NhRkpSQkKBvvvnG5oqAvCOcKMIeffRRTZ061bo/fvx4DRo0SGlpade8llOnTqlt27ZatmyZJMnf31/fffedQkNDr3ktAAAAwI2mS5cu1u29e/faWAmQP4QTRVz//v01ZcoU6/67777rst7DtbBo0SLVrl1bP//8sySpZMmSWrp0qRo1anTNagAAAABuZIGBgdbtlJQUGysB8odwohgYNGiQoqOj5eZ26a9z06ZNatCggSZMmFCooyhOnz6t7t27q2PHjkpISJAk3XzzzVq1apWaN29eaNcFAAAA4GrLli3W7ZtuusnGSoD8IZwoJqKiorRu3TrVrFlTkpSamqoXXnhBTZo00YIFC3Tx4sUCu1ZiYqKmTJmiO+64Q5988onV3qFDB23dutVlSyMAAAAAhSstLU3vv/++JMnhcKhDhw42VwTkHeFEMXLXXXdp69atGjp0qDWKYsuWLerSpYtCQkI0ZswYxcfH5/v8W7duVe/evRUUFKR///vf1miJwMBARUdH65tvvlFQUFCBPBcAAAAAV2aM0fPPP6+DBw9Kku6//35VrVrV5qqAvGMr0WJq/fr16t27t3bu3OnS7u7uroYNGyosLMz68/bbb5eHh4dLv6SkJP3666+KiYnR5s2btXnzZu3atSvLdSIjIzVt2jRCCQAAgGywlSgKizFGq1ev1uuvv64lS5ZIktzc3PTjjz8qPDzc5uqAvCOcKMaMMVqxYoWmTZumhQsXyul0ZtvPw8NDJUqUkI+Pj5xOp1JSUnTu3LkctyUNCAhQVFSU+vfvr9tvv70wnwIAAECRRjiBwrBz5041bdpU586dc2mfMWOG+vbta1NVwNXxuHIXFFUOh0Nt2rRRmzZtdOjQIb3//vuaN29elq2F0tLSdObMGZ05cybHc3l4eKhBgwbq2bOnHn/8cfn7+xd2+QAAAACysXr1apdg4pZbbtHbb7+trl272lgVcHUYOXEDSkxM1NatWxUTE6OYmBjt3r1bycnJ2r9/v9LS0uTl5aX69eurbt26CgsLU1hYmOrUqSNvb2+7SwcAAChSGDmBwlCzZk3t2bNHfn5+mjVrljp16iQvLy+7ywKuCuEELPznCQAAULD4+QqFgfcViiN26wAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALYinAAAAAAAALbysLsAAAAAoLg6c+aMJOnIkSMKDg62uRoUF0ePHpUknT9/3uZKgIJDOAFLQECAy58AAAC4OklJSZIkY4zi4+NtrgbFTXJyst0lAAWGcAKWcePG6fXXX9fQoUPtLgUAAKBYKFGihM6dOyeHw6GKFSvaXQ6KifPnzys5OVkDBgywuxSgwDiMMcbuIgAAAIDiKDg4WPHx8QoKCtLhw4ftLgcArlssiAkAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGxFOAEAAAAAAGzlMMYYu4sAAAAArnddu3bVF198ke/jg4KCctUvICBA48aNU+fOnfN9LQAoaggnAAAAgFxwOBzX7FqNGzfWhg0brtn1AMBuHnYXAAAAABQFXbt21eeff57v4/MycmLo0KH5vg4AFEWMnAAAAAAAALZiQUwAAAAAAGArwgkAAAAAAGAr1pwAAAAA8mH+/PkaNWqUzp49e9XnYocOADc61pwAAAAA8qFx48batGlTgZ6PHToA3KgYOQEAAADkw7BhwzRy5MgCGznBDh0AbmSMnAAAAAAAALZiQUwAAAAAAGArwgkAAAAAAGArwgkAAACgAM2fP1+hoaEKDg52+QoNDdWCBQvsLg8ArkusOQEAAAAUoMvt4sGOHACQPXbrAAAAAApQTrt4sCMHAOSMkRMAAAAAAMBWrDkBAAAAAABsRTgBAAAAAABsRTgBAAAAAABs9f8AAawb3aVpIwgAAAAASUVORK5CYII=\n",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"765.364375pt\" height=\"248.4pt\" viewBox=\"0 0 765.364375 248.4\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-08-05T03:59:38.060424</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.10.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.4 \nL 765.364375 248.4 \nL 765.364375 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 94.684375 184.68 \nC 99.458031 184.68 104.036813 182.783406 107.412297 179.407922 \nC 110.787781 176.032438 112.684375 171.453656 112.684375 166.68 \nC 112.684375 161.906344 110.787781 157.327562 107.412297 153.952078 \nC 104.036813 150.576594 99.458031 148.68 94.684375 148.68 \nC 89.910719 148.68 85.331937 150.576594 81.956453 153.952078 \nC 78.580969 157.327562 76.684375 161.906344 76.684375 166.68 \nC 76.684375 171.453656 78.580969 176.032438 81.956453 179.407922 \nC 85.331937 182.783406 89.910719 184.68 94.684375 184.68 \nL 94.684375 184.68 \nz\n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 466.384375 103.68 \nL 478.984375 112.68 \nL 466.384375 121.68 \nL 466.384375 103.68 \nz\n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 634.684375 157.68 \nC 635.877391 157.68 637.022765 157.205571 637.866356 156.361981 \nC 638.709946 155.51839 639.184375 154.373016 639.184375 153.18 \nC 639.184375 151.986984 638.709946 150.84161 637.866356 149.998019 \nC 637.022765 149.154429 635.877391 148.68 634.684375 148.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 634.684375 166.68 \nC 635.877391 166.68 637.022765 166.205571 637.866356 165.361981 \nC 638.709946 164.51839 639.184375 163.373016 639.184375 162.18 \nC 639.184375 160.986984 638.709946 159.84161 637.866356 158.998019 \nC 637.022765 158.154429 635.877391 157.68 634.684375 157.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 634.684375 175.68 \nC 635.877391 175.68 637.022765 175.205571 637.866356 174.361981 \nC 638.709946 173.51839 639.184375 172.373016 639.184375 171.18 \nC 639.184375 169.986984 638.709946 168.84161 637.866356 167.998019 \nC 637.022765 167.154429 635.877391 166.68 634.684375 166.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 634.684375 184.68 \nC 635.877391 184.68 637.022765 184.205571 637.866356 183.361981 \nC 638.709946 182.51839 639.184375 181.373016 639.184375 180.18 \nC 639.184375 178.986984 638.709946 177.84161 637.866356 176.998019 \nC 637.022765 176.154429 635.877391 175.68 634.684375 175.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 742.684375 76.68 \nC 747.458031 76.68 752.036813 74.783406 755.412297 71.407922 \nC 758.787781 68.032438 760.684375 63.453656 760.684375 58.68 \nC 760.684375 53.906344 758.787781 49.327562 755.412297 45.952078 \nC 752.036813 42.576594 747.458031 40.68 742.684375 40.68 \nC 737.910719 40.68 733.331937 42.576594 729.956453 45.952078 \nC 726.580969 49.327562 724.684375 53.906344 724.684375 58.68 \nC 724.684375 63.453656 726.580969 68.032438 729.956453 71.407922 \nC 733.331937 74.783406 737.910719 76.68 742.684375 76.68 \nL 742.684375 76.68 \nz\n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"line2d_1\">\n    <path d=\"M 94.684375 220.68 \nL 94.684375 184.68 \nL 94.684375 184.68 \nM 94.684375 148.68 \nL 94.684375 148.68 \nL 94.684375 112.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_2\">\n    <path d=\"M 98.284375 175.68 \nL 91.084375 175.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_3\">\n    <path d=\"M 94.684375 161.28 \nL 94.684375 154.08 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_4\">\n    <path d=\"M 98.284375 157.68 \nL 91.084375 157.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_5\">\n    <path d=\"M 94.684375 112.68 \nL 148.684375 112.68 \nL 202.684375 112.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_6\">\n    <path d=\"M 202.684375 112.68 \nL 238.684375 112.68 \nM 247.324375 109.08 \nL 267.484375 96.48 \nM 274.684375 112.68 \nL 310.684375 112.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_7\">\n    <path d=\"M 310.684375 112.68 \nL 364.684375 112.68 \nL 418.684375 112.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_8\">\n    <path d=\"M 418.684375 112.68 \nL 466.384375 112.68 \nM 478.984375 103.68 \nL 478.984375 121.68 \nM 478.984375 112.68 \nL 526.684375 112.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_9\">\n    <path d=\"M 526.684375 112.68 \nL 580.684375 112.68 \nL 634.684375 112.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_10\">\n    <path d=\"M 634.684375 112.68 \nL 634.684375 148.68 \nM 634.684375 184.68 \nL 634.684375 220.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 634.684375 220.68 \nL 580.684375 220.68 \nL 526.684375 220.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 526.684375 220.68 \nL 526.684375 235.08 \nL 517.684375 235.08 \nL 535.684375 235.08 \nM 520.384375 239.4 \nL 532.984375 239.4 \nM 524.884375 243.72 \nL 528.484375 243.72 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 526.684375 220.68 \nL 526.684375 166.68 \nL 526.684375 112.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 526.684375 112.68 \nL 577.444375 112.68 \nM 577.444375 103.68 \nL 577.444375 121.68 \nM 583.924375 103.68 \nL 583.924375 121.68 \nM 583.924375 112.68 \nL 634.684375 112.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 634.684375 112.68 \nL 688.684375 112.68 \nL 742.684375 112.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 742.684375 112.68 \nL 742.684375 76.68 \nL 742.684375 76.68 \nM 742.684375 40.68 \nL 742.684375 40.68 \nL 742.684375 4.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 751.684375 58.68 \nL 750.934375 56.816503 \nL 750.184375 55.08 \nL 749.434375 53.588831 \nL 748.684375 52.444617 \nL 747.934375 51.725334 \nL 747.184375 51.48 \nL 746.434375 51.725334 \nL 745.684375 52.444617 \nL 744.934375 53.588831 \nL 744.184375 55.08 \nL 743.434375 56.816503 \nL 742.684375 58.68 \nL 741.934375 60.543497 \nL 741.184375 62.28 \nL 740.434375 63.771169 \nL 739.684375 64.915383 \nL 738.934375 65.634666 \nL 738.184375 65.88 \nL 737.434375 65.634666 \nL 736.684375 64.915383 \nL 735.934375 63.771169 \nL 735.184375 62.28 \nL 734.434375 60.543497 \nL 733.684375 58.68 \n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: round\"/>\n   </g>\n   <g id=\"text_1\">\n    <!-- DC Source -->\n    <g transform=\"translate(-0 170.543125) scale(0.14 -0.14)\">\n     <defs>\n      <path id=\"DejaVuSans-44\" d=\"M 1259 4147 \nL 1259 519 \nL 2022 519 \nQ 2988 519 3436 956 \nQ 3884 1394 3884 2338 \nQ 3884 3275 3436 3711 \nQ 2988 4147 2022 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 1925 4666 \nQ 3281 4666 3915 4102 \nQ 4550 3538 4550 2338 \nQ 4550 1131 3912 565 \nQ 3275 0 1925 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-44\"/>\n     <use xlink:href=\"#DejaVuSans-43\" transform=\"translate(77.001953 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(146.826172 0)\"/>\n     <use xlink:href=\"#DejaVuSans-53\" transform=\"translate(178.613281 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(242.089844 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(303.271484 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(366.650391 0)\"/>\n     <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(405.513672 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(460.494141 0)\"/>\n    </g>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 243.004375 117 \nC 244.150052 117 245.24896 116.544818 246.059076 115.734701 \nC 246.869193 114.924585 247.324375 113.825677 247.324375 112.68 \nC 247.324375 111.534323 246.869193 110.435415 246.059076 109.625299 \nC 245.24896 108.815182 244.150052 108.36 243.004375 108.36 \nC 241.858698 108.36 240.75979 108.815182 239.949674 109.625299 \nC 239.139557 110.435415 238.684375 111.534323 238.684375 112.68 \nC 238.684375 113.825677 239.139557 114.924585 239.949674 115.734701 \nC 240.75979 116.544818 241.858698 117 243.004375 117 \nz\n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: #ffffff; stroke: #000000; stroke-width: 2; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 270.364375 117 \nC 271.510052 117 272.60896 116.544818 273.419076 115.734701 \nC 274.229193 114.924585 274.684375 113.825677 274.684375 112.68 \nC 274.684375 111.534323 274.229193 110.435415 273.419076 109.625299 \nC 272.60896 108.815182 271.510052 108.36 270.364375 108.36 \nC 269.218698 108.36 268.11979 108.815182 267.309674 109.625299 \nC 266.499557 110.435415 266.044375 111.534323 266.044375 112.68 \nC 266.044375 113.825677 266.499557 114.924585 267.309674 115.734701 \nC 268.11979 116.544818 269.218698 117 270.364375 117 \nz\n\" clip-path=\"url(#p232b5cbdd3)\" style=\"fill: #ffffff; stroke: #000000; stroke-width: 2; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"text_2\">\n    <!-- Switch -->\n    <g transform=\"translate(233.541719 89.968437) scale(0.14 -0.14)\">\n     <defs>\n      <path id=\"DejaVuSans-77\" d=\"M 269 3500 \nL 844 3500 \nL 1563 769 \nL 2278 3500 \nL 2956 3500 \nL 3675 769 \nL 4391 3500 \nL 4966 3500 \nL 4050 0 \nL 3372 0 \nL 2619 2869 \nL 1863 0 \nL 1184 0 \nL 269 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-53\"/>\n     <use xlink:href=\"#DejaVuSans-77\" transform=\"translate(63.476562 0)\"/>\n     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(145.263672 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(173.046875 0)\"/>\n     <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(212.255859 0)\"/>\n     <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(267.236328 0)\"/>\n    </g>\n   </g>\n   <g id=\"text_3\">\n    <!-- Diode -->\n    <g transform=\"translate(452.315469 97.168437) scale(0.14 -0.14)\">\n     <defs>\n      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-44\"/>\n     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(77.001953 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(104.785156 0)\"/>\n     <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(165.966797 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(229.443359 0)\"/>\n    </g>\n   </g>\n   <g id=\"text_4\">\n    <!-- Inductor -->\n    <g transform=\"translate(572.81375 170.543125) scale(0.14 -0.14)\">\n     <defs>\n      <path id=\"DejaVuSans-49\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-49\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(29.492188 0)\"/>\n     <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(92.871094 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(156.347656 0)\"/>\n     <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(219.726562 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(274.707031 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(313.916016 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(375.097656 0)\"/>\n    </g>\n   </g>\n   <g id=\"text_5\">\n    <!-- Capacitor -->\n    <g transform=\"translate(547.074531 97.168437) scale(0.14 -0.14)\">\n     <defs>\n      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-43\"/>\n     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(69.824219 0)\"/>\n     <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(131.103516 0)\"/>\n     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(194.580078 0)\"/>\n     <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(255.859375 0)\"/>\n     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(310.839844 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(338.623047 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(377.832031 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(439.013672 0)\"/>\n    </g>\n   </g>\n   <g id=\"text_6\">\n    <!-- AC Output -->\n    <g transform=\"translate(648.896875 62.543125) scale(0.14 -0.14)\">\n     <defs>\n      <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \nQ 1834 4238 1429 3725 \nQ 1025 3213 1025 2328 \nQ 1025 1447 1429 934 \nQ 1834 422 2522 422 \nQ 3209 422 3611 934 \nQ 4013 1447 4013 2328 \nQ 4013 3213 3611 3725 \nQ 3209 4238 2522 4238 \nz\nM 2522 4750 \nQ 3503 4750 4090 4092 \nQ 4678 3434 4678 2328 \nQ 4678 1225 4090 567 \nQ 3503 -91 2522 -91 \nQ 1538 -91 948 565 \nQ 359 1222 359 2328 \nQ 359 3434 948 4092 \nQ 1538 4750 2522 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-41\"/>\n     <use xlink:href=\"#DejaVuSans-43\" transform=\"translate(66.658203 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(136.482422 0)\"/>\n     <use xlink:href=\"#DejaVuSans-4f\" transform=\"translate(168.269531 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(246.980469 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(310.359375 0)\"/>\n     <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(349.568359 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(413.044922 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(476.423828 0)\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p232b5cbdd3\">\n   <rect x=\"0.952375\" y=\"-0\" width=\"764.412\" height=\"248.4\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<schemdraw.backends.mpl.Figure object at 0x7982e8304290>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import schemdraw\n",
        "import schemdraw.elements as elm\n",
        "\n",
        "# Function to generate DC waveform\n",
        "def generate_dc_waveform(t, dc_voltage=12):\n",
        "    return np.full_like(t, dc_voltage)\n",
        "\n",
        "# Function to generate AC waveform\n",
        "def generate_ac_waveform(t, freq=50, amplitude=12):\n",
        "    return amplitude * np.sin(2 * np.pi * freq * t)\n",
        "\n",
        "# Function to generate PWM waveform\n",
        "def generate_pwm_waveform(t, freq=50, duty_cycle=0.5):\n",
        "    pwm_wave = np.where(np.sin(2 * np.pi * freq * t) >= duty_cycle, 1, -1)\n",
        "    return pwm_wave * 12  # Scale to match voltage level\n",
        "\n",
        "# Time vector (1 cycle at 50Hz)\n",
        "t = np.linspace(0, 1/50, 1000)\n",
        "\n",
        "dc_wave = generate_dc_waveform(t)\n",
        "ac_wave = generate_ac_waveform(t)\n",
        "pwm_wave = generate_pwm_waveform(t)\n",
        "\n",
        "# Create a figure for live plotting\n",
        "fig, ax = plt.subplots(3, 1, figsize=(10, 6))\n",
        "\n",
        "def update(frame):\n",
        "    ax[0].cla()\n",
        "    ax[1].cla()\n",
        "    ax[2].cla()\n",
        "\n",
        "    ax[0].plot(t[:frame], dc_wave[:frame], 'r')\n",
        "    ax[0].set_title('DC Waveform')\n",
        "    ax[0].set_xlabel('Time (s)')\n",
        "    ax[0].set_ylabel('Voltage (V)')\n",
        "    ax[0].grid()\n",
        "\n",
        "    ax[1].plot(t[:frame], pwm_wave[:frame], 'g')\n",
        "    ax[1].set_title('PWM Waveform (Inverter Switching)')\n",
        "    ax[1].set_xlabel('Time (s)')\n",
        "    ax[1].set_ylabel('Voltage (V)')\n",
        "    ax[1].grid()\n",
        "\n",
        "    ax[2].plot(t[:frame], ac_wave[:frame], 'b')\n",
        "    ax[2].set_title('AC Waveform (One Phase)')\n",
        "    ax[2].set_xlabel('Time (s)')\n",
        "    ax[2].set_ylabel('Voltage (V)')\n",
        "    ax[2].grid()\n",
        "\n",
        "ani = animation.FuncAnimation(fig, update, frames=len(t), interval=20, repeat=False)\n",
        "plt.show()\n",
        "\n",
        "# Create a simple inverter circuit diagram\n",
        "d = schemdraw.Drawing()\n",
        "d += elm.SourceV().label('DC Source')\n",
        "d += elm.Line().right()\n",
        "d += elm.Switch().right().label('Switch')\n",
        "d += elm.Line().right()\n",
        "d += elm.Diode().right().label('Diode')\n",
        "d += elm.Line().right()\n",
        "d += elm.Inductor().down().label('Inductor')\n",
        "d += elm.Line().left()\n",
        "d += elm.Ground()\n",
        "d += elm.Line().up()\n",
        "d += elm.Capacitor().right().label('Capacitor')\n",
        "d += elm.Line().right()\n",
        "# Use elm.SourceSin instead of elm.SineV\n",
        "d += elm.SourceSin().label('AC Output')  # Change this line\n",
        "d.draw()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "Dc-UMqYO-eBR",
        "outputId": "78afb0e0-86ba-44ad-8e85-3e4fde5386a6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAy/FJREFUeJzs3XdYFGf7NuBr6R2UKhEVhYgaVERFEMWCGmtMjAWjqLGm+dryGvLGmsTejdEUFTXEXkJir1GxFyJGRTQUC2gsNEHq8/3ht/Nj3UUBd9lBrvM4OHSfeXbm3r0Z5HJmZxRCCAEiIiIiIiIi0joDfRdARERERERE9Lpi6CYiIiIiIiLSEYZuIiIiIiIiIh1h6CYiIiIiIiLSEYZuIiIiIiIiIh1h6CYiIiIiIiLSEYZuIiIiIiIiIh1h6CYiIiIiIiLSEYZuIiIiIiIiIh1h6CYiIiK9yMzMxLBhw+Di4gKFQoExY8bouyQiIiKtY+gmIiLSkvDwcCgUCunLzMwMrq6u6NSpE5YsWYKMjIxinxsdHY0BAwbAzc0NpqamqFq1KoKDg7F69WoUFBQU+7wuXbqgSpUqEEKojF+8eBEKhQI1a9ZUe86hQ4egUCjw448/lv3FasGMGTMQHh6Ojz76COvWrcPAgQP1Wg8REZEuGOm7ACIiotfN9OnT4e7ujry8PKSkpODIkSMYM2YMFixYgMjISDRs2FBl/s8//4xRo0bB2dkZAwcOhKenJzIyMnDw4EEMHToUycnJ+PLLLzVuKzAwELt378bly5fh7e0tjUdFRcHIyAhJSUm4ffs2qlevrrJM+Vx9OnToEFq0aIEpU6botQ4iIiJdYugmIiLSss6dO6Np06bS47CwMBw6dAjdunVDjx49cPXqVZibmwMATp06hVGjRsHf3x+7du2CtbW19LwxY8bg3LlzuHz5crHbUgbn48ePq4XuLl264NChQzh+/Dj69esnLTt+/Djs7e1Rr149rb3msrh//z7q16+vtfXl5+ejsLAQJiYmWlsnERHRq+Lp5UREROWgXbt2mDRpEhITE/HLL79I49OmTYNCoUBERIRK4FZq2rQpBg8eXOx6mzdvDhMTE+notVJUVBRat26N5s2bqywrLCzEqVOnEBAQAIVCgUePHmHChAnw9vaGlZUVbGxs0LlzZ/z111/Sc+7duwcjIyNMmzZNbfuxsbFQKBT47rvvpLHU1FSMGTNGOlXew8MDs2fPRmFhIQDgyJEjUCgUiI+Px86dO6XT8RMSEgA8C+NDhw6Fs7MzzMzM0KhRI6xZs0ZluwkJCVAoFJg3bx4WLVqEOnXqwNTUFFeuXMHUqVOhUChw/fp1DBgwALa2tnB0dMSkSZMghMCtW7fwzjvvwMbGBi4uLpg/f36x7y8REdGrYugmIiIqJ8rPLO/btw8AkJWVhYMHD6J169aoUaNGmdZpZmYGX19fHD9+XBq7desWbt26hYCAAAQEBKiE7piYGKSnp0tHyP/55x/s2LED3bp1w4IFC/D5558jJiYGQUFBuHv3LgDA2dkZQUFB2LRpk9r2N27cCENDQ/Tu3Vt6TUFBQfjll18QGhqKJUuWoGXLlggLC8O4ceMAAPXq1cO6devg4OCAxo0bY926dVi3bh0cHR2RnZ2NNm3aYN26dfjggw8wd+5c2NraYvDgwVi8eLHa9levXo2lS5dixIgRmD9/PqpWrSot69u3LwoLCzFr1iz4+fnhm2++waJFi9ChQwe88cYbmD17Njw8PDBhwgQcPXq0TO8/ERHRSwkiIiLSitWrVwsA4uzZs8XOsbW1FT4+PkIIIf766y8BQPznP/95pe1+/vnnAoC4ffu2EEKI9evXCzMzM5GTkyN27dolDA0NRXp6uhBCiO+++04AEFFRUUIIIZ4+fSoKCgpU1hcfHy9MTU3F9OnTpbEffvhBABAxMTEqc+vXry/atWsnPf7666+FpaWluH79usq8L774QhgaGoqkpCRprGbNmqJr164q8xYtWiQAiF9++UUay83NFf7+/sLKykp6HfHx8QKAsLGxEffv31dZx5QpUwQAMWLECGksPz9fVK9eXSgUCjFr1ixp/PHjx8Lc3FwMGjRI01tLRET0ynikm4iIqBxZWVlJVzFPT08HAI2nlZeG8qj1sWPHADw7tdzX1xcmJibw9/eXTilXLjMzM5M+c25qagoDg2e/DhQUFODhw4ewsrJC3bp1ceHCBWkb7733HoyMjLBx40Zp7PLly7hy5Qr69u0rjW3evBmtWrVClSpV8ODBA+krODgYBQUFLz2ivGvXLri4uCAkJEQaMzY2xujRo5GZmYk///xTZX6vXr3g6OiocV3Dhg2T/m5oaIimTZtCCIGhQ4dK43Z2dqhbty7++eefF9ZFRERUVgzdRERE5SgzM1MK2TY2NgDwwluJlUTLli2hUCik08ijoqLQsmVLAM9CZf369VWWNWvWTLrYWGFhIRYuXAhPT0+YmprCwcEBjo6OuHTpEtLS0qRtODg4oH379iqnmG/cuBFGRkZ47733pLG4uDjs2bMHjo6OKl/BwcEAnn1e+0USExPh6ekp/UeAkvKib4mJiSrj7u7uxa7r+VP2bW1tYWZmBgcHB7Xxx48fv7AuIiKisuLVy4mIiMrJ7du3kZaWBg8PDwCAh4cHjIyMEBMT80rrtbe3h5eXF44fP47MzExcunRJ5TZcAQEBOH78OG7fvo2kpCR88MEH0rIZM2Zg0qRJ+PDDD/H111+jatWqMDAwwJgxY6QLnyn169cPQ4YMQXR0NBo3boxNmzahffv2KiG2sLAQHTp0wH//+1+Ntb755puv9Fqfp7wKvCaGhoYlGgOgdp9zIiIibWHoJiIiKifr1q0DAHTq1AkAYGFhgXbt2uHQoUO4desW3NzcyrzuwMBArFq1Cvv27UNBQQECAgKkZQEBAVi/fj2OHDkizVXasmUL2rZti5UrV6qsLzU1Ve2IcM+ePTFy5EjpFPPr168jLCxMZU6dOnWQmZkpHdkurZo1a+LSpUsoLCxUOdp97do1aTkREVFFwtPLiYiIysGhQ4fw9ddfw93dXeVI85QpUyCEwMCBA5GZman2vPPnz6vdLkuTwMBAFBQUYN68efD09FT5nHNAQAAyMzPx/fffw8DAQCWQGxoaqh3l3bx5M+7cuaO2DTs7O3Tq1AmbNm3Chg0bYGJigp49e6rM6dOnD06ePIm9e/eqPT81NRX5+fkvfB1dunRBSkqKymfH8/PzsXTpUlhZWSEoKOiFzyciIpIbHukmIiLSst27d+PatWvIz8/HvXv3cOjQIezfvx81a9ZEZGQkzMzMpLkBAQFYtmwZPv74Y3h5eWHgwIHw9PRERkYGjhw5gsjISHzzzTcv3aby6PXJkyfV7uv95ptvwsHBASdPnoS3tzfs7OykZd26dcP06dMxZMgQBAQEICYmBhEREahdu7bG7fTt2xcDBgzA999/j06dOqmsCwA+//xzREZGolu3bhg8eDB8fX3x5MkTxMTEYMuWLUhISFA7gl7UiBEj8MMPP2Dw4ME4f/48atWqhS1btiAqKgqLFi165YvOERERlTeGbiIiIi2bPHkyAMDExARVq1aFt7c3Fi1ahCFDhmgMjSNHjkSzZs0wf/58rF27Fv/++y+srKzQpEkTrF69GgMGDHjpNmvXrg1XV1fcvXtX5Ui2UkBAACIjI1VOLQeAL7/8Ek+ePMGvv/6KjRs3okmTJti5cye++OILjdvp0aMHzM3NkZGRoXLVciULCwv8+eefmDFjBjZv3oy1a9fCxsYGb775JqZNmwZbW9sXvg5zc3McOXIEX3zxBdasWYP09HTUrVsXq1evVvvPBCIioopAIXjlECIiIiIiIiKd4Ge6iYiIiIiIiHSEoZuIiIiIiIhIRxi6iYiIiIiIiHSEoZuIiIiIiIhIRxi6iYiIiIiIiHSEoZuIiIiIiIhIR3ifbg0KCwtx9+5dWFtbQ6FQ6LscIiIiIiIikhkhBDIyMuDq6goDg+KPZzN0a3D37l24ubnpuwwiIiIiIiKSuVu3bqF69erFLmfo1sDa2hrAszfPxsZGz9UULy8vD/v27UPHjh1hbGys73KoCPZGvtgbeWN/5Iu9kS/2Rt7YH/lib+StIvQnPT0dbm5uUn4sDkO3BspTym1sbGQfui0sLGBjYyPbb8TKir2RL/ZG3tgf+WJv5Iu9kTf2R77YG3mrSP152UeSeSE1IiIiIiIiIh1h6CYiIiIiIiLSEYZuIiIiIiIiIh1h6CYiIiIiIiLSEYZuIiIiIiIiIh1h6CYiIiIiIiLSEYZuIiIiIiIiIh3Ra+g+evQounfvDldXVygUCuzYsUNalpeXh4kTJ8Lb2xuWlpZwdXVFaGgo7t69+8J1Tp06FQqFQuXLy8tLx6+EiIiIiIiISJ1eQ/eTJ0/QqFEjLFu2TG1ZVlYWLly4gEmTJuHChQvYtm0bYmNj0aNHj5eut0GDBkhOTpa+jh8/rovyiYiIiIiIiF7ISJ8b79y5Mzp37qxxma2tLfbv368y9t1336F58+ZISkpCjRo1il2vkZERXFxctForERERERERUWnpNXSXVlpaGhQKBezs7F44Ly4uDq6urjAzM4O/vz9mzpz5wpCek5ODnJwc6XF6ejqAZ6e45+XlaaV2XVDWJucaKyv2Rr7YG3ljf+SLvZEv9kbe2B/5Ym/krSL0p6S1KYQQQse1lIhCocD27dvRs2dPjcufPn2Kli1bwsvLCxEREcWuZ/fu3cjMzETdunWRnJyMadOm4c6dO7h8+TKsra01Pmfq1KmYNm2a2vivv/4KCwuLMr0eIiIiIiIien1lZWWhf//+SEtLg42NTbHzKkTozsvLQ69evXD79m0cOXLkhS/oeampqahZsyYWLFiAoUOHapyj6Ui3m5sbHjx4UKptlbe8vDzs378fHTp0gLGxsb7LoSLYG/lib+SN/ZEv9ka+2Bt5Y3/ki72Rt4rQn/T0dDg4OLw0dMv+9PK8vDz06dMHiYmJOHToUKlDsJ2dHd58803cuHGj2DmmpqYwNTVVGzc2NpZtg4uqKHVWRuyNfLE38sb+yBd7I1/sjbyxP/LF3sibnPtT0rpkfZ9uZeCOi4vDgQMHYG9vX+p1ZGZm4ubNm6hWrZoOKiQiIiIiIiIqnl5Dd2ZmJqKjoxEdHQ0AiI+PR3R0NJKSkpCXl4f3338f586dQ0REBAoKCpCSkoKUlBTk5uZK62jfvj2+++476fGECRPw559/IiEhASdOnMC7774LQ0NDhISElPfLIyIiIiIiokpOr6eXnzt3Dm3btpUejxs3DgAwaNAgTJ06FZGRkQCAxo0bqzzv8OHDaNOmDQDg5s2bePDggbTs9u3bCAkJwcOHD+Ho6IjAwECcOnUKjo6Oun0xRERERERERM/Ra+hu06YNXnQdt5Jc4y0hIUHl8YYNG161LCIiIiIiIiKtKFXoTk1Nxfbt23Hs2DEkJiYiKysLjo6O8PHxQadOnRAQEKCrOomIiIiIiIgqnBJ9pvvu3bsYNmwYqlWrhm+++QbZ2dlo3Lgx2rdvj+rVq+Pw4cPo0KED6tevj40bN+q6ZiIiIiIiIqIKoURHun18fDBo0CCcP38e9evX1zgnOzsbO3bswKJFi3Dr1i1MmDBBq4USERERERERVTQlCt1Xrlx56e26zM3NERISIl3EjIiIiIiIiKiyK9Hp5fb29vjjjz9QWFhYopWW5X7aRERERERERK+bEt+nu2fPnnBzc8P//vc/3LhxQ5c1EREREREREb0WShy64+PjMXLkSGzYsAF169ZFUFAQ1q1bh+zsbF3WR0RERERERFRhlTh0u7m5YfLkybh58yYOHDiAWrVq4aOPPkK1atUwatQonD17Vpd1EhEREREREVU4JQ7dRbVt2xZr1qxBcnIy5s6di5iYGLRo0QKNGjXSdn1EREREREREFVaJrl5eHGtra7Rv3x6JiYm4du0arly5oq26iIiIiIiIiCq8Mh3pzs7Oxtq1a9GmTRt4enpiw4YNGDduHBISErRcHhEREREREVHFVaoj3adOncKqVauwadMm5Obm4r333sOBAwfQtm1bXdVHREREREREVGGVOHTXr18fsbGx8PHxwcyZM9G/f3/Y2trqsjYiIiIiIiKiCq3EoTs4OBjr16/nxdKIiIiIiIiISqjEoXvJkiW6rIOIiIiIiIjotVOiC6m9/fbbOHXq1EvnZWRkYPbs2Vi2bNkrF0ZERERERERU0ZXoSHfv3r3Rq1cv2Nraonv37mjatClcXV1hZmaGx48f48qVKzh+/Dh27dqFrl27Yu7cubqum4iIiIiIiEj2ShS6hw4digEDBmDz5s3YuHEjfvzxR6SlpQEAFAoF6tevj06dOuHs2bOoV6+eTgsmIiIiIiIiqihK/JluU1NTDBgwAAMGDAAApKWlITs7G/b29jA2NtZZgUREREREREQVVanu012Ura0tbxlGRERERERE9AIlupAaEREREREREZUeQzcRERERERGRjjB0ExEREREREekIQzcRERERERGRjpQpdKempuLnn39GWFgYHj16BAC4cOEC7ty5o9XiiIiIiIiIiCqyUl+9/NKlSwgODoatrS0SEhIwfPhwVK1aFdu2bUNSUhLWrl2rizqJiIiIiIiIKpxSH+keN24cBg8ejLi4OJiZmUnjXbp0wdGjR7VaHBEREREREVFFVurQffbsWYwcOVJt/I033kBKSopWiiIiIiIiIiJ6HZQ6dJuamiI9PV1t/Pr163B0dNRKUURERERERESvg1KH7h49emD69OnIy8sDACgUCiQlJWHixIno1auX1gskIiIiIiIiqqhKHbrnz5+PzMxMODk5ITs7G0FBQfDw8IC1tTW+/fZbXdRIREREREREVCGV+urltra22L9/P44fP45Lly4hMzMTTZo0QXBwsC7qIyIiIiIiIqqwynSfbgAIDAzExx9/jP/+979lDtxHjx5F9+7d4erqCoVCgR07dkjL8vLyMHHiRHh7e8PS0hKurq4IDQ3F3bt3X7reZcuWoVatWjAzM4Ofnx/OnDlTpvqIiIiIiIiIXkWpj3QvWbJE47hCoYCZmRk8PDzQunVrGBoavnRdT548QaNGjfDhhx/ivffeU1mWlZWFCxcuYNKkSWjUqBEeP36M//znP+jRowfOnTtX7Do3btyIcePGYcWKFfDz88OiRYvQqVMnxMbGwsnJqXQvloiIiIiIiOgVlDp0L1y4EP/++y+ysrJQpUoVAMDjx49hYWEBKysr3L9/H7Vr18bhw4fh5ub2wnV17twZnTt31rhMeRp7Ud999x2aN2+OpKQk1KhRQ+PzFixYgOHDh2PIkCEAgBUrVmDnzp1YtWoVvvjii9K+XCIiIiIiIqIyK3XonjFjBn788Uf8/PPPqFOnDgDgxo0bGDlyJEaMGIGWLVuiX79+GDt2LLZs2aLVYtPS0qBQKGBnZ6dxeW5uLs6fP4+wsDBpzMDAAMHBwTh58qRWa9E7IYAnT2D49Cnw5AlgbKzviqiovDz2Rq7YG3ljf+SLvZEv9kbe2B/5Ym/kTdkfIfRdySsrdej+6quvsHXrVilwA4CHhwfmzZuHXr164Z9//sGcOXO0fvuwp0+fYuLEiQgJCYGNjY3GOQ8ePEBBQQGcnZ1Vxp2dnXHt2rVi152Tk4OcnBzpsfI+5Hl5edKt0WTnyRMYV6mCbvqugzQyBtgbmWJv5I39kS/2Rr7YG3ljf+SLvZE3ZX+y7t8Hijnoqm8lzYqlDt3JycnIz89XG8/Pz0dKSgoAwNXVFRkZGaVddbHy8vLQp08fCCGwfPlyra1XaebMmZg2bZra+L59+2BhYaH17WmD4dOn/CFBRERERESvtUOHDqHAzEzfZWiUlZVVonmlDt1t27bFyJEj8fPPP8PHxwcAcPHiRXz00Udo164dACAmJgbu7u6lXbVGysCdmJiIQ4cOFXuUGwAcHBxgaGiIe/fuqYzfu3cPLi4uxT4vLCwM48aNkx6np6fDzc0NHTt2fOH29EoIZN2/j0OHDqFdu3Yw5ikxspKXl8feyBR7I2/sj3yxN/LF3sgb+yNf7I28Sf3p1g3GJib6Lkcj5RnSL1Pq0L1y5UoMHDgQvr6+0jdnfn4+2rdvj5UrVwIArKysMH/+/NKuWo0ycMfFxeHw4cOwt7d/4XwTExP4+vri4MGD6NmzJwCgsLAQBw8exKefflrs80xNTWFqaqo2bmxsLO8d0M4OBWZmMLazk3edlVFeHnsjV+yNvLE/8sXeyBd7I2/sj3yxN/Km7I+JiWz7U9K6Sh26XVxcsH//fly7dg3Xr18HANStWxd169aV5rRt27ZE68rMzMSNGzekx/Hx8YiOjkbVqlVRrVo1vP/++7hw4QL++OMPFBQUSKevV61aFSb//3872rdvj3fffVcK1ePGjcOgQYPQtGlTNG/eHIsWLcKTJ0+kq5kTERERERERlZdSh24lLy8veHl5vdLGz507pxLQlad4Dxo0CFOnTkVkZCQAoHHjxirPO3z4MNq0aQMAuHnzJh48eCAt69u3L/79919MnjwZKSkpaNy4Mfbs2aN2cTUiIiIiIiIiXStT6L59+zYiIyORlJSE3NxclWULFiwo8XratGkD8YJLwL9omVJCQoLa2KeffvrC08mJiIiIiIiIykOpQ/fBgwfRo0cP1K5dG9euXcNbb72FhIQECCHQpEkTXdRIREREREREVCEZlPYJYWFhmDBhAmJiYmBmZoatW7fi1q1bCAoKQu/evXVRIxEREREREVGFVOrQffXqVYSGhgIAjIyMkJ2dDSsrK0yfPh2zZ8/WeoFEREREREREFVWpQ7elpaX0Oe5q1arh5s2b0rKiFzQjIiIiIiIiquxK/ZnuFi1a4Pjx46hXrx66dOmC8ePHIyYmBtu2bUOLFi10USMRERERERFRhVTq0L1gwQJkZmYCAKZNm4bMzExs3LgRnp6epbpyOREREREREdHrrtShu3bt2tLfLS0tsWLFCq0WRERERERERPS6KPVnumvXro2HDx+qjaempqoEciIiIiIiIqLKrtShOyEhAQUFBWrjOTk5uHPnjlaKIiIiIiIiInodlPj08sjISOnve/fuha2trfS4oKAABw8eRK1atbRaHBEREREREVFFVuLQ3bNnTwCAQqHAoEGDVJYZGxujVq1amD9/vlaLIyIiIiIiIqrIShy6CwsLAQDu7u44e/YsHBwcdFYUERERERER0eug1Fcvj4+P10UdRERERERERK+dEoXuJUuWlHiFo0ePLnMxRERERERERK+TEoXuhQsXlmhlCoWCoZuIiIiIiIjo/ytR6OYp5URERERERESlV+r7dBclhIAQQlu1EBEREREREb1WyhS6165dC29vb5ibm8Pc3BwNGzbEunXrtF0bERERERERUYVW6quXL1iwAJMmTcKnn36Kli1bAgCOHz+OUaNG4cGDBxg7dqzWiyQiIiIiIiKqiEodupcuXYrly5cjNDRUGuvRowcaNGiAqVOnMnQTERERERER/X+lPr08OTkZAQEBauMBAQFITk7WSlFEREREREREr4NSh24PDw9s2rRJbXzjxo3w9PTUSlFEREREREREr4NSn14+bdo09O3bF0ePHpU+0x0VFYWDBw9qDONERERERERElVWJj3RfvnwZANCrVy+cPn0aDg4O2LFjB3bs2AEHBwecOXMG7777rs4KJSIiIiIiIqpoSnyku2HDhmjWrBmGDRuGfv364ZdfftFlXUREREREREQVXomPdP/5559o0KABxo8fj2rVqmHw4ME4duyYLmsjIiIiIiIiqtBKHLpbtWqFVatWITk5GUuXLkV8fDyCgoLw5ptvYvbs2UhJSdFlnUREREREREQVTqmvXm5paYkhQ4bgzz//xPXr19G7d28sW7YMNWrUQI8ePXRRIxEREREREVGFVOrQXZSHhwe+/PJLfPXVV7C2tsbOnTu1VRcRERERERFRhVfqW4YpHT16FKtWrcLWrVthYGCAPn36YOjQodqsjYiIiIiIiKhCK1Xovnv3LsLDwxEeHo4bN24gICAAS5YsQZ8+fWBpaamrGomIiIiIiIgqpBKH7s6dO+PAgQNwcHBAaGgoPvzwQ9StW1eXtRERERERERFVaCX+TLexsTG2bNmC27dvY/bs2VoJ3EePHkX37t3h6uoKhUKBHTt2qCzftm0bOnbsCHt7eygUCkRHR790neHh4VAoFCpfZmZmr1wrERERERERUWmV+Eh3ZGSk1jf+5MkTNGrUCB9++CHee+89jcsDAwPRp08fDB8+vMTrtbGxQWxsrPRYoVBopV4iIiIiIiKi0ijzhdS0oXPnzujcuXOxywcOHAgASEhIKNV6FQoFXFxcXqU0IiIiIiIiolf2SrcMk6vMzEzUrFkTbm5ueOedd/D333/ruyQiIiIiIiKqhPR6pFsX6tati1WrVqFhw4ZIS0vDvHnzEBAQgL///hvVq1fX+JycnBzk5ORIj9PT0wEAeXl5yMvLK5e6y0JZm5xrrKzYG/lib+SN/ZEv9ka+2Bt5Y3/ki72Rt4rQn5LWphBCCB3XUiIKhQLbt29Hz5491ZYlJCTA3d0dFy9eROPGjUu13ry8PNSrVw8hISH4+uuvNc6ZOnUqpk2bpjb+66+/wsLColTbIyIiIiIiotdfVlYW+vfvj7S0NNjY2BQ777U70v08Y2Nj+Pj44MaNG8XOCQsLw7hx46TH6enpcHNzQ8eOHV/45ulbXl4e9u/fjw4dOsDY2Fjf5VAR7I18sTfyxv7IF3sjX+yNvLE/8sXeyFtF6I/yDOmXee1Dd0FBAWJiYtClS5di55iamsLU1FRt3NjYWLYNLqqi1FkZsTfyxd7IG/sjX+yNfLE38sb+yBd7I29y7k9J69Jr6M7MzFQ5Ah0fH4/o6GhUrVoVNWrUwKNHj5CUlIS7d+8CgHQbMBcXF+nq5KGhoXjjjTcwc+ZMAMD06dPRokULeHh4IDU1FXPnzkViYiKGDRtWzq+OiIiIiIiIKju9hu5z586hbdu20mPlKd6DBg1CeHg4IiMjMWTIEGl5v379AABTpkzB1KlTAQBJSUkwMPi/i7A/fvwYw4cPR0pKCqpUqQJfX1+cOHEC9evXL4dXRERERERERPR/9Bq627Rpgxddx23w4MEYPHjwC9dx5MgRlccLFy7EwoULtVAdERERERER0at5Le/TTURERERERCQHDN1EREREREREOsLQTURERERERKQjDN1EREREREREOsLQTURERERERKQjDN1EREREREREOsLQTURERERERKQjer1Pt1wp7x2enp6u50peLC8vD1lZWUhPT4exsbG+y6Ei2Bv5Ym/kjf2RL/ZGvtgbeWN/5Iu9kbeK0B9lXlTmx+IwdGuQkZEBAHBzc9NzJURERERERCRnGRkZsLW1LXa5QrwslldChYWFuHv3LqytraFQKPRdTrHS09Ph5uaGW7duwcbGRt/lUBHsjXyxN/LG/sgXeyNf7I28sT/yxd7IW0XojxACGRkZcHV1hYFB8Z/c5pFuDQwMDFC9enV9l1FiNjY2sv1GrOzYG/lib+SN/ZEv9ka+2Bt5Y3/ki72RN7n350VHuJV4ITUiIiIiIiIiHWHoJiIiIiIiItIRhu4KzNTUFFOmTIGpqam+S6HnsDfyxd7IG/sjX+yNfLE38sb+yBd7I2+vU394ITUiIiIiIiIiHeGRbiIiIiIiIiIdYegmIiIiIiIi0hGGbiIiIiIiIiIdYeguJ8uWLUOtWrVgZmYGPz8/nDlz5oXzN2/eDC8vL5iZmcHb2xu7du1SWS6EwOTJk1GtWjWYm5sjODgYcXFxKnMePXqEDz74ADY2NrCzs8PQoUORmZmpMufSpUto1aoVzMzM4Obmhjlz5mjnBVcw5d2fhIQEDB06FO7u7jA3N0edOnUwZcoU5ObmqsxRKBRqX6dOndLui5c5few7tWrVUnvfZ82apTKH+0759+bIkSMa9wmFQoGzZ88C4H5TlLb7s23bNnTs2BH29vZQKBSIjo5WW8fTp0/xySefwN7eHlZWVujVqxfu3bunMicpKQldu3aFhYUFnJyc8PnnnyM/P/+VX29FUt69efToET777DPUrVsX5ubmqFGjBkaPHo20tDSVeZr2nQ0bNmjlNVck+th32rRpo/bejxo1SmUO953y701x/6YoFAps3rxZmsd9R7u9ycvLw8SJE+Ht7Q1LS0u4uroiNDQUd+/eVVlHhco6gnRuw4YNwsTERKxatUr8/fffYvjw4cLOzk7cu3dP4/yoqChhaGgo5syZI65cuSK++uorYWxsLGJiYqQ5s2bNEra2tmLHjh3ir7/+Ej169BDu7u4iOztbmvP222+LRo0aiVOnToljx44JDw8PERISIi1PS0sTzs7O4oMPPhCXL18W69evF+bm5uKHH37Q3ZshQ/roz+7du8XgwYPF3r17xc2bN8Vvv/0mnJycxPjx46V1xMfHCwDiwIEDIjk5WfrKzc3V7RsiI/rad2rWrCmmT5+u8r5nZmZKy7nv6Kc3OTk5Kj1JTk4Ww4YNE+7u7qKwsFAIwf1GSRf9Wbt2rZg2bZr46aefBABx8eJFtfWMGjVKuLm5iYMHD4pz586JFi1aiICAAGl5fn6+eOutt0RwcLC4ePGi2LVrl3BwcBBhYWFafw/kSh+9iYmJEe+9956IjIwUN27cEAcPHhSenp6iV69eKvMAiNWrV6vsO0V/NlYG+tp3goKCxPDhw1Xe+7S0NGk59x399CY/P1/t351p06YJKysrkZGRIc2r7PuOtnuTmpoqgoODxcaNG8W1a9fEyZMnRfPmzYWvr6/KeipS1mHoLgfNmzcXn3zyifS4oKBAuLq6ipkzZ2qc36dPH9G1a1eVMT8/PzFy5EghhBCFhYXCxcVFzJ07V1qempoqTE1Nxfr164UQQly5ckUAEGfPnpXm7N69WygUCnHnzh0hhBDff/+9qFKlisjJyZHmTJw4UdStW/cVX3HFoo/+aDJnzhzh7u4uPVaGB03/OFcW+upNzZo1xcKFC4uti/uOPPab3Nxc4ejoKKZPny6Ncb95Rtv9Kaq49zg1NVUYGxuLzZs3S2NXr14VAMTJkyeFEELs2rVLGBgYiJSUFGnO8uXLhY2Njcr+9DrTR2802bRpkzAxMRF5eXnSGACxffv2kr2Q15S++hMUFCT+85//FFsX9x357DuNGzcWH374ocpYZd93dNkbpTNnzggAIjExUQhR8bIOTy/XsdzcXJw/fx7BwcHSmIGBAYKDg3Hy5EmNzzl58qTKfADo1KmTND8+Ph4pKSkqc2xtbeHn5yfNOXnyJOzs7NC0aVNpTnBwMAwMDHD69GlpTuvWrWFiYqKyndjYWDx+/PgVX3nFoK/+aJKWloaqVauqjffo0QNOTk4IDAxEZGRkqV5fRabv3syaNQv29vbw8fHB3LlzVU7hq+z7jr57oxQZGYmHDx9iyJAhassq634D6KY/JXH+/Hnk5eWprMfLyws1atRQ+bfJ29sbzs7OKttJT0/H33//XeJtVVT66o0maWlpsLGxgZGRkcr4J598AgcHBzRv3hyrVq2CqER3ltV3fyIiIuDg4IC33noLYWFhyMrKUtkO9x397zvnz59HdHQ0hg4dqrassu475dWbtLQ0KBQK2NnZSeuoSFnH6OVT6FU8ePAABQUFKj8kAcDZ2RnXrl3T+JyUlBSN81NSUqTlyrEXzXFyclJZbmRkhKpVq6rMcXd3V1uHclmVKlVK/DorKn3153k3btzA0qVLMW/ePGnMysoK8+fPR8uWLWFgYICtW7eiZ8+e2LFjB3r06FG6F1oB6bM3o0ePRpMmTVC1alWcOHECYWFhSE5OxoIFC6T1VOZ9Ry77zcqVK9GpUydUr15dGqvs+w2gm/6UREpKCkxMTKRfiDStp7jtKJe97vTVG011fP311xgxYoTK+PTp09GuXTtYWFhg3759+Pjjj5GZmYnRo0eXeVsViT77079/f9SsWROurq64dOkSJk6ciNjYWGzbtu2F21Eue93JZd9ZuXIl6tWrh4CAAJXxyrzvlEdvnj59iokTJyIkJAQ2NjbSOipS1mHoJtKzO3fu4O2330bv3r0xfPhwadzBwQHjxo2THjdr1gx3797F3LlzK0140Jei73vDhg1hYmKCkSNHYubMmTA1NdVjZaR0+/Zt7N27F5s2bVIZ535D9GLp6eno2rUr6tevj6lTp6osmzRpkvR3Hx8fPHnyBHPnzq0UwUHfiv4HiLe3N6pVq4b27dvj5s2bqFOnjh4rI6Xs7Gz8+uuvKvuJEvcd3cnLy0OfPn0ghMDy5cv1XU6Z8fRyHXNwcIChoaHa1Vvv3bsHFxcXjc9xcXF54Xzlny+bc//+fZXl+fn5ePTokcocTesouo3Xnb76o3T37l20bdsWAQEB+PHHH19ar5+fH27cuPHSea8DffemKD8/P+Tn5yMhIeGF2ym6jdeZHHqzevVq2NvblyhIV6b9BtBNf0rCxcUFubm5SE1NLXY93Hf00xuljIwMvP3227C2tsb27dthbGz8wvl+fn64ffs2cnJySr2tikjf/SnKz88PAKSfXdx39N+bLVu2ICsrC6GhoS+dW5n2HV32Rhm4ExMTsX//fukot3IdFSnrMHTrmImJCXx9fXHw4EFprLCwEAcPHoS/v7/G5/j7+6vMB4D9+/dL893d3eHi4qIyJz09HadPn5bm+Pv7IzU1FefPn5fmHDp0CIWFhdIPcn9/fxw9ehR5eXkq26lbt+5rf3qskr76Azw7wt2mTRv4+vpi9erVMDB4+e4YHR2NatWqleo1VlT67M3zoqOjYWBgIJ3GVNn3HX33RgiB1atXIzQ09KWhAahc+w2gm/6UhK+vL4yNjVXWExsbi6SkJJV/m2JiYlR+UVL+IlW/fv0Sb6ui0ldvgGf7U8eOHWFiYoLIyEiYmZm99DnR0dGoUqVKpTnDR5/9eZ7y1lXKn13cd/Tfm5UrV6JHjx5wdHR86dzKtO/oqjfKwB0XF4cDBw7A3t5ebR0VKuuU+6XbKqENGzYIU1NTER4eLq5cuSJGjBgh7OzspCtQDhw4UHzxxRfS/KioKGFkZCTmzZsnrl69KqZMmaLx1jp2dnbit99+E5cuXRLvvPOOxluG+fj4iNOnT4vjx48LT09Plcvop6amCmdnZzFw4EBx+fJlsWHDBmFhYVGpbnskhH76c/v2beHh4SHat28vbt++rXKLCaXw8HDx66+/iqtXr4qrV6+Kb7/9VhgYGIhVq1aV0zujf/rozYkTJ8TChQtFdHS0uHnzpvjll1+Eo6OjCA0NldbBfUd/P9eEEOLAgQMCgLh69apaXdxvntFFfx4+fCguXrwodu7cKQCIDRs2iIsXL6r83Bo1apSoUaOGOHTokDh37pzw9/cX/v7+0nLlbY86duwooqOjxZ49e4Sjo2Olu+1RefcmLS1N+Pn5CW9vb3Hjxg2Vf3Py8/OFEEJERkaKn376ScTExIi4uDjx/fffCwsLCzF58uRyfHf0Tx/9uXHjhpg+fbo4d+6ciI+PF7/99puoXbu2aN26tbQO7jv6+7kmhBBxcXFCoVCI3bt3q9XFfUf7vcnNzRU9evQQ1atXF9HR0So/s4peibwiZR2G7nKydOlSUaNGDWFiYiKaN28uTp06JS0LCgoSgwYNUpm/adMm8eabbwoTExPRoEEDsXPnTpXlhYWFYtKkScLZ2VmYmpqK9u3bi9jYWJU5Dx8+FCEhIcLKykrY2NiIIUOGqNxTUAgh/vrrLxEYGChMTU3FG2+8IWbNmqXdF15BlHd/Vq9eLQBo/FIKDw8X9erVExYWFsLGxkY0b95c5VY8lUV59+b8+fPCz89P2NraCjMzM1GvXj0xY8YM8fTpU5X1cN/Rz881IYQICQlRufdzUdxv/o+2+1Pcz60pU6ZIc7Kzs8XHH38sqlSpIiwsLMS7776r9strQkKC6Ny5szA3NxcODg5i/PjxKretqgzKuzeHDx8u9t+c+Ph4IcSzW+00btxYWFlZCUtLS9GoUSOxYsUKUVBQoMu3QpbKuz9JSUmidevWomrVqsLU1FR4eHiIzz//XOU+3UJw3xFCPz/XhBAiLCxMuLm5adwfuO88o83eKG/hpunr8OHD0ryKlHUUQlSS69kTERERERERlTN+ppuIiIiIiIhIRxi6iYiIiIiIiHSEoZuIiIiIiIhIRxi6iYiIiIiIiHSEoZuIiIiIiIhIRxi6iYiIiIiIiHSEoZuIiIiIiIhIRxi6iYiIiIiIiHSEoZuIiOg1NnjwYPTs2VNv2x84cCBmzJhRorn9+vXD/PnzdVwRERFR+VIIIYS+iyAiIqLSUygUL1w+ZcoUjB07FkII2NnZlU9RRfz1119o164dEhMTYWVl9dL5ly9fRuvWrREfHw9bW9tyqJCIiEj3GLqJiIgqqJSUFOnvGzduxOTJkxEbGyuNWVlZlSjs6sqwYcNgZGSEFStWlPg5zZo1w+DBg/HJJ5/osDIiIqLyw9PLiYiIKigXFxfpy9bWFgqFQmXMyspK7fTyNm3a4LPPPsOYMWNQpUoVODs746effsKTJ08wZMgQWFtbw8PDA7t371bZ1uXLl9G5c2dYWVnB2dkZAwcOxIMHD4qtraCgAFu2bEH37t1Vxr///nt4enrCzMwMzs7OeP/991WWd+/eHRs2bHj1N4eIiEgmGLqJiIgqmTVr1sDBwQFnzpzBZ599ho8++gi9e/dGQEAALly4gI4dO2LgwIHIysoCAKSmpqJdu3bw8fHBuXPnsGfPHty7dw99+vQpdhuXLl1CWloamjZtKo2dO3cOo0ePxvTp0xEbG4s9e/agdevWKs9r3rw5zpw5g5ycHN28eCIionLG0E1ERFTJNGrUCF999RU8PT0RFhYGMzMzODg4YPjw4fD09MTkyZPx8OFDXLp0CQDw3XffwcfHBzNmzICXlxd8fHywatUqHD58GNevX9e4jcTERBgaGsLJyUkaS0pKgqWlJbp164aaNWvCx8cHo0ePVnmeq6srcnNzVU6dJyIiqsgYuomIiCqZhg0bSn83NDSEvb09vL29pTFnZ2cAwP379wE8uyDa4cOHpc+IW1lZwcvLCwBw8+ZNjdvIzs6GqampysXeOnTogJo1a6J27doYOHAgIiIipKPpSubm5gCgNk5ERFRRMXQTERFVMsbGxiqPFQqFypgyKBcWFgIAMjMz0b17d0RHR6t8xcXFqZ0eruTg4ICsrCzk5uZKY9bW1rhw4QLWr1+PatWqYfLkyWjUqBFSU1OlOY8ePQIAODo6auW1EhER6RtDNxEREb1QkyZN8Pfff6NWrVrw8PBQ+bK0tNT4nMaNGwMArly5ojJuZGSE4OBgzJkzB5cuXUJCQgIOHTokLb98+TKqV68OBwcHnb0eIiKi8sTQTURERC/0ySef4NGjRwgJCcHZs2dx8+ZN7N27F0OGDEFBQYHG5zg6OqJJkyY4fvy4NPbHH39gyZIliI6ORmJiItauXYvCwkLUrVtXmnPs2DF07NhR56+JiIiovDB0ExER0Qu5uroiKioKBQUF6NixI7y9vTFmzBjY2dnBwKD4XyWGDRuGiIgI6bGdnR22bduGdu3aoV69elixYgXWr1+PBg0aAACePn2KHTt2YPjw4Tp/TUREROVFIYQQ+i6CiIiIXj/Z2dmoW7cuNm7cCH9//5fOX758ObZv3459+/aVQ3VERETlg0e6iYiISCfMzc2xdu1aPHjwoETzjY2NsXTpUh1XRUREVL54pJuIiIiIiIhIR3ikm4iIiIiIiEhHGLqJiIiIiIiIdIShm4iIiIiIiEhHGLqJiIiIiIiIdIShm4iIiIiIiEhHGLqJiIiIiIiIdIShm4iIiIiIiEhHGLqJiIiIiIiIdIShm4iIiIiIiEhHGLqJiIiIiIiIdIShm4iIiIiIiEhHGLqJiIiIiIiIdIShm4iIiIiIiEhHGLqJiIiIiIiIdIShm4iIiIiIiEhHGLqJiIi05OzZswgICIClpSUUCgWio6P1XdJLbdq0CVWrVkVmZqa+SyEAU6dOhUKh0Nr6wsPDoVAocO7cuZfObdOmDdq0aaO1bWty5coVGBkZ4fLlyzrdDhGRnDB0ExG9ppS/bCu/zMzM8Oabb+LTTz/FvXv3AABnzpyBQqHAwoUL1Z7/zjvvQKFQYPXq1WrLWrdujTfeeEN63KZNGygUCnh6emqsZf/+/VIdW7ZsKbbm+/fvQ6FQ4D//+Y/asv/85z9QKBSYMmWK2rLQ0FAYGxsjKyur2HXrWl5eHnr37o1Hjx5h4cKFWLduHWrWrKm3ekqioKAAU6ZMwWeffQYrKytpvFatWujWrZseKyuZXbt2YerUqeW+3d9//x1BQUFwcnKChYUFateujT59+mDPnj062d6MGTOwY8cOnay7vNWvXx9du3bF5MmT9V0KEVG5YegmInrNTZ8+HevWrcN3332HgIAALF++HP7+/sjKykKTJk1gYWGB48ePqz3vxIkTMDIyQlRUlMp4bm4uzp49i5YtW6qMm5mZ4caNGzhz5ozauiIiImBmZvbSWp2cnODp6amxnqioKI31KJf5+PjAwsLipdvQlZs3byIxMRETJkzAiBEjMGDAAFSpUkVv9ZTE77//jtjYWIwYMULfpZTJrl27MG3atHLd5rx589CjRw8oFAqEhYVh4cKF6NWrF+Li4rBhw4ZXXv9XX32F7OxslbHyCt379u3Dvn37dL6dUaNGYfv27bh586bOt0VEJAdG+i6AiIh0q3PnzmjatCkAYNiwYbC3t8eCBQvw22+/ISQkBH5+fmpBNjY2Fg8ePED//v3VAvD58+fx9OlTBAYGqozXqVMH+fn5WL9+PZo3by6NP336FNu3b0fXrl2xdevWl9YbGBiItWvXIjMzUzr6+uTJE/z111/o06cPIiMjUVBQAENDQwBAcnIy/vnnH7zzzjulf3O06P79+wAAOzs7ra3zyZMnsLS01Nr6nrd69Wq0bNlS5ayFikCX74sQAk+fPoW5ubnasvz8fHz99dfo0KGDxnCq/B54FUZGRjAy0s+vZyYmJuWyneDgYFSpUgVr1qzB9OnTy2WbRET6xCPdRESVTLt27QAA8fHxAJ6F3Hv37uHGjRvSnKioKNjY2GDEiBFSAC+6TPm854WEhGDjxo0oLCyUxn7//XdkZWWhT58+JaovMDAQBQUFOHXqlDR2+vRp5OfnY8KECcjMzFT5rPTz9Rw7dgy9e/dGjRo1YGpqCjc3N4wdO1bl6OG8efOgUCiQmJiotv2wsDCYmJjg8ePHKtt/++23YWtrCwsLCwQFBan8R8XgwYMRFBQEAOjduzcUCoXKZ2MPHTqEVq1awdLSEnZ2dnjnnXdw9epVle0qP8t75coV9O/fH1WqVJFek/J07yNHjqBp06YwNzeHt7c3jhw5AgDYtm0bvL29YWZmBl9fX1y8ePGl7/PTp0+xZ88eBAcHv3RuQkICFAoF5s2bhx9//BF16tSBqakpmjVrhrNnz+rsfX3R+zJ48GAsW7YMAFQ+RqFUWFiIRYsWoUGDBjAzM4OzszNGjhypsv2i7+3evXul9/aHH37Q+D48ePAA6enpamd5KDk5OQF4FtwdHBwwbtw4lXrs7OxgaGiI1NRUaXz27NkwMjKSPlP//Ge6FQoFnjx5gjVr1kivcfDgwdLyO3fuYOjQoXB1dYWpqSnc3d3x0UcfITc3V6W2nJwcjBs3Do6OjrC0tMS7776Lf//9V2XO85/pPnLkCBQKBTZt2oRvv/0W1atXh5mZGdq3b6/y80Jp2bJlqF27NszNzdG8eXMcO3ZM4+fEjY2N0aZNG/z2228a30ciotcNQzcRUSWjPKXT3t4ewP+F1aJHtKOiotCiRQv4+fnB2NgYJ06cUFlmbW2NRo0aqa27f//+SE5OlsIgAPz6669o3769FEheprh63nzzTfj4+KB69eoqwez50L1582ZkZWXho48+wtKlS9GpUycsXboUoaGh0nP69OkjhYnnbdq0CR07dpRODT906BBat26N9PR0TJkyBTNmzEBqairatWsnnUo/cuRIfPnllwCA0aNHY926dfjf//4HADhw4AA6deqE+/fvY+rUqRg3bhxOnDiBli1bIiEhQW37vXv3RlZWFmbMmIHhw4dL4zdu3ED//v3RvXt3zJw5E48fP0b37t0RERGBsWPHYsCAAZg2bRpu3ryJPn36qPzHhybnz59Hbm4umjRp8sJ5Rf3666+YO3cuRo4ciW+++QYJCQl47733kJeXp5P39UXvy8iRI9GhQwcAwLp166QvpZEjR+Lzzz9Hy5YtsXjxYgwZMgQRERHo1KmTVK9SbGwsQkJC0KFDByxevBiNGzfW+PqdnJxgbm6O33//HY8ePSr2fVIoFGjZsiWOHj0qjV26dAlpaWkAoPL9e+zYMfj4+Kh8pr6odevWwdTUFK1atZJe48iRIwEAd+/eRfPmzbFhwwb07dsXS5YswcCBA/Hnn3+qXd/gs88+w19//YUpU6bgo48+wu+//45PP/202NdQ1KxZs7B9+3ZMmDABYWFhOHXqFD744AOVOcuXL8enn36K6tWrY86cOWjVqhV69uyJ27dva1ynr68vLl++jPT09BLVQERUoQkiInotrV69WgAQBw4cEP/++6+4deuW2LBhg7C3txfm5ubi9u3bQggh0tPThaGhoRg6dKj03Lp164pp06YJIYRo3ry5+Pzzz6Vljo6OokOHDirbCgoKEg0aNBBCCNG0aVNpXY8fPxYmJiZizZo14vDhwwKA2Lx580trd3JyEu3bt5ced+rUSQwZMkQIIUSfPn1E7969pWVNmzYVnp6e0uOsrCy19c2cOVMoFAqRmJgojfn7+wtfX1+VeWfOnBEAxNq1a4UQQhQWFgpPT0/RqVMnUVhYqLINd3d3lfehuNfXuHFj4eTkJB4+fCiN/fXXX8LAwECEhoZKY1OmTBEAREhIiFr9NWvWFADEiRMnpLG9e/cKAMLc3Fzldf3www8CgDh8+LDaeor6+eefBQARExOjcXtdu3aVHsfHxwsAwt7eXjx69Ega/+233wQA8fvvv0tj2n5fX/S+fPLJJ0LTrzLHjh0TAERERITK+J49e9TGle/tnj171N8kDSZPniwACEtLS9G5c2fx7bffivPnz6vNmzt3rjA0NBTp6elCCCGWLFkiatasKZo3by4mTpwohBCioKBA2NnZibFjx6q93qIsLS3FoEGD1LYRGhoqDAwMxNmzZ9WWKd9X5c+B4OBglfd67NixwtDQUKSmpkpjQUFBIigoSHqs/J6uV6+eyMnJkcYXL16s8r2Tk5Mj7O3tRbNmzUReXp40Lzw8XABQWafSr7/+KgCI06dPqy0jInrd8Eg3EdFrLjg4GI6OjnBzc0O/fv1gZWWF7du3S5/jtba2RsOGDaUjyw8ePEBsbCwCAgIAAC1btpSOzF2/fh3//vuvxlPLlfr3749t27YhNzcXW7ZsgaGhId59991S1dyyZUucPn0aBQUFKCwsxKlTpzTWk5WVhejoaJV6in4W98mTJ3jw4AECAgIghFA57bpv3744f/68ysWcNm7cCFNTU+nz4dHR0YiLi0P//v3x8OFDPHjwAA8ePMCTJ0/Qvn17HD169IVHlJOTkxEdHY3BgwejatWq0njDhg3RoUMH7Nq1S+05o0aN0riu+vXrw9/fX3rs5+cH4NnHBWrUqKE2/s8//xRbFwA8fPgQAEp1sbe+ffuqzG/VqpXatnT1vhb3vmiyefNm2NraokOHDtK6Hzx4AF9fX1hZWeHw4cMq893d3dGpU6cSrXvatGn49ddf4ePjg7179+J///sffH190aRJE5WPDLRq1QoFBQXSWSLHjh1Dq1at0KpVKxw7dgwAcPnyZaSmpkrvY2kUFhZix44d6N69u3TNhqKev+3YiBEjVMaU9Wn6KMDzhgwZovJ57+f7fu7cOTx8+BDDhw9X+Tz6Bx98UOz3l3K86EdXiIheVwzdRESvuWXLlmH//v04fPgwrly5gn/++UctYAQGBkqf3T5x4gQMDQ3RokULAEBAQADOnz+PnJycF36eW6lfv35IS0vD7t27ERERgW7dusHa2rpUNQcGBkqf3b58+TLS0tKkz9EGBATg7t27SEhIkD7rXbSepKQkKeRaWVnB0dFR+ry18vRe4NnpygYGBti4cSOAZ5/D3bx5Mzp37gwbGxsAQFxcHABg0KBBcHR0VPn6+eefkZOTo7LO5ykDTd26ddWW1atXTwqaRbm7u2tcV9FgDQC2trYAADc3N43jz392uThCiBLN01SDMjgV3Zau3tfi3hdN4uLikJaWBicnJ7X1Z2Zmql3wrDTrBp5du+DYsWN4/Pgx9u3bh/79++PixYvo3r07nj59CgDSnQGUAVsZulu3bo1z587h6dOn0rIX7U/F+ffff5Geno633nqrRPNL0ruyPlf5fe7h4aEyz8jICLVq1dK4TuX3nTbvSU5EJFe8ejkR0WuuefPmGo+EFRUYGIilS5ciKioKJ06cgLe3t/QZ04CAAOTk5ODs2bM4fvw4jIyMpECuSbVq1dCmTRvMnz8fUVFRJbpiuaZ6gGef6zYxMUHVqlXh5eUFAGjcuLF0m7OiF4MDnt13ukOHDnj06BEmTpwILy8vWFpa4s6dOxg8eLDK0VNXV1e0atUKmzZtwpdffolTp04hKSkJs2fPluYo58+dO7fYz/kW91ncstJ01WwA0tXaSzr+sjCt/Ez/48ePUb169RLVVpJt6ep9Le590aSwsBBOTk6IiIjQuNzR0bHM6y7KxsYGHTp0QIcOHWBsbIw1a9bg9OnTCAoKgrGxMfz8/HD06FHcuHEDKSkpaNWqFZydnZGXl4fTp0/j2LFj8PLyUqtHF8r6ffKqzy2OMrA7ODiUeR1ERBUFQzcREamE3JMnT6pcndnV1RU1a9ZEVFRUie+H3b9/fwwbNgx2dnbo0qVLqespev9wU1NT+Pv7S0fEjIyM0KxZM0RFRSE+Ph5OTk548803AQAxMTG4fv061qxZo3LhtP3792vcTt++ffHxxx8jNjYWGzduhIWFBbp37y4tr1OnDoBn4aokV/l+Xs2aNQE8u1DX865duwYHBwed3hLsRZT/iREfHw9vb2+trlvX76tScUdJ69SpgwMHDqBly5ZlDtSl1bRpU6xZswbJycnSWKtWrTB79mwcOHAADg4O8PLygkKhQIMGDXDs2DEcO3YM3bp1e+m6Nb1OR0dH2NjY4PLly1p9HWWh/D6/ceMG2rZtK43n5+cjISEBDRs2VHtOfHw8DAwMpH2XiOh1xtPLiYgIrq6ucHd3x8GDB3Hu3Dnp89NKAQEB2LFjB2JjY0t0Kuz777+PKVOm4Pvvvy/TvX+NjIyk+4dHRUVprOfo0aM4deqUyn8QKI/IFT0CJ4TA4sWLNW6nV69eMDQ0xPr167F582Z069ZNJQT7+vqiTp06mDdvnnRLp6Kev+XS86pVq4bGjRtjzZo1KreJunz5Mvbt21em/5DQFl9fX5iYmODcuXNaX7eu31cl5TqLvrfAs6uoFxQU4Ouvv1Z7Tn5+vtr8ksrKysLJkyc1Ltu9ezcA1Y8StGrVCjk5OVi0aBECAwOl8Ky8Evndu3dL9HluS0tLtZoNDAzQs2dP/P777xp7+CpHoUuradOmsLe3x08//YT8/HxpPCIiotjT18+fP48GDRpIH4cgInqd8Ug3EREBeHa0W3nLpefvQxwQEID169dL817G1tYWU6dOfeV6lBe80lTPzJkz1erx8vJCnTp1MGHCBNy5cwc2NjbYunVrsb/4Ozk5oW3btliwYAEyMjLQt29fleUGBgb4+eef0blzZzRo0ABDhgzBG2+8gTt37uDw4cOwsbHB77///sLXMXfuXHTu3Bn+/v4YOnQosrOzsXTpUq28R6/CzMwMHTt2xIEDBzB9+nStrrs83lfgWXgHnt2mrVOnTjA0NES/fv0QFBSEkSNHYubMmYiOjkbHjh1hbGyMuLg4bN68GYsXL8b7779f6teVlZWFgIAAtGjRAm+//Tbc3NyQmpqKHTt24NixY+jZsyd8fHyk+f7+/jAyMkJsbCxGjBghjbdu3RrLly8HgBKFbl9fXxw4cAALFiyQ/oPMz88PM2bMwL59+xAUFIQRI0agXr16SE5OxubNm3H8+HHY2dmV+jWWhYmJCaZOnYrPPvsM7dq1Q58+fZCQkIDw8HDUqVNH7Uh9Xl4e/vzzT3z88cflUh8Rkb7xSDcREQH4v/D6xhtvSKeLKhUNvWW56NOr1KM8nbyogIAA6Rf5ovUYGxvj999/R+PGjTFz5kxMmzYNnp6eWLt2bbHb6du3LzIyMmBtba3xyHObNm1w8uRJNG3aFN999x0+++wzhIeHw8XFBWPHjn3p6wgODsaePXtgb2+PyZMnY968eWjRogWioqJKfQEvbfvwww9x6tQp3Lp1S+vr1vX7CgDvvfcePvvsM+zZswcDBw5ESEiItGzFihX48ccfcf/+fXz55ZcICwvDoUOHMGDAALX/xCkpOzs7/PTTT3BxccHq1avx8ccfY9KkScjMzMTcuXOli8cpWVpaSiG86PepMmi7ubmp7WuaLFiwAL6+vvjqq68QEhIiBfY33ngDp0+fxvvvv4+IiAiMHj0aa9euRZs2bV76ERBt+/TTT7FkyRIkJSVhwoQJOHbsGCIjI2FnZwczMzOVuQcPHsSjR48waNCgcq2RiEhfFKI8zz8iIiIi2SgoKED9+vXRp08fjadiE72KwsJCODo64r333sNPP/0kjffs2RMKhQLbt2/XY3VEROWHR7qJiIgqKUNDQ0yfPh3Lli3T+NlqopJ6+vSp2ufI165di0ePHqFNmzbS2NWrV/HHH3/wP3mIqFLhkW4iIiIieiVHjhzB2LFj0bt3b9jb2+PChQtYuXIl6tWrh/Pnz5fpgopERK8LXkiNiIiIiF5JrVq14ObmhiVLluDRo0eoWrUqQkNDMWvWLAZuIqr0eKSbiIiIiIiISEf4mW4iIiIiIiIiHWHoJiIiIiIiItIRfqZbg8LCQty9exfW1tbSfWCJiIiIiIiIlIQQyMjIgKurKwwMij+ezdCtwd27d+Hm5qbvMoiIiIiIiEjmbt26herVqxe7nKFbA2trawDP3jwbGxs9V1O8vLw87Nu3Dx07doSxsbG+y6Ei2Bv5Ym/kjf2RL/ZGvtgbeWN/5Iu9kbeK0J/09HS4ublJ+bE4DN0aKE8pt7GxkX3otrCwgI2NjWy/ESsr9ka+2Bt5Y3/ki72RL/ZG3tgf+WJv5K0i9edlH0nmhdSIiIiIiIiIdIRHuum18mfCnzgYf1DfZaCgoAA3km/gzJ9nYGhoqO9yqAj2Rt7k1J/27u0RVCtIrzUQERFRxcfQTa+Vdze+i8dPH+u7jP9zT98FULHYG3mTQX++O/MdHk18pO8yiIiIqIJj6KbXijJwf9j4Q1gYW+itjsLCQiQkJqBWzVovvH0AlT/2Rt7k0J8neU+wOno1Up+m6mX7RERE9Hph6KbXhhBC+vus4FlwtHTUWy15eXnYtWsXunTqIvsLP1Q27I28yaE/9zLvYXX0aggICCFeenEUIiIiohfhYR56bRSKQunvBgp+axNR2RT9+SEgXjCTiIiI6OWYTOi1wdBNRNpQ9OdH0Z8rRERERGVR4ZLJ0aNH0b17d7i6ukKhUGDHjh0qy4UQmDx5MqpVqwZzc3MEBwcjLi5OP8VSuWLoJiJtYOgmIiIibapwyeTJkydo1KgRli1bpnH5nDlzsGTJEqxYsQKnT5+GpaUlOnXqhKdPn5ZzpVTeGLqJSBsMDf7vVmUM3URERPSqKtyF1Dp37ozOnTtrXCaEwKJFi/DVV1/hnXfeAQCsXbsWzs7O2LFjB/r161eepVI5K/rLcdFfmomISoNHuomIiEibKlzofpH4+HikpKQgODhYGrO1tYWfnx9OnjxZbOjOyclBTk6O9Dg9PR3As6vo5uXl6bboV6CsTc41lqec3P/rYUF+AfKgv/eFvZEv9kbe5NCfgvwC6e85uTkwBq9yD8ijN6QZeyNv7I98sTfyVhH6U9LaXqvQnZKSAgBwdnZWGXd2dpaWaTJz5kxMmzZNbXzfvn2wsNDfvZ5Lav/+/fouQRaeFDyR/r53z14YG+j/F2X2Rr7YG3nTZ39yC3Olv+/ZuwcWhvL/d6A8cd+RL/ZG3tgf+WJv5E3O/cnKyirRvNcqdJdVWFgYxo0bJz1OT0+Hm5sbOnbsCBsbGz1W9mJ5eXnYv38/OnTowPsNA3ic/RiIefb3rl26wshAf9/e7I18sTfyJof+5BbkApee/T24QzDszOz0UofcyKE3pBl7I2/sj3yxN/JWEfqjPEP6ZV6r0O3i4gIAuHfvHqpVqyaN37t3D40bNy72eaampjA1NVUbNzY2lm2Di6oodeqaYd7/fY7b1MRUFhdTY2/ki72RN332R2GokP5uaGTI75PncN+RL/ZG3tgf+WJv5E3O/SlpXfpPJVrk7u4OFxcXHDx4UBpLT0/H6dOn4e/vr8fKqDwUveCRAooXzCQiKh4vpEZERETaVOGOdGdmZuLGjRvS4/j4eERHR6Nq1aqoUaMGxowZg2+++Qaenp5wd3fHpEmT4Orqip49e+qvaCoXyl+OFVBAoWDoJqKyKfqfdgzdRERE9KoqXOg+d+4c2rZtKz1WfhZ70KBBCA8Px3//+188efIEI0aMQGpqKgIDA7Fnzx6YmZnpq2QqJ8pfjuVwWjkRVVwKhQIKKCAgGLqJiIjolVW40N2mTRsIIYpdrlAoMH36dEyfPr0cqyI5YOgmIm0xUBigQBQwdBMREdErK1PoTk1Nxfbt23Hs2DEkJiYiKysLjo6O8PHxQadOnRAQEKDtOoleiqGbiLSFoZuIiIi0pVTp5O7duxg2bBiqVauGb775BtnZ2WjcuDHat2+P6tWr4/Dhw+jQoQPq16+PjRs36qpmIo0YuolIW5Q/Rxi6iYiI6FWV6ki3j48PBg0ahPPnz6N+/foa52RnZ2PHjh1YtGgRbt26hQkTJmilUKKXYegmIm1h6CYiIiJtKVXovnLlCuzt7V84x9zcHCEhIQgJCcHDhw9fqTii0mDoJiJtYegmIiIibSlVOrG3t8cff/yBwsKS/RLysoBOpE0M3USkLQzdREREpC2lTic9e/aEm5sb/ve//6ncL5tI3xi6iUhbGLqJiIhIW0qdTuLj4zFy5Ehs2LABdevWRVBQENatW4fs7Gxd1EdUYgzdRKQtDN1ERESkLaVOJ25ubpg8eTJu3ryJAwcOoFatWvjoo49QrVo1jBo1CmfPntVFnUQvxdBNRNrC0E1ERETa8krppG3btlizZg2Sk5Mxd+5cxMTEoEWLFmjUqJG26iMqMYZuItIWhm4iIiLSllJdvbw41tbWaN++PRITE3Ht2jVcuXJFG6slKhWGbiLSFoZuIiIi0pZXSifZ2dlYu3Yt2rRpA09PT2zYsAHjxo1DQkKClsojKrkCUQCAoZuIXp3y50hBYYGeKyEiIqKKrkxHuk+dOoVVq1Zh06ZNyM3NxXvvvYcDBw6gbdu22q6PqMR4pJuItIVHuomIiEhbSh2669evj9jYWPj4+GDmzJno378/bG1tdVEbUakwdBORtjB0ExERkbaUOnQHBwdj/fr1vFgayQ5DNxFpC0M3ERERaUupQ/eSJUt0UQfRK2PoJiJtYegmIiIibSlVOnn77bdx6tSpl87LyMjA7NmzsWzZsjIXRlRaDN1EpC2GBoYAGLqJiIjo1ZXqSHfv3r3Rq1cv2Nraonv37mjatClcXV1hZmaGx48f48qVKzh+/Dh27dqFrl27Yu7cubqqm0gNQzcRaQuPdBMREZG2lCp0Dx06FAMGDMDmzZuxceNG/Pjjj0hLSwMAKBQK1K9fH506dcLZs2dRr149nRRMVByGbiLSFoZuIiIi0pZSf6bb1NQUAwYMwIABAwAAaWlpyM7Ohr29PYyNjbVeIFFJMXQTkbYwdBMREZG2lOk+3UXZ2trylmEkCwzdRKQtDN1ERESkLUwn9Npg6CYibWHoJiIiIm1hOqHXBkM3EWkLQzcRERFpC9MJvTYYuolIWxi6iYiISFuYTui1wdBNRNrC0E1ERETa8krpJDU1FT///DPCwsLw6NEjAMCFCxdw584drRRHVBrKX44NDQz1XAkRVXQM3URERKQtZb56+aVLlxAcHAxbW1skJCRg+PDhqFq1KrZt24akpCSsXbtWm3USvRSPdBORtjB0ExERkbaUOZ2MGzcOgwcPRlxcHMzMzKTxLl264OjRo1opjqg0GLqJSFsYuomIiEhbypxOzp49i5EjR6qNv/HGG0hJSXmloojKgqGbiLSFoZuIiIi0pczpxNTUFOnp6Wrj169fh6Oj4ysVRVQWDN1EpC0M3URERKQtZU4nPXr0wPTp05GXlwcAUCgUSEpKwsSJE9GrVy+tFUhUUgzdRKQtDN1ERESkLWVOJ/Pnz0dmZiacnJyQnZ2NoKAgeHh4wNraGt9++602ayQqEYZuItIWhm4iIiLSljJfvdzW1hb79+/H8ePHcenSJWRmZqJJkyYIDg7WZn1EJcbQTUTawtBNRERE2lLm0K0UGBiIwMBAbdSidcuWLcPcuXORkpKCRo0aYenSpWjevLm+yyIdYegmIm1h6CYiIiJtKXPoXrJkicZxhUIBMzMzeHh4oHXr1jA0NCxzca9i48aNGDduHFasWAE/Pz8sWrQInTp1QmxsLJycnPRSE+kWQzcRaQtDNxEREWlLmUP3woUL8e+//yIrKwtVqlQBADx+/BgWFhawsrLC/fv3Ubt2bRw+fBhubm5aK7ikFixYgOHDh2PIkCEAgBUrVmDnzp1YtWoVvvjii3Kvh3SPoZuItIWhm4iIiLSlzOlkxowZaNasGeLi4vDw4UM8fPgQ169fh5+fHxYvXoykpCS4uLhg7Nix2qy3RHJzc3H+/HmVz5cbGBggODgYJ0+eLPd6qHwwdBORtjB0ExERkbaU+Uj3V199ha1bt6JOnTrSmIeHB+bNm4devXrhn3/+wZw5c/Ry+7AHDx6goKAAzs7OKuPOzs64du2a2vycnBzk5ORIj5X3H8/Ly5NuiSZHytrkXGN5ys3LffYXof/3hL2RL/ZG3mTTH/Hsj9z8XP3XIhOy6Q2pYW/kjf2RL/ZG3ipCf0paW5lDd3JyMvLz89XG8/PzkZKSAgBwdXVFRkZGWTdRbmbOnIlp06apje/btw8WFhZ6qKh09u/fr+8SZOHSg0sAgPv37mPXrl16ruYZ9ka+2Bt503d//r3/LwDgUswl7EqWx88TudB3b6h47I28sT/yxd7Im5z7k5WVVaJ5ZQ7dbdu2xciRI/Hzzz/Dx8cHAHDx4kV89NFHaNeuHQAgJiYG7u7uZd1EmTk4OMDQ0BD37t1TGb937x5cXFzU5oeFhWHcuHHS4/T0dLi5uaFjx46wsbHReb1llZeXh/3796NDhw4wNjbWdzl6l3guEbgNuFZzRZcuXfRaC3sjX+yNvMmlP+Fbw4E0oH6D+ujiq9+fJ3Ihl96QOvZG3tgf+WJv5K0i9Ed5hvTLlDl0r1y5EgMHDoSvr6/0JuTn56N9+/ZYuXIlAMDKygrz588v6ybKzMTEBL6+vjh48CB69uwJACgsLMTBgwfx6aefqs03NTWFqamp2rixsbFsG1xURalT1xQGCgCAkaGRbN4P9ka+2Bt503d/jAyf/fOoMFDw++Q5+u4NFY+9kTf2R77YG3mTc39KWleZQ7eLiwv279+Pa9eu4fr16wCAunXrom7dutKctm3blnX1r2zcuHEYNGgQmjZtiubNm2PRokV48uSJdDVzev3wQmpEpC2Gime3u+SF1IiIiOhVlTl0K3l5ecHLy0sbtWhV37598e+//2Ly5MlISUlB48aNsWfPHrWLq9Hrg6GbiLSFVy8nIiIibXml0H379m1ERkYiKSkJubm5KssWLFjwSoVpw6effqrxdHJ6PTF0E5G2MHQTERGRtpQ5dB88eBA9evRA7dq1ce3aNbz11ltISEiAEAJNmjTRZo1EJcLQTUTawtBNRERE2lLmdBIWFoYJEyYgJiYGZmZm2Lp1K27duoWgoCD07t1bmzUSlQhDNxFpC0M3ERERaUuZ08nVq1cRGhoKADAyMkJ2djasrKwwffp0zJ49W2sFEpWUFLrL/m1NRASAoZuIiIi0p8zpxNLSUvocd7Vq1XDz5k1p2YMHD169MqJS4pFuItIWhm4iIiLSljJ/prtFixY4fvw46tWrhy5dumD8+PGIiYnBtm3b0KJFC23WSFQiDN1EpC0M3URERKQtZQ7dCxYsQGZmJgBg2rRpyMzMxMaNG+Hp6SmLK5dT5cPQTUTawtBNRERE2lLm0F27dm3p75aWllixYoVWCiIqK4ZuItIWhm4iIiLSljKnk9q1a+Phw4dq46mpqSqBnKi8MHQTkbYwdBMREZG2lDmdJCQkoKCgQG08JycHd+7ceaWiiMqCoZuItIWhm4iIiLSl1KeXR0ZGSn/fu3cvbG1tpccFBQU4ePAgatWqpZXiiEqDoZuItIWhm4iIiLSl1KG7Z8+eAACFQoFBgwapLDM2NkatWrUwf/58rRRHVBoM3USkLQzdREREpC2lDt2Fhc9+AXF3d8fZs2fh4OCg9aKIyoKhm4i0haGbiIiItKXMVy+Pj4/XZh1Er4yhm4i0haGbiIiItKVUoXvJkiUlnjt69OhSF0P0Khi6iUhbGLqJiIhIW0oVuhcuXFiieQqFgqGbyh1DNxFpC0M3ERERaUupQjdPKSc5U/5ybGhgqOdKiKiiY+gmIiIibdHKIUEhBIQQ2lgVUZnxSDcRaQtDNxEREWnLK6WTtWvXwtvbG+bm5jA3N0fDhg2xbt06bdVGVCoM3USkLQzdREREpC1lvnr5ggULMGnSJHz66ado2bIlAOD48eMYNWoUHjx4gLFjx2qtSKKSKBAFABi6iejVKX+OFBQW6LkSIiIiqujKHLqXLl2K5cuXIzQ0VBrr0aMHGjRogKlTpzJ0U7njkW4i0hYe6SYiIiJtKXM6SU5ORkBAgNp4QEAAkpOTX6koorJg6CYibWHoJiIiIm0pczrx8PDApk2b1MY3btwIT0/PVyqKqCwYuolIW6TQDYZuIiIiejVlPr182rRp6Nu3L44ePSp9pjsqKgoHDx7UGMaJdI2hm4i0xVDx7NaDPNJNREREr6rU6eTy5csAgF69euH06dNwcHDAjh07sGPHDjg4OODMmTN49913tV4o0cswdBORtvD0ciIiItKWUh/pbtiwIZo1a4Zhw4ahX79++OWXX3RRF1GpMXQTkbYwdBMREZG2lDqd/Pnnn2jQoAHGjx+PatWqYfDgwTh27JguaiMqFYZuItIWhm4iIiLSllKnk1atWmHVqlVITk7G0qVLER8fj6CgILz55puYPXs2UlJSdFEn0UsxdBORtjB0ExERkbaUOZ1YWlpiyJAh+PPPP3H9+nX07t0by5YtQ40aNdCjRw9t1khUIgzdRKQtDN1ERESkLVpJJx4eHvjyyy/x1VdfwdraGjt37tTGaolKhaGbiLSFoZuIiIi0pcy3DFM6evQoVq1aha1bt8LAwAB9+vTB0KFDtVEbUakwdBORtjB0ExERkbaUKXTfvXsX4eHhCA8Px40bNxAQEIAlS5agT58+sLS01HaNRCXC0E1E2sLQTURERNpS6tDduXNnHDhwAA4ODggNDcWHH36IunXr6qI2olJh6CYibWHoJiIiIm0pdToxNjbGli1bcPv2bcyePbvcA/e3336LgIAAWFhYwM7OTuOcpKQkdO3aFRYWFnBycsLnn3+O/Pz8cq2Tyh9DNxFpC0M3ERERaUupj3RHRkbqoo4Sy83NRe/eveHv74+VK1eqLS8oKEDXrl3h4uKCEydOIDk5GaGhoTA2NsaMGTP0UDGVF4ZuItIWhm4iIiLSlgqXTqZNm4axY8fC29tb4/J9+/bhypUr+OWXX9C4cWN07twZX3/9NZYtW4bc3NxyrpbKE0M3EWkLQzcRERFpy2uXTk6ePAlvb284OztLY506dUJ6ejr+/vtvPVZGusbQTUTawtBNRERE2vLKtwyTm5SUFJXADUB6nJKSovE5OTk5yMnJkR6np6cDAPLy8pCXl6ejSl+dsjY511ieCgoLAACFBYV6f0/YG/lib+RNLv0pLHwWtgsKCvRei1zIpTekjr2RN/ZHvtgbeasI/SlpbbII3V988QVmz579wjlXr16Fl5eXTrY/c+ZMTJs2TW183759sLCw0Mk2tWn//v36LkEW/n3wLwDgr+i/YJ1oredqnmFv5Iu9kTd99+fS40sAgH8f/otdu3bptRa50XdvqHjsjbyxP/LF3sibnPuTlZVVonmyCN3jx4/H4MGDXzindu3aJVqXi4sLzpw5ozJ27949aZkmYWFhGDdunPQ4PT0dbm5u6NixI2xsbEq0XX3Iy8vD/v370aFDBxgbG+u7HL2bt24e8ATwbeKLLvW66LUW9ka+2Bt5k0t/sq5mAYlAlSpV0KWLfn+eyIVcekPq2Bt5Y3/ki72Rt4rQH+UZ0i8ji9Dt6OgIR0dHrazL398f3377Le7fvw8nJycAz/53xMbGBvXr19f4HFNTU5iamqqNGxsby7bBRVWUOnVNQAAATIxNZPN+sDfyxd7Im777Y2JkAgAQCsHvk+fouzdUPPZG3tgf+WJv5E3O/SlpXbII3aWRlJSER48eISkpCQUFBYiOjgYAeHh4wMrKCh07dkT9+vUxcOBAzJkzBykpKfjqq6/wySefaAzW9PrghdSISFt4ITUiIiLSlgoXuidPnow1a9ZIj318fAAAhw8fRps2bWBoaIg//vgDH330Efz9/WFpaYlBgwZh+vTp+iqZyglDNxFpC0M3ERERaUuFC93h4eEIDw9/4ZyaNWvywjeVEEM3EWkLQzcRERFpC9MJvTYKxLNbhjF0E9GrUv4cUd6KkIiIiKisKtyRbnpm7429OBx/GDeTb+LkkZMwNDDUd0l6dyf9DgCGbiJ6dcqfI7fTb+N/B/+n52rkoaCwgP/myBR7I2/sj3yxN/JWUFiA3Ee56IKKfxcRhu4K6nDCYcw+8f/vbX5Pv7XIjbWJPO7RTUQVl43ps9tF3ntyDzOOz9BzNTLDf3Pki72RN/ZHvtgb2fKz9dN3CVrB0F1BtXRric+afYb4+Hi4u7vDwIBHdwGgpm1N+Lv567sMIqrg/N38saDjAiSmJeq7FNkoLCzkvzkyxd7IG/sjX+yNvBUWFqIw5fW4tgpDdwXVvW53vF37bezatQtdOnSR7b3riIgqIgOFAcb6j9V3GbKSl5fHf3Nkir2RN/ZHvtgbeVP253XA/9IhIiIiIiIi0hGGbiIiIiIiIiId4enlGgghAADp6el6ruTF8vLykJWVhfT0dJ4SIzPsjXyxN/LG/sgXeyNf7I28sT/yxd7IW0XojzIvKvNjcRi6NcjIyAAAuLm56bkSIiIiIiIikrOMjAzY2toWu1whXhbLK6HCwkLcvXsX1tbWUCgU+i6nWOnp6XBzc8OtW7dgY2Oj73KoCPZGvtgbeWN/5Iu9kS/2Rt7YH/lib+StIvRHCIGMjAy4urq+8Ar4PNKtgYGBAapXr67vMkrMxsZGtt+IlR17I1/sjbyxP/LF3sgXeyNv7I98sTfyJvf+vOgItxIvpEZERERERESkIwzdRERERERERDrC0F2BmZqaYsqUKTA1NdV3KfQc9ka+2Bt5Y3/ki72RL/ZG3tgf+WJv5O116g8vpEZERERERESkIzzSTURERERERKQjDN1EREREREREOsLQTURERERERKQjDN3lZNmyZahVqxbMzMzg5+eHM2fOvHD+5s2b4eXlBTMzM3h7e2PXrl0qy4UQmDx5MqpVqwZzc3MEBwcjLi5OZc6jR4/wwQcfwMbGBnZ2dhg6dCgyMzNV5ly6dAmtWrWCmZkZ3NzcMGfOHO284AqmvPuTkJCAoUOHwt3dHebm5qhTpw6mTJmC3NxclTkKhULt69SpU9p98TKnj32nVq1aau/7rFmzVOZw3yn/3hw5ckTjPqFQKHD27FkA3G+K0nZ/tm3bho4dO8Le3h4KhQLR0dFq63j69Ck++eQT2Nvbw8rKCr169cK9e/dU5iQlJaFr166wsLCAk5MTPv/8c+Tn57/y661Iyrs3jx49wmeffYa6devC3NwcNWrUwOjRo5GWlqYyT9O+s2HDBq285opEH/tOmzZt1N77UaNGqczhvlP+vSnu3xSFQoHNmzdL87jvaLc3eXl5mDhxIry9vWFpaQlXV1eEhobi7t27KuuoUFlHkM5t2LBBmJiYiFWrVom///5bDB8+XNjZ2Yl79+5pnB8VFSUMDQ3FnDlzxJUrV8RXX30ljI2NRUxMjDRn1qxZwtbWVuzYsUP89ddfokePHsLd3V1kZ2dLc95++23RqFEjcerUKXHs2DHh4eEhQkJCpOVpaWnC2dlZfPDBB+Ly5cti/fr1wtzcXPzwww+6ezNkSB/92b17txg8eLDYu3evuHnzpvjtt9+Ek5OTGD9+vLSO+Ph4AUAcOHBAJCcnS1+5ubm6fUNkRF/7Ts2aNcX06dNV3vfMzExpOfcd/fQmJydHpSfJycli2LBhwt3dXRQWFgohuN8o6aI/a9euFdOmTRM//fSTACAuXryotp5Ro0YJNzc3cfDgQXHu3DnRokULERAQIC3Pz88Xb731lggODhYXL14Uu3btEg4ODiIsLEzr74Fc6aM3MTEx4r333hORkZHixo0b4uDBg8LT01P06tVLZR4AsXr1apV9p+jPxspAX/tOUFCQGD58uMp7n5aWJi3nvqOf3uTn56v9uzNt2jRhZWUlMjIypHmVfd/Rdm9SU1NFcHCw2Lhxo7h27Zo4efKkaN68ufD19VVZT0XKOgzd5aB58+bik08+kR4XFBQIV1dXMXPmTI3z+/TpI7p27aoy5ufnJ0aOHCmEEKKwsFC4uLiIuXPnSstTU1OFqampWL9+vRBCiCtXrggA4uzZs9Kc3bt3C4VCIe7cuSOEEOL7778XVapUETk5OdKciRMnirp1677iK65Y9NEfTebMmSPc3d2lx8rwoOkf58pCX72pWbOmWLhwYbF1cd+Rx36Tm5srHB0dxfTp06Ux7jfPaLs/RRX3HqempgpjY2OxefNmaezq1asCgDh58qQQQohdu3YJAwMDkZKSIs1Zvny5sLGxUdmfXmf66I0mmzZtEiYmJiIvL08aAyC2b99eshfymtJXf4KCgsR//vOfYuviviOffadx48biww8/VBmr7PuOLnujdObMGQFAJCYmCiEqXtbh6eU6lpubi/PnzyM4OFgaMzAwQHBwME6ePKnxOSdPnlSZDwCdOnWS5sfHxyMlJUVljq2tLfz8/KQ5J0+ehJ2dHZo2bSrNCQ4OhoGBAU6fPi3Nad26NUxMTFS2Exsbi8ePH7/iK68Y9NUfTdLS0lC1alW18R49esDJyQmBgYGIjIws1euryPTdm1mzZsHe3h4+Pj6YO3euyil8lX3f0XdvlCIjI/Hw4UMMGTJEbVll3W8A3fSnJM6fP4+8vDyV9Xh5eaFGjRoq/zZ5e3vD2dlZZTvp6en4+++/S7ytikpfvdEkLS0NNjY2MDIyUhn/5JNP4ODggObNm2PVqlUQlejOsvruT0REBBwcHPDWW28hLCwMWVlZKtvhvqP/fef8+fOIjo7G0KFD1ZZV1n2nvHqTlpYGhUIBOzs7aR0VKesYvXwKvYoHDx6goKBA5YckADg7O+PatWsan5OSkqJxfkpKirRcOfaiOU5OTirLjYyMULVqVZU57u7uautQLqtSpUqJX2dFpa/+PO/GjRtYunQp5s2bJ41ZWVlh/vz5aNmyJQwMDLB161b07NkTO3bsQI8ePUr3QisgffZm9OjRaNKkCapWrYoTJ04gLCwMycnJWLBggbSeyrzvyGW/WblyJTp16oTq1atLY5V9vwF005+SSElJgYmJifQLkab1FLcd5bLXnb56o6mOr7/+GiNGjFAZnz59Otq1awcLCwvs27cPH3/8MTIzMzF69Ogyb6si0Wd/+vfvj5o1a8LV1RWXLl3CxIkTERsbi23btr1wO8plrzu57DsrV65EvXr1EBAQoDJemfed8ujN06dPMXHiRISEhMDGxkZaR0XKOgzdRHp2584dvP322+jduzeGDx8ujTs4OGDcuHHS42bNmuHu3buYO3dupQkP+lL0fW/YsCFMTEwwcuRIzJw5E6ampnqsjJRu376NvXv3YtOmTSrj3G+IXiw9PR1du3ZF/fr1MXXqVJVlkyZNkv7u4+ODJ0+eYO7cuZUiOOhb0f8A8fb2RrVq1dC+fXvcvHkTderU0WNlpJSdnY1ff/1VZT9R4r6jO3l5eejTpw+EEFi+fLm+yykznl6uYw4ODjA0NFS7euu9e/fg4uKi8TkuLi4vnK/882Vz7t+/r7I8Pz8fjx49UpmjaR1Ft/G601d/lO7evYu2bdsiICAAP/7440vr9fPzw40bN14673Wg794U5efnh/z8fCQkJLxwO0W38TqTQ29Wr14Ne3v7EgXpyrTfALrpT0m4uLggNzcXqampxa6H+45+eqOUkZGBt99+G9bW1ti+fTuMjY1fON/Pzw+3b99GTk5OqbdVEem7P0X5+fkBgPSzi/uO/nuzZcsWZGVlITQ09KVzK9O+o8veKAN3YmIi9u/fLx3lVq6jImUdhm4dMzExga+vLw4ePCiNFRYW4uDBg/D399f4HH9/f5X5ALB//35pvru7O1xcXFTmpKen4/Tp09Icf39/pKam4vz589KcQ4cOobCwUPpB7u/vj6NHjyIvL09lO3Xr1n3tT49V0ld/gGdHuNu0aQNfX1+sXr0aBgYv3x2jo6NRrVq1Ur3GikqfvXledHQ0DAwMpNOYKvu+o+/eCCGwevVqhIaGvjQ0AJVrvwF005+S8PX1hbGxscp6YmNjkZSUpPJvU0xMjMovSspfpOrXr1/ibVVU+uoN8Gx/6tixI0xMTBAZGQkzM7OXPic6OhpVqlSpNGf46LM/z1Peukr5s4v7jv57s3LlSvTo0QOOjo4vnVuZ9h1d9UYZuOPi4nDgwAHY29urraNCZZ1yv3RbJbRhwwZhamoqwsPDxZUrV8SIESOEnZ2ddAXKgQMHii+++EKaHxUVJYyMjMS8efPE1atXxZQpUzTeWsfOzk789ttv4tKlS+Kdd97ReMswHx8fcfr0aXH8+HHh6empchn91NRU4ezsLAYOHCguX74sNmzYICwsLCrVbY+E0E9/bt++LTw8PET79u3F7du3VW4xoRQeHi5+/fVXcfXqVXH16lXx7bffCgMDA7Fq1apyemf0Tx+9OXHihFi4cKGIjo4WN2/eFL/88otwdHQUoaGh0jq47+jv55oQQhw4cEAAEFevXlWri/vNM7roz8OHD8XFixfFzp07BQCxYcMGcfHiRZWfW6NGjRI1atQQhw4dEufOnRP+/v7C399fWq687VHHjh1FdHS02LNnj3B0dKx0tz0q796kpaUJPz8/4e3tLW7cuKHyb05+fr4QQojIyEjx008/iZiYGBEXFye+//57YWFhISZPnlyO747+6aM/N27cENOnTxfnzp0T8fHx4rfffhO1a9cWrVu3ltbBfUd/P9eEECIuLk4oFAqxe/dutbq472i/N7m5uaJHjx6ievXqIjo6WuVnVtErkVekrMPQXU6WLl0qatSoIUxMTETz5s3FqVOnpGVBQUFi0KBBKvM3bdok3nzzTWFiYiIaNGggdu7cqbK8sLBQTJo0STg7OwtTU1PRvn17ERsbqzLn4cOHIiQkRFhZWQkbGxsxZMgQlXsKCiHEX3/9JQIDA4Wpqal44403xKxZs7T7wiuI8u7P6tWrBQCNX0rh4eGiXr16wsLCQtjY2IjmzZur3Iqnsijv3pw/f174+fkJW1tbYWZmJurVqydmzJghnj59qrIe7jv6+bkmhBAhISEq934uivvN/9F2f4r7uTVlyhRpTnZ2tvj4449FlSpVhIWFhXj33XfVfnlNSEgQnTt3Fubm5sLBwUGMHz9e5bZVlUF59+bw4cPF/psTHx8vhHh2q53GjRsLKysrYWlpKRo1aiRWrFghCgoKdPlWyFJ59ycpKUm0bt1aVK1aVZiamgoPDw/x+eefq9ynWwjuO0Lo5+eaEEKEhYUJNzc3jfsD951ntNkb5S3cNH0dPnxYmleRso5CiEpyPXsiIiIiIiKicsbPdBMRERERERHpCEM3ERERERERkY4wdBMRERERERHpCEM3ERERERERkY4wdBMRERERERHpCEM3ERERERERkY4wdBMRERERERHpCEM3ERERERERkY4wdBMRERERERHpCEM3ERHRa2zw4MHo2bOn3rY/cOBAzJgxo0Rz+/Xrh/nz5+u4IiIiovKlEEIIfRdBREREpadQKF64fMqUKRg7diyEELCzsyufoor466+/0K5dOyQmJsLKyuql8y9fvozWrVsjPj4etra25VAhERGR7jF0ExERVVApKSnS3zdu3IjJkycjNjZWGrOysipR2NWVYcOGwcjICCtWrCjxc5o1a4bBgwfjk08+0WFlRERE5YenlxMREVVQLi4u0petrS0UCoXKmJWVldrp5W3atMFnn32GMWPGoEqVKnB2dsZPP/2EJ0+eYMiQIbC2toaHhwd2796tsq3Lly+jc+fOsLKygrOzMwYOHIgHDx4UW1tBQQG2bNmC7t27q4x///338PT0hJmZGZydnfH++++rLO/evTs2bNjw6m8OERGRTDB0ExERVTJr1qyBg4MDzpw5g88++wwfffQRevfujYCAAFy4cAEdO3bEwIEDkZWVBQBITU1Fu3bt4OPjg3PnzmHPnj24d+8e+vTpU+w2Ll26hLS0NDRt2lQaO3fuHEaPHo3p06cjNjYWe/bsQevWrVWe17x5c5w5cwY5OTm6efFERETljKGbiIiokmnUqBG++uoreHp6IiwsDGZmZnBwcMDw4cPh6emJyZMn4+HDh7h06RIA4LvvvoOPjw9mzJgBLy8v+Pj4YNWqVTh8+DCuX7+ucRuJiYkwNDSEk5OTNJaUlARLS0t069YNNWvWhI+PD0aPHq3yPFdXV+Tm5qqcOk9ERFSRMXQTERFVMg0bNpT+bmhoCHt7e3h7e0tjzs7OAID79+8DeHZBtMOHD0ufEbeysoKXlxcA4ObNmxq3kZ2dDVNTU5WLvXXo0AE1a9ZE7dq1MXDgQEREREhH05XMzc0BQG2ciIioomLoJiIiqmSMjY1VHisUCpUxZVAuLCwEAGRmZqJ79+6Ijo5W+YqLi1M7PVzJwcEBWVlZyM3Nlcasra1x4cIFrF+/HtWqVcPkyZPRqFEjpKamSnMePXoEAHB0dNTKayUiItI3hm4iIiJ6oSZNmuDvv/9GrVq14OHhofJlaWmp8TmNGzcGAFy5ckVl3MjICMHBwZgzZw4uXbqEhIQEHDp0SFp++fJlVK9eHQ4ODjp7PUREROWJoZuIiIhe6JNPPsGjR48QEhKCs2fP4ubNm9i7dy+GDBmCgoICjc9xdHREkyZNcPz4cWnsjz/+wJIlSxAdHY3ExESsXbsWhYWFqFu3rjTn2LFj6Nixo85fExERUXlh6CYiIqIXcnV1RVRUFAoKCtCxY0d4e3tjzJgxsLOzg4FB8b9KDBs2DBEREdJjOzs7bNu2De3atUO9evWwYsUKrF+/Hg0aNAAAPH36FDt27MDw4cN1/pqIiIjKi0IIIfRdBBEREb1+srOzUbduXWzcuBH+/v4vnb98+XJs374d+/btK4fqiIiIygePdBMREZFOmJubY+3atXjw4EGJ5hsbG2Pp0qU6roqIiKh88Ug3ERERERERkY7wSDcRERERERGRjjB0ExEREREREekIQzcRERERERGRjjB0ExEREREREekIQzcRERERERGRjjB0ExEREREREekIQzcRERERERGRjjB0ExEREREREekIQzcRERERERGRjjB0ExEREREREekIQzcRERERERGRjjB0ExEREREREekIQzcRERERERGRjjB0ExEREREREekIQzcREZHMzZ07F7Vr14ahoSEaN26s73JKpEuXLhg+fLi+y9CqI0eOQKFQYMuWLfouRaMvvvgCfn5++i6DiIiew9BNRER69/3330OhULw0MNy7dw8TJkyAl5cXLCwsYGlpCV9fX3zzzTdITU0t9nlz5syBQqHAxYsXVcaFEKhSpQoUCgXi4+NVlj19+hSmpqbo379/mV+XNuzbtw///e9/0bJlS6xevRozZszQaz0lERUVhX379mHixIlqy5KSkjBq1CjUqlULpqamcHJyQs+ePREVFaWHSp9Rhmnll7GxMWrXro3Q0FD8888/equrtMaMGYO//voLkZGR+i6FiIiKMNJ3AURERBEREahVqxbOnDmDGzduwMPDQ23O2bNn0aVLF2RmZmLAgAHw9fUFAJw7dw6zZs3C0aNHsW/fPo3rDwwMBAAcP34cPj4+0vjff/+N1NRUGBkZISoqCu7u7irby83NlZ6rL4cOHYKBgQFWrlwJExMTvdZSUnPnzkX79u3V+hgVFYUuXboAAIYNG4b69esjJSUF4eHhaNWqFRYvXozPPvtMHyUDAEaPHo1mzZohLy8PFy5cwI8//oidO3ciJiYGrq6uequrpFxcXPDOO+9g3rx56NGjh77LISKi/49HuomISK/i4+Nx4sQJLFiwAI6OjoiIiFCbk5qainfffReGhoa4ePEifvrpJ4waNQqjRo3Czz//jJs3b6J169bFbqNp06YwMzPD8ePHVcajoqJgb2+P9u3bqy1TPtZ36L5//z7Mzc21FriFEMjOztbKujS5f/8+du7ciT59+qiMP378GO+//z7Mzc1x4cIFzJ8/H0OHDsX//vc/XLp0CYGBgRgzZgxOnDihs9peplWrVhgwYACGDBmCpUuXYt68eXj06BHWrFmjt5pKq0+fPjh+/HiFOkJPRPS6Y+gmIiK9ioiIQJUqVdC1a1e8//77GkP3Dz/8gDt37mDBggXw8vJSW+7s7Iyvvvqq2G2YmJigWbNmaqcwR0VFwd/fHy1bttS4zM7ODm+99RYAYN68eQgICIC9vT3Mzc3h6+ur9tnet956C23btlXbfmFhId544w28//77KmOLFi1CgwYNYGZmBmdnZ4wcORKPHz+W5igUCqxevRpPnjyRTn0ODw8HAOTn5+Prr79GnTp1YGpqilq1auHLL79ETk6OyrZr1aqFbt26Ye/evWjatCnMzc3xww8/SKdUb9q0CdOmTcMbb7wBa2trvP/++0hLS0NOTg7GjBkDJycnWFlZYciQIWrr1mTnzp3Iz89HcHCwyvgPP/yAlJQUzJ07F3Xq1FFZZm5ujjVr1kChUGD69OnSeHh4OBQKBaKiojBu3Dg4OjrC0tIS7777Lv7991+1be/evRutWrWCpaUlrK2t0bVrV/z9998vrbk47dq1AwC1jx4UFhbi22+/RfXq1WFmZob27dvjxo0bKnOOHTuG3r17o0aNGjA1NYWbmxvGjh2r9h8eKSkpGDJkCKpXrw5TU1NUq1YN77zzDhISEsr02pTv+2+//Vbm101ERNrF0E1ERHoVERGB9957DyYmJggJCUFcXBzOnj2rMicyMhLm5uYqobW0AgMDcefOHZUwExUVhYCAAAQEBEinmgPPjgafOHEC/v7+MDB49k/l4sWL4ePjg+nTp2PGjBkwMjJC7969sXPnTml9ffv2xdGjR5GSkqKy7ePHj+Pu3bvo16+fNDZy5Eh8/vnnaNmyJRYvXowhQ4YgIiICnTp1Ql5eHgBg3bp1aNWqFUxNTbFu3TqsW7dOOqI/bNgwTJ48GU2aNMHChQsRFBSEmTNnqmxDKTY2FiEhIejQoQMWL16scjG2mTNnYu/evfjiiy/w4YcfYtu2bRg1ahQ+/PBDXL9+HVOnTsV7772H8PBwzJ49+6Xv84kTJ2Bvb4+aNWuqjP/+++8wMzNTOwKu5O7ujsDAQBw6dEgtmH722Wf466+/MGXKFHz00Uf4/fff8emnn6rMWbduHbp27QorKyvMnj0bkyZNwpUrVxAYGKgWYEvq5s2bAAB7e3uV8VmzZmH79u2YMGECwsLCcOrUKXzwwQcqczZv3oysrCx89NFHWLp0KTp16oSlS5ciNDRUZV6vXr2wfft2DBkyBN9//z1Gjx6NjIwMJCUllem12draok6dOnr9jDwRET1HEBER6cm5c+cEALF//34hhBCFhYWievXq4j//+Y/KvCpVqohGjRq90rZ27twpAIh169YJIYRITk4WAMSff/4pMjIyhKGhodi5c6cQQojLly8LAOLbb7+Vnp+VlaWyvtzcXPHWW2+Jdu3aSWOxsbECgFi6dKnK3I8//lhYWVlJ6zh27JgAICIiIlTm7dmzR2180KBBwtLSUmVedHS0ACCGDRumMj5hwgQBQBw6dEgaq1mzpgAg9uzZozL38OHDAoB46623RG5urjQeEhIiFAqF6Ny5s8p8f39/UbNmTfEygYGBwtfXV23czs7upT0cPXq0ACAuXbokhBBi9erVAoAIDg4WhYWF0ryxY8cKQ0NDkZqaKoQQIiMjQ9jZ2Ynhw4errC8lJUXY2tqqjT9P+V6sWrVK/Pvvv+Lu3bti586dolatWkKhUIizZ8+qzKtXr57IycmRnr948WIBQMTExEhjz3+/CCHEzJkzhUKhEImJiUIIIR4/fiwAiLlz5xZbW1leW8eOHUW9evVe+JqJiKj88Eg3ERHpTUREBJydnaVTshUKBfr27YsNGzagoKBAmpeeng5ra+tX2lZAQAAMDAykz2pHRUXB2NgYzZo1g5WVFRo2bCgdHVT+WfTz3Obm5tLfHz9+jLS0NLRq1QoXLlyQxt988000btwYGzdulMYKCgqwZcsWdO/eXVrH5s2bYWtriw4dOuDBgwfSl6+vL6ysrHD48OEXvpZdu3YBAMaNG6cyPn78eABQOfoOPDuK3KlTJ43rCg0NhbGxsfTYz88PQgh8+OGHKvP8/Pxw69Yt5Ofnv7C2hw8fokqVKmrjGRkZL+2hcnl6errK+IgRI6BQKKTHrVq1QkFBARITEwEA+/fvR2pqKkJCQlTeT0NDQ/j5+b30/VT68MMP4ejoCFdXV3Tt2hVPnjzBmjVr0LRpU5V5Q4YMUfmMfatWrQBA5XPURb9fnjx5ggcPHiAgIABCCOkq+srP6h85ckTlYwVFleW1ValSBQ8ePCjRayYiIt3j1cuJiEgvCgoKsGHDBrRt21blM7N+fn6YP38+Dh48iI4dOwIAbGxskJGR8Urbs7OzQ4MGDVSCtY+PjxSOAgICVJaZmJigefPm0vP/+OMPfPPNN4iOjlb5bHPRMAg8O8X8yy+/xJ07d/DGG2/gyJEjuH//Pvr27SvNiYuLQ1paGpycnDTWev/+/Re+lsTERBgYGKhdHdzFxQV2dnZSGFUqelX259WoUUPlsa2tLQDAzc1NbbywsBBpaWlqp1s/TwihNmZtbf3SHiqXPx/On69RGeqVQTUuLg7A/30G+3k2NjYv3K7S5MmT0apVKxgaGsLBwQH16tWDkZH6r0ovqwd4dmu0yZMnIzIyUi1Qp6WlAQBMTU0xe/ZsjB8/Hs7OzmjRogW6deuG0NBQuLi4lPm1CSHUvi+JiEh/GLqJiEgvDh06hOTkZGzYsAEbNmxQWx4RESGFbi8vL0RHRyM3N/eVruIdGBiIFStWIDU1Vfo8t1JAQABWrVqFvLw8HD9+HL6+vjAzMwPw7KJYPXr0QOvWrfH999+jWrVqMDY2xurVq/Hrr7+qbKNv374ICwvD5s2bMWbMGGzatAm2trZ4++23pTmFhYVwcnLSeNE4AHB0dCzR6ylpsCp61PV5hoaGpRrXFKiLsre313jUtl69erh48SJycnJgamqq8bmXLl2CsbExPD09S1VLYWEhgGeffVaG1aI0BWdNvL291S4Ap8nL6ikoKECHDh3w6NEjTJw4EV5eXrC0tMSdO3cwePBgqV7g2b21u3fvjh07dmDv3r2YNGkSZs6ciUOHDsHHx6dMr+3x48dwcHAo0WsmIiLdY+gmIiK9iIiIgJOTE5YtW6a2bNu2bdi+fTtWrFgBc3NzdO/eHSdPnsTWrVsREhJS5m0GBgZi+fLlOHDgAC5evIjPP/9cWhYQEIDs7Gzs3LkT//zzD3r16iUt27p1K8zMzLB3716VwLh69Wq1bbi7u6N58+bYuHEjPv30U2zbtg09e/ZUeV6dOnVw4MABtGzZ8oWBuDg1a9ZEYWEh4uLiUK9ePWn83r17SE1NVbuIWXny8vLC1q1b1ca7deuGkydPYvPmzRgwYIDa8oSEBBw7dgzBwcGlfk+UV0N3cnIqUWjWtZiYGFy/fh1r1qxRuXDa/v37Nc6vU6cOxo8fj/HjxyMuLg6NGzfG/Pnz8csvv5TptcXHx6NRo0av/kKIiEgr+JluIiIqd9nZ2di2bRu6deuG999/X+3r008/RUZGBiIjIwEAo0aNQrVq1TB+/Hhcv35dbX3379/HN99889LtKj+jvWDBAuTl5akc6a5VqxaqVauGOXPmqMwFnh3ZVCgUKp8zT0hIwI4dOzRup2/fvjh16hRWrVqFBw8eqJxaDjy7l3JBQQG+/vprtefm5+dLV1EvTpcuXQAAixYtUhlfsGABAKBr164vfL4u+fv74/Hjx2r3iR45ciScnJzw+eefqy17+vQphgwZAiEEJk+eXOptdurUCTY2NpgxY4Z05feiNN1eTJeUR8KLnhUghMDixYtV5mVlZeHp06cqY3Xq1IG1tbX0EYbSvra0tDTcvHlT5XubiIj0i0e6iYio3EVGRiIjIwM9evTQuLxFixZwdHREREQE+vbtiypVqmD79u3o0qULGjdujAEDBsDX1xcAcOHCBaxfvx7+/v4v3W6NGjXg5uaGkydPolatWnB1dVVZHhAQgK1bt0KhUKBly5bSeNeuXbFgwQK8/fbb6N+/P+7fv49ly5bBw8MDly5dUttOnz59MGHCBEyYMAFVq1ZVO0IZFBSEkSNHYubMmYiOjkbHjh1hbGyMuLg4bN68GYsXL37h7dEaNWqEQYMG4ccff0RqaiqCgoJw5swZrFmzBj179tR4r/Dy0rVrVxgZGeHAgQMYMWKENG5vb48tW7aga9euaNKkCYYNG4b69esjJSUF4eHhuHHjBhYvXlymsGhjY4Ply5dj4MCBaNKkCfr16wdHR0ckJSVh586daNmyJb777jttvswX8vLyQp06dTBhwgTcuXMHNjY22Lp1q9pp99evX0f79u3Rp08f1K9fH0ZGRti+fTvu3bsn3fqttK/twIEDEELgnXfeKbfXS0REL8bQTURE5S4iIgJmZmbo0KGDxuUGBgbo2rUrIiIi8PDhQ9jb28PPzw+XL1/G3LlzsXPnTqxbtw4GBgaoV68evvjiC7X7NhcnMDAQ69ev1xjuWrZsia1bt8LLy0vlYmHt2rXDypUrMWvWLIwZMwbu7u6YPXs2EhISNIbu6tWrSxdmGzZsmMrVwZVWrFgBX19f/PDDD/jyyy9hZGSEWrVqYcCAASqBvzg///wzateujfDwcGzfvh0uLi4ICwvDlClTSvQ+6IqzszO6dOmCTZs2qYRu4NlVvi9duoQZM2Zg8+bNSE5Ohq2trfR5+qJnF5RW//794erq+v/au/OwKKv2D+DfYd9BBVkUFQPFHTTFfUXc0izT0txN0xYrrcx+pelbWi7Za+v7mmtmLrnmjmi5r4kbouICKosroIKs5/fH/c7ABCogwwzw/VzXuWCe52HmHm6eYe455zkHX375JWbOnIm0tDRUqVIFbdq0wbBhw572aRWKpaUl/vjjD4wdOxbTp0+HjY0NXnjhBbz11lt6w769vb3Rv39/hIWF4ZdffoGFhQX8/f2xcuVKvcsbCvPcVq1ahdatW+uGpRMRkfFp1JNmRCEiIiIqhD179qB9+/aIjIzMMykaGU58fDx8fHywfPly9nQTEZkQFt1ERERU7Lp164aqVati3rx5xg6l3Pjoo4+wc+dOHD582NihEBFRLiy6iYiIiIiIiAyEs5cTERERERERGQiLbiIiIiIiIiIDYdFNREREREREZCAsuomIiIiIiIgMhOt05yM7OxuxsbFwdHSERqMxdjhERERERERkYpRSuHfvHry8vGBm9uj+bBbd+YiNjYW3t7exwyAiIiIiIiITd/XqVVStWvWR+1l058PR0RGA/PKcnJyMHM2jZWRkYPv27QgJCYGlpaWxw6FcmBvTxdyYNubHdDE3pou5MW3Mj+libkxbachPcnIyvL29dfXjo7Dozod2SLmTk5PJF912dnZwcnIy2T/E8oq5MV3MjWljfkwXc2O6mBvTxvyYLubGtJWm/DzpkmROpEZERERERERkIOzpJqJSIz0dSEwE7t8HUlOlpaTk/f7hQyArK/+Wnm6G8+f9cfSoGaytAXPznGZhkfO9jQ1gZyfN1jbne+1tR0fAyQl4zJwZREREREQsuomo5GVnS/GckADcuJG33b0r+5OS5Kv2+9TU4nh0cwC1i+OOoNFI4e3ikrdVqABUrizN3V3/q61tsTw8EREREZUCLLqJqFilpQHXrwNXr+Zt165JoX3zJpCZWfTHsLfP6X22tc37vbW1fq917qbRZOHq1Wh4e1dHdra5rgc8MzPna2amPA9tz3lKSt7vMzIApeTDgKQkIDq64PE7OkoB7u4OVK0KeHtLq1Yt53s3NynqiYiIiKh0Y9FNRIWiFBAXB0RFSbt4Ub5euiSFdUJCwe/LxSVvb7CbG1Cxon6vsbNzzveOjlI8F1VGRjY2bz6F7t29YWlZ9DtKS9Pvif9nu307p+de26OfkCBD5O/dkxYV9ej7t7bOKcCfeQbw9ZX2zDPSnjBJJhERERGZCBbdRJSvxEQgIkJaZGROgX3x4pOHedvY5BSMuVvVqoCHR05xbW1dIk/FIKytcz4wKCilgOTknAI8Pl5/JEBMjHyNj5eiXvvBxq5dee/L3T2nEPf1Bfz9gXr15HsTn+CTiIiIqFxh0U1Uzt2+LYX1mTM5RXZEhPRmP4q5OVC9ek7Pq68vULOmbPP2BipV4tDo/Gg00mvv7Az4+T36uPT0nCH60dEyikBbgEdFAbduSdGekADs26f/sxYWQK1aUoDXrSutXj15PCsrwz4/IiIiIsqr1BXdu3fvxsyZM3Hs2DHExcVh7dq16N27t26/UgqTJ0/GvHnzkJiYiFatWuHHH3+E3+Pe4RKVA9nZ0ksdHi7t+HH5+rji2ttbijZ/fynatEV29ersTTUkKyvAx0dafhITc4b1R0UBFy4AZ8/KhyX37+d8cJKbhYXkMSAACAyUFhAgE74RERERkeGUuqL7wYMHaNSoEYYPH44XX3wxz/4ZM2Zg7ty5WLx4MXx8fPDpp5+iS5cuiIiIgI2NjREiJip5mZnA6dPAsWM5BfaJE1KQ5adGDf1eUW2h7eRUklFTQbm4AE2aSMtNKekd/+fIhTNn5Bry06elLV2a8zPVq+cU4IGBcp9VqpTksyEiIiIq20pd0d2tWzd069Yt331KKXzzzTf45JNP8PzzzwMAlixZAnd3d6xbtw6vvPJKSYZKVCKUkiHIhw4Bhw9LO3Ys/+uubWyABg1yiqyAALnt4FDSUZMhaDQyA3q1akDXrjnblZKZ40+ckA9gtKMcLl+Wv53oaGDdupzjq1QBmjUDgoKkNWnCiduIiIiIiqrUFd2Pc/nyZcTHxyM4OFi3zdnZGUFBQThw4MAji+60tDSkpaXpbicnJwMAMjIykJGRYdign4I2NlOOsbwyZG7u3QMOHdLg0CENjhyRdvNm3guonZ0VmjRRCAhQaNhQvtaqJcOM88Zb7GGarPJ63nh4SOvSJWdbYiJw4oQGJ05oEB4uLSICuH5dg7VrgbVr5TgzM4U6dYCmTRWaNctGUJBCvXqAmVnxx1le81MaMDemi7kxbcyP6WJuTFtpyE9BY9MopZSBYzEYjUajd033/v370apVK8TGxsLT01N3XL9+/aDRaLBixYp87+ezzz7DlClT8mxftmwZ7OzsDBI7UUHdvWuNs2crIiKiEiIiKuHKFWdkZ+sX2RYW2fDxSYKf3134+d1FrVqJ8PS8b5CiiMq2hw/NcfGiCy5ccMH58xVw/nwF3LqV93XQ3j4ddercQZ06d1C37m34+ibC0jLbCBETERERGUdKSgoGDBiApKQkOD3muswy1dNdVBMnTsS4ceN0t5OTk+Ht7Y2QkJDH/vKMLSMjA6GhoejcuTMsOauVSSlqbpSSSbH27dNg3z4z7N+vQVRU3l5sHx+F5s0VmjVTaNpUerJtbBwAOADwLr4nUgbxvCm8uLgM3aiKI0dklMWDB1Y4etQDR496AACsreVvsWVLhdatFVq0UHB2LvxjMT+mi7kxXcyNaWN+TBdzY9pKQ360I6SfpEwV3R4e8uYvISFBr6c7ISEBAQEBj/w5a2trWOezYLClpaXJJji30hJneVSQ3Fy+DOzcCYSFydeEBP39Gg3QsCHQujXQpg3QqhVQtaoGANfkeho8bwpOe514nz5yOzNTrgnfuxfYs0fazZsa7N2rwd69wIwZ8ncbEAB06gR07Ch/u4WZO4D5MV3Mjelibkwb82O6mBvTZsr5KWhcZaro9vHxgYeHB8LCwnRFdnJyMg4dOoQxY8YYNzii/4mLA3btyimyr1zR329tLZNYaYvsFi1ktmoiU2FhATz7rLR3380ZobFnT04hfvFizqRts2bJzzRvLgV4p04yQVs+n3USERERlTmlrui+f/8+oqKidLcvX76M8PBwVKxYEdWqVcO7776Lzz//HH5+frolw7y8vPTW8iYqSffuSXG9Y4cU2mfP6u+3sJACpGNHac2byyzjRKWFRgPUqiVtxAjZFhsL/Pmn/M2HhckM6Xv3Sps6FbC1lQ+VOnYEOneWXnHOQUBERERlUakruo8ePYoOHTrobmuvxR4yZAgWLVqEDz/8EA8ePMCoUaOQmJiI1q1bY+vWrVyjm0qMUsDJk8CaNb6YM8cc+/frzw6u0ciSXdoiu7DDbolKAy8vYMAAaUrJZRTa0R07dwI3bgDbt0v76CPA3V1mVg8O1gAwzSFkREREREVR6oru9u3b43ETrms0GkydOhVTp04twaiovLt7FwgNBbZulRYXZwmgnm7/M89IQdGpE9CuHVCpkvFiJSppGg1Qs6a0kSOlCD9zJqcXXDuXwZIlwJIlFtBouuG77xS6dQO6dZNh7Obmxn4WREREREVTpKI7MTERa9euxZ49exAdHY2UlBS4ubkhMDAQXbp0QcuWLYs7TiKTopRcq7ppkxTZBw8C2blWS7KzU6hbNwEDB7qhRw9z+PoaL1YiU6PRAPXrS3vnHSA9XYadb90KbNmicPq0BocPa3D4MDBlClCxIhASAl0R7uZm7GdAREREVHCFKrpjY2MxadIk/Prrr/Dy8kKzZs0QEBAAW1tb3LlzB7t27cKsWbNQvXp1TJ48GS+//LKh4iYqcQ8fygRoGzYAf/wBXL+uv79ePaBrV2lBQZnYufMQunfvDktLdtERPY6VVc7lFl98kYklS3YiK6sTQkMtEBoK3LkDLF8uTaORyQV79ZLm7y/biIiIiExVoYruwMBADBkyBMeOHUPdunXzPSY1NRXr1q3DN998g6tXr+L9998vlkCJjOHmTenN3rBBrj198CBnn7299L517y5Dx71zLY+d+xpuIiocV9eH6N5dYdQoWZ7s4EHpBd+8WUaY7N8v7aOPAF9foGdPKcBbt5aJCYmIiIhMSaHenkRERKDSEy5GtbW1Rf/+/dG/f3/cvn37qYIjKmlKyezi2t7sAwdkm1aVKjk9bO3bc5ZxIkOzsJBiunVr4PPPgatXgY0b5RzduROIigLmzJFWoYJ8CNarl3wQ5uxs7OiJiIiICll0V6pUCRs3bkT37t1hVoC1XZ5UoBOZAqWAv/8GVq8G1qwBzp3T39+4cU6hHRDAoaxExuTtDYwZI+3ePZnAcMMGKcRv3wZ+/VWapaVMXNinD/D887wOnIiIiIyn0APxevfuDXd3dwwdOhTDhg2DL2eIolIoO1uGrGoL7StXcvZZWcmb9V69gOeeA6pWNVqYRPQYjo7Aiy9Ky8qSkSnaUSqRkTmrCbz+uqwa0KcP8MILspwZERERUUl5cnf1P1y+fBmvv/46li9fjtq1a6Ndu3b45ZdfkJqaaoj4iIpNZqZMhPbWW9Jb1qoV8PXXUnDb2ckb8mXL5DruzZuB0aNZcBOVFubmMgR9xgy5ROTsWRmOHhgoH7Jpz/2qVXPO/ehoY0dNRERE5UGhi25vb29MmjQJFy9exI4dO1CjRg2MGTMGnp6eGD16NI4cOWKIOImKJCNDerpeew3w9JTZkb//HoiNBZycgAEDpLf75k3g99+B/v1lOxGVbv7+wP/9n1w6cvEiMHMm0Ly5XE6yfz8wfjxQo4asAT59OnDhgrEjJiIiorKq0EV3bh06dMDixYsRFxeHmTNn4tSpU2jevDkaNWpUXPERFVpWFvDnn9JT7ekp6/rOnw/cugVUqgQMHy4zkt+4Idd+vvii9HQTUdlUsybw/vsy/PzqVWDuXBlubmYGHDsGfPwxUKuWFOCzZgExMcaOmIiIiMqSYllcxdHREZ06dUJ0dDQiIyMRERFRHHdLVGBKyTXay5cDK1cC8fE5+9zcZOj4Sy/JG20uKURUflWtCrz9trQbN4B162SUy86dUoAfOwZ88AHQsiXwyitA376Ah4exoyYiIqLS7Kl6ulNTU7FkyRK0b98efn5+WL58OcaNG4cruWelIjIQ7azjH34I+PjIm+S5c6XgdnEBRoyQmY1jY4Eff5TJ0VhwE5FW5crAqFHA9u1AXJy8TrRrJysU7N8PjB0rywR26gTMmyezoxMREREVVpFKkIMHD2LBggVYuXIl0tPT8eKLL2LHjh3o0KFDccdHlEdEhPRoL1+ufx2mgwPQu7f0TnXuLLOQExEVhJubXJIyerR8ULdqlbzGHDwoveA7dwJvvAGEhMhrzPPPc/4HIiIiKphCF91169bFuXPnEBgYiOnTp2PAgAFwdnY2RGxEOrGxwG+/Ab/8Apw4kbPdxgbo2RN4+WWge3fA1tZ4MRJR2eDlBbzzjrTLl+WSleXLgfBwWdlg82bA2lqWFRw4EOjalR/yERER0aMVuugODg7Gb7/9xsnSyODu3QPWrgWWLgXCwmTZHwCwtJQ3ua+8IgW3o6Nx4ySissvHB5gwQVpkJLBihRTgkZHSG75qlUzQ+PLLwKBBQFCQDE8nIiIi0ip00T137lxDxEEEQNbSDg2VQnvtWiD38u+tWkmvUr9+QMWKxouRiMonf39g8mRg0iTp9V66FFi2TOaR+OEHab6+8jr16qvyPREREVGhJlLr2rUrDh48+MTj7t27h6+++grff/99kQOj8kMp4OhRGcpZpYoME1+2TAruWrWAqVNlnd29e+V6SxbcRGRMGg0QGAjMni1LkG3bJoW2nR0QFQV89hng5yeTO/7wAydgIyIiKu8K1dPdt29f9OnTB87OzujZsyeeffZZeHl5wcbGBnfv3kVERAT27t2LzZs3o0ePHpg5c6ah4qYy4MoVWSf7l1+Ac+dytru5ydDxgQOBpk05VJOITJeFhUyuFhIis5+vWyevaTt2yLrgBw7IB4rdu8vw8+eek7koiIiIqPwoVNE9YsQIDBw4EKtWrcKKFSvw3//+F0lJSQAAjUaDunXrokuXLjhy5Ajq1KljkICpdLt/X9bEXbQI+OuvnO02NjLz+MCB8ubV0tJYERIRFY2Dg7yGDRwoS5AtXy4F+PHjwIYN0pyd5frvYcN4/TcREVF5Uehruq2trTFw4EAMHDgQAJCUlITU1FRUqlQJlqyUKB9KAXv2AAsXyqRDDx7Ido0G6NhR3qC++CKX3yGissPTE3jvPWlnzsj137/+KsPR//tfaf7+wNCh0gPu5WXsiImIiMhQCnVNd36cnZ3h4eHBgpvyiI4G/vUvmUyoXTvp3X7wQG5//rns37FD3nSy4CaisqpePWD6dLmkJixMimxbW5kB/aOPAG9vGX6+ciXw8KGxoyUiIqLiVuiebqLHSUkB1qyRAnvnTunlBmTY5csvS4HdqhWHVBJR+WNmJqN7OnYEvvtORv4sWiSTRG7ZIq1CBaB/fxl+3qQJXyuJiIjKgqfu6SZSCti/Hxg5EvDwkF6csDDZ3rEjsGSJLKnz889A69Z8E0lE5OQEjBghl96cPw/83/8BVasCd+/KjOdNmwINGgCzZsnrJxEREZVeLLqpyK5dkyGT/v7Se/3zz8C9e4CPDzBlCnD5cs5QSnt7Y0dLRGSa/PzkkpsrV4Dt26Wn28ZGrgX/4AMpxnv2lFFE6enGjpaIiIgKi8PLqVDS02UG3p9/BkJDgexs2W5nB/TtK0Mi27SRYZRERFRw5uZA587SEhPlGu+FC4GDB4GNG6VVqgQMHiy95PXqGTtiIiIiKoinKo0SExPx888/Y+LEibhz5w4A4O+//8b169eLJTgyHZGRwPvvS49L377Atm1ScLdtCyxYIMMfFy2SCdNYcBMRPR0XF2DUKFnn++xZYMIEmRH99m1gzhygfn2gRQtg/nxZipGIiIhMV5HLo5MnT6JWrVr46quvMGvWLCQmJgIA1qxZg4kTJxZXfGREKSnA4sXSc12nDjB7NnDzprzx+/hj4MIFWWt72DDA0dHY0RIRlU3+/sCXXwIxMdLb/cILgIWF9IC/9pq8Jr/2mtzWTl5JREREpqPIRfe4ceMwdOhQXLhwATY2Nrrt3bt3x+7du4slODKOY8eAMWPkjdzQoTKzrrk50KuXDC2PiQG++EKW/iIiopJhYQH06CHXdl+9Cnz1lVwPfv++9Hi3aCGTr33zDXDrlrGjJSIiIq0iF91HjhzB66+/nmd7lSpVEM+pVkudxESZMbdxY+DZZ4GffgKSk4GaNaXAjokB1q+XyXwsOBMAEZFReXgAH34InDsH7N4t13nb2srka++9B1SpIss0bt+eM/cGERERGUeRi25ra2skJyfn2X7+/Hm4ubk9VVBUMpTKebPm6Qm8+SZw/DhgZSWz54aFyRDyjz8GvLyMHS0REf2TRiOXAC1eDMTFAT/+KOt7p6fLRGxdusiHp1OnSu84ERERlbwiF929evXC1KlTkZGRAQDQaDSIiYnBhAkT0KdPn2ILkIpfQgIwc6ZcJ9iuHfDLL8DDhzIxzzffALGxwLJlssY2J0UjIiodnJ2B0aOBo0eBv/+WD1JdXIDoaGDyZKB6daBbN2D1ai49RkREVJKKXFLNnj0b9+/fR+XKlZGamop27drB19cXjo6O+OKLL4ozRioGWVnAli1Anz4yA/mHHwLnz8v62doJeE6eBN55R5akISKi0iswEPjuO/kQdelSoH17Gd20dSvw0kvyf+D992VmdCIiIjKsIl+d6+zsjNDQUOzduxcnT57E/fv30bhxYwQHBxdnfPSUoqNlSa8FC4Br13K2BwUBI0cC/fpx5nEiorLK1hZ49VVpUVHyv2DhQlnmcfZsaa1ayYevffvKB7FERERUvJ568HDr1q3xxhtv4MMPPzS5gvv7779HjRo1YGNjg6CgIBw+fNjYIZWI9HTg99+Brl0BHx+5lu/aNaBiRenJPnlSerZHjGDBTURUXvj6AtOmybXd69fLihTm5sC+fbL0o6enDE8/doxLjxERERWnIvd0z507N9/tGo0GNjY28PX1Rdu2bWFubl7k4J7GihUrMG7cOPz0008ICgrCN998gy5duuDcuXOoXLmyUWIytLNnZdmYJUtkPW2tTp2kF6N3byDX6m5ERFQOWVhIwd2rlww/X7wY+Pln4NIl4D//kRYQIP83BgwAKlQwdsRERESlW5GL7jlz5uDmzZtISUlBhf/9R7579y7s7Ozg4OCAGzduoGbNmti1axe8vb2LLeCC+vrrrzFy5EgMGzYMAPDTTz9h06ZNWLBgAT766KMSj8dQHj40x5IlGixcKL0VWp6e0nMxYoTMXEtERPRPXl7AxInAhAnAX38B8+bJRGvh4cBbb8l13y+9JJcjNW9u7GiJiIhKpyIPL582bRqaNm2KCxcu4Pbt27h9+zbOnz+PoKAg/Pvf/0ZMTAw8PDzw3nvvFWe8BZKeno5jx47pDXc3MzNDcHAwDhw4UOLxGMLx48Bbb5lh+PAueO01C+zbJ8MEe/UCNmyQdbW/+IIFNxERPZmZGdChg6xcERsL/PvfsqLFw4cyEVu7dkC9ehZYs8YXCQnGjpaIiMq68+eBjz4yw8GDnsYOpVgUuaf7k08+werVq/HMM8/otvn6+mLWrFno06cPLl26hBkzZhhl+bBbt24hKysL7u7uetvd3d0RGRmZ5/i0tDSkpaXpbmvXH8/IyNAtiWZqvvnGHEuWmAMwh49PNoYNUxg8OFu3nrZSgImGXi5o/25M9e+nPGNuTBvzY3xOTsCYMdrlxzRYsMAMK1ZoEBWlQVRUPSxbptCjRzaGD89GSIiCka4io1x43pg25sd0MTem5eFDYM0a+b+ze7cZAHPUq1cTn35quvkp6N9OkYvuuLg4ZGZm5tmemZmJ+Ph4AICXlxfu3btX1IcoMdOnT8eUKVPybN++fTvs7OyMENGT1a1bAW3a1ETnztGoX/8WzMxkOGB4uLEjo9xCQ0ONHQI9AnNj2pgf09GzJxAcbI69e6tgx47qOHeuItav12D9ejNUqpSK4OBodOwYA3f3VGOHWu7xvDFtzI/pYm6M68oVR+zYUR1//umN+/ctAQBmZgqNGyegc+dohIbGGznCR0tJSSnQcRqlijZHaY8ePRAfH4+ff/4ZgYGBAIDjx49j5MiR8PDwwMaNG/HHH3/g448/xqlTp4ryEEWWnp4OOzs7/P777+jdu7du+5AhQ5CYmIj169frHZ9fT7e3tzdu3boFJyenkgq70DIyMhAaGorOnTvD0tLS2OFQLsyN6WJuTBvzY7q0ufHyCsHSpVZYutQMd+5oAAAajUJwsMKwYdno1UvBysrIwZYzPG9MG/Njupgb47l3D1i5Unq1jxzJueK5WjWFoUOzMWRINjw8TD8/ycnJcHV1RVJS0mPrxiL3dM+fPx+DBg1CkyZNdL+EzMxMdOrUCfPnzwcAODg4YPbs2UV9iCKzsrJCkyZNEBYWpiu6s7OzERYWhrfeeivP8dbW1rC2ts6z3dLS0mQTnFtpibM8Ym5MF3Nj2pgf0xUQYIGmTc0xYwawbp3MfL5jhwahoRqEhprB1RUYMkQm8qxTx9jRli88b0wb82O6mJuSoRRw6JD831i+HHjwQLZbWADPPy//N0JCNP9b/cpcd6msKeenoHEVuej28PBAaGgoIiMjcf78eQBA7dq1Ubt2bd0xHTp0KOrdP7Vx48ZhyJAhePbZZ9GsWTN88803ePDggW42cyIiIio6a2vg5ZelXboELFgALFwoE7HNni2tVStZeqxvX8De3tgRExGRMdy+LZNy/vwzcPp0zvZateR/xODBwD+m4ipzilx0a/n7+8Pf3784YilWL7/8Mm7evIlJkyYhPj4eAQEB2Lp1a57J1YiIiOjp1KwJfP458NlnwNatsvTYpk2ylOW+fcDYsbLm98iRQOPGgEZj7IiJiMiQsrOBXbuk0F6zBkhPl+02NvJB7MiRQOvW5ef/wVMV3deuXcOGDRsQExODdO1v8n++/vrrpwqsOLz11lv5DicnIiKi4mdhATz3nLTYWGDxYmD+fODiReA//5EWECA9GwMGABUqGDtiIiIqTrGxwKJF8tp/6VLO9oAAKbQHDABcXIwUnBEVuegOCwtDr169ULNmTURGRqJ+/fq4cuUKlFJo3LhxccZIREREpYyXFzBxIjBhAvDXX9LbsXq1rLLx1lvA++8DL70kb8LatCk/vR1ERGVNZiawZYu8zm/aBGRlyXYnJ/1RTuWZ2ZMPyd/EiRPx/vvv49SpU7CxscHq1atx9epVtGvXDn379i3OGImIiKiUMjMDOnQAfv1VekD+/W+gfn1Zj3XpUqBdO6B2bWDGDCAhwdjREhFRQV26BPzf/wHVqgG9egEbNkjB3aqV9HbHxgI//siCG3iKovvs2bMYPHgwAMDCwgKpqalwcHDA1KlT8dVXXxVbgERERFQ2VKwo13efPCkz2I4cCTg4ABcuSI941arAiy8Cmzfn9JQQEZHpSEuTmceDg4FnngGmTQPi4gBXV2D8eCAiAti7V1ax4ASaOYpcdNvb2+uu4/b09MTFixd1+27duvX0kREREVGZpNEAzZoB//2vvFmbPx9o0UKGKK5dC/ToAdSoAUyeDFy5YuxoiYjoxAngnXfk0qH+/YGwMHktDwkBVq4Erl8HZs3iUpGPUuSiu3nz5ti7dy8AoHv37hg/fjy++OILDB8+HM2bNy+2AImIiKjscnAAhg8H9u8HTp0C3n1XesSvXQOmTpWZ0bt0AVatypn9loiIDO/OHeC772R4eEAAMHeubKtSBfj0Uxlevm2bzEZuZWXsaE1bkSdS+/rrr3H//n0AwJQpU3D//n2sWLECfn5+JjFzOREREZUu9esDc+YAX34JrFsnk/Ls2AFs3y7N1VWGLI4Ywd4UIiJDyMoCQkOBhQvldVj7YaelJfD888CwYfJBqLm5UcMsdYpcdNesWVP3vb29PX766adiCYiIiIjKN2tr4OWXpV26BCxYIG8AY2OB2bOltWwpb/769ZMZcomIqOguXJDJzxYvlqHiWgEB8lo7YIB88ElFU+Th5TVr1sTt27fzbE9MTNQryImIiIiKqmZN4PPPgeho4I8/pKfF3FyGo48cCXh4AAMHSs8MJ18jIiq4+/flA822bYFatWRStOvX5RKft98G/v4bOH5cJsBkwf10itzTfeXKFWTl898tLS0N13N/PEJERET0lCwsgOeekxYXB/zyi/TKnD0ry5H9+qvMfj54sAxBr1XL2BETEZkepWR28YULZQK0Bw9ku5mZDBsfPhzo2VNGHFHxKXTRvWHDBt3327Ztg7Ozs+52VlYWwsLCUKNGjWIJjoiIiOifPD2BDz8EPvgAOHpUiu/ffpPJ16ZNk9aiBTB0qAw/d3ExcsBEREYWEwMsXSqvlxcu5Gz385NCe9AgmSCNDKPQRXfv3r0BABqNBkOGDNHbZ2lpiRo1amD27NnFEhwRERHRo2g0QNOm0r7+WoafL1oEbN0KHDggbexY4IUXpAAPDubkP0RUfiQnA6tXy8igP/+UXm5AVo3o10+K7ZYt5bWUDKvQRXd2djYAwMfHB0eOHIErB/gTERGRkVlbAy+9JC0uToabL1oEnDkDLF8uzctLenOGDOHs50RUNmVmyqoPv/wCrF0LpKbm7OvQQS7BeeklKbyp5BR5IrXLly+z4CYiIiKT4+kJvP++rPt99Cjw1lsyMVBsLPDVV0DdukCzZrLmbEKCsaMlInp6J04A48cD3t5At27AsmVScPv7yyU30dHAzp0y6ocFd8krVE/33LlzC3zs2LFjCx0MERERUXHRaIAmTaTNmgVs2iS935s3A0eOSBs3DujcGXj1VaB3b74ZJaLSIzZWiuslS+RDRi1XV6B/f+nVbtKEw8dNQaGK7jlz5hToOI1Gw6KbiIiITIa1NfDii9ISEoAVK2QI+uHDcg341q2AnZ0U3q++KoW4paWxoyYi0nf/PrBunQwf37ED+N+Vv7CyAnr1kkK7a1e+fpmaQhXdly9fNlQcRERERCXC3V0mWBs7Vmbx1S45FhUlvUbLlgFubsDLL8sa4M2asaeIiIwnLU0+GPztN2DDBv3rtFu1kkK7b1+gQgXjxUiPV+RrunNTSkFpp8MjIiIiKiX8/IDPPgPOnwcOHgTeflsK7ps3ge++A5o3l2MmT5ZjiIhKQlYWEBYGjBgBeHjIKJwVK6Tg9vWV16SoKFlze9QoFtym7qmK7iVLlqBBgwawtbWFra0tGjZsiF9++aW4YiMiIiIqERoNEBQkk6tdvy7Xfb/6qgw5v3gRmDoVqF1bliebNUvWvCUiKk5KyYd/77wDVK0qyxwuWAAkJsrqC+PGyVwU58/Lh4XPPGPsiKmgCr1kmNbXX3+NTz/9FG+99RZatWoFANi7dy9Gjx6NW7du4b333iu2IImIiIhKiqWlzP7brZtcP7l+PbB0KRAaKrOhHz0KfPAB0KKFrHXbty9QpYqxoyai0ur0aRk6vnw5cOlSzvaKFWV5r/79gTZtAHNz48VIT6fIRfe3336LH3/8EYMHD9Zt69WrF+rVq4fPPvuMRTcRERGVeg4O0uP96qvAjRvA778DK1cCu3cDBw5IGzcOaN1aCvCXXpKhoEREj3PmDLBqlbymnDmTs93eHnj+eWDAAJnQ0crKeDFS8Sly0R0XF4eWLVvm2d6yZUvExcU9VVBEREREpqZyZeCNN6TFxsqb5RUrgP37gT17pL3zDtCunUzC9uKLcn04EZFS0qOtLbTPns3ZZ2kJdO8uPdrPPSeFN5UtRb6m29fXFytXrsyzfcWKFfDz83uqoIiIiIhMmZeXzH6+b59c3z17tsxynp0N7NoFjB4NeHoCISHAf/4DxMcbO2IiKmlKASdOAJ98AtSpAzRsCPzrX1JwW1lJgb14sYyiWbdOPqxjwV02Fbmne8qUKXj55Zexe/du3TXd+/btQ1hYWL7FOBEREVFZ5O0tQ8zHjQOuXJHh5ytWAH//LdeBh4YCY8YALVtK7/cLLwA+PsaOmogMQSkgPDynR/vChZx91tZAly4yD0TPnoCzs9HCpBJW6KL79OnTqF+/Pvr06YNDhw5hzpw5WLduHQCgTp06OHz4MAIDA4s7TiIiIiKTV6MG8OGH0qKi5I332rUy4/C+fdLGjwcCAnIK8Hr1uA44UWmWmSmXl6xbJxMvRkfn7LO2lkkZ+/aVnm0nJ6OFSUZU6KK7YcOGaNq0KV577TW88sorWLp0qSHiIiIiIirVfH2BiROlXb0qb8jXrgX++kt6wsLDgUmTZB3wF16QIrxpU8DsqRZ0JaKS8OABsG2bnNcbNwJ37+bss7XNKbR79AAcHY0WJpmIQr+s//XXX6hXrx7Gjx8PT09PDB06FHv27DFEbERERERlgrc38PbbwM6dQEKCrL373HPSC3bhAjBjBtC8uazNO2oUsGGDvKknItNx4wYwf74MDa9UCejTB/jlFym4XV2BYcOkp/vWLWD1auCVV1hwkyh0T3ebNm3Qpk0bfPvtt1i5ciUWLVqEdu3awdfXFyNGjMCQIUPgwbUyiIiIiPKlfXM+bBhw7x6wdSuwZg2waRMQFwfMmyfN2hro2FHe4PfoAVSrZuzIicoX7URomzfL+XnggGzTqlkT6N1bWsuWXEebHq3IE6nZ29tj2LBhGDZsGKKiorBw4UJ8//33+PTTT9G1a1ds2LChOOMkIiIiKnMcHWUIat++QFqaDD3fuBH44w+ZlG3LFmmAzHz83HPSmjXjG3wiQ7h3D9ixQwrtzZtlecDcnn1Wiuznn+d8DFRwRS66c/P19cXHH3+M6tWrY+LEidi0aVNx3C0RERFRuWFtLUuMhYQA//43EBEhBfjGjbIW+MmT0qZNk97yrl1lJuT27Y0dOVHppRQQGSmrDGzeDOzeDWRk5Oy3swOCg2W0SffucgkIUWE9ddG9e/duLFiwAKtXr4aZmRn69euHESNGFEdsREREROWSRiO9aPXqARMmALdvS4/3xo0yHP3WLWDpUmmAJXx82mHPHjN07w60aiUFPBHlLzER2LUL2LbNDOvWBSMhwVJvv5+fFNg9egBt2/J8oqdXpKI7NjYWixYtwqJFixAVFYWWLVti7ty56NevH+y5ojsRERFRsapUCRg4UFpGhiw9tm2btOPHgcuXXTB7NjB7tvTMtW8vveAhIUDt2hwCS+Vbejpw8KD0ZoeGyhJ+2dkAYA7AHlZWCu3ba9Cjh8w67udn5ICpzCl00d2tWzfs2LEDrq6uGDx4MIYPH47atWsbIjYiIiIi+gdLSymq27cHpk8Hrl/PwOzZJ3HjRiB27DBDQkLO9aiATMDWqZMc36GDzKROVJYpJZdnaIvsv/7KuxqAvz/QsWMWXFyO4IMPmsDFxTL/OyMqBoUuui0tLfH777/jueeeg7kRZvD44osvsGnTJoSHh8PKygqJiYl5jomJicGYMWOwa9cuODg4YMiQIZg+fTosLIrlEnYiIiIik1G5MtCu3TV0794QFhZmOHkS2L5desH37AFiYoCFC6UBMuNyhw45RXiVKkYNn+ipZWcDZ85Icf3XX3Jd9o0b+sdUrizXZmubtzeQkZGNzZsTwIG6ZGiFrkKNPSt5eno6+vbtixYtWmD+/Pl59mdlZaFHjx7w8PDA/v37ERcXh8GDB8PS0hLTpk0zQsREREREJUOjARo1kvbBB0BKihQgf/4p17AePQpcuiRN+zbKzy+nAG/dmj3hZPqysmQpL22BvXs3cOeO/jG2tnI9dnAw0Lkz0KABYGZmnHiJSl3X75QpUwAAixYtynf/9u3bERERgR07dsDd3R0BAQH417/+hQkTJuCzzz6DlZVVCUZLREREZDx2djLLedeucjs5Gdi7VwrwXbvkevALF6TNmyfHeHvLmsOtWklr2BDgYEEypgcP5Drsgwfl73fvXiApSf8Ye3v5u23XTlrTppwAjUxHmXsJPXDgABo0aAB3d3fdti5dumDMmDE4c+YMAgMDjRgdERERkfE4OcmszN27y+3ERBmC/uef0k6cAK5eBVaskAZIMRMUlFOIN28OuLgYJ34q+5QCLl4EDhyQdvCgLJWXlaV/nJOTjMzQFtmNG8t8B0SmqMwV3fHx8XoFNwDd7fj4+Hx/Ji0tDWlpabrbycnJAICMjAxk5F6oz8RoYzPlGMsr5sZ0MTemjfkxXcyN6Xqa3Njb6/eE378PHDmiwYED0g4e1CApSYOdO4GdO3N+rlYthWefVWjSRL42aqRgZ1ccz6bs4bnzeLdvA8ePa3D0qPy9HT6swa1beafbr1pVIShIoXlzhTZtstGoEfDP6aUK+ytmbkxbachPQWPTKKWUgWN5oo8++ghfffXVY485e/Ys/P39dbcXLVqEd999N89EaqNGjUJ0dDS2bdum25aSkgJ7e3ts3rwZ3bp1y3Pfn332mW7Yem7Lli2DHf+DEBERUTmVnQ1cveqIyMiKuhYX55DnODMzBW/vZPj6Jupa9erJsLLKNkLUZKqSkqxw8aLL/5ozLl50wc2bed9rW1hk4ZlnklC79h3Urn0XtWvfgavrQyNETPR4KSkpGDBgAJKSkuDk5PTI40yip3v8+PEYOnToY4+pWbNmge7Lw8MDhw8f1tuWkJCg25efiRMnYty4cbrbycnJ8Pb2RkhIyGN/ecaWkZGB0NBQdO7cGZYcT2NSmBvTxdyYNubHdDE3pqukc3PzZgaOHdPg2DHpnTx2TIP4eA2io50RHe2MsLDqAABzcwU/P6BhQ4UGDaQ1bKhQpUr5Wje8PJ47mZlAVBRw5owGp09rcPKkBsePa3DtWv6J9/VVCAzM6clu1EjB2toRgCOA6gaLszzmpjQpDfnRjpB+EpMout3c3ODm5lYs99WiRQt88cUXuHHjBipXrgwACA0NhZOTE+rWrZvvz1hbW8M6n5kWLC0tTTbBuZWWOMsj5sZ0MTemjfkxXcyN6Sqp3Hh5SevZM2fb9esyM/qRI/L16FHg9m0NIiOByEgNVq7MObZiRZmcrWFDoF49WS/Z3x9wcyvbxXhZPHeUkjkATp+WduqUfD17Fsh15aaORgPUqgU0aSLXYDdpAgQEAC4uGgDGS35ZzE1ZYsr5KWhcJlF0F0ZMTAzu3LmDmJgYZGVlITw8HADg6+sLBwcHhISEoG7duhg0aBBmzJiB+Ph4fPLJJ3jzzTfzLayJiIiI6OlUqSLt+efltlJAXJxMzHbyZM7XyEhZ2kk7cVtuFSrkFOD+/kDt2vLVxwfg4jPGlZgInD+ff3vwIP+fsbeXD1Xq15flurQFtqNjSUZOZBpKXdE9adIkLF68WHdbOxv5rl270L59e5ibm2Pjxo0YM2YMWrRoAXt7ewwZMgRTp041VshERERE5YpGk9Mjnns6nbQ0ICJCCvCTJ6VHNDISuHIFuHs3Z8bq3MzMgKpVgZo1pQCvWVP/+8qVy3YPeUlIT5ce6ytXgOjonK8XL0phffPmo3/WwkI+HNEW1/XrS6tRg+tiE2mVuqJ70aJFj1yjW6t69erYvHlzyQRERERERAVibQ0EBkrLLTVV1gqPjATOncP/hqVLS0kBYmKk/bN3HJC1yKtVk552L6+cXvfczd29fK41rpTMSB8XJy0+Puf7q1dzCuy4ODn2cby8ZGj4PxtHIhA9WTl8+SEiIiIiU2Jrm3Odd25KAQkJwKVLwOXLeb9evSpFubZAfxQzM7lm3NU1/6bdV6GCrP/s6Chf7e1Np7c2K0uGct+7J6MCbt+Wofq5m3ZbQkJOcZ2SUrD7t7UFqleXHurq1aXVrCmFtZ8f4JB30noiKiAW3URERERkkjQawMNDWsuWefenp0sP+NWrMplbfi0uTgrWhARpheXoqN9sbKTH/lFNu3a0RiNNKTNculQPu3ebwdxcYsnIkNhzf9V+n5YmvdP/bKmpRf89OjgAnp7SPDzka9Wq+gV2WZ/IjsiYWHQTERERUalkZQX4+kp7lKws4MYNabduPb7duSM9ycnJ8nOA3L5372miNAfwmAALycxMZoDXtkqV9G9XrCjXuecustlLTWRcLLqJiIiIqMwyN88pQAtKKeDhQym+tUW4tvhOS8vbHj7M+T47O+c+lAIyM7Nw6dIl+PjUhEZjDnNz+bDA0jL/r9bWUiQ/qllbs0eaqLRh0U1ERERElItGI9c429rKJGxPIyMjG5s3R6B79xqwtDQvngCJqFQxkakhiIiIiIiIiMoeFt1EREREREREBsLh5flQ/1uoMDk52ciRPF5GRgZSUlKQnJwMS0tLY4dDuTA3pou5MW3Mj+libkwXc2PamB/TxdyYttKQH229qJ6w0D2L7nzc+98Uld7e3kaOhIiIiIiIiEzZvXv34Ozs/Mj9GvWksrwcys7ORmxsLBwdHaEx4ekhk5OT4e3tjatXr8LJycnY4VAuzI3pYm5MG/Njupgb08XcmDbmx3QxN6atNORHKYV79+7By8sLZmaPvnKbPd35MDMzQ9WqVY0dRoE5OTmZ7B9iecfcmC7mxrQxP6aLuTFdzI1pY35MF3Nj2kw9P4/r4dbiRGpEREREREREBsKim4iIiIiIiMhAWHSXYtbW1pg8eTKsra2NHQr9A3Njupgb08b8mC7mxnQxN6aN+TFdzI1pK0v54URqRERERERERAbCnm4iIiIiIiIiA2HRTURERERERGQgLLqJiIiIiIiIDIRFdwn5/vvvUaNGDdjY2CAoKAiHDx9+7PGrVq2Cv78/bGxs0KBBA2zevFlvv1IKkyZNgqenJ2xtbREcHIwLFy7oHXPnzh28+uqrcHJygouLC0aMGIH79+/rHXPy5Em0adMGNjY28Pb2xowZM4rnCZcyJZ2fK1euYMSIEfDx8YGtrS2eeeYZTJ48Genp6XrHaDSaPO3gwYPF++RNnDHOnRo1auT5vX/55Zd6x/DcKfnc/Pnnn/meExqNBkeOHAHA8ya34s7PmjVrEBISgkqVKkGj0SA8PDzPfTx8+BBvvvkmKlWqBAcHB/Tp0wcJCQl6x8TExKBHjx6ws7ND5cqV8cEHHyAzM/Opn29pUtK5uXPnDt5++23Url0btra2qFatGsaOHYukpCS94/I7d5YvX14sz7k0Mca50759+zy/+9GjR+sdw3On5HPzqP8pGo0Gq1at0h3Hc6d4c5ORkYEJEyagQYMGsLe3h5eXFwYPHozY2Fi9+yhVtY4ig1u+fLmysrJSCxYsUGfOnFEjR45ULi4uKiEhId/j9+3bp8zNzdWMGTNURESE+uSTT5SlpaU6deqU7pgvv/xSOTs7q3Xr1qkTJ06oXr16KR8fH5Wamqo7pmvXrqpRo0bq4MGDas+ePcrX11f1799ftz8pKUm5u7urV199VZ0+fVr99ttvytbWVv3nP/8x3C/DBBkjP1u2bFFDhw5V27ZtUxcvXlTr169XlStXVuPHj9fdx+XLlxUAtWPHDhUXF6dr6enphv2FmBBjnTvVq1dXU6dO1fu9379/X7ef545xcpOWlqaXk7i4OPXaa68pHx8flZ2drZTieaNliPwsWbJETZkyRc2bN08BUMePH89zP6NHj1be3t4qLCxMHT16VDVv3ly1bNlStz8zM1PVr19fBQcHq+PHj6vNmzcrV1dXNXHixGL/HZgqY+Tm1KlT6sUXX1QbNmxQUVFRKiwsTPn5+ak+ffroHQdALVy4UO/cyf3aWB4Y69xp166dGjlypN7vPikpSbef545xcpOZmZnn/86UKVOUg4ODunfvnu648n7uFHduEhMTVXBwsFqxYoWKjIxUBw4cUM2aNVNNmjTRu5/SVOuw6C4BzZo1U2+++abudlZWlvLy8lLTp0/P9/h+/fqpHj166G0LCgpSr7/+ulJKqezsbOXh4aFmzpyp25+YmKisra3Vb7/9ppRSKiIiQgFQR44c0R2zZcsWpdFo1PXr15VSSv3www+qQoUKKi0tTXfMhAkTVO3atZ/yGZcuxshPfmbMmKF8fHx0t7XFQ37/nMsLY+WmevXqas6cOY+Mi+eOaZw36enpys3NTU2dOlW3jeeNKO785Pao33FiYqKytLRUq1at0m07e/asAqAOHDiglFJq8+bNyszMTMXHx+uO+fHHH5WTk5Pe+VSWGSM3+Vm5cqWysrJSGRkZum0A1Nq1awv2RMooY+WnXbt26p133nlkXDx3TOfcCQgIUMOHD9fbVt7PHUPmRuvw4cMKgIqOjlZKlb5ah8PLDSw9PR3Hjh1DcHCwbpuZmRmCg4Nx4MCBfH/mwIEDescDQJcuXXTHX758GfHx8XrHODs7IygoSHfMgQMH4OLigmeffVZ3THBwMMzMzHDo0CHdMW3btoWVlZXe45w7dw537959ymdeOhgrP/lJSkpCxYoV82zv1asXKleujNatW2PDhg2Fen6lmbFz8+WXX6JSpUoIDAzEzJkz9Ybwlfdzx9i50dqwYQNu376NYcOG5dlXXs8bwDD5KYhjx44hIyND7378/f1RrVo1vf9NDRo0gLu7u97jJCcn48yZMwV+rNLKWLnJT1JSEpycnGBhYaG3/c0334SrqyuaNWuGBQsWQJWjlWWNnZ9ff/0Vrq6uqF+/PiZOnIiUlBS9x+G5Y/xz59ixYwgPD8eIESPy7Cuv505J5SYpKQkajQYuLi66+yhNtY7Fkw+hp3Hr1i1kZWXpvUgCgLu7OyIjI/P9mfj4+HyPj4+P1+3XbnvcMZUrV9bbb2FhgYoVK+od4+Pjk+c+tPsqVKhQ4OdZWhkrP/8UFRWFb7/9FrNmzdJtc3BwwOzZs9GqVSuYmZlh9erV6N27N9atW4devXoV7omWQsbMzdixY9G4cWNUrFgR+/fvx8SJExEXF4evv/5adz/l+dwxlfNm/vz56NKlC6pWrarbVt7PG8Aw+SmI+Ph4WFlZ6d4Q5Xc/j3oc7b6yzli5yS+Of/3rXxg1apTe9qlTp6Jjx46ws7PD9u3b8cYbb+D+/fsYO3ZskR+rNDFmfgYMGIDq1avDy8sLJ0+exIQJE3Du3DmsWbPmsY+j3VfWmcq5M3/+fNSpUwctW7bU216ez52SyM3Dhw8xYcIE9O/fH05OTrr7KE21DotuIiO7fv06unbtir59+2LkyJG67a6urhg3bpzudtOmTREbG4uZM2eWm+LBWHL/3hs2bAgrKyu8/vrrmD59OqytrY0YGWldu3YN27Ztw8qVK/W287wherzk5GT06NEDdevWxWeffaa379NPP9V9HxgYiAcPHmDmzJnlonAwttwfgDRo0ACenp7o1KkTLl68iGeeecaIkZFWamoqli1bpneeaPHcMZyMjAz069cPSin8+OOPxg6nyDi83MBcXV1hbm6eZ/bWhIQEeHh45PszHh4ejz1e+/VJx9y4cUNvf2ZmJu7cuaN3TH73kfsxyjpj5UcrNjYWHTp0QMuWLfHf//73ifEGBQUhKirqiceVBcbOTW5BQUHIzMzElStXHvs4uR+jLDOF3CxcuBCVKlUqUCFdns4bwDD5KQgPDw+kp6cjMTHxkffDc8c4udG6d+8eunbtCkdHR6xduxaWlpaPPT4oKAjXrl1DWlpaoR+rNDJ2fnILCgoCAN1rF88d4+fm999/R0pKCgYPHvzEY8vTuWPI3GgL7ujoaISGhup6ubX3UZpqHRbdBmZlZYUmTZogLCxMty07OxthYWFo0aJFvj/TokULveMBIDQ0VHe8j48PPDw89I5JTk7GoUOHdMe0aNECiYmJOHbsmO6YnTt3Ijs7W/dC3qJFC+zevRsZGRl6j1O7du0yPzxWy1j5AaSHu3379mjSpAkWLlwIM7Mnn47h4eHw9PQs1HMsrYyZm38KDw+HmZmZbhhTeT93jJ0bpRQWLlyIwYMHP7FoAMrXeQMYJj8F0aRJE1haWurdz7lz5xATE6P3v+nUqVN6b5S0b6Tq1q1b4McqrYyVG0DOp5CQEFhZWWHDhg2wsbF54s+Eh4ejQoUK5WaEjzHz80/apau0r108d4yfm/nz56NXr15wc3N74rHl6dwxVG60BfeFCxewY8cOVKpUKc99lKpap8SnbiuHli9frqytrdWiRYtURESEGjVqlHJxcdHNQDlo0CD10Ucf6Y7ft2+fsrCwULNmzVJnz55VkydPzndpHRcXF7V+/Xp18uRJ9fzzz+e7ZFhgYKA6dOiQ2rt3r/Lz89ObRj8xMVG5u7urQYMGqdOnT6vly5crOzu7crXskVLGyc+1a9eUr6+v6tSpk7p27ZreEhNaixYtUsuWLVNnz55VZ8+eVV988YUyMzNTCxYsKKHfjPEZIzf79+9Xc+bMUeHh4erixYtq6dKlys3NTQ0ePFh3Hzx3jPe6ppRSO3bsUADU2bNn88TF80YYIj+3b99Wx48fV5s2bVIA1PLly9Xx48f1XrdGjx6tqlWrpnbu3KmOHj2qWrRooVq0aKHbr132KCQkRIWHh6utW7cqNze3crfsUUnnJikpSQUFBakGDRqoqKgovf85mZmZSimlNmzYoObNm6dOnTqlLly4oH744QdlZ2enJk2aVIK/HeMzRn6ioqLU1KlT1dGjR9Xly5fV+vXrVc2aNVXbtm1198Fzx3iva0opdeHCBaXRaNSWLVvyxMVzp/hzk56ernr16qWqVq2qwsPD9V6zcs9EXppqHRbdJeTbb79V1apVU1ZWVqpZs2bq4MGDun3t2rVTQ4YM0Tt+5cqVqlatWsrKykrVq1dPbdq0SW9/dna2+vTTT5W7u7uytrZWnTp1UufOndM75vbt26p///7KwcFBOTk5qWHDhumtKaiUUidOnFCtW7dW1tbWqkqVKurLL78s3ideSpR0fhYuXKgA5Nu0Fi1apOrUqaPs7OyUk5OTatasmd5SPOVFSefm2LFjKigoSDk7OysbGxtVp04dNW3aNPXw4UO9++G5Y5zXNaWU6t+/v97az7nxvMlR3Pl51OvW5MmTdcekpqaqN954Q1WoUEHZ2dmpF154Ic+b1ytXrqhu3bopW1tb5erqqsaPH6+3bFV5UNK52bVr1yP/51y+fFkpJUvtBAQEKAcHB2Vvb68aNWqkfvrpJ5WVlWXIX4VJKun8xMTEqLZt26qKFSsqa2tr5evrqz744AO9dbqV4rmjlHFe15RSauLEicrb2zvf84HnjijO3GiXcMuv7dq1S3dcaap1NEqVk/nsiYiIiIiIiEoYr+kmIiIiIiIiMhAW3UREREREREQGwqKbiIiIiIiIyEBYdBMREREREREZCItuIiIiIiIiIgNh0U1ERERERERkICy6iYiIiIiIiAyERTcRERERERGRgbDoJiIiKsOGDh2K3r17G+3xBw0ahGnTphXo2FdeeQWzZ882cEREREQlS6OUUsYOgoiIiApPo9E8dv/kyZPx3nvvQSkFFxeXkgkqlxMnTqBjx46Ijo6Gg4PDE48/ffo02rZti8uXL8PZ2bkEIiQiIjI8Ft1ERESlVHx8vO77FStWYNKkSTh37pxum4ODQ4GKXUN57bXXYGFhgZ9++qnAP9O0aVMMHToUb775pgEjIyIiKjkcXk5ERFRKeXh46JqzszM0Go3eNgcHhzzDy9u3b4+3334b7777LipUqAB3d3fMmzcPDx48wLBhw+Do6AhfX19s2bJF77FOnz6Nbt26wcHBAe7u7hg0aBBu3br1yNiysrLw+++/o2fPnnrbf/jhB/j5+cHGxgbu7u546aWX9Pb37NkTy5cvf/pfDhERkYlg0U1ERFTOLF68GK6urjh8+DDefvttjBkzBn379kXLli3x999/IyQkBIMGDUJKSgoAIDExER07dkRgYCCOHj2KrVu3IiEhAf369XvkY5w8eRJJSUl49tlndduOHj2KsWPHYurUqTh37hy2bt2Ktm3b6v1cs2bNcPjwYaSlpRnmyRMREZUwFt1ERETlTKNGjfDJJ5/Az88PEydOhI2NDVxdXTFy5Ej4+flh0qRJuH37Nk6ePAkA+O677xAYGIhp06bB398fgYGBWLBgAXbt2oXz58/n+xjR0dEwNzdH5cqVddtiYmJgb2+P5557DtWrV0dgYCDGjh2r93NeXl5IT0/XGzpPRERUmrHoJiIiKmcaNmyo+97c3ByVKlVCgwYNdNvc3d0BADdu3AAgE6Lt2rVLd424g4MD/P39AQAXL17M9zFSU1NhbW2tN9lb586dUb16ddSsWRODBg3Cr7/+qutN17K1tQWAPNuJiIhKKxbdRERE5YylpaXebY1Go7dNWyhnZ2cDAO7fv4+ePXsiPDxcr124cCHP8HAtV1dXpKSkID09XbfN0dERf//9N3777Td4enpi0qRJaNSoERITE3XH3LlzBwDg5uZWLM+ViIjI2Fh0ExER0WM1btwYZ86cQY0aNeDr66vX7O3t8/2ZgIAAAEBERITedgsLCwQHB2PGjBk4efIkrly5gp07d+r2nz59GlWrVoWrq6vBng8REVFJYtFNREREj/Xmm2/izp076N+/P44cOYKLFy9i27ZtGDZsGLKysvL9GTc3NzRu3Bh79+7Vbdu4cSPmzp2L8PBwREdHY8mSJcjOzkbt2rV1x+zZswchISEGf05EREQlhUU3ERERPZaXlxf27duHrKwshISEoEGDBnj33Xfh4uICM7NHv5V47bXX8Ouvv+puu7i4YM2aNejYsSPq1KmDn376Cb/99hvq1asHAHj48CHWrVuHkSNHGvw5ERERlRSNUkoZOwgiIiIqe1JTU1G7dm2sWLECLVq0eOLxP/74I9auXYvt27eXQHREREQlgz3dREREZBC2trZYsmQJbt26VaDjLS0t8e233xo4KiIiopLFnm4iIiIiIiIiA2FPNxEREREREZGBsOgmIiIiIiIiMhAW3UREREREREQGwqKbiIiIiIiIyEBYdBMREREREREZCItuIiIiIiIiIgNh0U1ERERERERkICy6iYiIiIiIiAyERTcRERERERGRgbDoJiIiIiIiIjKQ/we4nrC+p6Jr+AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1000x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_dc_waveform(t, dc_voltage=12):\n",
        "    return np.full_like(t, dc_voltage)\n",
        "\n",
        "def generate_ac_waveform(t, freq=50, amplitude=12):\n",
        "    return amplitude * np.sin(2 * np.pi * freq * t)\n",
        "\n",
        "def generate_pwm_waveform(t, freq=50, duty_cycle=0.5):\n",
        "    pwm_wave = np.where(np.sin(2 * np.pi * freq * t) >= duty_cycle, 1, -1)\n",
        "    return pwm_wave * 12  # Scale to match voltage level\n",
        "\n",
        "# Time vector (1 cycle at 50Hz)\n",
        "t = np.linspace(0, 1/50, 1000)\n",
        "\n",
        "dc_wave = generate_dc_waveform(t)\n",
        "ac_wave = generate_ac_waveform(t)\n",
        "pwm_wave = generate_pwm_waveform(t)\n",
        "\n",
        "# Plot waveforms\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(t, dc_wave, label='DC Input', color='r')\n",
        "plt.title('DC Waveform')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Voltage (V)')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(t, pwm_wave, label='PWM Signal', color='g')\n",
        "plt.title('PWM Waveform (Inverter Switching)')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Voltage (V)')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(t, ac_wave, label='AC Output', color='b')\n",
        "plt.title('AC Waveform (One Phase)')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Voltage (V)')\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyh4NockEfRA"
      },
      "source": [
        "# **MAIN MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS4Jg2kZUWLL"
      },
      "source": [
        "Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "9PJdy2ANf2cd",
        "outputId": "3eaa7a4f-f194-4b28-94ca-ac2ab606a5ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please upload your dataset (CSV/XLSX):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fca37699-a722-42af-8a88-ae650e685592\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fca37699-a722-42af-8a88-ae650e685592\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "\n",
        "# 📌 Step 1: Upload & Load Dataset\n",
        "print(\"Please upload your dataset (CSV/XLSX):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.csv'):\n",
        "        df = pd.read_csv(filename)\n",
        "    elif filename.endswith('.xlsx'):\n",
        "        df = pd.read_excel(filename)\n",
        "    else:\n",
        "        print(\"Unsupported file format.\")\n",
        "\n",
        "# 📌 Step 2: Clean the Data\n",
        "print(\"\\nInitial Data Overview:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill missing values (optional: choose mean, median, or forward fill)\n",
        "df.fillna(method='ffill', inplace=True)  # Forward fill\n",
        "\n",
        "# 📌 Step 3: Convert Time Column to Datetime (if applicable)\n",
        "time_col = \"Time (s)\"  # Match the exact column name\n",
        "  # Change if necessary\n",
        "df[time_col] = pd.to_datetime(df[time_col], errors='coerce')\n",
        "df.set_index(time_col, inplace=True)\n",
        "\n",
        "# 📌 Step 4: Visualize Data\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "# Plot Voltage Over Time\n",
        "plt.subplot(2,2,1)\n",
        "sns.lineplot(data=df, x=df.index, y='Voltage (V)', color='blue')\n",
        "plt.title(\"Voltage Over Time\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Voltage (V)\")\n",
        "\n",
        "# Plot Current Over Time\n",
        "plt.subplot(2,2,2)\n",
        "sns.lineplot(data=df, x=df.index, y='Current (A)', color='red')\n",
        "plt.title(\"Current Over Time\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Current (A)\")\n",
        "\n",
        "# Plot Power Consumption Over Time\n",
        "plt.subplot(2,2,3)\n",
        "sns.lineplot(data=df, x=df.index, y='Power (W)', color='green')\n",
        "plt.title(\"Power Consumption Over Time\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Power (W)\")\n",
        "\n",
        "# Plot Frequency Over Time\n",
        "plt.subplot(2,2,4)\n",
        "sns.lineplot(data=df, x=df.index, y='Frequency (Hz)', color='purple')\n",
        "plt.title(\"Frequency Over Time\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Frequency (Hz)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 📌 Step 5: Prepare Data for Reinforcement Learning (RL)\n",
        "# Define State Variables\n",
        "df_rl = df[['Voltage (V)', 'Current (A)', 'Power (W)', 'Frequency (Hz)', 'Power Factor']]\n",
        "\n",
        "# Normalize Data for RL\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df_rl_scaled = pd.DataFrame(scaler.fit_transform(df_rl), columns=df_rl.columns, index=df.index)\n",
        "\n",
        "print(\"\\n✅ Data Prepared for RL Training! Shape:\", df_rl_scaled.shape)\n",
        "\n",
        "# Save Processed Data for RL Training\n",
        "df_rl_scaled.to_csv(\"processed_data_for_rl.csv\")\n",
        "print(\"\\n📁 Processed dataset saved as 'processed_data_for_rl.csv'. You can now use it for RL training!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hRJQAjXUb6A"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oUL7mCuI_4b"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3[extra] gym\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcyNOdFqKZYc"
      },
      "outputs": [],
      "source": [
        "!pip install shimmy>=2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuKFO5BLIz91"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 📌 Step 1: Upload & Load Dataset\n",
        "print(\"Please upload your dataset (CSV/XLSX):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.csv'):\n",
        "        df = pd.read_csv(filename)\n",
        "    elif filename.endswith('.xlsx'):\n",
        "        df = pd.read_excel(filename)\n",
        "    else:\n",
        "        print(\"Unsupported file format.\")\n",
        "\n",
        "# 📌 Step 2: Clean the Data\n",
        "print(\"\\nInitial Data Overview:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill missing values\n",
        "df.fillna(method='ffill', inplace=True)  # Forward fill\n",
        "\n",
        "time_col = \"Time (s)\"  # Change if necessary\n",
        "df[time_col] = pd.to_datetime(df[time_col], errors='coerce')\n",
        "df.set_index(time_col, inplace=True)\n",
        "\n",
        "# 📌 Step 3: Prepare Data for RL\n",
        "features = ['Voltage (V)', 'Current (A)', 'Power (W)', 'Frequency (Hz)', 'Power Factor']\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df[features]), columns=features, index=df.index)\n",
        "\n",
        "# 📌 Step 4: Define RL Environment\n",
        "class InverterEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(InverterEnv, self).__init__()\n",
        "        self.state = df_scaled.iloc[0].values\n",
        "        self.current_step = 0\n",
        "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)  # PWM control\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(5,), dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(df_scaled):\n",
        "            done = True\n",
        "            return self.state, 0, done, {}\n",
        "\n",
        "        self.state = df_scaled.iloc[self.current_step].values\n",
        "        reward = -abs(self.state[0] - 0.5)  # Reward for maintaining stable voltage\n",
        "        return self.state, reward, False, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        self.state = df_scaled.iloc[0].values\n",
        "        return self.state\n",
        "\n",
        "# 📌 Step 5: Train RL Model\n",
        "env = DummyVecEnv([lambda: InverterEnv()])\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# 📌 Step 6: Save RL Model\n",
        "model.save(\"inverter_rl_model\")\n",
        "print(\"\\n✅ RL Model Training Complete. Model saved as 'inverter_rl_model'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMjUAOLkU-ae"
      },
      "source": [
        "Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wiB9ZbuL35t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 📌 Step 1: Upload & Load Dataset\n",
        "print(\"Please upload your dataset (CSV/XLSX):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.csv'):\n",
        "        df = pd.read_csv(filename)\n",
        "    elif filename.endswith('.xlsx'):\n",
        "        df = pd.read_excel(filename)\n",
        "    else:\n",
        "        print(\"Unsupported file format.\")\n",
        "\n",
        "# 📌 Step 2: Clean the Data\n",
        "print(\"\\nInitial Data Overview:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill missing values\n",
        "df.fillna(method='ffill', inplace=True)  # Forward fill\n",
        "\n",
        "time_col = \"Time (s)\"  # Change if necessary\n",
        "df[time_col] = pd.to_datetime(df[time_col], errors='coerce')\n",
        "df.set_index(time_col, inplace=True)\n",
        "\n",
        "# 📌 Step 3: Prepare Data for RL\n",
        "features = ['Voltage (V)', 'Current (A)', 'Power (W)', 'Frequency (Hz)', 'Power Factor']\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df[features]), columns=features, index=df.index)\n",
        "\n",
        "# 📌 Step 4: Define RL Environment\n",
        "class InverterEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(InverterEnv, self).__init__()\n",
        "        self.state = df_scaled.iloc[0].values\n",
        "        self.current_step = 0\n",
        "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)  # PWM control\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(5,), dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(df_scaled):\n",
        "            done = True\n",
        "            return self.state, 0, done, {}\n",
        "\n",
        "        self.state = df_scaled.iloc[self.current_step].values\n",
        "        reward = -abs(self.state[0] - 0.5)  # Reward for maintaining stable voltage\n",
        "        return self.state, reward, False, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        self.state = df_scaled.iloc[0].values\n",
        "        return self.state\n",
        "\n",
        "# 📌 Step 5: Train RL Model\n",
        "env = DummyVecEnv([lambda: InverterEnv()])\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# 📌 Step 6: Save RL Model\n",
        "model.save(\"inverter_rl_model\")\n",
        "print(\"\\n✅ RL Model Training Complete. Model saved as 'inverter_rl_model'.\")\n",
        "\n",
        "# 📌 Step 7: Test RL Model\n",
        "def test_model(model, env, steps=100):\n",
        "    obs = env.reset()\n",
        "    for _ in range(steps):\n",
        "        action, _states = model.predict(obs)\n",
        "        obs, rewards, done, info = env.step(action)\n",
        "        print(f\"Action: {action}, Reward: {rewards}\")\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "test_model(model, env)\n",
        "\n",
        "# 📌 Step 8: Deploy on ESP32 (Generate Control Commands)\n",
        "def generate_pwm_commands(model, env, steps=50):\n",
        "    obs = env.reset()\n",
        "    pwm_commands = []\n",
        "    for _ in range(steps):\n",
        "        action, _states = model.predict(obs)\n",
        "        pwm_value = int((action[0] + 1) * 127.5)  # Convert [-1,1] range to [0,255]\n",
        "        pwm_commands.append(pwm_value)\n",
        "    print(\"Generated PWM Commands:\", pwm_commands)\n",
        "    return pwm_commands\n",
        "\n",
        "generate_pwm_commands(model, env)\n",
        "\n",
        "# 📌 Step 9: Optimize RL Training (Hyperparameter Tuning)\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "def optimize_rl_model():\n",
        "    best_reward = -np.inf\n",
        "    best_model = None\n",
        "    for lr in [0.0003, 0.0001, 0.00005]:\n",
        "        model = PPO(\"MlpPolicy\", env, learning_rate=lr, verbose=1)\n",
        "        model.learn(total_timesteps=5000)\n",
        "        mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=5)\n",
        "        if mean_reward > best_reward:\n",
        "            best_reward = mean_reward\n",
        "            best_model = model\n",
        "    best_model.save(\"optimized_inverter_rl_model\")\n",
        "    print(\"✅ Best RL Model Trained and Saved as 'optimized_inverter_rl_model'\")\n",
        "\n",
        "optimize_rl_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4VYNweyVIoh"
      },
      "source": [
        "Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLVWwH5fQlCh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 📌 Step 1: Upload & Load Dataset\n",
        "print(\"Please upload your dataset (CSV/XLSX):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.csv'):\n",
        "        df = pd.read_csv(filename)\n",
        "    elif filename.endswith('.xlsx'):\n",
        "        df = pd.read_excel(filename)\n",
        "    else:\n",
        "        print(\"Unsupported file format.\")\n",
        "\n",
        "# 📌 Step 2: Clean the Data\n",
        "print(\"\\nInitial Data Overview:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill missing values\n",
        "df.fillna(method='ffill', inplace=True)  # Forward fill\n",
        "\n",
        "time_col = \"Time (s)\"  # Change if necessary\n",
        "df[time_col] = pd.to_datetime(df[time_col], errors='coerce')\n",
        "df.set_index(time_col, inplace=True)\n",
        "\n",
        "# 📌 Step 3: Prepare Data for RL\n",
        "features = ['Voltage (V)', 'Current (A)', 'Power (W)', 'Frequency (Hz)', 'Power Factor']\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df[features]), columns=features, index=df.index)\n",
        "\n",
        "# 📌 Step 4: Define RL Environment\n",
        "class InverterEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(InverterEnv, self).__init__()\n",
        "        self.state = df_scaled.iloc[0].values\n",
        "        self.current_step = 0\n",
        "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)  # PWM control\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(5,), dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(df_scaled):\n",
        "            done = True\n",
        "            return self.state, 0, done, {}\n",
        "\n",
        "        self.state = df_scaled.iloc[self.current_step].values\n",
        "        reward = -abs(self.state[0] - 0.5)  # Reward for maintaining stable voltage\n",
        "        return self.state, reward, False, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        self.state = df_scaled.iloc[0].values\n",
        "        return self.state\n",
        "\n",
        "# 📌 Step 5: Train RL Model\n",
        "env = DummyVecEnv([lambda: InverterEnv()])\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# 📌 Step 6: Save RL Model\n",
        "model.save(\"inverter_rl_model\")\n",
        "print(\"\\n✅ RL Model Training Complete. Model saved as 'inverter_rl_model'.\")\n",
        "\n",
        "# 📌 Step 7: Test RL Model\n",
        "def test_model(model, env, steps=100):\n",
        "    obs = env.reset()\n",
        "    for _ in range(steps):\n",
        "        action, _states = model.predict(obs)\n",
        "        obs, rewards, done, info = env.step(action)\n",
        "        print(f\"Action: {action}, Reward: {rewards}\")\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "test_model(model, env)\n",
        "\n",
        "# 📌 Step 8: Deploy on ESP32 (Generate Control Commands)\n",
        "def generate_pwm_commands(model, env, steps=50):\n",
        "    obs = env.reset()\n",
        "    pwm_commands = []\n",
        "    for _ in range(steps):\n",
        "        action, _states = model.predict(obs)\n",
        "        pwm_value = int((action[0] + 1) * 127.5)  # Convert [-1,1] range to [0,255]\n",
        "        pwm_commands.append(pwm_value)\n",
        "    print(\"Generated PWM Commands:\", pwm_commands)\n",
        "    return pwm_commands\n",
        "\n",
        "generate_pwm_commands(model, env)\n",
        "\n",
        "# 📌 Step 9: Optimize RL Training (Hyperparameter Tuning)\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "def optimize_rl_model():\n",
        "    best_reward = -np.inf\n",
        "    best_model = None\n",
        "    for lr in [0.0003, 0.0001, 0.00005]:\n",
        "        model = PPO(\"MlpPolicy\", env, learning_rate=lr, verbose=1)\n",
        "        model.learn(total_timesteps=5000)\n",
        "        mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=5)\n",
        "        if mean_reward > best_reward:\n",
        "            best_reward = mean_reward\n",
        "            best_model = model\n",
        "    best_model.save(\"optimized_inverter_rl_model\")\n",
        "    print(\"✅ Best RL Model Trained and Saved as 'optimized_inverter_rl_model'\")\n",
        "\n",
        "optimize_rl_model()\n",
        "\n",
        "# 📌 Step 10: Visualize Model Architecture and Processing\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def visualize_model_architecture(model):\n",
        "    \"\"\"\n",
        "    Generates an infographic visualizing the RL model's architecture and data flow.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(16, 8))\n",
        "    ax.axis('off')  # Hide the axes\n",
        "\n",
        "    # Colors\n",
        "    input_color = '#ADD8E6'  # Light blue\n",
        "    hidden_color = '#90EE90'  # Light green\n",
        "    output_color = '#FFB347'  # Light orange\n",
        "    arrow_color = '#808080'    # Gray\n",
        "\n",
        "    # Positions (adjust as needed)\n",
        "    x_start = 0.1\n",
        "    x_mid = 0.4\n",
        "    x_end = 0.7\n",
        "    y_center = 0.5\n",
        "    y_offset = 0.2\n",
        "\n",
        "    # Input Layer\n",
        "    ax.add_patch(patches.Rectangle((x_start - 0.05, y_center - y_offset), 0.1, 2 * y_offset, facecolor=input_color, edgecolor='black'))\n",
        "    ax.text(x_start, y_center, \"Input: Scaled\\nFeatures (5)\", ha='center', va='center')\n",
        "\n",
        "    # Hidden Layers\n",
        "    ax.add_patch(patches.Rectangle((x_mid - 0.05, y_center - y_offset), 0.1, 2 * y_offset, facecolor=hidden_color, edgecolor='black'))\n",
        "    ax.text(x_mid, y_center, \"Hidden Layers\\n(MlpPolicy)\", ha='center', va='center')\n",
        "\n",
        "    # Output Layer\n",
        "    ax.add_patch(patches.Rectangle((x_end - 0.05, y_center - y_offset), 0.1, 2 * y_offset, facecolor=output_color, edgecolor='black'))\n",
        "    ax.text(x_end, y_center, \"Output: PWM\\nControl Action\", ha='center', va='center')\n",
        "\n",
        "    # Arrows\n",
        "    ax.arrow(x_start + 0.05, y_center, x_mid - x_start - 0.1, 0, head_width=0.02, head_length=0.02, fc=arrow_color, ec=arrow_color)\n",
        "    ax.arrow(x_mid + 0.05, y_center, x_end - x_mid - 0.1, 0, head_width=0.02, head_length=0.02, fc=arrow_color, ec=arrow_color)\n",
        "\n",
        "    # Data Scaling\n",
        "    ax.text(x_start - 0.2, y_center, \"MinMaxScaler\\n(Data Scaling)\", ha='center', va='center', bbox=dict(facecolor=input_color, alpha=0.5))\n",
        "    ax.arrow(x_start - 0.1, y_center, 0.05, 0, head_width=0.02, head_length=0.02, fc=arrow_color, ec=arrow_color)\n",
        "\n",
        "    # RL Training Loop\n",
        "    ax.text(x_mid, y_center - 0.4, \"RL Training Loop:\\n- Observe State\\n- Take Action\\n- Get Reward\\n- Update Policy\", ha='center', va='top', fontsize=9, bbox=dict(facecolor=hidden_color, alpha=0.3))\n",
        "\n",
        "    # Title\n",
        "    plt.suptitle(\"RL Model Architecture for Inverter Control\", fontsize=16)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to visualize the model\n",
        "visualize_model_architecture(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdIjq_ikTkKu"
      },
      "source": [
        "# **VALIDATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJxc6qDuT0ig"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ✅ Load Dataset\n",
        "df = pd.read_csv(\"processed_data_for_rl.csv\")\n",
        "features = ['Voltage (V)', 'Current (A)', 'Power (W)', 'Frequency (Hz)', 'Power Factor']\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df[features]), columns=features)\n",
        "\n",
        "# ✅ Define Custom RL Environment\n",
        "class InverterEnv(gym.Env):\n",
        "    def __init__(self, df_scaled):\n",
        "        super(InverterEnv, self).__init__()\n",
        "        self.df_scaled = df_scaled\n",
        "        self.state = df_scaled.iloc[0].values\n",
        "        self.current_step = 0\n",
        "        self.action_space = gym.spaces.Box(low=-2, high=2, shape=(1,), dtype=np.float32)  # 🔥 Expanded Action Space\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(5,), dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(self.df_scaled):\n",
        "            done = True\n",
        "            return self.state, 0, done, {}\n",
        "\n",
        "        self.state = self.df_scaled.iloc[self.current_step].values\n",
        "\n",
        "        # ✅ Extract Correct Power Output\n",
        "        voltage = self.state[0]  # Voltage (normalized)\n",
        "        current = self.state[1]  # Current (normalized)\n",
        "        power = self.state[2]     # Power (normalized)\n",
        "\n",
        "        # ✅ 🔥 New Reward Function → Maximizing Power Output\n",
        "        reward = power - abs(voltage - 0.5)  # Higher power = more reward\n",
        "\n",
        "        return self.state, reward, False, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        self.state = self.df_scaled.iloc[0].values\n",
        "        return self.state\n",
        "\n",
        "# ✅ Initialize Environment\n",
        "env = DummyVecEnv([lambda: InverterEnv(df_scaled)])\n",
        "\n",
        "# ✅ Train RL Model (Increased Steps)\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=50000)  # 🔥 Increased Training Steps\n",
        "\n",
        "# ✅ Save Model\n",
        "model.save(\"improved_inverter_rl_model\")\n",
        "print(\"\\n✅ RL Model Training Complete. Model saved as 'improved_inverter_rl_model'.\")\n",
        "\n",
        "# ✅ Evaluate Model\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "print(f\"✅ Model Evaluation: Mean Reward = {mean_reward}, Standard Deviation = {std_reward}\")\n",
        "\n",
        "# ✅ Function to Generate Performance Metrics\n",
        "def plot_performance_metrics(model):\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(12, 12))\n",
        "\n",
        "    # ✅ Reward Trend Over Time\n",
        "    rewards = []\n",
        "    obs = env.reset()\n",
        "    for _ in range(100):\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        rewards.append(reward)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    axes[0].plot(rewards, label=\"Reward\", color='green', linewidth=2)\n",
        "    axes[0].set_title(\"Reward Trend Over Time\")\n",
        "    axes[0].set_xlabel(\"Timesteps\")\n",
        "    axes[0].set_ylabel(\"Reward\")\n",
        "    axes[0].grid()\n",
        "    axes[0].legend()\n",
        "\n",
        "    # ✅ Action Distribution\n",
        "    actions = []\n",
        "    obs = env.reset()\n",
        "    for _ in range(100):\n",
        "        action, _ = model.predict(obs)\n",
        "        actions.append(action[0][0])\n",
        "        obs, _, done, _ = env.step(action)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    sns.histplot(actions, bins=20, kde=True, ax=axes[1], color='blue')\n",
        "    axes[1].set_title(\"Action Distribution\")\n",
        "    axes[1].set_xlabel(\"Action Value\")\n",
        "    axes[1].grid()\n",
        "\n",
        "    # ✅ Loss Trend (Simulated)\n",
        "    loss_values = np.exp(-np.array(range(100)) / 20)\n",
        "    axes[2].plot(loss_values, color='red', linewidth=2)\n",
        "    axes[2].set_title(\"Loss Trend Over Training Steps\")\n",
        "    axes[2].set_xlabel(\"Training Steps\")\n",
        "    axes[2].set_ylabel(\"Loss (Simulated)\")\n",
        "    axes[2].grid()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ✅ Generate Performance Metrics\n",
        "plot_performance_metrics(model)\n",
        "\n",
        "# ✅ Function to Calculate Efficiency\n",
        "def calculate_efficiency():\n",
        "    max_power = df[\"Power (W)\"].max()\n",
        "    predicted_power = scaler.inverse_transform([env.reset()[0]])[0][2]  # Convert back to actual power\n",
        "\n",
        "    efficiency = (predicted_power / max_power) * 100\n",
        "    return round(efficiency, 2)\n",
        "\n",
        "# ✅ Display Efficiency\n",
        "efficiency = calculate_efficiency()\n",
        "print(f\"\\n⚡️ Model Efficiency: {efficiency}%\")\n",
        "\n",
        "# ✅ Function to Plot AC, Current, and Power Waveform Together\n",
        "def plot_waveforms():\n",
        "    t = np.linspace(0, 1/50, 1000)\n",
        "\n",
        "    voltage = 230\n",
        "    current = 5\n",
        "    power = voltage * current * np.sin(2 * np.pi * 50 * t)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(t, voltage * np.sin(2 * np.pi * 50 * t), label=\"AC Voltage\", color=\"blue\", linewidth=3)\n",
        "    plt.plot(t, current * np.sin(2 * np.pi * 50 * t), label=\"Current\", color=\"red\", linestyle=\"dashed\", linewidth=3)\n",
        "    plt.plot(t, power, label=\"Power\", color=\"magenta\", linestyle=\"dotted\", linewidth=3)\n",
        "\n",
        "    plt.title(\"AC Voltage, Current & Power Waveform\")\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# ✅ Plot Waveforms\n",
        "plot_waveforms()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPneMWRQAcB8"
      },
      "source": [
        "# **INTERFACE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt6YQhhDD_JV"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dBbC_-rtjl4",
        "outputId": "b918fcd3-d0cf-431a-dc66-6c2fd389e0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "w25so18nO__6",
        "outputId": "4f700efe-3cb4-4a81-e845-10161c676c33"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'optimized_inverter_rl_model.zip'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2904143448.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# ✅ Load Pre-trained RL Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimized_inverter_rl_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 📌 Function to Predict Power, Frequency, and Power Factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mget_system_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         data, params, pytorch_variables = load_from_zip_file(\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py\u001b[0m in \u001b[0;36mload_from_zip_file\u001b[0;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mdict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpytorch\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \"\"\"\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;31m# set device to cpu if cuda is not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    907\u001b[0m                             '1 positional argument')\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py\u001b[0m in \u001b[0;36mopen_path_str\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \"\"\"\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen_path_pathlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py\u001b[0m in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m#   with corrections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen_path_pathlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py\u001b[0m in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py\u001b[0m in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'optimized_inverter_rl_model.zip'"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "# ✅ Load Pre-trained RL Model\n",
        "model = PPO.load(\"optimized_inverter_rl_model\")\n",
        "\n",
        "# 📌 Function to Predict Power, Frequency, and Power Factor\n",
        "def predict_values(voltage, current):\n",
        "    obs = np.array([[voltage, current, 0, 0, 0]])  # Assuming other inputs as 0\n",
        "    action, _ = model.predict(obs)\n",
        "\n",
        "    # Convert RL Output to Real Values\n",
        "    predicted_power = round((action[0][0] + 1) * 127.5, 2)\n",
        "    predicted_freq = round((action[0][0] + 1) * 25 + 25, 2)\n",
        "    predicted_pf = round((action[0][0] + 1) / 2, 2)\n",
        "\n",
        "    return predicted_power, predicted_freq, predicted_pf\n",
        "\n",
        "# 📌 Function to Generate DC Waveform\n",
        "def generate_dc_waveform(voltage):\n",
        "    t = np.linspace(0, 1, 1000)\n",
        "    dc_wave = np.full_like(t, voltage)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(t, dc_wave, 'r', linewidth=3)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Voltage (V)\")\n",
        "    plt.title(\"DC Waveform\")\n",
        "    plt.grid(True)\n",
        "    fig_path = \"dc_waveform.png\"\n",
        "    plt.savefig(fig_path)\n",
        "    return fig_path\n",
        "\n",
        "# 📌 Function to Generate PWM Waveform\n",
        "def generate_pwm_waveform(voltage):\n",
        "    t = np.linspace(0, 1/50, 1000)\n",
        "    pwm_wave = np.where(np.sin(2 * np.pi * 50 * t) >= 0, voltage, 0)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(t, pwm_wave, 'g', linewidth=3)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Voltage (V)\")\n",
        "    plt.title(\"PWM Waveform\")\n",
        "    plt.grid(True)\n",
        "    fig_path = \"pwm_waveform.png\"\n",
        "    plt.savefig(fig_path)\n",
        "    return fig_path\n",
        "\n",
        "# 📌 Function to Generate AC Waveform\n",
        "def generate_ac_waveform(voltage):\n",
        "    t = np.linspace(0, 1/50, 1000)\n",
        "    ac_wave = voltage * np.sin(2 * np.pi * 50 * t)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(t, ac_wave, 'b', linewidth=3)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Voltage (V)\")\n",
        "    plt.title(\"AC Waveform\")\n",
        "    plt.grid(True)\n",
        "    fig_path = \"ac_waveform.png\"\n",
        "    plt.savefig(fig_path)\n",
        "    return fig_path\n",
        "\n",
        "# 📌 Function to Generate Merged AC, Current & Power Waveform\n",
        "def generate_combined_waveform(voltage, current):\n",
        "    t = np.linspace(0, 1/50, 1000)\n",
        "\n",
        "    ac_wave = voltage * np.sin(2 * np.pi * 50 * t)\n",
        "    current_wave = current * np.sin(2 * np.pi * 50 * t)\n",
        "    power_wave = voltage * current * (np.sin(2 * np.pi * 50 * t))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(t, ac_wave, label='AC Voltage (V)', color='blue', linewidth=3, alpha=0.8)\n",
        "    plt.plot(t, current_wave, label='Current (A)', color='red', linestyle='dashed', linewidth=3, alpha=0.8)\n",
        "    plt.plot(t, power_wave, label='Power (W)', color='yellow', linestyle='dotted', linewidth=4, alpha=0.9)\n",
        "\n",
        "    plt.title('AC Voltage, Current, and Power Waveform')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    fig_path = \"merged_waveform.png\"\n",
        "    plt.savefig(fig_path)\n",
        "    return fig_path\n",
        "\n",
        "# 🚀 Create Gradio Interface\n",
        "with gr.Blocks() as ui:\n",
        "    gr.Markdown(\"# ⚡ RL-Based Inverter Prediction & Waveform Visualization\")\n",
        "\n",
        "    with gr.Row():\n",
        "        voltage = gr.Number(label=\"Voltage (V)\")\n",
        "        current = gr.Number(label=\"Current (A)\")\n",
        "        power_out = gr.Number(label=\"Predicted Power (W)\")\n",
        "        freq_out = gr.Number(label=\"Predicted Frequency (Hz)\")\n",
        "        pf_out = gr.Number(label=\"Predicted Power Factor\")\n",
        "        predict_btn = gr.Button(\"Predict Values\")\n",
        "        predict_btn.click(predict_values, inputs=[voltage, current], outputs=[power_out, freq_out, pf_out])\n",
        "\n",
        "    gr.Markdown(\"## 📊 Waveform Visualizations\")\n",
        "\n",
        "    with gr.Column():\n",
        "        dc_btn = gr.Button(\"Show DC Waveform\")\n",
        "        pwm_btn = gr.Button(\"Show PWM Waveform\")\n",
        "        ac_btn = gr.Button(\"Show AC Waveform\")\n",
        "        merged_btn = gr.Button(\"Show Merged Waveform\")\n",
        "\n",
        "        dc_plot = gr.Image()\n",
        "        pwm_plot = gr.Image()\n",
        "        ac_plot = gr.Image()\n",
        "        merged_plot = gr.Image()\n",
        "\n",
        "        dc_btn.click(generate_dc_waveform, inputs=[voltage], outputs=[dc_plot])\n",
        "        pwm_btn.click(generate_pwm_waveform, inputs=[voltage], outputs=[pwm_plot])\n",
        "        ac_btn.click(generate_ac_waveform, inputs=[voltage], outputs=[ac_plot])\n",
        "        merged_btn.click(generate_combined_waveform, inputs=[voltage, current], outputs=[merged_plot])\n",
        "\n",
        "ui.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UcBXVH3TMGb"
      },
      "source": [
        "THE END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfIqjKM0_YKz"
      },
      "source": [
        "# ***Notun jinish bedaaaa***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKfLIfpC_b3w",
        "outputId": "11e7df56-065b-4bc4-9fdf-396640a3f2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install numpy scipy matplotlib gymnasium stable-baselines3 torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WSgvndhI_hD4"
      },
      "outputs": [],
      "source": [
        "# inverter_model.py\n",
        "import numpy as np\n",
        "from scipy.integrate import solve_ivp\n",
        "\n",
        "class InverterModel:\n",
        "    \"\"\"\n",
        "    A high-fidelity, simulation-based model of a single-phase H-bridge inverter\n",
        "    with an LC filter. This model includes non-ideal characteristics for\n",
        "    Q1-level academic rigor.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 v_dc=48.0,          # DC bus voltage (V)\n",
        "                 l=1.5e-3,           # Filter inductor (H)\n",
        "                 c=10e-6,            # Filter capacitor (F)\n",
        "                 r_esr_l=0.1,        # Inductor ESR (Ohm)\n",
        "                 r_esr_c=0.05,       # Capacitor ESR (Ohm)\n",
        "                 rds_on=0.08,        # MOSFET On-Resistance (Ohm)\n",
        "                 dead_time=1e-6,     # Switching dead time (s)\n",
        "                 pwm_freq=20000,     # PWM switching frequency (Hz)\n",
        "                 ac_freq=50.0):      # Target AC output frequency (Hz)\n",
        "\n",
        "        # Store parameters\n",
        "        self.V_dc = v_dc\n",
        "        self.L = l\n",
        "        self.C = c\n",
        "        self.R_esr_L = r_esr_l\n",
        "        self.R_esr_C = r_esr_c\n",
        "        self.Rds_on = rds_on\n",
        "        self.dead_time = dead_time\n",
        "        self.pwm_freq = pwm_freq\n",
        "        self.ac_freq = ac_freq\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "\n",
        "        # Initial state: [inductor_current, capacitor_voltage]\n",
        "        self.state = np.array([0.0, 0.0])\n",
        "        self.sim_time = 0.0\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Resets the simulation to its initial state.\"\"\"\n",
        "        self.state = np.array([0.0, 0.0])\n",
        "        self.sim_time = 0.0\n",
        "        return self.state\n",
        "\n",
        "    def _state_space_equations(self, t, y, v_inverter, r_load):\n",
        "        \"\"\"\n",
        "        Defines the differential equations for the LC filter with parasitics.\n",
        "        y = [i_L, v_C]\n",
        "        \"\"\"\n",
        "        i_L, v_C = y\n",
        "\n",
        "        # Current through capacitor's ESR and the load\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "\n",
        "        # Equations including ESR\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "\n",
        "        return [diL_dt, dvC_dt]\n",
        "\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        \"\"\"\n",
        "        Simulates one time step of the inverter.\n",
        "\n",
        "        Args:\n",
        "            modulation_index (float): The amplitude of the sine wave reference (0 to 1).\n",
        "            r_load (float): The load resistance in Ohms.\n",
        "            dt (float): The simulation time step.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (new_state, power_dissipated)\n",
        "        \"\"\"\n",
        "        # --- PWM Generation with Dead Time ---\n",
        "        # Generate the sinusoidal reference for this time step\n",
        "        sine_ref = modulation_index * np.sin(2 * np.pi * self.ac_freq * self.sim_time)\n",
        "\n",
        "        # Generate a high-frequency triangular carrier wave\n",
        "        carrier = 2 * (np.abs(2 * ((self.sim_time / self.pwm_period) - np.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "\n",
        "        v_inverter = 0\n",
        "        # Determine the switching state based on the carrier and reference\n",
        "        if sine_ref > carrier: # Top-left and bottom-right switches ON\n",
        "            v_inverter = self.V_dc\n",
        "        elif sine_ref < carrier: # Top-right and bottom-left switches ON\n",
        "            v_inverter = -self.V_dc\n",
        "\n",
        "        # --- Conduction Losses (Rds_on) ---\n",
        "        # The effective voltage is reduced by the MOSFET's on-resistance\n",
        "        v_inverter_eff = v_inverter - np.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # --- Dead Time Effect (Simplified Model) ---\n",
        "        # During dead time, the output voltage is clamped by the body diodes\n",
        "        time_in_pwm_cycle = self.sim_time % self.pwm_period\n",
        "        if time_in_pwm_cycle < self.dead_time or time_in_pwm_cycle > (self.pwm_period - self.dead_time):\n",
        "             # Diode drop opposes the current flow\n",
        "             v_inverter_eff = -np.sign(self.state[0]) * 0.7 # Approximate diode drop\n",
        "\n",
        "        # --- Solve the system for this time step ---\n",
        "        sol = solve_ivp(\n",
        "            fun=self._state_space_equations,\n",
        "            t_span=(0, dt),\n",
        "            y0=self.state,\n",
        "            args=(v_inverter_eff, r_load),\n",
        "            t_eval=[dt]\n",
        "        )\n",
        "        self.state = sol.y[:, -1]\n",
        "        self.sim_time += dt\n",
        "\n",
        "        # Calculate losses for efficiency calculation\n",
        "        conduction_loss = (self.state[0] ** 2) * self.Rds_on\n",
        "        esr_loss = (self.state[0] ** 2) * self.R_esr_L + ((self.state[1] / r_load)**2) * self.R_esr_C\n",
        "        total_loss = conduction_loss + esr_loss\n",
        "\n",
        "        return self.state, total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "113f1201",
        "outputId": "320e24fe-242f-4630-fac0-808369de4795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing inverter_model.py\n"
          ]
        }
      ],
      "source": [
        "# Save the InverterModel class to a Python file\n",
        "%%writefile inverter_model.py\n",
        "import numpy as np\n",
        "from scipy.integrate import solve_ivp\n",
        "\n",
        "class InverterModel:\n",
        "    \"\"\"\n",
        "    A high-fidelity, simulation-based model of a single-phase H-bridge inverter\n",
        "    with an LC filter. This model includes non-ideal characteristics for\n",
        "    Q1-level academic rigor.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 v_dc=48.0,          # DC bus voltage (V)\n",
        "                 l=1.5e-3,           # Filter inductor (H)\n",
        "                 c=10e-6,            # Filter capacitor (F)\n",
        "                 r_esr_l=0.1,        # Inductor ESR (Ohm)\n",
        "                 r_esr_c=0.05,       # Capacitor ESR (Ohm)\n",
        "                 rds_on=0.08,        # MOSFET On-Resistance (Ohm)\n",
        "                 dead_time=1e-6,     # Switching dead time (s)\n",
        "                 pwm_freq=20000,     # PWM switching frequency (Hz)\n",
        "                 ac_freq=50.0):      # Target AC output frequency (Hz)\n",
        "\n",
        "        # Store parameters\n",
        "        self.V_dc = v_dc\n",
        "        self.L = l\n",
        "        self.C = c\n",
        "        self.R_esr_L = r_esr_l\n",
        "        self.R_esr_C = r_esr_c\n",
        "        self.Rds_on = rds_on\n",
        "        self.dead_time = dead_time\n",
        "        self.pwm_freq = pwm_freq\n",
        "        self.ac_freq = ac_freq\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "\n",
        "        # Initial state: [inductor_current, capacitor_voltage]\n",
        "        self.state = np.array([0.0, 0.0])\n",
        "        self.sim_time = 0.0\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Resets the simulation to its initial state.\"\"\"\n",
        "        self.state = np.array([0.0, 0.0])\n",
        "        self.sim_time = 0.0\n",
        "        return self.state\n",
        "\n",
        "    def _state_space_equations(self, t, y, v_inverter, r_load):\n",
        "        \"\"\"\n",
        "        Defines the differential equations for the LC filter with parasitics.\n",
        "        y = [i_L, v_C]\n",
        "        \"\"\"\n",
        "        i_L, v_C = y\n",
        "\n",
        "        # Current through capacitor's ESR and the load\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "\n",
        "        # Equations including ESR\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "\n",
        "        return [diL_dt, dvC_dt]\n",
        "\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        \"\"\"\n",
        "        Simulates one time step of the inverter.\n",
        "\n",
        "        Args:\n",
        "            modulation_index (float): The amplitude of the sine wave reference (0 to 1).\n",
        "            r_load (float): The load resistance in Ohms.\n",
        "            dt (float): The simulation time step.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (new_state, power_dissipated)\n",
        "        \"\"\"\n",
        "        # --- PWM Generation with Dead Time ---\n",
        "        # Generate the sinusoidal reference for this time step\n",
        "        sine_ref = modulation_index * np.sin(2 * np.pi * self.ac_freq * self.sim_time)\n",
        "\n",
        "        # Generate a high-frequency triangular carrier wave\n",
        "        carrier = 2 * (np.abs(2 * ((self.sim_time / self.pwm_period) - np.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "\n",
        "        v_inverter = 0\n",
        "        # Determine the switching state based on the carrier and reference\n",
        "        if sine_ref > carrier: # Top-left and bottom-right switches ON\n",
        "            v_inverter = self.V_dc\n",
        "        elif sine_ref < carrier: # Top-right and bottom-left switches ON\n",
        "            v_inverter = -self.V_dc\n",
        "\n",
        "        # --- Conduction Losses (Rds_on) ---\n",
        "        # The effective voltage is reduced by the MOSFET's on-resistance\n",
        "        v_inverter_eff = v_inverter - np.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # --- Dead Time Effect (Simplified Model) ---\n",
        "        # During dead time, the output voltage is clamped by the body diodes\n",
        "        time_in_pwm_cycle = self.sim_time % self.pwm_period\n",
        "        if time_in_pwm_cycle < self.dead_time or time_in_pwm_cycle > (self.pwm_period - self.dead_time):\n",
        "             # Diode drop opposes the current flow\n",
        "             v_inverter_eff = -np.sign(self.state[0]) * 0.7 # Approximate diode drop\n",
        "\n",
        "        # --- Solve the system for this time step ---\n",
        "        sol = solve_ivp(\n",
        "            fun=self._state_space_equations,\n",
        "            t_span=(0, dt),\n",
        "            y0=self.state,\n",
        "            args=(v_inverter_eff, r_load),\n",
        "            t_eval=[dt]\n",
        "        )\n",
        "        self.state = sol.y[:, -1]\n",
        "        self.sim_time += dt\n",
        "\n",
        "        # Calculate losses for efficiency calculation\n",
        "        conduction_loss = (self.state[0] ** 2) * self.Rds_on\n",
        "        esr_loss = (self.state[0] ** 2) * self.R_esr_L + ((self.state[1] / r_load)**2) * self.R_esr_C\n",
        "        total_loss = conduction_loss + esr_loss\n",
        "\n",
        "        return self.state, total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb561373",
        "outputId": "2c9885f0-ecaf-46c0-e2e8-11090b9066d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing rl_environment.py\n"
          ]
        }
      ],
      "source": [
        "# Save the InverterEnv class to a Python file\n",
        "%%writefile rl_environment.py\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "from inverter_model import InverterModel\n",
        "\n",
        "class InverterEnv(gym.Env):\n",
        "    \"\"\"A custom Gymnasium environment for the RL-controlled inverter.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(InverterEnv, self).__init__()\n",
        "        self.inverter = InverterModel()\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        # Action: A single continuous value for modulation index\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "\n",
        "        # Observation: [V_rms, I_rms, Power, PF, THD]\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.max_steps = 200 # An episode will last 200 AC cycles\n",
        "\n",
        "    def _get_obs(self, v_history, i_history):\n",
        "        if len(v_history) < 2:\n",
        "            return np.zeros(5)\n",
        "\n",
        "        v_rms = np.sqrt(np.mean(np.square(v_history)))\n",
        "        i_rms = np.sqrt(np.mean(np.square(i_history)))\n",
        "        power = np.mean(v_history * i_history)\n",
        "        pf = power / (v_rms * i_rms) if v_rms > 0 and i_rms > 0 else 0.0\n",
        "\n",
        "        # Calculate THD (Total Harmonic Distortion)\n",
        "        fft = np.fft.fft(v_history)\n",
        "        harmonics = np.abs(fft[1:10]) # Look at the first few harmonics\n",
        "        fundamental = harmonics[0]\n",
        "        higher_harmonics = np.sqrt(np.sum(harmonics[1:]**2))\n",
        "        thd = higher_harmonics / fundamental if fundamental > 0 else 1.0\n",
        "\n",
        "\n",
        "        # Ensure the observation space is within defined bounds (0 to inf)\n",
        "        # This is a simplified check, consider more robust handling of NaNs/Infs\n",
        "        obs = np.array([v_rms, i_rms, power, pf, thd], dtype=np.float32)\n",
        "        obs[~np.isfinite(obs)] = 0.0  # Replace non-finite values with 0\n",
        "\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = np.random.uniform(20, 80) # Randomize load on reset\n",
        "        obs = self._get_obs(np.array([]), np.array([]))\n",
        "        return obs, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = (action[0] + 1.0) / 2.0 # De-normalize action from [-1, 1] to [0, 1]\n",
        "\n",
        "        v_history = []\n",
        "        i_history = []\n",
        "\n",
        "        for _ in range(self.sim_steps_per_cycle):\n",
        "            state, _ = self.inverter.step(modulation_index, self.load_resistance)\n",
        "            i_history.append(state[0])\n",
        "            v_history.append(state[1])\n",
        "\n",
        "        v_history = np.array(v_history)\n",
        "        i_history = np.array(i_history)\n",
        "\n",
        "        obs = self._get_obs(v_history, i_history)\n",
        "        v_rms, _, _, _, thd = obs\n",
        "\n",
        "\n",
        "        # --- Multi-Objective Reward Function ---\n",
        "        target_v_rms = 30.0 # Target voltage in our low-voltage simulation\n",
        "\n",
        "        # 1. Voltage Error Penalty\n",
        "        voltage_error = np.abs(target_v_rms - v_rms)\n",
        "        reward_voltage = - (voltage_error**2)\n",
        "\n",
        "        # 2. THD Penalty\n",
        "        reward_thd = - (thd**2) if thd < 0.5 else -10.0 # Heavily penalize high distortion\n",
        "\n",
        "        # 3. Stability Reward\n",
        "        reward_stability = 5.0 if voltage_error < 1.0 and thd < 0.1 else 0.0\n",
        "\n",
        "        reward = reward_voltage + reward_thd + reward_stability\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "        truncated = False\n",
        "\n",
        "        return obs, reward, done, truncated, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc7475a7",
        "outputId": "a7a846f6-31e4-4d74-973f-8394907db54e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing controllers.py\n"
          ]
        }
      ],
      "source": [
        "# Save the controller classes to a Python file\n",
        "%%writefile controllers.py\n",
        "import numpy as np\n",
        "\n",
        "class SPWMController:\n",
        "    \"\"\"Simple Sine-PWM controller (Open Loop).\"\"\"\n",
        "    def __init__(self, modulation_index=0.8):\n",
        "        self.modulation_index = modulation_index\n",
        "\n",
        "    def get_modulation_index(self, t, v_c_history=None):\n",
        "        # In open-loop, the modulation index is constant or based on a simple reference\n",
        "        return self.modulation_index\n",
        "\n",
        "class PIController:\n",
        "    \"\"\"Basic PI Controller for RMS Voltage regulation.\"\"\"\n",
        "    def __init__(self, Kp=0.1, Ki=1.0, target_rms=30.0, ac_freq=50.0):\n",
        "        self.Kp = Kp\n",
        "        self.Ki = Ki\n",
        "        self.target_rms = target_rms\n",
        "        self.error_integral = 0.0\n",
        "        self.last_error = 0.0\n",
        "        self.ac_period = 1.0 / ac_freq\n",
        "        self.modulation_index = 0.5 # Start with a default\n",
        "\n",
        "    def update_modulation_index(self, v_c_history):\n",
        "        \"\"\"Update PI controller based on the voltage history of the last cycle.\"\"\"\n",
        "        if len(v_c_history) < 2:\n",
        "            return # Not enough data yet\n",
        "\n",
        "        current_rms = np.sqrt(np.mean(np.square(v_c_history)))\n",
        "        error = self.target_rms - current_rms\n",
        "\n",
        "        # Simple Euler integration for the integral term\n",
        "        # Assumes v_c_history covers one full cycle\n",
        "        self.error_integral += error * self.ac_period\n",
        "\n",
        "        # PI control output\n",
        "        pi_output = self.Kp * error + self.Ki * self.error_integral\n",
        "\n",
        "        # Update modulation index, clipping to [0, 1]\n",
        "        # The relationship between PI output and modulation index depends on the system\n",
        "        # This is a simplified mapping. You might need to tune this.\n",
        "        self.modulation_index = np.clip(0.5 + pi_output * 0.1, 0.0, 1.0)\n",
        "\n",
        "\n",
        "    def get_modulation_index(self, t, v_c_history=None):\n",
        "         # The PI controller's output (modulation_index) is updated periodically\n",
        "         # The actual modulation signal for PWM is still sinusoidal\n",
        "        return self.modulation_index * np.sin(2 * np.pi * 50.0 * t) # Use the latest PI output as the amplitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytqQKQu2BKrJ",
        "outputId": "e1f9dad4-aa56-4895-dbd6-6ef3bf07f8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium stable-baselines3[extra] torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "ltvb4lZqBQ6v",
        "outputId": "099950a9-fe18-49e5-baf6-7f4d9d415852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "--- Starting RL Agent Training ---\n",
            "Logging to ./ppo_inverter_tensorboard/PPO_1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4182265049.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# This will take several minutes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Starting RL Agent Training ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Training Complete ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 311\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/rl_environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim_steps_per_cycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodulation_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_resistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mi_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mv_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/inverter_model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, modulation_index, r_load, dt)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# --- Solve the system for this time step ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         sol = solve_ivp(\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_space_equations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mt_span\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/integrate/_ivp/ivp.py\u001b[0m in \u001b[0;36msolve_ivp\u001b[0;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt_eval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/integrate/_ivp/rk.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, t0, y0, t_bound, max_step, rtol, atol, vectorized, first_step, **extraneous)\u001b[0m\n\u001b[1;32m     87\u001b[0m                  first_step=None, **extraneous):\n\u001b[1;32m     88\u001b[0m         \u001b[0mwarn_extraneous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextraneous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         super().__init__(fun, t0, y0, t_bound, vectorized,\n\u001b[0m\u001b[1;32m     90\u001b[0m                          support_complex=True)\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/integrate/_ivp/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, t0, y0, t_bound, vectorized, support_complex)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/integrate/_ivp/base.py\u001b[0m in \u001b[0;36mcheck_arguments\u001b[0;34m(fun, y0, support_complex)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"\"\"Helper function for checking arguments common to all solvers.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupport_complex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             raise ValueError(\"`y0` is complex, but the chosen solver does \"\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \"\"\"\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0marg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train_rl.py\n",
        "from stable_baselines3 import PPO\n",
        "from rl_environment import InverterEnv\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "\n",
        "# 1. Instantiate the environment\n",
        "# Colab can now find this class because you uploaded the file\n",
        "env = InverterEnv()\n",
        "\n",
        "# Optional: Check if the environment is valid\n",
        "# check_env(env)\n",
        "\n",
        "# 2. Define the PPO model with TensorBoard logging\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    verbose=1,\n",
        "    tensorboard_log=\"./ppo_inverter_tensorboard/\"\n",
        ")\n",
        "\n",
        "# 3. Train the model\n",
        "# We will train for 100,000 timesteps for a more robust agent.\n",
        "# This will take several minutes.\n",
        "print(\"--- Starting RL Agent Training ---\")\n",
        "model.learn(total_timesteps=100000)\n",
        "print(\"--- Training Complete ---\")\n",
        "\n",
        "# 4. Save the trained model\n",
        "model_zip_name = \"ppo_inverter_model.zip\"\n",
        "model.save(model_zip_name)\n",
        "print(f\"--- Model Saved as {model_zip_name} ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyX7UhZPjQoS"
      },
      "source": [
        "GPU CHUDOOOO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB0T30dzjR02",
        "outputId": "a2d8b674-2c64-4d26-bccb-38adff72fc91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium stable-baselines3[extra] torch torchdiffeq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JT6yNztXjbBy",
        "outputId": "6940e6a5-a8c1-4b84-eb11-e44b85f7a234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting GPU-Based Inverter RL Training ---\n",
            "\n",
            "Environment using device: cpu\n",
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Logging to ./ppo_inverter_tensorboard/PPO_2\n",
            "[Step 1] VRMS: 9.68, THD: 16.714, Reward: -2343.82, Step time: 0.981s\n",
            "[Step 2] VRMS: 31.96, THD: 0.318, Reward: -19.22, Step time: 0.844s\n",
            "[Step 3] VRMS: 32.80, THD: 0.309, Reward: -39.30, Step time: 0.770s\n",
            "[Step 4] VRMS: 19.37, THD: 0.696, Reward: -565.35, Step time: 0.814s\n",
            "[Step 5] VRMS: 19.64, THD: 0.653, Reward: -536.90, Step time: 0.790s\n",
            "[Step 6] VRMS: 33.80, THD: 0.307, Reward: -72.18, Step time: 0.790s\n",
            "[Step 7] VRMS: 20.73, THD: 0.501, Reward: -429.84, Step time: 0.782s\n",
            "[Step 8] VRMS: 10.03, THD: 3.228, Reward: -2005.31, Step time: 0.777s\n",
            "[Step 9] VRMS: 34.02, THD: 0.300, Reward: -80.96, Step time: 0.764s\n",
            "[Step 10] VRMS: 10.01, THD: 3.212, Reward: -2008.98, Step time: 1.012s\n",
            "[Step 11] VRMS: 15.89, THD: 1.435, Reward: -997.13, Step time: 1.064s\n",
            "[Step 12] VRMS: 18.82, THD: 0.770, Reward: -625.61, Step time: 1.179s\n",
            "[Step 13] VRMS: 34.18, THD: 0.294, Reward: -87.39, Step time: 0.782s\n",
            "[Step 14] VRMS: 10.02, THD: 3.252, Reward: -2005.89, Step time: 0.777s\n",
            "[Step 15] VRMS: 33.55, THD: 0.304, Reward: -62.93, Step time: 0.761s\n",
            "[Step 16] VRMS: 27.93, THD: 0.439, Reward: -21.55, Step time: 0.772s\n",
            "[Step 17] VRMS: 10.03, THD: 5.494, Reward: -2024.40, Step time: 0.763s\n",
            "[Step 18] VRMS: 30.80, THD: 0.358, Reward: -3.35, Step time: 0.832s\n",
            "[Step 19] VRMS: 10.03, THD: 3.261, Reward: -2004.24, Step time: 0.780s\n",
            "[Step 20] VRMS: 19.03, THD: 0.706, Reward: -602.64, Step time: 0.778s\n",
            "[Step 21] VRMS: 19.99, THD: 0.628, Reward: -501.35, Step time: 0.790s\n",
            "[Step 22] VRMS: 17.84, THD: 0.914, Reward: -740.73, Step time: 0.770s\n",
            "[Step 23] VRMS: 9.66, THD: 3.504, Reward: -2081.86, Step time: 0.749s\n",
            "[Step 24] VRMS: 9.60, THD: 3.003, Reward: -2090.05, Step time: 0.773s\n",
            "[Step 25] VRMS: 32.38, THD: 0.315, Reward: -28.51, Step time: 0.856s\n",
            "[Step 26] VRMS: 10.08, THD: 3.305, Reward: -1995.20, Step time: 1.098s\n",
            "[Step 27] VRMS: 30.17, THD: 0.384, Reward: -0.29, Step time: 1.153s\n",
            "[Step 28] VRMS: 17.50, THD: 0.988, Reward: -782.84, Step time: 0.870s\n",
            "[Step 29] VRMS: 20.18, THD: 0.562, Reward: -482.27, Step time: 0.816s\n",
            "[Step 30] VRMS: 31.15, THD: 0.351, Reward: -6.70, Step time: 0.770s\n",
            "[Step 31] VRMS: 10.05, THD: 3.245, Reward: -2000.27, Step time: 0.770s\n",
            "[Step 32] VRMS: 9.60, THD: 2.999, Reward: -2090.03, Step time: 0.773s\n",
            "[Step 33] VRMS: 9.60, THD: 3.001, Reward: -2090.06, Step time: 0.810s\n",
            "[Step 34] VRMS: 15.87, THD: 0.971, Reward: -998.65, Step time: 0.810s\n",
            "[Step 35] VRMS: 35.03, THD: 0.269, Reward: -126.73, Step time: 0.797s\n",
            "[Step 36] VRMS: 10.57, THD: 3.237, Reward: -1898.98, Step time: 0.794s\n",
            "[Step 37] VRMS: 30.30, THD: 0.329, Reward: -0.57, Step time: 0.776s\n",
            "[Step 38] VRMS: 34.88, THD: 0.261, Reward: -119.33, Step time: 0.766s\n",
            "[Step 39] VRMS: 34.99, THD: 0.261, Reward: -124.53, Step time: 0.806s\n",
            "[Step 40] VRMS: 19.15, THD: 0.589, Reward: -589.26, Step time: 0.893s\n",
            "[Step 41] VRMS: 9.60, THD: 3.304, Reward: -2092.48, Step time: 1.109s\n",
            "[Step 42] VRMS: 9.60, THD: 3.000, Reward: -2090.03, Step time: 1.186s\n",
            "[Step 43] VRMS: 34.64, THD: 0.254, Reward: -107.54, Step time: 0.829s\n",
            "[Step 44] VRMS: 18.52, THD: 0.612, Reward: -659.69, Step time: 0.777s\n",
            "[Step 45] VRMS: 19.14, THD: 0.533, Reward: -589.68, Step time: 0.799s\n",
            "[Step 46] VRMS: 30.67, THD: 0.296, Reward: -2.37, Step time: 0.802s\n",
            "[Step 47] VRMS: 9.73, THD: 3.238, Reward: -2065.82, Step time: 0.805s\n",
            "[Step 48] VRMS: 27.42, THD: 0.358, Reward: -33.42, Step time: 0.803s\n",
            "[Step 49] VRMS: 22.47, THD: 0.355, Reward: -283.77, Step time: 0.782s\n",
            "[Step 50] VRMS: 34.86, THD: 0.232, Reward: -118.27, Step time: 0.751s\n",
            "[Step 51] VRMS: 26.65, THD: 0.342, Reward: -56.09, Step time: 0.786s\n",
            "[Step 52] VRMS: 18.95, THD: 0.549, Reward: -610.55, Step time: 0.779s\n",
            "[Step 53] VRMS: 31.73, THD: 0.283, Reward: -15.08, Step time: 0.802s\n",
            "[Step 54] VRMS: 9.62, THD: 7.997, Reward: -2139.84, Step time: 0.819s\n",
            "[Step 55] VRMS: 28.28, THD: 0.344, Reward: -14.88, Step time: 0.878s\n",
            "[Step 56] VRMS: 29.90, THD: 0.310, Reward: -0.14, Step time: 1.170s\n",
            "[Step 57] VRMS: 34.59, THD: 0.250, Reward: -105.18, Step time: 1.330s\n",
            "[Step 58] VRMS: 34.86, THD: 0.251, Reward: -118.16, Step time: 0.818s\n",
            "[Step 59] VRMS: 34.73, THD: 0.255, Reward: -111.96, Step time: 0.824s\n",
            "[Step 60] VRMS: 18.16, THD: 0.698, Reward: -701.01, Step time: 0.798s\n",
            "[Step 61] VRMS: 9.81, THD: 3.365, Reward: -2050.24, Step time: 0.791s\n",
            "[Step 62] VRMS: 9.60, THD: 2.999, Reward: -2090.02, Step time: 0.782s\n",
            "[Step 63] VRMS: 9.60, THD: 3.001, Reward: -2090.06, Step time: 0.795s\n",
            "[Step 64] VRMS: 31.69, THD: 0.310, Reward: -14.36, Step time: 0.796s\n",
            "[Step 65] VRMS: 32.07, THD: 0.304, Reward: -21.43, Step time: 0.842s\n",
            "[Step 66] VRMS: 34.70, THD: 0.269, Reward: -110.37, Step time: 0.767s\n",
            "[Step 67] VRMS: 20.18, THD: 0.594, Reward: -482.14, Step time: 0.790s\n",
            "[Step 68] VRMS: 23.15, THD: 0.481, Reward: -234.55, Step time: 0.811s\n",
            "[Step 69] VRMS: 34.61, THD: 0.271, Reward: -106.54, Step time: 0.835s\n",
            "[Step 70] VRMS: 34.36, THD: 0.281, Reward: -95.33, Step time: 0.995s\n",
            "[Step 71] VRMS: 34.13, THD: 0.288, Reward: -85.42, Step time: 1.155s\n",
            "[Step 72] VRMS: 16.13, THD: 1.289, Reward: -963.79, Step time: 1.142s\n",
            "[Step 73] VRMS: 34.14, THD: 0.275, Reward: -85.67, Step time: 0.808s\n",
            "[Step 74] VRMS: 34.34, THD: 0.279, Reward: -94.32, Step time: 0.803s\n",
            "[Step 75] VRMS: 18.44, THD: 0.757, Reward: -669.01, Step time: 0.829s\n",
            "[Step 76] VRMS: 33.21, THD: 0.295, Reward: -51.45, Step time: 0.797s\n",
            "[Step 77] VRMS: 33.37, THD: 0.296, Reward: -56.85, Step time: 0.802s\n",
            "[Step 78] VRMS: 31.81, THD: 0.313, Reward: -16.56, Step time: 0.784s\n",
            "[Step 79] VRMS: 30.82, THD: 0.322, Reward: -3.46, Step time: 0.835s\n",
            "[Step 80] VRMS: 17.61, THD: 0.758, Reward: -768.60, Step time: 0.849s\n",
            "[Step 81] VRMS: 19.29, THD: 0.550, Reward: -573.43, Step time: 0.816s\n",
            "[Step 82] VRMS: 9.64, THD: 3.219, Reward: -2083.89, Step time: 0.800s\n",
            "[Step 83] VRMS: 9.60, THD: 3.000, Reward: -2090.06, Step time: 0.795s\n",
            "[Step 84] VRMS: 30.33, THD: 0.305, Reward: -0.64, Step time: 0.797s\n",
            "[Step 85] VRMS: 10.70, THD: 7.974, Reward: -1925.15, Step time: 1.137s\n",
            "[Step 86] VRMS: 9.63, THD: 0.928, Reward: -2076.54, Step time: 1.118s\n",
            "[Step 87] VRMS: 9.63, THD: 3.210, Reward: -2084.90, Step time: 1.060s\n",
            "[Step 88] VRMS: 31.15, THD: 0.293, Reward: -6.73, Step time: 0.847s\n",
            "[Step 89] VRMS: 34.31, THD: 0.242, Reward: -92.74, Step time: 0.808s\n",
            "[Step 90] VRMS: 34.84, THD: 0.235, Reward: -117.29, Step time: 0.803s\n",
            "[Step 91] VRMS: 34.87, THD: 0.232, Reward: -118.53, Step time: 0.830s\n",
            "[Step 92] VRMS: 19.76, THD: 0.515, Reward: -524.52, Step time: 0.897s\n",
            "[Step 93] VRMS: 17.61, THD: 0.561, Reward: -767.46, Step time: 0.793s\n",
            "[Step 94] VRMS: 21.52, THD: 0.405, Reward: -359.88, Step time: 0.811s\n",
            "[Step 95] VRMS: 16.47, THD: 0.599, Reward: -915.17, Step time: 0.770s\n",
            "[Step 96] VRMS: 35.55, THD: 0.211, Reward: -154.30, Step time: 0.784s\n",
            "[Step 97] VRMS: 34.97, THD: 0.216, Reward: -123.71, Step time: 0.800s\n",
            "[Step 98] VRMS: 19.21, THD: 0.483, Reward: -582.49, Step time: 0.773s\n",
            "[Step 99] VRMS: 35.00, THD: 0.208, Reward: -124.97, Step time: 0.826s\n",
            "[Step 100] VRMS: 31.59, THD: 0.267, Reward: -12.74, Step time: 1.148s\n",
            "[Step 1] VRMS: 19.06, THD: 0.676, Reward: -598.90, Step time: 1.170s\n",
            "[Step 2] VRMS: 9.67, THD: 3.229, Reward: -2076.55, Step time: 0.972s\n",
            "[Step 3] VRMS: 27.31, THD: 0.443, Reward: -36.36, Step time: 0.795s\n",
            "[Step 4] VRMS: 33.53, THD: 0.308, Reward: -62.42, Step time: 0.781s\n",
            "[Step 5] VRMS: 17.90, THD: 0.865, Reward: -732.64, Step time: 0.789s\n",
            "[Step 6] VRMS: 9.62, THD: 3.370, Reward: -2088.39, Step time: 0.825s\n",
            "[Step 7] VRMS: 20.15, THD: 0.546, Reward: -485.39, Step time: 0.814s\n",
            "[Step 8] VRMS: 33.48, THD: 0.305, Reward: -60.80, Step time: 0.809s\n",
            "[Step 9] VRMS: 9.80, THD: 3.207, Reward: -2051.05, Step time: 0.798s\n",
            "[Step 10] VRMS: 9.59, THD: 3.002, Reward: -2091.03, Step time: 0.779s\n",
            "[Step 11] VRMS: 32.08, THD: 0.315, Reward: -21.72, Step time: 0.818s\n",
            "[Step 12] VRMS: 33.93, THD: 0.290, Reward: -77.21, Step time: 0.771s\n",
            "[Step 13] VRMS: 28.43, THD: 0.418, Reward: -12.53, Step time: 0.803s\n",
            "[Step 14] VRMS: 9.82, THD: 6.211, Reward: -2074.53, Step time: 0.982s\n",
            "[Step 15] VRMS: 19.91, THD: 0.582, Reward: -509.26, Step time: 1.164s\n",
            "[Step 16] VRMS: 19.19, THD: 0.668, Reward: -585.14, Step time: 1.207s\n",
            "[Step 17] VRMS: 19.73, THD: 0.617, Reward: -527.93, Step time: 0.790s\n",
            "[Step 18] VRMS: 9.61, THD: 3.214, Reward: -2088.84, Step time: 0.785s\n",
            "[Step 19] VRMS: 17.01, THD: 1.009, Reward: -844.40, Step time: 0.781s\n",
            "[Step 20] VRMS: 30.11, THD: 0.369, Reward: -0.20, Step time: 0.802s\n",
            "[Step 21] VRMS: 29.48, THD: 0.390, Reward: -1.49, Step time: 0.770s\n",
            "[Step 22] VRMS: 9.81, THD: 3.285, Reward: -2048.58, Step time: 0.806s\n",
            "[Step 23] VRMS: 9.59, THD: 3.000, Reward: -2091.07, Step time: 0.803s\n",
            "[Step 24] VRMS: 9.59, THD: 3.006, Reward: -2091.09, Step time: 0.772s\n",
            "[Step 25] VRMS: 20.15, THD: 0.533, Reward: -485.12, Step time: 0.794s\n",
            "[Step 26] VRMS: 27.37, THD: 0.460, Reward: -34.80, Step time: 0.787s\n",
            "[Step 27] VRMS: 33.70, THD: 0.294, Reward: -68.41, Step time: 0.786s\n",
            "[Step 28] VRMS: 33.91, THD: 0.289, Reward: -76.63, Step time: 0.753s\n",
            "[Step 29] VRMS: 20.56, THD: 0.552, Reward: -445.48, Step time: 0.917s\n",
            "[Step 30] VRMS: 9.82, THD: 4.282, Reward: -2053.74, Step time: 1.124s\n",
            "[Step 31] VRMS: 9.59, THD: 3.000, Reward: -2091.02, Step time: 1.187s\n",
            "[Step 32] VRMS: 9.59, THD: 3.003, Reward: -2091.07, Step time: 0.757s\n",
            "[Step 33] VRMS: 34.57, THD: 0.274, Reward: -104.36, Step time: 0.764s\n",
            "[Step 34] VRMS: 15.58, THD: 1.091, Reward: -1041.16, Step time: 0.754s\n",
            "[Step 35] VRMS: 16.48, THD: 0.829, Reward: -915.29, Step time: 0.790s\n",
            "[Step 36] VRMS: 31.44, THD: 0.307, Reward: -10.43, Step time: 0.813s\n",
            "[Step 37] VRMS: 34.70, THD: 0.263, Reward: -110.43, Step time: 0.787s\n",
            "[Step 38] VRMS: 32.15, THD: 0.302, Reward: -23.27, Step time: 0.759s\n",
            "[Step 39] VRMS: 22.13, THD: 0.431, Reward: -310.22, Step time: 0.756s\n",
            "[Step 40] VRMS: 27.17, THD: 0.393, Reward: -40.12, Step time: 0.792s\n",
            "[Step 41] VRMS: 19.17, THD: 0.524, Reward: -586.84, Step time: 0.786s\n",
            "[Step 42] VRMS: 34.45, THD: 0.253, Reward: -99.29, Step time: 0.767s\n",
            "[Step 43] VRMS: 26.09, THD: 0.405, Reward: -76.64, Step time: 0.761s\n",
            "[Step 44] VRMS: 22.11, THD: 0.383, Reward: -311.47, Step time: 0.854s\n",
            "[Step 45] VRMS: 9.59, THD: 3.702, Reward: -2095.57, Step time: 1.149s\n",
            "[Step 46] VRMS: 9.59, THD: 3.002, Reward: -2091.03, Step time: 1.184s\n",
            "[Step 47] VRMS: 34.67, THD: 0.242, Reward: -109.04, Step time: 0.828s\n",
            "[Step 48] VRMS: 18.72, THD: 0.584, Reward: -636.17, Step time: 0.772s\n",
            "[Step 49] VRMS: 14.90, THD: 0.749, Reward: -1140.81, Step time: 0.817s\n",
            "[Step 50] VRMS: 31.07, THD: 0.288, Reward: -5.86, Step time: 0.770s\n",
            "[Step 51] VRMS: 9.62, THD: 4.804, Reward: -2098.80, Step time: 0.795s\n",
            "[Step 52] VRMS: 22.28, THD: 0.349, Reward: -297.84, Step time: 0.773s\n",
            "[Step 53] VRMS: 33.29, THD: 0.261, Reward: -54.32, Step time: 0.789s\n",
            "[Step 54] VRMS: 22.18, THD: 0.374, Reward: -306.12, Step time: 0.770s\n",
            "[Step 55] VRMS: 13.51, THD: 0.860, Reward: -1359.53, Step time: 0.769s\n",
            "[Step 56] VRMS: 9.60, THD: 11.048, Reward: -2202.16, Step time: 0.756s\n",
            "[Step 57] VRMS: 30.00, THD: 0.308, Reward: -0.09, Step time: 0.756s\n",
            "[Step 58] VRMS: 31.92, THD: 0.289, Reward: -18.45, Step time: 0.739s\n",
            "[Step 59] VRMS: 34.57, THD: 0.253, Reward: -104.48, Step time: 0.792s\n",
            "[Step 60] VRMS: 15.00, THD: 0.884, Reward: -1125.80, Step time: 1.120s\n",
            "[Step 61] VRMS: 19.15, THD: 0.541, Reward: -589.24, Step time: 1.120s\n",
            "[Step 62] VRMS: 19.25, THD: 0.551, Reward: -578.11, Step time: 0.954s\n",
            "[Step 63] VRMS: 9.66, THD: 2.061, Reward: -2071.92, Step time: 0.761s\n",
            "[Step 64] VRMS: 30.69, THD: 0.319, Reward: -2.51, Step time: 0.742s\n",
            "[Step 65] VRMS: 34.80, THD: 0.264, Reward: -115.21, Step time: 0.762s\n",
            "[Step 66] VRMS: 10.56, THD: 14.796, Reward: -2108.95, Step time: 0.773s\n",
            "[Step 67] VRMS: 34.26, THD: 0.270, Reward: -90.89, Step time: 0.760s\n",
            "[Step 68] VRMS: 27.00, THD: 0.440, Reward: -45.12, Step time: 0.738s\n",
            "[Step 69] VRMS: 32.27, THD: 0.302, Reward: -25.84, Step time: 0.779s\n",
            "[Step 70] VRMS: 34.04, THD: 0.279, Reward: -81.59, Step time: 0.786s\n",
            "[Step 71] VRMS: 33.84, THD: 0.288, Reward: -74.00, Step time: 0.778s\n",
            "[Step 72] VRMS: 20.50, THD: 0.564, Reward: -451.11, Step time: 0.784s\n",
            "[Step 73] VRMS: 9.86, THD: 2.751, Reward: -2034.76, Step time: 0.794s\n",
            "[Step 74] VRMS: 30.16, THD: 0.346, Reward: -0.25, Step time: 0.815s\n",
            "[Step 75] VRMS: 19.54, THD: 0.644, Reward: -547.62, Step time: 1.041s\n",
            "[Step 76] VRMS: 34.49, THD: 0.269, Reward: -101.03, Step time: 1.112s\n",
            "[Step 77] VRMS: 10.54, THD: 7.142, Reward: -1943.70, Step time: 1.092s\n",
            "[Step 78] VRMS: 9.61, THD: 1.440, Reward: -2080.18, Step time: 0.803s\n",
            "[Step 79] VRMS: 31.97, THD: 0.297, Reward: -19.57, Step time: 0.782s\n",
            "[Step 80] VRMS: 29.25, THD: 0.357, Reward: -2.96, Step time: 0.782s\n",
            "[Step 81] VRMS: 32.18, THD: 0.292, Reward: -23.81, Step time: 0.776s\n",
            "[Step 82] VRMS: 10.55, THD: 7.953, Reward: -1954.83, Step time: 0.789s\n",
            "[Step 83] VRMS: 34.88, THD: 0.253, Reward: -119.20, Step time: 0.783s\n",
            "[Step 84] VRMS: 32.48, THD: 0.290, Reward: -30.83, Step time: 0.771s\n",
            "[Step 85] VRMS: 26.99, THD: 0.385, Reward: -45.59, Step time: 0.761s\n",
            "[Step 86] VRMS: 18.96, THD: 0.536, Reward: -609.41, Step time: 0.776s\n",
            "[Step 87] VRMS: 26.73, THD: 0.374, Reward: -53.46, Step time: 0.798s\n",
            "[Step 88] VRMS: 32.85, THD: 0.267, Reward: -40.63, Step time: 0.785s\n",
            "[Step 89] VRMS: 19.84, THD: 0.494, Reward: -516.62, Step time: 0.756s\n",
            "[Step 90] VRMS: 16.71, THD: 0.641, Reward: -883.62, Step time: 0.984s\n",
            "[Step 91] VRMS: 31.64, THD: 0.281, Reward: -13.55, Step time: 1.187s\n",
            "[Step 92] VRMS: 18.53, THD: 0.538, Reward: -658.37, Step time: 1.106s\n",
            "[Step 93] VRMS: 9.82, THD: 3.219, Reward: -2046.45, Step time: 0.795s\n",
            "[Step 94] VRMS: 24.55, THD: 0.314, Reward: -148.85, Step time: 0.768s\n",
            "[Step 95] VRMS: 31.07, THD: 0.273, Reward: -5.78, Step time: 0.769s\n",
            "[Step 96] VRMS: 29.91, THD: 0.290, Reward: -0.12, Step time: 0.779s\n",
            "[Step 97] VRMS: 21.71, THD: 0.380, Reward: -343.75, Step time: 0.778s\n",
            "[Step 98] VRMS: 28.23, THD: 0.301, Reward: -15.73, Step time: 0.788s\n",
            "[Step 99] VRMS: 10.10, THD: 3.542, Reward: -1992.71, Step time: 0.770s\n",
            "[Step 100] VRMS: 35.08, THD: 0.203, Reward: -129.29, Step time: 0.771s\n",
            "[Step 1] VRMS: 18.73, THD: 0.792, Reward: -635.21, Step time: 0.798s\n",
            "[Step 2] VRMS: 18.68, THD: 0.792, Reward: -641.80, Step time: 0.769s\n",
            "[Step 3] VRMS: 34.00, THD: 0.298, Reward: -80.15, Step time: 0.753s\n",
            "[Step 4] VRMS: 30.29, THD: 0.371, Reward: -0.55, Step time: 0.768s\n",
            "[Step 5] VRMS: 20.70, THD: 0.538, Reward: -432.85, Step time: 0.935s\n",
            "[Step 6] VRMS: 9.97, THD: 3.413, Reward: -2017.30, Step time: 1.114s\n",
            "[Step 7] VRMS: 9.60, THD: 2.997, Reward: -2089.97, Step time: 1.166s\n",
            "[Step 8] VRMS: 34.01, THD: 0.299, Reward: -80.55, Step time: 0.759s\n",
            "[Step 9] VRMS: 34.05, THD: 0.293, Reward: -82.12, Step time: 0.780s\n",
            "[Step 10] VRMS: 34.15, THD: 0.291, Reward: -86.30, Step time: 0.806s\n",
            "[Step 11] VRMS: 20.77, THD: 0.499, Reward: -426.45, Step time: 0.757s\n",
            "[Step 12] VRMS: 34.44, THD: 0.301, Reward: -98.54, Step time: 0.761s\n",
            "[Step 13] VRMS: 20.65, THD: 0.515, Reward: -437.68, Step time: 0.763s\n",
            "[Step 14] VRMS: 18.62, THD: 0.852, Reward: -648.53, Step time: 0.774s\n",
            "[Step 15] VRMS: 20.20, THD: 0.585, Reward: -480.50, Step time: 0.891s\n",
            "[Step 16] VRMS: 9.80, THD: 3.794, Reward: -2055.25, Step time: 1.151s\n",
            "[Step 17] VRMS: 34.08, THD: 0.296, Reward: -83.13, Step time: 1.162s\n",
            "[Step 18] VRMS: 20.88, THD: 0.509, Reward: -416.51, Step time: 0.857s\n",
            "[Step 19] VRMS: 19.30, THD: 0.716, Reward: -572.88, Step time: 0.949s\n",
            "[Step 20] VRMS: 27.62, THD: 0.458, Reward: -28.44, Step time: 1.090s\n",
            "[Step 21] VRMS: 15.96, THD: 1.343, Reward: -987.29, Step time: 1.227s\n",
            "[Step 22] VRMS: 19.66, THD: 0.658, Reward: -535.09, Step time: 0.801s\n",
            "[Step 23] VRMS: 19.67, THD: 0.651, Reward: -534.00, Step time: 0.765s\n",
            "[Step 24] VRMS: 18.95, THD: 0.742, Reward: -611.27, Step time: 0.749s\n",
            "[Step 25] VRMS: 33.02, THD: 0.309, Reward: -45.66, Step time: 0.764s\n",
            "[Step 26] VRMS: 12.07, THD: 2.114, Reward: -1612.38, Step time: 0.799s\n",
            "[Step 27] VRMS: 19.85, THD: 0.636, Reward: -515.90, Step time: 0.814s\n",
            "[Step 28] VRMS: 29.79, THD: 0.394, Reward: -0.37, Step time: 0.837s\n",
            "[Step 29] VRMS: 10.05, THD: 3.229, Reward: -2000.61, Step time: 0.810s\n",
            "[Step 30] VRMS: 20.08, THD: 0.551, Reward: -492.74, Step time: 0.797s\n",
            "[Step 31] VRMS: 20.11, THD: 0.563, Reward: -489.20, Step time: 0.781s\n",
            "[Step 32] VRMS: 34.71, THD: 0.278, Reward: -111.15, Step time: 0.773s\n",
            "[Step 33] VRMS: 22.16, THD: 0.478, Reward: -307.69, Step time: 0.822s\n",
            "[Step 34] VRMS: 35.25, THD: 0.272, Reward: -137.66, Step time: 1.001s\n",
            "[Step 35] VRMS: 24.56, THD: 0.479, Reward: -148.33, Step time: 1.105s\n",
            "[Step 36] VRMS: 34.93, THD: 0.268, Reward: -121.40, Step time: 1.164s\n",
            "[Step 37] VRMS: 19.77, THD: 0.561, Reward: -523.25, Step time: 0.787s\n",
            "[Step 38] VRMS: 9.63, THD: 4.338, Reward: -2094.17, Step time: 0.808s\n",
            "[Step 39] VRMS: 34.84, THD: 0.261, Reward: -117.29, Step time: 0.786s\n",
            "[Step 40] VRMS: 31.41, THD: 0.307, Reward: -10.04, Step time: 0.758s\n",
            "[Step 41] VRMS: 34.90, THD: 0.255, Reward: -120.28, Step time: 0.804s\n",
            "[Step 42] VRMS: 34.67, THD: 0.254, Reward: -109.12, Step time: 0.795s\n",
            "[Step 43] VRMS: 10.31, THD: 3.208, Reward: -1948.85, Step time: 0.798s\n",
            "[Step 44] VRMS: 9.60, THD: 2.991, Reward: -2089.93, Step time: 0.774s\n",
            "[Step 45] VRMS: 9.60, THD: 3.001, Reward: -2089.96, Step time: 0.785s\n",
            "[Step 46] VRMS: 31.88, THD: 0.289, Reward: -17.73, Step time: 0.779s\n",
            "[Step 47] VRMS: 9.73, THD: 3.216, Reward: -2063.98, Step time: 0.829s\n",
            "[Step 48] VRMS: 21.98, THD: 0.371, Reward: -321.81, Step time: 0.857s\n",
            "[Step 49] VRMS: 18.97, THD: 0.579, Reward: -609.19, Step time: 1.081s\n",
            "[Step 50] VRMS: 16.51, THD: 0.632, Reward: -910.84, Step time: 1.128s\n",
            "[Step 51] VRMS: 9.76, THD: 3.220, Reward: -2058.58, Step time: 1.136s\n",
            "[Step 52] VRMS: 9.60, THD: 3.008, Reward: -2090.03, Step time: 0.803s\n",
            "[Step 53] VRMS: 17.72, THD: 0.590, Reward: -754.66, Step time: 0.771s\n",
            "[Step 54] VRMS: 9.77, THD: 3.283, Reward: -2057.06, Step time: 0.782s\n",
            "[Step 55] VRMS: 34.78, THD: 0.242, Reward: -114.12, Step time: 0.784s\n",
            "[Step 56] VRMS: 32.30, THD: 0.283, Reward: -26.47, Step time: 0.794s\n",
            "[Step 57] VRMS: 9.89, THD: 3.288, Reward: -2032.33, Step time: 0.808s\n",
            "[Step 58] VRMS: 27.56, THD: 0.370, Reward: -29.95, Step time: 0.772s\n",
            "[Step 59] VRMS: 19.04, THD: 0.557, Reward: -601.25, Step time: 0.763s\n",
            "[Step 60] VRMS: 9.59, THD: 3.245, Reward: -2092.95, Step time: 0.769s\n",
            "[Step 61] VRMS: 32.72, THD: 0.292, Reward: -36.94, Step time: 0.789s\n",
            "[Step 62] VRMS: 35.07, THD: 0.262, Reward: -128.61, Step time: 0.788s\n",
            "[Step 63] VRMS: 10.77, THD: 16.976, Reward: -2137.64, Step time: 0.796s\n",
            "[Step 64] VRMS: 30.31, THD: 0.322, Reward: -0.60, Step time: 1.027s\n",
            "[Step 65] VRMS: 18.84, THD: 0.656, Reward: -623.67, Step time: 1.113s\n",
            "[Step 66] VRMS: 9.72, THD: 3.213, Reward: -2066.48, Step time: 1.096s\n",
            "[Step 67] VRMS: 18.70, THD: 0.647, Reward: -638.60, Step time: 0.764s\n",
            "[Step 68] VRMS: 34.52, THD: 0.270, Reward: -102.21, Step time: 0.769s\n",
            "[Step 69] VRMS: 19.83, THD: 0.619, Reward: -517.08, Step time: 0.789s\n",
            "[Step 70] VRMS: 26.01, THD: 0.476, Reward: -79.97, Step time: 0.817s\n",
            "[Step 71] VRMS: 33.64, THD: 0.289, Reward: -66.46, Step time: 0.798s\n",
            "[Step 72] VRMS: 32.42, THD: 0.313, Reward: -29.30, Step time: 0.762s\n",
            "[Step 73] VRMS: 10.80, THD: 4.256, Reward: -1861.62, Step time: 0.793s\n",
            "[Step 74] VRMS: 9.60, THD: 2.993, Reward: -2089.95, Step time: 0.784s\n",
            "[Step 75] VRMS: 34.55, THD: 0.271, Reward: -103.56, Step time: 0.785s\n",
            "[Step 76] VRMS: 20.59, THD: 0.540, Reward: -442.83, Step time: 0.760s\n",
            "[Step 77] VRMS: 35.38, THD: 0.265, Reward: -145.00, Step time: 0.794s\n",
            "[Step 78] VRMS: 10.83, THD: 5.440, Reward: -1867.06, Step time: 0.811s\n",
            "[Step 79] VRMS: 29.72, THD: 0.344, Reward: -0.52, Step time: 1.008s\n",
            "[Step 80] VRMS: 32.45, THD: 0.291, Reward: -30.19, Step time: 1.107s\n",
            "[Step 81] VRMS: 18.47, THD: 0.663, Reward: -664.69, Step time: 1.137s\n",
            "[Step 82] VRMS: 9.65, THD: 3.441, Reward: -2081.65, Step time: 0.783s\n",
            "[Step 83] VRMS: 27.72, THD: 0.379, Reward: -26.17, Step time: 0.754s\n",
            "[Step 84] VRMS: 19.19, THD: 0.557, Reward: -584.79, Step time: 0.801s\n",
            "[Step 85] VRMS: 9.67, THD: 3.222, Reward: -2076.42, Step time: 0.793s\n",
            "[Step 86] VRMS: 18.34, THD: 0.568, Reward: -679.80, Step time: 0.820s\n",
            "[Step 87] VRMS: 35.42, THD: 0.240, Reward: -147.16, Step time: 0.768s\n",
            "[Step 88] VRMS: 10.94, THD: 9.459, Reward: -1904.94, Step time: 0.801s\n",
            "[Step 89] VRMS: 15.98, THD: 0.699, Reward: -982.84, Step time: 0.821s\n",
            "[Step 90] VRMS: 35.06, THD: 0.234, Reward: -127.95, Step time: 0.798s\n",
            "[Step 91] VRMS: 23.09, THD: 0.349, Reward: -238.75, Step time: 0.774s\n",
            "[Step 92] VRMS: 35.02, THD: 0.223, Reward: -125.82, Step time: 0.812s\n",
            "[Step 93] VRMS: 11.01, THD: 5.946, Reward: -1839.09, Step time: 0.786s\n",
            "[Step 94] VRMS: 22.93, THD: 0.340, Reward: -250.10, Step time: 1.037s\n",
            "[Step 95] VRMS: 9.62, THD: 17.027, Reward: -2367.35, Step time: 1.073s\n",
            "[Step 96] VRMS: 35.22, THD: 0.212, Reward: -136.16, Step time: 1.172s\n",
            "[Step 97] VRMS: 11.02, THD: 0.818, Reward: -1801.05, Step time: 0.799s\n",
            "[Step 98] VRMS: 9.60, THD: 3.416, Reward: -2092.53, Step time: 0.781s\n",
            "[Step 99] VRMS: 9.60, THD: 3.003, Reward: -2090.01, Step time: 0.822s\n",
            "[Step 100] VRMS: 15.78, THD: 0.579, Reward: -1011.37, Step time: 0.797s\n",
            "[Step 1] VRMS: 9.66, THD: 21.543, Reward: -2532.44, Step time: 0.786s\n",
            "[Step 2] VRMS: 25.48, THD: 0.488, Reward: -102.59, Step time: 0.804s\n",
            "[Step 3] VRMS: 9.90, THD: 3.209, Reward: -2030.55, Step time: 0.798s\n",
            "[Step 4] VRMS: 9.60, THD: 3.004, Reward: -2090.72, Step time: 0.805s\n",
            "[Step 5] VRMS: 33.92, THD: 0.297, Reward: -76.82, Step time: 0.809s\n",
            "[Step 6] VRMS: 9.85, THD: 3.206, Reward: -2040.33, Step time: 0.828s\n",
            "[Step 7] VRMS: 33.80, THD: 0.298, Reward: -72.38, Step time: 0.822s\n",
            "[Step 8] VRMS: 9.85, THD: 3.205, Reward: -2040.59, Step time: 0.790s\n",
            "[Step 9] VRMS: 33.83, THD: 0.299, Reward: -73.26, Step time: 1.152s\n",
            "[Step 10] VRMS: 30.11, THD: 0.366, Reward: -0.19, Step time: 1.181s\n",
            "[Step 11] VRMS: 9.88, THD: 5.294, Reward: -2052.58, Step time: 1.073s\n",
            "[Step 12] VRMS: 31.32, THD: 0.329, Reward: -8.85, Step time: 0.790s\n",
            "[Step 13] VRMS: 19.96, THD: 0.598, Reward: -504.04, Step time: 0.861s\n",
            "[Step 14] VRMS: 25.59, THD: 0.483, Reward: -97.67, Step time: 0.788s\n",
            "[Step 15] VRMS: 19.27, THD: 0.683, Reward: -576.31, Step time: 0.814s\n",
            "[Step 16] VRMS: 9.69, THD: 3.270, Reward: -2072.34, Step time: 0.812s\n",
            "[Step 17] VRMS: 33.86, THD: 0.295, Reward: -74.68, Step time: 0.908s\n",
            "[Step 18] VRMS: 19.35, THD: 0.674, Reward: -567.13, Step time: 0.926s\n",
            "[Step 19] VRMS: 9.68, THD: 3.741, Reward: -2078.23, Step time: 0.969s\n",
            "[Step 20] VRMS: 34.04, THD: 0.291, Reward: -81.77, Step time: 0.883s\n",
            "[Step 21] VRMS: 17.69, THD: 0.929, Reward: -758.65, Step time: 0.823s\n",
            "[Step 22] VRMS: 19.88, THD: 0.599, Reward: -512.51, Step time: 0.792s\n",
            "[Step 23] VRMS: 33.87, THD: 0.290, Reward: -75.10, Step time: 1.127s\n",
            "[Step 24] VRMS: 15.82, THD: 1.254, Reward: -1006.80, Step time: 1.254s\n",
            "[Step 25] VRMS: 30.62, THD: 0.355, Reward: -2.05, Step time: 1.203s\n",
            "[Step 26] VRMS: 20.36, THD: 0.517, Reward: -464.67, Step time: 0.857s\n",
            "[Step 27] VRMS: 19.87, THD: 0.625, Reward: -513.22, Step time: 0.850s\n",
            "[Step 28] VRMS: 9.69, THD: 3.812, Reward: -2076.77, Step time: 0.802s\n",
            "[Step 29] VRMS: 26.53, THD: 0.469, Reward: -60.31, Step time: 0.843s\n",
            "[Step 30] VRMS: 28.59, THD: 0.421, Reward: -10.06, Step time: 0.843s\n",
            "[Step 31] VRMS: 19.75, THD: 0.561, Reward: -526.06, Step time: 0.885s\n",
            "[Step 32] VRMS: 29.08, THD: 0.405, Reward: -4.44, Step time: 0.848s\n",
            "[Step 33] VRMS: 22.12, THD: 0.435, Reward: -310.81, Step time: 0.954s\n",
            "[Step 34] VRMS: 29.65, THD: 0.356, Reward: -0.73, Step time: 0.859s\n",
            "[Step 35] VRMS: 26.34, THD: 0.435, Reward: -67.04, Step time: 0.858s\n",
            "[Step 36] VRMS: 16.92, THD: 0.773, Reward: -855.73, Step time: 0.804s\n",
            "[Step 37] VRMS: 18.56, THD: 0.594, Reward: -654.39, Step time: 1.239s\n",
            "[Step 38] VRMS: 18.05, THD: 0.628, Reward: -714.54, Step time: 1.208s\n",
            "[Step 39] VRMS: 9.62, THD: 3.216, Reward: -2087.20, Step time: 0.996s\n",
            "[Step 40] VRMS: 14.47, THD: 0.916, Reward: -1207.35, Step time: 0.792s\n",
            "[Step 41] VRMS: 28.03, THD: 0.370, Reward: -19.50, Step time: 0.816s\n",
            "[Step 42] VRMS: 32.18, THD: 0.293, Reward: -23.83, Step time: 0.812s\n",
            "[Step 43] VRMS: 29.65, THD: 0.325, Reward: -0.73, Step time: 0.831s\n",
            "[Step 44] VRMS: 18.56, THD: 0.588, Reward: -654.56, Step time: 0.805s\n",
            "[Step 45] VRMS: 18.06, THD: 0.600, Reward: -712.61, Step time: 0.795s\n",
            "[Step 46] VRMS: 9.79, THD: 3.203, Reward: -2053.07, Step time: 0.789s\n",
            "[Step 47] VRMS: 18.24, THD: 0.588, Reward: -692.33, Step time: 0.831s\n",
            "[Step 48] VRMS: 10.14, THD: 1.446, Reward: -1974.28, Step time: 0.810s\n",
            "[Step 49] VRMS: 9.60, THD: 5.906, Reward: -2116.02, Step time: 0.789s\n",
            "[Step 50] VRMS: 10.12, THD: 0.880, Reward: -1976.84, Step time: 0.836s\n",
            "[Step 51] VRMS: 17.52, THD: 0.563, Reward: -778.57, Step time: 1.007s\n",
            "[Step 52] VRMS: 25.10, THD: 0.346, Reward: -120.10, Step time: 1.210s\n",
            "[Step 53] VRMS: 24.55, THD: 0.356, Reward: -148.67, Step time: 1.233s\n",
            "[Step 54] VRMS: 34.72, THD: 0.241, Reward: -111.39, Step time: 0.835s\n",
            "[Step 55] VRMS: 34.74, THD: 0.242, Reward: -112.62, Step time: 0.788s\n",
            "[Step 56] VRMS: 22.37, THD: 0.385, Reward: -291.59, Step time: 0.814s\n",
            "[Step 57] VRMS: 18.82, THD: 0.542, Reward: -625.74, Step time: 0.838s\n",
            "[Step 58] VRMS: 18.74, THD: 0.569, Reward: -634.20, Step time: 0.878s\n",
            "[Step 59] VRMS: 34.64, THD: 0.252, Reward: -107.78, Step time: 0.863s\n",
            "[Step 60] VRMS: 31.73, THD: 0.299, Reward: -15.10, Step time: 0.797s\n",
            "[Step 61] VRMS: 34.71, THD: 0.259, Reward: -111.22, Step time: 0.823s\n",
            "[Step 62] VRMS: 14.43, THD: 0.977, Reward: -1213.14, Step time: 0.814s\n",
            "[Step 63] VRMS: 34.74, THD: 0.263, Reward: -112.33, Step time: 0.875s\n",
            "[Step 64] VRMS: 10.57, THD: 9.592, Reward: -1979.50, Step time: 0.815s\n",
            "[Step 65] VRMS: 9.60, THD: 3.001, Reward: -2090.68, Step time: 0.860s\n",
            "[Step 66] VRMS: 14.65, THD: 1.104, Reward: -1179.38, Step time: 1.205s\n",
            "[Step 67] VRMS: 34.34, THD: 0.271, Reward: -94.39, Step time: 1.258s\n",
            "[Step 68] VRMS: 18.47, THD: 0.734, Reward: -665.11, Step time: 0.866s\n",
            "[Step 69] VRMS: 9.59, THD: 3.208, Reward: -2093.21, Step time: 0.801s\n",
            "[Step 70] VRMS: 20.02, THD: 0.590, Reward: -498.26, Step time: 0.773s\n",
            "[Step 71] VRMS: 9.86, THD: 3.206, Reward: -2038.52, Step time: 0.777s\n",
            "[Step 72] VRMS: 9.60, THD: 3.003, Reward: -2090.72, Step time: 0.774s\n",
            "[Step 73] VRMS: 29.56, THD: 0.375, Reward: -1.12, Step time: 0.776s\n",
            "[Step 74] VRMS: 26.68, THD: 0.455, Reward: -55.35, Step time: 0.788s\n",
            "[Step 75] VRMS: 34.34, THD: 0.265, Reward: -94.45, Step time: 0.778s\n",
            "[Step 76] VRMS: 32.12, THD: 0.310, Reward: -22.55, Step time: 0.812s\n",
            "[Step 77] VRMS: 19.81, THD: 0.598, Reward: -519.88, Step time: 0.785s\n",
            "[Step 78] VRMS: 9.66, THD: 3.207, Reward: -2079.51, Step time: 0.780s\n",
            "[Step 79] VRMS: 9.60, THD: 3.007, Reward: -2090.74, Step time: 0.782s\n",
            "[Step 80] VRMS: 9.60, THD: 3.000, Reward: -2090.68, Step time: 0.781s\n",
            "[Step 81] VRMS: 20.86, THD: 0.463, Reward: -417.57, Step time: 1.185s\n",
            "[Step 82] VRMS: 27.65, THD: 0.387, Reward: -27.87, Step time: 1.132s\n",
            "[Step 83] VRMS: 21.70, THD: 0.420, Reward: -344.36, Step time: 0.901s\n",
            "[Step 84] VRMS: 28.71, THD: 0.341, Reward: -8.38, Step time: 0.811s\n",
            "[Step 85] VRMS: 10.15, THD: 3.659, Reward: -1982.89, Step time: 0.795s\n",
            "[Step 86] VRMS: 18.40, THD: 0.565, Reward: -673.01, Step time: 0.792s\n",
            "[Step 87] VRMS: 18.98, THD: 0.533, Reward: -607.04, Step time: 0.815s\n",
            "[Step 88] VRMS: 17.82, THD: 0.605, Reward: -741.60, Step time: 0.769s\n",
            "[Step 89] VRMS: 28.42, THD: 0.345, Reward: -12.57, Step time: 0.787s\n",
            "[Step 90] VRMS: 34.72, THD: 0.231, Reward: -111.63, Step time: 0.764s\n",
            "[Step 91] VRMS: 34.79, THD: 0.232, Reward: -114.95, Step time: 0.775s\n",
            "[Step 92] VRMS: 19.55, THD: 0.512, Reward: -546.36, Step time: 0.751s\n",
            "[Step 93] VRMS: 10.06, THD: 3.577, Reward: -2001.72, Step time: 0.764s\n",
            "[Step 94] VRMS: 9.60, THD: 3.007, Reward: -2090.74, Step time: 0.789s\n",
            "[Step 95] VRMS: 17.48, THD: 0.534, Reward: -784.01, Step time: 0.778s\n",
            "[Step 96] VRMS: 9.74, THD: 3.203, Reward: -2062.34, Step time: 1.119s\n",
            "[Step 97] VRMS: 31.56, THD: 0.267, Reward: -12.19, Step time: 1.148s\n",
            "[Step 98] VRMS: 10.65, THD: 5.726, Reward: -1904.41, Step time: 0.952s\n",
            "[Step 99] VRMS: 35.14, THD: 0.205, Reward: -132.09, Step time: 0.749s\n",
            "[Step 100] VRMS: 10.59, THD: 6.066, Reward: -1920.86, Step time: 0.782s\n",
            "[Step 1] VRMS: 9.62, THD: 7.418, Reward: -2131.13, Step time: 0.812s\n",
            "[Step 2] VRMS: 19.61, THD: 0.590, Reward: -540.12, Step time: 0.770s\n",
            "[Step 3] VRMS: 18.18, THD: 0.753, Reward: -699.27, Step time: 0.762s\n",
            "[Step 4] VRMS: 9.58, THD: 3.310, Reward: -2096.14, Step time: 0.783s\n",
            "[Step 5] VRMS: 18.28, THD: 0.740, Reward: -686.82, Step time: 0.776s\n",
            "[Step 6] VRMS: 16.38, THD: 1.061, Reward: -928.97, Step time: 0.804s\n",
            "[Step 7] VRMS: 24.83, THD: 0.491, Reward: -133.64, Step time: 0.761s\n",
            "[Step 8] VRMS: 9.70, THD: 3.208, Reward: -2070.31, Step time: 0.779s\n",
            "[Step 9] VRMS: 19.42, THD: 0.610, Reward: -559.85, Step time: 0.782s\n",
            "[Step 10] VRMS: 33.48, THD: 0.293, Reward: -60.70, Step time: 0.782s\n",
            "[Step 11] VRMS: 16.98, THD: 0.943, Reward: -847.86, Step time: 1.122s\n",
            "[Step 12] VRMS: 17.66, THD: 0.843, Reward: -762.21, Step time: 1.102s\n",
            "[Step 13] VRMS: 9.58, THD: 3.229, Reward: -2096.08, Step time: 1.032s\n",
            "[Step 14] VRMS: 20.05, THD: 0.525, Reward: -495.43, Step time: 0.766s\n",
            "[Step 15] VRMS: 18.41, THD: 0.732, Reward: -672.02, Step time: 0.772s\n",
            "[Step 16] VRMS: 30.90, THD: 0.329, Reward: -4.18, Step time: 0.816s\n",
            "[Step 17] VRMS: 33.46, THD: 0.291, Reward: -59.81, Step time: 0.854s\n",
            "[Step 18] VRMS: 16.41, THD: 1.065, Reward: -924.04, Step time: 0.746s\n",
            "[Step 19] VRMS: 9.58, THD: 4.520, Reward: -2104.34, Step time: 0.759s\n",
            "[Step 20] VRMS: 19.84, THD: 0.543, Reward: -516.45, Step time: 0.797s\n",
            "[Step 21] VRMS: 9.70, THD: 3.196, Reward: -2069.81, Step time: 0.802s\n",
            "[Step 22] VRMS: 33.56, THD: 0.289, Reward: -63.38, Step time: 0.780s\n",
            "[Step 23] VRMS: 9.82, THD: 20.732, Reward: -2466.27, Step time: 0.812s\n",
            "[Step 24] VRMS: 13.95, THD: 1.576, Reward: -1289.97, Step time: 0.785s\n",
            "[Step 25] VRMS: 9.59, THD: 4.696, Reward: -2105.66, Step time: 0.772s\n",
            "[Step 26] VRMS: 18.58, THD: 0.694, Reward: -652.69, Step time: 1.113s\n",
            "[Step 27] VRMS: 24.46, THD: 0.504, Reward: -153.56, Step time: 1.099s\n",
            "[Step 28] VRMS: 18.60, THD: 0.685, Reward: -649.78, Step time: 1.018s\n",
            "[Step 29] VRMS: 33.92, THD: 0.281, Reward: -76.95, Step time: 0.800s\n",
            "[Step 30] VRMS: 34.13, THD: 0.277, Reward: -85.26, Step time: 0.751s\n",
            "[Step 31] VRMS: 9.99, THD: 3.415, Reward: -2013.62, Step time: 0.772s\n",
            "[Step 32] VRMS: 22.81, THD: 0.475, Reward: -258.94, Step time: 0.774s\n",
            "[Step 33] VRMS: 34.27, THD: 0.273, Reward: -91.41, Step time: 0.746s\n",
            "[Step 34] VRMS: 34.57, THD: 0.270, Reward: -104.46, Step time: 0.812s\n",
            "[Step 35] VRMS: 19.17, THD: 0.605, Reward: -586.51, Step time: 0.791s\n",
            "[Step 36] VRMS: 29.36, THD: 0.353, Reward: -2.14, Step time: 0.752s\n",
            "[Step 37] VRMS: 34.40, THD: 0.263, Reward: -97.01, Step time: 0.776s\n",
            "[Step 38] VRMS: 10.06, THD: 3.205, Reward: -1998.85, Step time: 0.794s\n",
            "[Step 39] VRMS: 13.31, THD: 1.021, Reward: -1393.55, Step time: 0.820s\n",
            "[Step 40] VRMS: 9.58, THD: 3.199, Reward: -2095.36, Step time: 0.793s\n",
            "[Step 41] VRMS: 9.59, THD: 3.001, Reward: -2092.70, Step time: 1.061s\n",
            "[Step 42] VRMS: 16.43, THD: 0.742, Reward: -920.66, Step time: 1.096s\n",
            "[Step 43] VRMS: 16.16, THD: 0.733, Reward: -957.80, Step time: 1.039s\n",
            "[Step 44] VRMS: 18.66, THD: 0.554, Reward: -643.22, Step time: 0.792s\n",
            "[Step 45] VRMS: 34.50, THD: 0.245, Reward: -101.47, Step time: 0.746s\n",
            "[Step 46] VRMS: 34.60, THD: 0.243, Reward: -105.98, Step time: 0.762s\n",
            "[Step 47] VRMS: 19.81, THD: 0.485, Reward: -519.55, Step time: 0.754s\n",
            "[Step 48] VRMS: 31.18, THD: 0.287, Reward: -7.03, Step time: 0.764s\n",
            "[Step 49] VRMS: 17.31, THD: 0.602, Reward: -806.05, Step time: 0.774s\n",
            "[Step 50] VRMS: 34.63, THD: 0.231, Reward: -107.15, Step time: 0.779s\n",
            "[Step 51] VRMS: 9.97, THD: 0.886, Reward: -2007.60, Step time: 0.745s\n",
            "[Step 52] VRMS: 9.67, THD: 1.077, Reward: -2067.19, Step time: 0.758s\n",
            "[Step 53] VRMS: 18.80, THD: 0.508, Reward: -627.50, Step time: 0.754s\n",
            "[Step 54] VRMS: 21.46, THD: 0.386, Reward: -364.89, Step time: 0.757s\n",
            "[Step 55] VRMS: 9.77, THD: 3.196, Reward: -2055.62, Step time: 0.752s\n",
            "[Step 56] VRMS: 18.25, THD: 0.588, Reward: -690.54, Step time: 0.894s\n",
            "[Step 57] VRMS: 27.46, THD: 0.364, Reward: -32.30, Step time: 1.170s\n",
            "[Step 58] VRMS: 18.53, THD: 0.580, Reward: -658.28, Step time: 1.274s\n",
            "[Step 59] VRMS: 18.32, THD: 0.584, Reward: -683.00, Step time: 0.803s\n",
            "[Step 60] VRMS: 9.57, THD: 3.207, Reward: -2096.64, Step time: 0.783s\n",
            "[Step 61] VRMS: 14.90, THD: 0.892, Reward: -1140.13, Step time: 0.801s\n",
            "[Step 62] VRMS: 34.49, THD: 0.259, Reward: -100.91, Step time: 0.784s\n",
            "[Step 63] VRMS: 30.43, THD: 0.318, Reward: -1.03, Step time: 0.852s\n",
            "[Step 64] VRMS: 9.96, THD: 3.225, Reward: -2018.52, Step time: 0.780s\n",
            "[Step 65] VRMS: 9.59, THD: 3.001, Reward: -2092.70, Step time: 0.810s\n",
            "[Step 66] VRMS: 18.03, THD: 0.660, Reward: -716.95, Step time: 0.803s\n",
            "[Step 67] VRMS: 9.62, THD: 3.302, Reward: -2088.25, Step time: 0.775s\n",
            "[Step 68] VRMS: 9.59, THD: 3.000, Reward: -2092.74, Step time: 0.762s\n",
            "[Step 69] VRMS: 30.12, THD: 0.336, Reward: -0.19, Step time: 0.793s\n",
            "[Step 70] VRMS: 10.16, THD: 3.272, Reward: -1979.42, Step time: 0.795s\n",
            "[Step 71] VRMS: 9.59, THD: 3.001, Reward: -2092.70, Step time: 0.945s\n",
            "[Step 72] VRMS: 33.38, THD: 0.281, Reward: -57.26, Step time: 1.089s\n",
            "[Step 73] VRMS: 29.71, THD: 0.363, Reward: -0.56, Step time: 1.189s\n",
            "[Step 74] VRMS: 33.56, THD: 0.272, Reward: -63.38, Step time: 0.762s\n",
            "[Step 75] VRMS: 18.89, THD: 0.635, Reward: -617.74, Step time: 0.759s\n",
            "[Step 76] VRMS: 9.90, THD: 1.473, Reward: -2022.50, Step time: 0.811s\n",
            "[Step 77] VRMS: 9.59, THD: 4.144, Reward: -2101.02, Step time: 0.817s\n",
            "[Step 78] VRMS: 25.83, THD: 0.426, Reward: -87.22, Step time: 0.803s\n",
            "[Step 79] VRMS: 15.70, THD: 0.948, Reward: -1023.53, Step time: 0.753s\n",
            "[Step 80] VRMS: 25.42, THD: 0.425, Reward: -105.08, Step time: 0.788s\n",
            "[Step 81] VRMS: 11.74, THD: 1.082, Reward: -1668.89, Step time: 0.782s\n",
            "[Step 82] VRMS: 31.31, THD: 0.296, Reward: -8.66, Step time: 0.786s\n",
            "[Step 83] VRMS: 18.60, THD: 0.580, Reward: -650.15, Step time: 0.754s\n",
            "[Step 84] VRMS: 18.31, THD: 0.569, Reward: -683.53, Step time: 0.766s\n",
            "[Step 85] VRMS: 33.89, THD: 0.256, Reward: -75.70, Step time: 0.771s\n",
            "[Step 86] VRMS: 10.29, THD: 4.077, Reward: -1959.88, Step time: 0.894s\n",
            "[Step 87] VRMS: 34.75, THD: 0.241, Reward: -113.10, Step time: 1.098s\n",
            "[Step 88] VRMS: 18.92, THD: 0.519, Reward: -614.27, Step time: 1.179s\n",
            "[Step 89] VRMS: 18.08, THD: 0.572, Reward: -710.82, Step time: 0.850s\n",
            "[Step 90] VRMS: 21.65, THD: 0.386, Reward: -348.58, Step time: 0.747s\n",
            "[Step 91] VRMS: 34.72, THD: 0.230, Reward: -111.61, Step time: 0.801s\n",
            "[Step 92] VRMS: 22.34, THD: 0.361, Reward: -293.55, Step time: 0.780s\n",
            "[Step 93] VRMS: 9.71, THD: 1.163, Reward: -2059.56, Step time: 0.791s\n",
            "[Step 94] VRMS: 33.17, THD: 0.246, Reward: -50.21, Step time: 0.820s\n",
            "[Step 95] VRMS: 15.39, THD: 0.688, Reward: -1067.30, Step time: 0.867s\n",
            "[Step 96] VRMS: 9.57, THD: 3.197, Reward: -2097.25, Step time: 1.137s\n",
            "[Step 97] VRMS: 9.59, THD: 3.004, Reward: -2092.74, Step time: 1.126s\n",
            "[Step 98] VRMS: 29.34, THD: 0.285, Reward: -2.27, Step time: 0.876s\n",
            "[Step 99] VRMS: 27.20, THD: 0.303, Reward: -39.28, Step time: 0.779s\n",
            "[Step 100] VRMS: 29.58, THD: 0.274, Reward: -0.97, Step time: 0.925s\n",
            "[Step 1] VRMS: 16.97, THD: 0.866, Reward: -849.09, Step time: 1.621s\n",
            "[Step 2] VRMS: 19.39, THD: 0.559, Reward: -563.14, Step time: 1.585s\n",
            "[Step 3] VRMS: 32.01, THD: 0.299, Reward: -20.21, Step time: 1.061s\n",
            "[Step 4] VRMS: 30.30, THD: 0.321, Reward: -0.56, Step time: 1.555s\n",
            "[Step 5] VRMS: 9.54, THD: 3.258, Reward: -2103.20, Step time: 1.750s\n",
            "[Step 6] VRMS: 18.02, THD: 0.709, Reward: -718.17, Step time: 0.893s\n",
            "[Step 7] VRMS: 32.83, THD: 0.291, Reward: -40.20, Step time: 0.769s\n",
            "[Step 8] VRMS: 32.82, THD: 0.289, Reward: -39.96, Step time: 0.775s\n",
            "[Step 9] VRMS: 26.64, THD: 0.435, Reward: -56.64, Step time: 0.762s\n",
            "[Step 10] VRMS: 18.58, THD: 0.644, Reward: -652.48, Step time: 0.783s\n",
            "[Step 11] VRMS: 32.98, THD: 0.288, Reward: -44.38, Step time: 0.774s\n",
            "[Step 12] VRMS: 32.97, THD: 0.286, Reward: -44.12, Step time: 0.982s\n",
            "[Step 13] VRMS: 19.50, THD: 0.542, Reward: -551.30, Step time: 1.096s\n",
            "[Step 14] VRMS: 30.29, THD: 0.324, Reward: -0.54, Step time: 1.233s\n",
            "[Step 15] VRMS: 9.53, THD: 3.174, Reward: -2105.00, Step time: 0.766s\n",
            "[Step 16] VRMS: 19.34, THD: 0.562, Reward: -568.41, Step time: 0.792s\n",
            "[Step 17] VRMS: 30.71, THD: 0.316, Reward: -2.62, Step time: 0.764s\n",
            "[Step 18] VRMS: 9.53, THD: 3.174, Reward: -2105.02, Step time: 0.787s\n",
            "[Step 19] VRMS: 28.53, THD: 0.386, Reward: -10.98, Step time: 0.783s\n",
            "[Step 20] VRMS: 32.53, THD: 0.294, Reward: -32.08, Step time: 0.807s\n",
            "[Step 21] VRMS: 19.73, THD: 0.532, Reward: -527.63, Step time: 0.770s\n",
            "[Step 22] VRMS: 19.51, THD: 0.545, Reward: -550.77, Step time: 0.776s\n",
            "[Step 23] VRMS: 32.92, THD: 0.287, Reward: -42.72, Step time: 0.760s\n",
            "[Step 24] VRMS: 23.94, THD: 0.504, Reward: -183.99, Step time: 0.801s\n",
            "[Step 25] VRMS: 9.55, THD: 3.477, Reward: -2102.75, Step time: 0.800s\n",
            "[Step 26] VRMS: 17.96, THD: 0.712, Reward: -725.01, Step time: 0.795s\n",
            "[Step 27] VRMS: 22.62, THD: 0.509, Reward: -272.83, Step time: 0.943s\n",
            "[Step 28] VRMS: 19.45, THD: 0.548, Reward: -556.35, Step time: 1.121s\n",
            "[Step 29] VRMS: 31.37, THD: 0.304, Reward: -9.44, Step time: 1.229s\n",
            "[Step 30] VRMS: 9.65, THD: 3.910, Reward: -2086.84, Step time: 0.766s\n",
            "[Step 31] VRMS: 9.56, THD: 3.001, Reward: -2097.94, Step time: 0.809s\n",
            "[Step 32] VRMS: 15.27, THD: 1.004, Reward: -1085.43, Step time: 0.780s\n",
            "[Step 33] VRMS: 33.77, THD: 0.270, Reward: -71.08, Step time: 0.774s\n",
            "[Step 34] VRMS: 9.76, THD: 3.198, Reward: -2057.60, Step time: 0.765s\n",
            "[Step 35] VRMS: 33.98, THD: 0.265, Reward: -79.31, Step time: 0.797s\n",
            "[Step 36] VRMS: 25.29, THD: 0.446, Reward: -111.03, Step time: 0.789s\n",
            "[Step 37] VRMS: 9.48, THD: 2.173, Reward: -2110.29, Step time: 0.773s\n",
            "[Step 38] VRMS: 27.32, THD: 0.391, Reward: -36.19, Step time: 0.752s\n",
            "[Step 39] VRMS: 23.52, THD: 0.415, Reward: -210.22, Step time: 0.790s\n",
            "[Step 40] VRMS: 31.29, THD: 0.293, Reward: -8.36, Step time: 0.762s\n",
            "[Step 41] VRMS: 16.97, THD: 0.690, Reward: -849.72, Step time: 0.769s\n",
            "[Step 42] VRMS: 17.71, THD: 0.605, Reward: -755.51, Step time: 0.794s\n",
            "[Step 43] VRMS: 27.31, THD: 0.365, Reward: -36.42, Step time: 1.127s\n",
            "[Step 44] VRMS: 33.17, THD: 0.262, Reward: -50.19, Step time: 1.159s\n",
            "[Step 45] VRMS: 34.29, THD: 0.243, Reward: -92.13, Step time: 0.899s\n",
            "[Step 46] VRMS: 21.05, THD: 0.411, Reward: -400.42, Step time: 0.804s\n",
            "[Step 47] VRMS: 9.59, THD: 3.313, Reward: -2092.88, Step time: 0.773s\n",
            "[Step 48] VRMS: 9.56, THD: 3.001, Reward: -2097.99, Step time: 0.770s\n",
            "[Step 49] VRMS: 34.33, THD: 0.232, Reward: -93.80, Step time: 0.758s\n",
            "[Step 50] VRMS: 18.72, THD: 0.500, Reward: -636.77, Step time: 0.783s\n",
            "[Step 51] VRMS: 34.43, THD: 0.225, Reward: -98.35, Step time: 0.850s\n",
            "[Step 52] VRMS: 34.43, THD: 0.226, Reward: -98.26, Step time: 0.806s\n",
            "[Step 53] VRMS: 9.60, THD: 4.608, Reward: -2103.05, Step time: 0.788s\n",
            "[Step 54] VRMS: 9.56, THD: 3.006, Reward: -2098.00, Step time: 0.841s\n",
            "[Step 55] VRMS: 17.13, THD: 0.627, Reward: -829.20, Step time: 0.813s\n",
            "[Step 56] VRMS: 29.41, THD: 0.310, Reward: -1.85, Step time: 0.778s\n",
            "[Step 57] VRMS: 17.84, THD: 0.602, Reward: -739.79, Step time: 0.812s\n",
            "[Step 58] VRMS: 16.73, THD: 0.670, Reward: -880.44, Step time: 1.113s\n",
            "[Step 59] VRMS: 18.85, THD: 0.538, Reward: -622.41, Step time: 1.186s\n",
            "[Step 60] VRMS: 34.01, THD: 0.254, Reward: -80.63, Step time: 0.864s\n",
            "[Step 61] VRMS: 34.14, THD: 0.257, Reward: -85.66, Step time: 0.768s\n",
            "[Step 62] VRMS: 19.36, THD: 0.527, Reward: -565.91, Step time: 0.806s\n",
            "[Step 63] VRMS: 9.58, THD: 7.120, Reward: -2136.43, Step time: 0.763s\n",
            "[Step 64] VRMS: 9.56, THD: 3.002, Reward: -2097.98, Step time: 0.758s\n",
            "[Step 65] VRMS: 33.91, THD: 0.261, Reward: -76.45, Step time: 0.784s\n",
            "[Step 66] VRMS: 9.90, THD: 3.734, Reward: -2034.36, Step time: 0.768s\n",
            "[Step 67] VRMS: 33.56, THD: 0.265, Reward: -63.41, Step time: 0.805s\n",
            "[Step 68] VRMS: 26.27, THD: 0.432, Reward: -69.65, Step time: 0.767s\n",
            "[Step 69] VRMS: 32.53, THD: 0.285, Reward: -32.10, Step time: 0.778s\n",
            "[Step 70] VRMS: 31.14, THD: 0.308, Reward: -6.54, Step time: 0.801s\n",
            "[Step 71] VRMS: 32.86, THD: 0.282, Reward: -41.00, Step time: 0.785s\n",
            "[Step 72] VRMS: 19.82, THD: 0.513, Reward: -518.24, Step time: 0.786s\n",
            "[Step 73] VRMS: 29.33, THD: 0.347, Reward: -2.35, Step time: 1.204s\n",
            "[Step 74] VRMS: 33.09, THD: 0.269, Reward: -47.73, Step time: 1.370s\n",
            "[Step 75] VRMS: 18.69, THD: 0.606, Reward: -639.94, Step time: 0.981s\n",
            "[Step 76] VRMS: 17.62, THD: 0.693, Reward: -766.71, Step time: 0.800s\n",
            "[Step 77] VRMS: 9.57, THD: 3.172, Reward: -2097.15, Step time: 0.787s\n",
            "[Step 78] VRMS: 9.56, THD: 3.001, Reward: -2097.99, Step time: 0.821s\n",
            "[Step 79] VRMS: 31.37, THD: 0.293, Reward: -9.50, Step time: 0.805s\n",
            "[Step 80] VRMS: 24.56, THD: 0.431, Reward: -148.37, Step time: 0.798s\n",
            "[Step 81] VRMS: 9.42, THD: 2.030, Reward: -2121.24, Step time: 0.774s\n",
            "[Step 82] VRMS: 9.63, THD: 1.080, Reward: -2075.67, Step time: 0.776s\n",
            "[Step 83] VRMS: 13.97, THD: 0.906, Reward: -1286.10, Step time: 0.770s\n",
            "[Step 84] VRMS: 18.97, THD: 0.527, Reward: -608.24, Step time: 0.758s\n",
            "[Step 85] VRMS: 24.85, THD: 0.389, Reward: -132.52, Step time: 0.765s\n",
            "[Step 86] VRMS: 33.94, THD: 0.244, Reward: -77.51, Step time: 0.772s\n",
            "[Step 87] VRMS: 33.66, THD: 0.255, Reward: -66.97, Step time: 0.773s\n",
            "[Step 88] VRMS: 9.93, THD: 3.474, Reward: -2025.14, Step time: 1.154s\n",
            "[Step 89] VRMS: 30.66, THD: 0.283, Reward: -2.27, Step time: 1.224s\n",
            "[Step 90] VRMS: 9.92, THD: 3.518, Reward: -2027.99, Step time: 0.925s\n",
            "[Step 91] VRMS: 15.55, THD: 0.673, Reward: -1043.77, Step time: 0.783s\n",
            "[Step 92] VRMS: 9.55, THD: 3.187, Reward: -2102.14, Step time: 0.775s\n",
            "[Step 93] VRMS: 30.79, THD: 0.274, Reward: -3.20, Step time: 0.811s\n",
            "[Step 94] VRMS: 10.02, THD: 0.715, Reward: -1997.28, Step time: 0.821s\n",
            "[Step 95] VRMS: 31.16, THD: 0.266, Reward: -6.75, Step time: 0.781s\n",
            "[Step 96] VRMS: 14.94, THD: 0.661, Reward: -1134.16, Step time: 0.746s\n",
            "[Step 97] VRMS: 15.60, THD: 0.605, Reward: -1037.50, Step time: 0.798s\n",
            "[Step 98] VRMS: 19.70, THD: 0.436, Reward: -530.22, Step time: 0.780s\n",
            "[Step 99] VRMS: 20.67, THD: 0.378, Reward: -435.36, Step time: 0.777s\n",
            "[Step 100] VRMS: 15.25, THD: 0.573, Reward: -1088.59, Step time: 0.744s\n",
            "[Step 1] VRMS: 9.63, THD: 8.762, Reward: -2151.54, Step time: 0.791s\n",
            "[Step 2] VRMS: 17.48, THD: 0.879, Reward: -783.97, Step time: 0.798s\n",
            "[Step 3] VRMS: 32.29, THD: 0.307, Reward: -26.26, Step time: 1.171s\n",
            "[Step 4] VRMS: 16.48, THD: 1.060, Reward: -915.23, Step time: 1.156s\n",
            "[Step 5] VRMS: 28.40, THD: 0.413, Reward: -13.00, Step time: 0.936s\n",
            "[Step 6] VRMS: 30.44, THD: 0.344, Reward: -1.10, Step time: 0.817s\n",
            "[Step 7] VRMS: 9.69, THD: 3.808, Reward: -2076.96, Step time: 0.781s\n",
            "[Step 8] VRMS: 33.46, THD: 0.296, Reward: -60.05, Step time: 0.762s\n",
            "[Step 9] VRMS: 33.49, THD: 0.293, Reward: -61.02, Step time: 0.774s\n",
            "[Step 10] VRMS: 32.75, THD: 0.300, Reward: -37.95, Step time: 0.782s\n",
            "[Step 11] VRMS: 30.98, THD: 0.323, Reward: -4.95, Step time: 0.777s\n",
            "[Step 12] VRMS: 30.97, THD: 0.324, Reward: -4.82, Step time: 0.770s\n",
            "[Step 13] VRMS: 19.54, THD: 0.597, Reward: -547.00, Step time: 0.804s\n",
            "[Step 14] VRMS: 17.74, THD: 0.836, Reward: -751.98, Step time: 0.794s\n",
            "[Step 15] VRMS: 19.11, THD: 0.645, Reward: -593.16, Step time: 0.822s\n",
            "[Step 16] VRMS: 33.52, THD: 0.293, Reward: -62.12, Step time: 0.810s\n",
            "[Step 17] VRMS: 33.55, THD: 0.291, Reward: -63.05, Step time: 0.814s\n",
            "[Step 18] VRMS: 33.66, THD: 0.289, Reward: -67.02, Step time: 1.115s\n",
            "[Step 19] VRMS: 9.77, THD: 3.770, Reward: -2061.15, Step time: 1.112s\n",
            "[Step 20] VRMS: 18.27, THD: 0.750, Reward: -688.59, Step time: 0.952s\n",
            "[Step 21] VRMS: 9.61, THD: 3.414, Reward: -2090.16, Step time: 0.781s\n",
            "[Step 22] VRMS: 31.04, THD: 0.326, Reward: -5.47, Step time: 0.787s\n",
            "[Step 23] VRMS: 33.54, THD: 0.287, Reward: -62.75, Step time: 0.762s\n",
            "[Step 24] VRMS: 33.72, THD: 0.286, Reward: -69.18, Step time: 0.825s\n",
            "[Step 25] VRMS: 33.82, THD: 0.284, Reward: -72.95, Step time: 0.809s\n",
            "[Step 26] VRMS: 9.93, THD: 5.148, Reward: -2040.83, Step time: 0.782s\n",
            "[Step 27] VRMS: 9.59, THD: 3.004, Reward: -2092.32, Step time: 0.766s\n",
            "[Step 28] VRMS: 18.31, THD: 0.737, Reward: -684.19, Step time: 0.810s\n",
            "[Step 29] VRMS: 9.62, THD: 3.198, Reward: -2086.02, Step time: 0.786s\n",
            "[Step 30] VRMS: 34.06, THD: 0.277, Reward: -82.70, Step time: 0.771s\n",
            "[Step 31] VRMS: 10.03, THD: 3.439, Reward: -2005.32, Step time: 0.777s\n",
            "[Step 32] VRMS: 9.59, THD: 3.004, Reward: -2092.32, Step time: 0.793s\n",
            "[Step 33] VRMS: 9.59, THD: 3.001, Reward: -2092.33, Step time: 1.138s\n",
            "[Step 34] VRMS: 34.51, THD: 0.271, Reward: -101.89, Step time: 1.130s\n",
            "[Step 35] VRMS: 32.31, THD: 0.297, Reward: -26.87, Step time: 0.947s\n",
            "[Step 36] VRMS: 32.84, THD: 0.292, Reward: -40.34, Step time: 0.762s\n",
            "[Step 37] VRMS: 9.98, THD: 3.231, Reward: -2015.19, Step time: 0.750s\n",
            "[Step 38] VRMS: 16.81, THD: 0.762, Reward: -870.83, Step time: 0.794s\n",
            "[Step 39] VRMS: 34.52, THD: 0.260, Reward: -102.05, Step time: 0.787s\n",
            "[Step 40] VRMS: 30.11, THD: 0.323, Reward: -0.16, Step time: 0.766s\n",
            "[Step 41] VRMS: 20.30, THD: 0.485, Reward: -470.22, Step time: 0.799s\n",
            "[Step 42] VRMS: 34.37, THD: 0.252, Reward: -95.35, Step time: 0.758s\n",
            "[Step 43] VRMS: 17.71, THD: 0.670, Reward: -755.78, Step time: 0.793s\n",
            "[Step 44] VRMS: 18.96, THD: 0.540, Reward: -609.58, Step time: 0.776s\n",
            "[Step 45] VRMS: 29.82, THD: 0.305, Reward: -0.26, Step time: 0.809s\n",
            "[Step 46] VRMS: 34.60, THD: 0.242, Reward: -105.64, Step time: 0.749s\n",
            "[Step 47] VRMS: 9.76, THD: 3.232, Reward: -2057.98, Step time: 0.769s\n",
            "[Step 48] VRMS: 9.59, THD: 3.001, Reward: -2092.33, Step time: 1.047s\n",
            "[Step 49] VRMS: 34.58, THD: 0.234, Reward: -105.01, Step time: 1.136s\n",
            "[Step 50] VRMS: 9.76, THD: 3.300, Reward: -2059.56, Step time: 1.058s\n",
            "[Step 51] VRMS: 9.59, THD: 3.002, Reward: -2092.28, Step time: 0.767s\n",
            "[Step 52] VRMS: 9.59, THD: 3.004, Reward: -2092.32, Step time: 0.755s\n",
            "[Step 53] VRMS: 29.83, THD: 0.300, Reward: -0.24, Step time: 0.754s\n",
            "[Step 54] VRMS: 27.58, THD: 0.347, Reward: -29.42, Step time: 0.763s\n",
            "[Step 55] VRMS: 30.68, THD: 0.293, Reward: -2.40, Step time: 0.788s\n",
            "[Step 56] VRMS: 9.62, THD: 9.098, Reward: -2159.83, Step time: 0.757s\n",
            "[Step 57] VRMS: 9.59, THD: 3.004, Reward: -2092.32, Step time: 0.753s\n",
            "[Step 58] VRMS: 18.81, THD: 0.535, Reward: -626.15, Step time: 0.772s\n",
            "[Step 59] VRMS: 19.13, THD: 0.524, Reward: -591.51, Step time: 0.761s\n",
            "[Step 60] VRMS: 9.92, THD: 1.102, Reward: -2017.49, Step time: 0.759s\n",
            "[Step 61] VRMS: 9.59, THD: 3.263, Reward: -2092.97, Step time: 0.762s\n",
            "[Step 62] VRMS: 31.63, THD: 0.297, Reward: -13.40, Step time: 0.773s\n",
            "[Step 63] VRMS: 34.54, THD: 0.264, Reward: -103.01, Step time: 0.894s\n",
            "[Step 64] VRMS: 10.27, THD: 6.121, Reward: -1984.25, Step time: 1.106s\n",
            "[Step 65] VRMS: 9.59, THD: 3.001, Reward: -2092.28, Step time: 1.179s\n",
            "[Step 66] VRMS: 34.16, THD: 0.267, Reward: -86.64, Step time: 0.809s\n",
            "[Step 67] VRMS: 10.33, THD: 5.520, Reward: -1964.46, Step time: 0.759s\n",
            "[Step 68] VRMS: 9.59, THD: 3.001, Reward: -2092.33, Step time: 0.773s\n",
            "[Step 69] VRMS: 19.74, THD: 0.577, Reward: -527.12, Step time: 0.755s\n",
            "[Step 70] VRMS: 30.84, THD: 0.320, Reward: -3.64, Step time: 0.777s\n",
            "[Step 71] VRMS: 10.18, THD: 3.474, Reward: -1976.03, Step time: 0.761s\n",
            "[Step 72] VRMS: 9.59, THD: 3.004, Reward: -2092.32, Step time: 0.786s\n",
            "[Step 73] VRMS: 16.67, THD: 0.937, Reward: -888.74, Step time: 0.776s\n",
            "[Step 74] VRMS: 31.62, THD: 0.303, Reward: -13.18, Step time: 0.814s\n",
            "[Step 75] VRMS: 12.98, THD: 1.476, Reward: -1451.12, Step time: 0.755s\n",
            "[Step 76] VRMS: 18.15, THD: 0.676, Reward: -702.25, Step time: 0.769s\n",
            "[Step 77] VRMS: 28.73, THD: 0.372, Reward: -8.26, Step time: 0.754s\n",
            "[Step 78] VRMS: 9.97, THD: 1.846, Reward: -2009.90, Step time: 0.764s\n",
            "[Step 79] VRMS: 9.59, THD: 3.421, Reward: -2095.02, Step time: 1.133s\n",
            "[Step 80] VRMS: 19.17, THD: 0.556, Reward: -586.54, Step time: 1.140s\n",
            "[Step 81] VRMS: 9.64, THD: 11.393, Reward: -2203.30, Step time: 0.908s\n",
            "[Step 82] VRMS: 19.10, THD: 0.526, Reward: -594.82, Step time: 0.765s\n",
            "[Step 83] VRMS: 31.24, THD: 0.295, Reward: -7.74, Step time: 0.758s\n",
            "[Step 84] VRMS: 28.59, THD: 0.352, Reward: -10.12, Step time: 0.757s\n",
            "[Step 85] VRMS: 21.82, THD: 0.403, Reward: -334.70, Step time: 0.737s\n",
            "[Step 86] VRMS: 28.80, THD: 0.335, Reward: -7.36, Step time: 0.749s\n",
            "[Step 87] VRMS: 10.08, THD: 3.701, Reward: -1996.95, Step time: 0.769s\n",
            "[Step 88] VRMS: 9.59, THD: 3.001, Reward: -2092.33, Step time: 0.752s\n",
            "[Step 89] VRMS: 30.84, THD: 0.289, Reward: -3.58, Step time: 0.764s\n",
            "[Step 90] VRMS: 33.30, THD: 0.254, Reward: -54.66, Step time: 0.754s\n",
            "[Step 91] VRMS: 10.32, THD: 0.717, Reward: -1937.06, Step time: 0.768s\n",
            "[Step 92] VRMS: 9.59, THD: 3.496, Reward: -2094.59, Step time: 0.747s\n",
            "[Step 93] VRMS: 34.79, THD: 0.220, Reward: -114.94, Step time: 0.757s\n",
            "[Step 94] VRMS: 10.37, THD: 3.976, Reward: -1941.54, Step time: 0.949s\n",
            "[Step 95] VRMS: 9.59, THD: 3.001, Reward: -2092.28, Step time: 1.077s\n",
            "[Step 96] VRMS: 29.70, THD: 0.288, Reward: -0.53, Step time: 1.173s\n",
            "[Step 97] VRMS: 10.19, THD: 4.790, Reward: -1984.43, Step time: 0.764s\n",
            "[Step 98] VRMS: 34.86, THD: 0.206, Reward: -118.32, Step time: 0.766s\n",
            "[Step 99] VRMS: 34.83, THD: 0.209, Reward: -116.78, Step time: 0.752s\n",
            "[Step 100] VRMS: 10.31, THD: 4.818, Reward: -1960.73, Step time: 0.825s\n",
            "[Step 1] VRMS: 33.48, THD: 0.298, Reward: -60.48, Step time: 0.825s\n",
            "[Step 2] VRMS: 26.82, THD: 0.441, Reward: -50.87, Step time: 0.789s\n",
            "[Step 3] VRMS: 9.76, THD: 3.200, Reward: -2058.68, Step time: 0.762s\n",
            "[Step 4] VRMS: 9.59, THD: 3.003, Reward: -2091.90, Step time: 0.799s\n",
            "[Step 5] VRMS: 27.85, THD: 0.429, Reward: -23.31, Step time: 0.811s\n",
            "[Step 6] VRMS: 9.75, THD: 3.236, Reward: -2060.18, Step time: 0.818s\n",
            "[Step 7] VRMS: 18.29, THD: 0.764, Reward: -686.17, Step time: 0.765s\n",
            "[Step 8] VRMS: 29.29, THD: 0.386, Reward: -2.66, Step time: 0.769s\n",
            "[Step 9] VRMS: 33.30, THD: 0.303, Reward: -54.49, Step time: 1.037s\n",
            "[Step 10] VRMS: 33.65, THD: 0.291, Reward: -66.85, Step time: 1.117s\n",
            "[Step 11] VRMS: 20.01, THD: 0.539, Reward: -499.29, Step time: 1.169s\n",
            "[Step 12] VRMS: 25.78, THD: 0.480, Reward: -89.48, Step time: 0.780s\n",
            "[Step 13] VRMS: 9.75, THD: 3.281, Reward: -2061.43, Step time: 0.800s\n",
            "[Step 14] VRMS: 19.31, THD: 0.636, Reward: -572.14, Step time: 0.798s\n",
            "[Step 15] VRMS: 33.30, THD: 0.299, Reward: -54.66, Step time: 0.750s\n",
            "[Step 16] VRMS: 32.55, THD: 0.303, Reward: -32.51, Step time: 0.801s\n",
            "[Step 17] VRMS: 33.61, THD: 0.291, Reward: -65.20, Step time: 0.803s\n",
            "[Step 18] VRMS: 30.00, THD: 0.363, Reward: -0.13, Step time: 0.796s\n",
            "[Step 19] VRMS: 9.71, THD: 3.280, Reward: -2068.86, Step time: 0.771s\n",
            "[Step 20] VRMS: 9.59, THD: 3.001, Reward: -2091.87, Step time: 0.887s\n",
            "[Step 21] VRMS: 19.24, THD: 0.644, Reward: -579.22, Step time: 0.809s\n",
            "[Step 22] VRMS: 33.70, THD: 0.288, Reward: -68.68, Step time: 0.794s\n",
            "[Step 23] VRMS: 25.88, THD: 0.478, Reward: -85.13, Step time: 0.799s\n",
            "[Step 24] VRMS: 33.78, THD: 0.289, Reward: -71.36, Step time: 1.049s\n",
            "[Step 25] VRMS: 17.45, THD: 0.918, Reward: -788.86, Step time: 1.108s\n",
            "[Step 26] VRMS: 33.84, THD: 0.284, Reward: -73.98, Step time: 1.122s\n",
            "[Step 27] VRMS: 10.00, THD: 4.544, Reward: -2020.90, Step time: 0.796s\n",
            "[Step 28] VRMS: 9.59, THD: 3.001, Reward: -2091.91, Step time: 0.847s\n",
            "[Step 29] VRMS: 34.07, THD: 0.281, Reward: -82.74, Step time: 0.775s\n",
            "[Step 30] VRMS: 26.42, THD: 0.474, Reward: -64.42, Step time: 0.792s\n",
            "[Step 31] VRMS: 34.24, THD: 0.276, Reward: -89.89, Step time: 0.808s\n",
            "[Step 32] VRMS: 10.11, THD: 3.396, Reward: -1990.31, Step time: 0.770s\n",
            "[Step 33] VRMS: 19.73, THD: 0.542, Reward: -527.99, Step time: 0.786s\n",
            "[Step 34] VRMS: 9.67, THD: 21.259, Reward: -2517.82, Step time: 0.763s\n",
            "[Step 35] VRMS: 9.59, THD: 3.000, Reward: -2091.86, Step time: 0.756s\n",
            "[Step 36] VRMS: 34.43, THD: 0.266, Reward: -98.28, Step time: 0.807s\n",
            "[Step 37] VRMS: 31.53, THD: 0.306, Reward: -11.79, Step time: 0.831s\n",
            "[Step 38] VRMS: 18.23, THD: 0.630, Reward: -693.54, Step time: 0.807s\n",
            "[Step 39] VRMS: 30.81, THD: 0.307, Reward: -3.36, Step time: 1.061s\n",
            "[Step 40] VRMS: 18.85, THD: 0.572, Reward: -622.23, Step time: 1.094s\n",
            "[Step 41] VRMS: 9.58, THD: 3.351, Reward: -2095.42, Step time: 1.057s\n",
            "[Step 42] VRMS: 30.44, THD: 0.304, Reward: -1.07, Step time: 0.796s\n",
            "[Step 43] VRMS: 9.68, THD: 3.244, Reward: -2074.49, Step time: 0.757s\n",
            "[Step 44] VRMS: 34.63, THD: 0.246, Reward: -107.08, Step time: 0.803s\n",
            "[Step 45] VRMS: 9.90, THD: 3.216, Reward: -2030.41, Step time: 0.805s\n",
            "[Step 46] VRMS: 15.79, THD: 0.711, Reward: -1010.69, Step time: 0.793s\n",
            "[Step 47] VRMS: 9.58, THD: 3.334, Reward: -2095.43, Step time: 0.803s\n",
            "[Step 48] VRMS: 34.66, THD: 0.236, Reward: -108.75, Step time: 0.751s\n",
            "[Step 49] VRMS: 34.66, THD: 0.235, Reward: -108.74, Step time: 0.760s\n",
            "[Step 50] VRMS: 17.51, THD: 0.591, Reward: -779.84, Step time: 0.793s\n",
            "[Step 51] VRMS: 9.63, THD: 3.752, Reward: -2088.21, Step time: 0.775s\n",
            "[Step 52] VRMS: 25.07, THD: 0.348, Reward: -121.60, Step time: 0.779s\n",
            "[Step 53] VRMS: 9.74, THD: 3.307, Reward: -2063.48, Step time: 0.772s\n",
            "[Step 54] VRMS: 27.81, THD: 0.342, Reward: -24.00, Step time: 0.987s\n",
            "[Step 55] VRMS: 18.34, THD: 0.588, Reward: -680.54, Step time: 1.112s\n",
            "[Step 56] VRMS: 9.80, THD: 1.170, Reward: -2041.79, Step time: 1.125s\n",
            "[Step 57] VRMS: 31.75, THD: 0.291, Reward: -15.33, Step time: 0.784s\n",
            "[Step 58] VRMS: 25.44, THD: 0.398, Reward: -104.20, Step time: 0.758s\n",
            "[Step 59] VRMS: 34.47, THD: 0.251, Reward: -100.03, Step time: 0.783s\n",
            "[Step 60] VRMS: 10.15, THD: 3.740, Reward: -1984.60, Step time: 0.790s\n",
            "[Step 61] VRMS: 18.81, THD: 0.566, Reward: -626.87, Step time: 0.776s\n",
            "[Step 62] VRMS: 9.58, THD: 3.200, Reward: -2096.09, Step time: 0.756s\n",
            "[Step 63] VRMS: 34.52, THD: 0.263, Reward: -102.17, Step time: 0.759s\n",
            "[Step 64] VRMS: 34.66, THD: 0.268, Reward: -108.75, Step time: 0.767s\n",
            "[Step 65] VRMS: 32.86, THD: 0.298, Reward: -40.88, Step time: 0.783s\n",
            "[Step 66] VRMS: 10.28, THD: 7.064, Reward: -1993.69, Step time: 0.772s\n",
            "[Step 67] VRMS: 9.59, THD: 3.005, Reward: -2091.92, Step time: 0.773s\n",
            "[Step 68] VRMS: 20.02, THD: 0.540, Reward: -498.16, Step time: 0.790s\n",
            "[Step 69] VRMS: 17.02, THD: 0.878, Reward: -842.86, Step time: 0.904s\n",
            "[Step 70] VRMS: 32.87, THD: 0.293, Reward: -41.39, Step time: 1.103s\n",
            "[Step 71] VRMS: 31.72, THD: 0.313, Reward: -14.95, Step time: 1.199s\n",
            "[Step 72] VRMS: 18.57, THD: 0.773, Reward: -654.10, Step time: 0.777s\n",
            "[Step 73] VRMS: 33.73, THD: 0.276, Reward: -69.71, Step time: 0.754s\n",
            "[Step 74] VRMS: 24.73, THD: 0.477, Reward: -139.00, Step time: 0.809s\n",
            "[Step 75] VRMS: 20.11, THD: 0.540, Reward: -489.53, Step time: 0.761s\n",
            "[Step 76] VRMS: 10.11, THD: 3.471, Reward: -1990.55, Step time: 0.769s\n",
            "[Step 77] VRMS: 31.08, THD: 0.311, Reward: -5.92, Step time: 1.036s\n",
            "[Step 78] VRMS: 10.26, THD: 5.853, Reward: -1982.42, Step time: 1.105s\n",
            "[Step 79] VRMS: 31.78, THD: 0.296, Reward: -15.99, Step time: 1.013s\n",
            "[Step 80] VRMS: 22.64, THD: 0.411, Reward: -270.74, Step time: 0.757s\n",
            "[Step 81] VRMS: 9.89, THD: 3.202, Reward: -2032.81, Step time: 0.781s\n",
            "[Step 82] VRMS: 34.73, THD: 0.256, Reward: -112.16, Step time: 0.774s\n",
            "[Step 83] VRMS: 31.40, THD: 0.300, Reward: -9.82, Step time: 0.818s\n",
            "[Step 84] VRMS: 34.51, THD: 0.254, Reward: -101.62, Step time: 1.167s\n",
            "[Step 85] VRMS: 10.42, THD: 0.895, Reward: -1917.85, Step time: 1.141s\n",
            "[Step 86] VRMS: 15.03, THD: 0.800, Reward: -1121.76, Step time: 0.830s\n",
            "[Step 87] VRMS: 9.61, THD: 3.369, Reward: -2089.80, Step time: 0.770s\n",
            "[Step 88] VRMS: 31.88, THD: 0.281, Reward: -17.77, Step time: 0.764s\n",
            "[Step 89] VRMS: 34.80, THD: 0.236, Reward: -115.02, Step time: 0.759s\n",
            "[Step 90] VRMS: 19.00, THD: 0.524, Reward: -604.90, Step time: 0.748s\n",
            "[Step 91] VRMS: 18.71, THD: 0.534, Reward: -637.18, Step time: 0.779s\n",
            "[Step 92] VRMS: 9.97, THD: 3.858, Reward: -2020.20, Step time: 0.766s\n",
            "[Step 93] VRMS: 17.90, THD: 0.520, Reward: -732.40, Step time: 0.767s\n",
            "[Step 94] VRMS: 10.23, THD: 0.881, Reward: -1954.62, Step time: 0.750s\n",
            "[Step 95] VRMS: 26.33, THD: 0.324, Reward: -67.61, Step time: 0.774s\n",
            "[Step 96] VRMS: 19.23, THD: 0.477, Reward: -580.31, Step time: 0.779s\n",
            "[Step 97] VRMS: 9.95, THD: 4.129, Reward: -2026.16, Step time: 0.769s\n",
            "[Step 98] VRMS: 18.28, THD: 0.490, Reward: -686.66, Step time: 0.745s\n",
            "[Step 99] VRMS: 20.84, THD: 0.399, Reward: -419.65, Step time: 1.056s\n",
            "[Step 100] VRMS: 18.86, THD: 0.451, Reward: -620.96, Step time: 1.104s\n",
            "[Step 1] VRMS: 28.89, THD: 0.395, Reward: -6.27, Step time: 1.074s\n",
            "[Step 2] VRMS: 9.72, THD: 3.261, Reward: -2066.80, Step time: 0.800s\n",
            "[Step 3] VRMS: 18.86, THD: 0.669, Reward: -621.26, Step time: 0.782s\n",
            "[Step 4] VRMS: 27.58, THD: 0.435, Reward: -29.55, Step time: 0.777s\n",
            "[Step 5] VRMS: 19.36, THD: 0.634, Reward: -566.81, Step time: 0.784s\n",
            "[Step 6] VRMS: 9.59, THD: 3.538, Reward: -2095.00, Step time: 0.839s\n",
            "[Step 7] VRMS: 30.76, THD: 0.331, Reward: -2.99, Step time: 0.804s\n",
            "[Step 8] VRMS: 27.41, THD: 0.435, Reward: -33.71, Step time: 0.796s\n",
            "[Step 9] VRMS: 9.72, THD: 3.330, Reward: -2068.23, Step time: 0.800s\n",
            "[Step 10] VRMS: 9.59, THD: 3.000, Reward: -2092.26, Step time: 0.803s\n",
            "[Step 11] VRMS: 9.59, THD: 3.002, Reward: -2092.27, Step time: 0.794s\n",
            "[Step 12] VRMS: 31.94, THD: 0.312, Reward: -18.83, Step time: 0.773s\n",
            "[Step 13] VRMS: 32.67, THD: 0.300, Reward: -35.64, Step time: 0.766s\n",
            "[Step 14] VRMS: 31.57, THD: 0.312, Reward: -12.41, Step time: 1.067s\n",
            "[Step 15] VRMS: 30.04, THD: 0.353, Reward: -0.13, Step time: 1.143s\n",
            "[Step 16] VRMS: 17.88, THD: 0.820, Reward: -735.19, Step time: 1.051s\n",
            "[Step 17] VRMS: 17.46, THD: 0.882, Reward: -787.42, Step time: 0.766s\n",
            "[Step 18] VRMS: 9.58, THD: 3.554, Reward: -2096.68, Step time: 0.781s\n",
            "[Step 19] VRMS: 33.49, THD: 0.293, Reward: -60.98, Step time: 0.780s\n",
            "[Step 20] VRMS: 9.84, THD: 9.523, Reward: -2121.84, Step time: 0.773s\n",
            "[Step 21] VRMS: 18.87, THD: 0.671, Reward: -620.02, Step time: 0.760s\n",
            "[Step 22] VRMS: 19.80, THD: 0.558, Reward: -520.78, Step time: 0.784s\n",
            "[Step 23] VRMS: 33.57, THD: 0.292, Reward: -63.94, Step time: 0.774s\n",
            "[Step 24] VRMS: 9.88, THD: 15.247, Reward: -2256.73, Step time: 0.741s\n",
            "[Step 25] VRMS: 9.59, THD: 3.000, Reward: -2092.26, Step time: 0.763s\n",
            "[Step 26] VRMS: 17.41, THD: 0.888, Reward: -793.61, Step time: 0.770s\n",
            "[Step 27] VRMS: 32.58, THD: 0.302, Reward: -33.35, Step time: 0.774s\n",
            "[Step 28] VRMS: 33.00, THD: 0.297, Reward: -44.97, Step time: 0.744s\n",
            "[Step 29] VRMS: 24.87, THD: 0.499, Reward: -131.66, Step time: 0.942s\n",
            "[Step 30] VRMS: 28.63, THD: 0.408, Reward: -9.57, Step time: 1.102s\n",
            "[Step 31] VRMS: 30.50, THD: 0.332, Reward: -1.37, Step time: 1.161s\n",
            "[Step 32] VRMS: 31.95, THD: 0.303, Reward: -19.16, Step time: 0.772s\n",
            "[Step 33] VRMS: 16.96, THD: 0.814, Reward: -851.13, Step time: 0.782s\n",
            "[Step 34] VRMS: 17.04, THD: 0.760, Reward: -840.85, Step time: 0.773s\n",
            "[Step 35] VRMS: 26.02, THD: 0.442, Reward: -79.36, Step time: 0.754s\n",
            "[Step 36] VRMS: 34.39, THD: 0.265, Reward: -96.21, Step time: 0.764s\n",
            "[Step 37] VRMS: 22.09, THD: 0.433, Reward: -313.24, Step time: 0.777s\n",
            "[Step 38] VRMS: 17.49, THD: 0.673, Reward: -783.02, Step time: 0.808s\n",
            "[Step 39] VRMS: 24.71, THD: 0.429, Reward: -139.99, Step time: 0.781s\n",
            "[Step 40] VRMS: 9.58, THD: 3.204, Reward: -2095.73, Step time: 0.765s\n",
            "[Step 41] VRMS: 9.59, THD: 3.002, Reward: -2092.27, Step time: 0.775s\n",
            "[Step 42] VRMS: 21.96, THD: 0.400, Reward: -323.55, Step time: 0.785s\n",
            "[Step 43] VRMS: 34.42, THD: 0.253, Reward: -97.93, Step time: 0.764s\n",
            "[Step 44] VRMS: 16.30, THD: 0.750, Reward: -939.02, Step time: 0.899s\n",
            "[Step 45] VRMS: 18.75, THD: 0.545, Reward: -633.49, Step time: 1.139s\n",
            "[Step 46] VRMS: 34.58, THD: 0.241, Reward: -104.84, Step time: 1.144s\n",
            "[Step 47] VRMS: 15.48, THD: 0.758, Reward: -1055.14, Step time: 0.809s\n",
            "[Step 48] VRMS: 26.81, THD: 0.353, Reward: -50.86, Step time: 0.763s\n",
            "[Step 49] VRMS: 34.60, THD: 0.234, Reward: -105.81, Step time: 0.777s\n",
            "[Step 50] VRMS: 34.27, THD: 0.237, Reward: -91.10, Step time: 0.759s\n",
            "[Step 51] VRMS: 16.96, THD: 0.605, Reward: -851.08, Step time: 0.762s\n",
            "[Step 52] VRMS: 21.90, THD: 0.363, Reward: -328.29, Step time: 0.771s\n",
            "[Step 53] VRMS: 9.74, THD: 3.199, Reward: -2063.14, Step time: 0.803s\n",
            "[Step 54] VRMS: 31.50, THD: 0.287, Reward: -11.37, Step time: 0.784s\n",
            "[Step 55] VRMS: 9.76, THD: 3.306, Reward: -2058.80, Step time: 0.767s\n",
            "[Step 56] VRMS: 15.22, THD: 0.780, Reward: -1092.48, Step time: 0.754s\n",
            "[Step 57] VRMS: 34.54, THD: 0.247, Reward: -103.15, Step time: 0.749s\n",
            "[Step 58] VRMS: 19.20, THD: 0.534, Reward: -583.33, Step time: 0.756s\n",
            "[Step 59] VRMS: 34.43, THD: 0.252, Reward: -98.27, Step time: 0.776s\n",
            "[Step 60] VRMS: 18.42, THD: 0.620, Reward: -671.40, Step time: 1.074s\n",
            "[Step 61] VRMS: 16.44, THD: 0.783, Reward: -919.34, Step time: 1.109s\n",
            "[Step 62] VRMS: 27.04, THD: 0.397, Reward: -44.08, Step time: 0.997s\n",
            "[Step 63] VRMS: 30.00, THD: 0.330, Reward: -0.11, Step time: 0.764s\n",
            "[Step 64] VRMS: 10.00, THD: 3.223, Reward: -2011.10, Step time: 0.751s\n",
            "[Step 65] VRMS: 19.41, THD: 0.564, Reward: -561.22, Step time: 0.774s\n",
            "[Step 66] VRMS: 18.48, THD: 0.610, Reward: -664.27, Step time: 0.761s\n",
            "[Step 67] VRMS: 32.38, THD: 0.296, Reward: -28.35, Step time: 0.761s\n",
            "[Step 68] VRMS: 34.14, THD: 0.274, Reward: -85.78, Step time: 0.745s\n",
            "[Step 69] VRMS: 22.08, THD: 0.471, Reward: -313.63, Step time: 0.757s\n",
            "[Step 70] VRMS: 9.97, THD: 4.071, Reward: -2022.03, Step time: 0.766s\n",
            "[Step 71] VRMS: 16.00, THD: 1.051, Reward: -981.41, Step time: 0.754s\n",
            "[Step 72] VRMS: 33.31, THD: 0.285, Reward: -54.85, Step time: 0.739s\n",
            "[Step 73] VRMS: 29.46, THD: 0.377, Reward: -1.59, Step time: 0.760s\n",
            "[Step 74] VRMS: 30.16, THD: 0.347, Reward: -0.25, Step time: 0.750s\n",
            "[Step 75] VRMS: 16.98, THD: 0.868, Reward: -848.42, Step time: 0.876s\n",
            "[Step 76] VRMS: 28.82, THD: 0.381, Reward: -7.08, Step time: 1.060s\n",
            "[Step 77] VRMS: 19.80, THD: 0.555, Reward: -520.00, Step time: 1.165s\n",
            "[Step 78] VRMS: 24.69, THD: 0.445, Reward: -141.24, Step time: 0.787s\n",
            "[Step 79] VRMS: 19.51, THD: 0.567, Reward: -550.31, Step time: 0.766s\n",
            "[Step 80] VRMS: 20.60, THD: 0.455, Reward: -441.56, Step time: 0.766s\n",
            "[Step 81] VRMS: 19.17, THD: 0.550, Reward: -586.43, Step time: 0.797s\n",
            "[Step 82] VRMS: 9.64, THD: 3.203, Reward: -2083.32, Step time: 0.755s\n",
            "[Step 83] VRMS: 18.07, THD: 0.611, Reward: -711.97, Step time: 0.790s\n",
            "[Step 84] VRMS: 34.67, THD: 0.251, Reward: -109.24, Step time: 0.766s\n",
            "[Step 85] VRMS: 10.33, THD: 5.032, Reward: -1960.77, Step time: 0.789s\n",
            "[Step 86] VRMS: 9.58, THD: 1.280, Reward: -2086.39, Step time: 0.781s\n",
            "[Step 87] VRMS: 14.57, THD: 0.776, Reward: -1191.31, Step time: 0.786s\n",
            "[Step 88] VRMS: 34.87, THD: 0.235, Reward: -118.43, Step time: 0.796s\n",
            "[Step 89] VRMS: 33.70, THD: 0.250, Reward: -68.57, Step time: 0.824s\n",
            "[Step 90] VRMS: 18.68, THD: 0.529, Reward: -641.49, Step time: 0.821s\n",
            "[Step 91] VRMS: 34.78, THD: 0.223, Reward: -114.48, Step time: 1.166s\n",
            "[Step 92] VRMS: 19.21, THD: 0.509, Reward: -582.13, Step time: 1.163s\n",
            "[Step 93] VRMS: 34.70, THD: 0.224, Reward: -110.64, Step time: 0.904s\n",
            "[Step 94] VRMS: 22.63, THD: 0.343, Reward: -271.48, Step time: 0.798s\n",
            "[Step 95] VRMS: 9.61, THD: 4.983, Reward: -2104.04, Step time: 0.811s\n",
            "[Step 96] VRMS: 18.25, THD: 0.510, Reward: -691.15, Step time: 0.787s\n",
            "[Step 97] VRMS: 29.32, THD: 0.287, Reward: -2.38, Step time: 0.814s\n",
            "[Step 98] VRMS: 10.09, THD: 4.015, Reward: -1998.11, Step time: 0.760s\n",
            "[Step 99] VRMS: 23.25, THD: 0.284, Reward: -227.56, Step time: 0.806s\n",
            "[Step 100] VRMS: 22.31, THD: 0.321, Reward: -296.12, Step time: 0.791s\n",
            "[Step 1] VRMS: 19.88, THD: 0.561, Reward: -512.22, Step time: 0.789s\n",
            "[Step 2] VRMS: 19.75, THD: 0.579, Reward: -525.60, Step time: 0.777s\n",
            "[Step 3] VRMS: 19.90, THD: 0.552, Reward: -510.57, Step time: 0.785s\n",
            "[Step 4] VRMS: 28.39, THD: 0.414, Reward: -13.15, Step time: 0.759s\n",
            "[Step 5] VRMS: 18.47, THD: 0.731, Reward: -665.51, Step time: 0.771s\n",
            "[Step 6] VRMS: 9.59, THD: 12.814, Reward: -2246.19, Step time: 1.149s\n",
            "[Step 7] VRMS: 9.59, THD: 3.007, Reward: -2092.47, Step time: 1.147s\n",
            "[Step 8] VRMS: 9.59, THD: 3.001, Reward: -2092.45, Step time: 0.914s\n",
            "[Step 9] VRMS: 9.59, THD: 3.004, Reward: -2092.46, Step time: 0.766s\n",
            "[Step 10] VRMS: 33.32, THD: 0.300, Reward: -55.32, Step time: 0.781s\n",
            "[Step 11] VRMS: 15.77, THD: 1.220, Reward: -1014.39, Step time: 0.776s\n",
            "[Step 12] VRMS: 9.59, THD: 11.186, Reward: -2208.55, Step time: 0.781s\n",
            "[Step 13] VRMS: 29.66, THD: 0.369, Reward: -0.72, Step time: 0.770s\n",
            "[Step 14] VRMS: 28.19, THD: 0.420, Reward: -16.54, Step time: 0.790s\n",
            "[Step 15] VRMS: 17.65, THD: 0.858, Reward: -763.18, Step time: 0.768s\n",
            "[Step 16] VRMS: 17.70, THD: 0.842, Reward: -757.33, Step time: 0.767s\n",
            "[Step 17] VRMS: 31.33, THD: 0.320, Reward: -8.96, Step time: 0.785s\n",
            "[Step 18] VRMS: 9.65, THD: 3.197, Reward: -2080.80, Step time: 0.769s\n",
            "[Step 19] VRMS: 30.62, THD: 0.338, Reward: -2.01, Step time: 0.763s\n",
            "[Step 20] VRMS: 19.87, THD: 0.537, Reward: -513.72, Step time: 0.743s\n",
            "[Step 21] VRMS: 32.80, THD: 0.303, Reward: -39.41, Step time: 1.057s\n",
            "[Step 22] VRMS: 25.76, THD: 0.472, Reward: -90.07, Step time: 1.139s\n",
            "[Step 23] VRMS: 20.03, THD: 0.538, Reward: -497.76, Step time: 1.037s\n",
            "[Step 24] VRMS: 17.16, THD: 0.930, Reward: -824.65, Step time: 0.787s\n",
            "[Step 25] VRMS: 9.59, THD: 7.400, Reward: -2137.55, Step time: 0.809s\n",
            "[Step 26] VRMS: 9.59, THD: 3.002, Reward: -2092.41, Step time: 0.797s\n",
            "[Step 27] VRMS: 9.59, THD: 3.004, Reward: -2092.45, Step time: 0.797s\n",
            "[Step 28] VRMS: 9.59, THD: 3.000, Reward: -2092.45, Step time: 0.796s\n",
            "[Step 29] VRMS: 31.73, THD: 0.310, Reward: -15.13, Step time: 0.806s\n",
            "[Step 30] VRMS: 9.77, THD: 4.313, Reward: -2065.60, Step time: 0.795s\n",
            "[Step 31] VRMS: 18.67, THD: 0.654, Reward: -642.74, Step time: 0.821s\n",
            "[Step 32] VRMS: 34.11, THD: 0.274, Reward: -84.74, Step time: 0.752s\n",
            "[Step 33] VRMS: 10.06, THD: 3.330, Reward: -1998.71, Step time: 0.764s\n",
            "[Step 34] VRMS: 31.91, THD: 0.301, Reward: -18.34, Step time: 0.804s\n",
            "[Step 35] VRMS: 29.09, THD: 0.376, Reward: -4.32, Step time: 0.824s\n",
            "[Step 36] VRMS: 29.89, THD: 0.332, Reward: -0.17, Step time: 1.097s\n",
            "[Step 37] VRMS: 19.33, THD: 0.533, Reward: -569.71, Step time: 1.146s\n",
            "[Step 38] VRMS: 18.38, THD: 0.597, Reward: -675.02, Step time: 0.987s\n",
            "[Step 39] VRMS: 34.51, THD: 0.260, Reward: -101.58, Step time: 0.756s\n",
            "[Step 40] VRMS: 31.23, THD: 0.302, Reward: -7.67, Step time: 0.766s\n",
            "[Step 41] VRMS: 9.89, THD: 3.377, Reward: -2032.57, Step time: 0.771s\n",
            "[Step 42] VRMS: 19.06, THD: 0.527, Reward: -598.24, Step time: 0.759s\n",
            "[Step 43] VRMS: 17.23, THD: 0.674, Reward: -816.29, Step time: 0.753s\n",
            "[Step 44] VRMS: 20.81, THD: 0.440, Reward: -422.34, Step time: 0.771s\n",
            "[Step 45] VRMS: 9.60, THD: 12.946, Reward: -2248.92, Step time: 0.774s\n",
            "[Step 46] VRMS: 31.69, THD: 0.289, Reward: -14.34, Step time: 0.773s\n",
            "[Step 47] VRMS: 31.60, THD: 0.286, Reward: -12.90, Step time: 0.752s\n",
            "[Step 48] VRMS: 18.64, THD: 0.572, Reward: -645.40, Step time: 0.776s\n",
            "[Step 49] VRMS: 17.06, THD: 0.589, Reward: -837.66, Step time: 0.785s\n",
            "[Step 50] VRMS: 20.42, THD: 0.435, Reward: -458.76, Step time: 0.780s\n",
            "[Step 51] VRMS: 30.30, THD: 0.290, Reward: -0.52, Step time: 1.021s\n",
            "[Step 52] VRMS: 9.63, THD: 3.318, Reward: -2086.19, Step time: 1.121s\n",
            "[Step 53] VRMS: 9.59, THD: 3.001, Reward: -2092.45, Step time: 1.172s\n",
            "[Step 54] VRMS: 30.20, THD: 0.298, Reward: -0.29, Step time: 0.776s\n",
            "[Step 55] VRMS: 23.47, THD: 0.354, Reward: -213.51, Step time: 0.765s\n",
            "[Step 56] VRMS: 34.63, THD: 0.243, Reward: -107.02, Step time: 0.775s\n",
            "[Step 57] VRMS: 27.30, THD: 0.371, Reward: -36.58, Step time: 0.786s\n",
            "[Step 58] VRMS: 17.77, THD: 0.640, Reward: -748.59, Step time: 0.762s\n",
            "[Step 59] VRMS: 29.03, THD: 0.336, Reward: -4.77, Step time: 0.829s\n",
            "[Step 60] VRMS: 19.03, THD: 0.563, Reward: -601.65, Step time: 0.808s\n",
            "[Step 61] VRMS: 29.77, THD: 0.316, Reward: -0.36, Step time: 0.777s\n",
            "[Step 62] VRMS: 28.90, THD: 0.353, Reward: -6.20, Step time: 0.771s\n",
            "[Step 63] VRMS: 27.96, THD: 0.388, Reward: -21.02, Step time: 0.782s\n",
            "[Step 64] VRMS: 9.86, THD: 3.225, Reward: -2038.04, Step time: 0.814s\n",
            "[Step 65] VRMS: 19.39, THD: 0.577, Reward: -563.42, Step time: 0.770s\n",
            "[Step 66] VRMS: 9.51, THD: 2.762, Reward: -2107.82, Step time: 0.986s\n",
            "[Step 67] VRMS: 16.07, THD: 0.906, Reward: -971.52, Step time: 1.101s\n",
            "[Step 68] VRMS: 9.59, THD: 3.334, Reward: -2093.35, Step time: 1.169s\n",
            "[Step 69] VRMS: 9.59, THD: 3.003, Reward: -2092.45, Step time: 0.829s\n",
            "[Step 70] VRMS: 16.74, THD: 0.914, Reward: -880.47, Step time: 0.775s\n",
            "[Step 71] VRMS: 30.24, THD: 0.337, Reward: -0.39, Step time: 0.779s\n",
            "[Step 72] VRMS: 10.20, THD: 3.349, Reward: -1971.82, Step time: 0.765s\n",
            "[Step 73] VRMS: 33.59, THD: 0.274, Reward: -64.54, Step time: 0.786s\n",
            "[Step 74] VRMS: 26.62, THD: 0.443, Reward: -57.20, Step time: 0.766s\n",
            "[Step 75] VRMS: 30.84, THD: 0.322, Reward: -3.64, Step time: 0.773s\n",
            "[Step 76] VRMS: 34.24, THD: 0.269, Reward: -89.89, Step time: 0.790s\n",
            "[Step 77] VRMS: 31.68, THD: 0.307, Reward: -14.26, Step time: 0.771s\n",
            "[Step 78] VRMS: 10.33, THD: 4.454, Reward: -1954.91, Step time: 0.741s\n",
            "[Step 79] VRMS: 17.78, THD: 0.666, Reward: -747.05, Step time: 0.784s\n",
            "[Step 80] VRMS: 19.21, THD: 0.538, Reward: -582.39, Step time: 0.785s\n",
            "[Step 81] VRMS: 9.66, THD: 3.287, Reward: -2080.27, Step time: 0.898s\n",
            "[Step 82] VRMS: 9.73, THD: 1.498, Reward: -2055.71, Step time: 1.116s\n",
            "[Step 83] VRMS: 18.19, THD: 0.598, Reward: -698.10, Step time: 1.200s\n",
            "[Step 84] VRMS: 32.40, THD: 0.284, Reward: -28.98, Step time: 0.799s\n",
            "[Step 85] VRMS: 27.64, THD: 0.373, Reward: -27.87, Step time: 0.755s\n",
            "[Step 86] VRMS: 34.45, THD: 0.243, Reward: -98.99, Step time: 0.771s\n",
            "[Step 87] VRMS: 17.50, THD: 0.641, Reward: -781.55, Step time: 0.798s\n",
            "[Step 88] VRMS: 27.26, THD: 0.360, Reward: -37.56, Step time: 0.803s\n",
            "[Step 89] VRMS: 34.70, THD: 0.231, Reward: -110.70, Step time: 0.775s\n",
            "[Step 90] VRMS: 31.88, THD: 0.281, Reward: -17.75, Step time: 0.795s\n",
            "[Step 91] VRMS: 10.33, THD: 4.178, Reward: -1951.95, Step time: 0.763s\n",
            "[Step 92] VRMS: 9.59, THD: 3.004, Reward: -2092.45, Step time: 0.778s\n",
            "[Step 93] VRMS: 26.05, THD: 0.335, Reward: -78.17, Step time: 0.766s\n",
            "[Step 94] VRMS: 22.34, THD: 0.343, Reward: -293.21, Step time: 0.761s\n",
            "[Step 95] VRMS: 17.53, THD: 0.528, Reward: -777.57, Step time: 0.790s\n",
            "[Step 96] VRMS: 31.10, THD: 0.269, Reward: -6.12, Step time: 0.808s\n",
            "[Step 97] VRMS: 10.31, THD: 5.463, Reward: -1968.38, Step time: 1.147s\n",
            "[Step 98] VRMS: 9.59, THD: 3.001, Reward: -2092.45, Step time: 1.126s\n",
            "[Step 99] VRMS: 22.74, THD: 0.301, Reward: -263.71, Step time: 0.942s\n",
            "[Step 100] VRMS: 9.62, THD: 3.459, Reward: -2089.28, Step time: 0.776s\n",
            "[Step 1] VRMS: 33.83, THD: 0.300, Reward: -73.47, Step time: 0.771s\n",
            "[Step 2] VRMS: 33.95, THD: 0.294, Reward: -77.91, Step time: 0.802s\n",
            "[Step 3] VRMS: 26.02, THD: 0.475, Reward: -79.34, Step time: 0.797s\n",
            "[Step 4] VRMS: 16.98, THD: 1.118, Reward: -848.97, Step time: 0.775s\n",
            "[Step 5] VRMS: 34.01, THD: 0.297, Reward: -80.59, Step time: 0.798s\n",
            "[Step 6] VRMS: 9.93, THD: 3.207, Reward: -2024.73, Step time: 0.820s\n",
            "[Step 7] VRMS: 19.92, THD: 0.615, Reward: -508.38, Step time: 0.791s\n",
            "[Step 8] VRMS: 20.24, THD: 0.565, Reward: -476.82, Step time: 0.814s\n",
            "[Step 9] VRMS: 23.03, THD: 0.483, Reward: -243.07, Step time: 0.776s\n",
            "[Step 10] VRMS: 17.17, THD: 1.087, Reward: -824.16, Step time: 0.774s\n",
            "[Step 11] VRMS: 20.15, THD: 0.581, Reward: -485.82, Step time: 0.806s\n",
            "[Step 12] VRMS: 33.03, THD: 0.306, Reward: -46.11, Step time: 1.147s\n",
            "[Step 13] VRMS: 19.40, THD: 0.667, Reward: -561.98, Step time: 1.173s\n",
            "[Step 14] VRMS: 33.57, THD: 0.305, Reward: -63.97, Step time: 0.892s\n",
            "[Step 15] VRMS: 19.42, THD: 0.669, Reward: -560.44, Step time: 0.770s\n",
            "[Step 16] VRMS: 19.41, THD: 0.671, Reward: -561.33, Step time: 0.787s\n",
            "[Step 17] VRMS: 9.72, THD: 3.774, Reward: -2070.95, Step time: 0.759s\n",
            "[Step 18] VRMS: 31.11, THD: 0.341, Reward: -6.32, Step time: 0.765s\n",
            "[Step 19] VRMS: 20.33, THD: 0.545, Reward: -467.79, Step time: 0.748s\n",
            "[Step 20] VRMS: 19.25, THD: 0.697, Reward: -578.40, Step time: 0.786s\n",
            "[Step 21] VRMS: 16.55, THD: 1.154, Reward: -905.89, Step time: 0.775s\n",
            "[Step 22] VRMS: 28.86, THD: 0.421, Reward: -6.69, Step time: 0.790s\n",
            "[Step 23] VRMS: 34.11, THD: 0.291, Reward: -84.69, Step time: 0.775s\n",
            "[Step 24] VRMS: 16.30, THD: 1.226, Reward: -940.10, Step time: 0.802s\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -7.9e+04 |\n",
            "| time/              |          |\n",
            "|    fps             | 1        |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 873      |\n",
            "|    total_timesteps | 1024     |\n",
            "---------------------------------\n",
            "[Step 25] VRMS: 21.30, THD: 0.484, Reward: -378.63, Step time: 0.819s\n",
            "[Step 26] VRMS: 9.95, THD: 3.608, Reward: -2023.05, Step time: 1.171s\n",
            "[Step 27] VRMS: 19.89, THD: 0.597, Reward: -511.22, Step time: 1.152s\n",
            "[Step 28] VRMS: 9.78, THD: 18.328, Reward: -2379.28, Step time: 0.971s\n",
            "[Step 29] VRMS: 19.77, THD: 0.600, Reward: -523.53, Step time: 0.812s\n",
            "[Step 30] VRMS: 9.81, THD: 5.349, Reward: -2066.75, Step time: 0.772s\n",
            "[Step 31] VRMS: 19.68, THD: 0.568, Reward: -533.32, Step time: 0.802s\n",
            "[Step 32] VRMS: 19.23, THD: 0.653, Reward: -580.61, Step time: 0.777s\n",
            "[Step 33] VRMS: 12.09, THD: 1.339, Reward: -1605.61, Step time: 0.776s\n",
            "[Step 34] VRMS: 31.64, THD: 0.312, Reward: -13.52, Step time: 0.760s\n",
            "[Step 35] VRMS: 31.56, THD: 0.314, Reward: -12.32, Step time: 0.779s\n",
            "[Step 36] VRMS: 10.07, THD: 8.034, Reward: -2051.18, Step time: 0.777s\n",
            "[Step 37] VRMS: 18.74, THD: 0.582, Reward: -634.09, Step time: 0.778s\n",
            "[Step 38] VRMS: 9.65, THD: 3.211, Reward: -2081.02, Step time: 0.739s\n",
            "[Step 39] VRMS: 15.02, THD: 0.918, Reward: -1123.44, Step time: 0.775s\n",
            "[Step 40] VRMS: 17.88, THD: 0.647, Reward: -735.48, Step time: 0.759s\n",
            "[Step 41] VRMS: 28.55, THD: 0.361, Reward: -10.63, Step time: 1.057s\n",
            "[Step 42] VRMS: 26.03, THD: 0.403, Reward: -78.80, Step time: 1.113s\n",
            "[Step 43] VRMS: 17.29, THD: 0.699, Reward: -807.58, Step time: 1.068s\n",
            "[Step 44] VRMS: 34.78, THD: 0.247, Reward: -114.43, Step time: 0.759s\n",
            "[Step 45] VRMS: 10.02, THD: 3.213, Reward: -2006.53, Step time: 0.757s\n",
            "[Step 46] VRMS: 27.93, THD: 0.358, Reward: -21.60, Step time: 0.777s\n",
            "[Step 47] VRMS: 16.91, THD: 0.655, Reward: -856.72, Step time: 0.787s\n",
            "[Step 48] VRMS: 9.64, THD: 4.289, Reward: -2090.84, Step time: 0.770s\n",
            "[Step 49] VRMS: 34.75, THD: 0.235, Reward: -112.80, Step time: 0.771s\n",
            "[Step 50] VRMS: 21.48, THD: 0.402, Reward: -363.13, Step time: 0.759s\n",
            "[Step 51] VRMS: 10.07, THD: 3.227, Reward: -1995.90, Step time: 0.762s\n",
            "[Step 52] VRMS: 34.84, THD: 0.229, Reward: -117.23, Step time: 0.762s\n",
            "[Step 53] VRMS: 9.70, THD: 3.288, Reward: -2071.30, Step time: 0.759s\n",
            "[Step 54] VRMS: 18.95, THD: 0.531, Reward: -611.22, Step time: 0.763s\n",
            "[Step 55] VRMS: 9.80, THD: 11.946, Reward: -2182.27, Step time: 0.760s\n",
            "[Step 56] VRMS: 9.60, THD: 3.002, Reward: -2090.30, Step time: 0.878s\n",
            "[Step 57] VRMS: 33.26, THD: 0.264, Reward: -53.27, Step time: 1.075s\n",
            "[Step 58] VRMS: 28.27, THD: 0.362, Reward: -15.04, Step time: 1.217s\n",
            "[Step 59] VRMS: 31.76, THD: 0.294, Reward: -15.55, Step time: 0.769s\n",
            "[Step 60] VRMS: 34.67, THD: 0.259, Reward: -109.19, Step time: 0.750s\n",
            "[Step 61] VRMS: 10.99, THD: 0.995, Reward: -1808.11, Step time: 0.774s\n",
            "[Step 62] VRMS: 14.88, THD: 0.926, Reward: -1143.43, Step time: 0.921s\n",
            "[Step 63] VRMS: 34.83, THD: 0.263, Reward: -116.69, Step time: 1.088s\n",
            "[Step 64] VRMS: 16.64, THD: 0.948, Reward: -893.05, Step time: 1.184s\n",
            "[Step 65] VRMS: 25.41, THD: 0.448, Reward: -105.55, Step time: 0.779s\n",
            "[Step 66] VRMS: 10.04, THD: 2.921, Reward: -2000.20, Step time: 0.802s\n",
            "[Step 67] VRMS: 34.42, THD: 0.270, Reward: -97.84, Step time: 0.791s\n",
            "[Step 68] VRMS: 10.80, THD: 6.183, Reward: -1882.20, Step time: 0.779s\n",
            "[Step 69] VRMS: 34.26, THD: 0.274, Reward: -91.00, Step time: 0.768s\n",
            "[Step 70] VRMS: 19.72, THD: 0.653, Reward: -528.53, Step time: 0.838s\n",
            "[Step 71] VRMS: 29.88, THD: 0.367, Reward: -0.20, Step time: 1.137s\n",
            "[Step 72] VRMS: 20.74, THD: 0.579, Reward: -429.04, Step time: 1.198s\n",
            "[Step 73] VRMS: 18.13, THD: 0.803, Reward: -704.84, Step time: 0.813s\n",
            "[Step 74] VRMS: 30.65, THD: 0.337, Reward: -2.21, Step time: 0.770s\n",
            "[Step 75] VRMS: 10.63, THD: 3.324, Reward: -1886.28, Step time: 0.772s\n",
            "[Step 76] VRMS: 18.73, THD: 0.631, Reward: -635.76, Step time: 0.739s\n",
            "[Step 77] VRMS: 9.56, THD: 2.422, Reward: -2094.80, Step time: 0.756s\n",
            "[Step 78] VRMS: 34.97, THD: 0.266, Reward: -123.37, Step time: 0.764s\n",
            "[Step 79] VRMS: 30.54, THD: 0.334, Reward: -1.54, Step time: 0.772s\n",
            "[Step 80] VRMS: 34.85, THD: 0.265, Reward: -117.86, Step time: 0.742s\n",
            "[Step 81] VRMS: 19.70, THD: 0.533, Reward: -531.02, Step time: 0.774s\n",
            "[Step 82] VRMS: 16.31, THD: 0.824, Reward: -938.08, Step time: 0.767s\n",
            "[Step 83] VRMS: 35.19, THD: 0.256, Reward: -134.68, Step time: 0.774s\n",
            "[Step 84] VRMS: 10.73, THD: 4.964, Reward: -1881.33, Step time: 0.750s\n",
            "[Step 85] VRMS: 31.54, THD: 0.292, Reward: -12.02, Step time: 0.766s\n",
            "[Step 86] VRMS: 34.08, THD: 0.260, Reward: -83.36, Step time: 1.048s\n",
            "[Step 87] VRMS: 11.04, THD: 1.012, Reward: -1798.18, Step time: 1.156s\n",
            "[Step 88] VRMS: 18.79, THD: 0.524, Reward: -629.15, Step time: 1.076s\n",
            "[Step 89] VRMS: 9.98, THD: 3.502, Reward: -2016.92, Step time: 0.834s\n",
            "[Step 90] VRMS: 30.65, THD: 0.292, Reward: -2.17, Step time: 0.784s\n",
            "[Step 91] VRMS: 34.78, THD: 0.230, Reward: -114.39, Step time: 0.821s\n",
            "[Step 92] VRMS: 34.78, THD: 0.227, Reward: -114.16, Step time: 0.815s\n",
            "[Step 93] VRMS: 34.79, THD: 0.225, Reward: -114.75, Step time: 0.852s\n",
            "[Step 94] VRMS: 10.87, THD: 4.551, Reward: -1851.35, Step time: 0.785s\n",
            "[Step 95] VRMS: 15.19, THD: 0.699, Reward: -1097.01, Step time: 0.783s\n",
            "[Step 96] VRMS: 22.88, THD: 0.336, Reward: -253.66, Step time: 0.790s\n",
            "[Step 97] VRMS: 27.67, THD: 0.305, Reward: -27.26, Step time: 0.772s\n",
            "[Step 98] VRMS: 27.15, THD: 0.304, Reward: -40.84, Step time: 0.779s\n",
            "[Step 99] VRMS: 32.24, THD: 0.247, Reward: -25.13, Step time: 0.781s\n",
            "[Step 100] VRMS: 34.95, THD: 0.206, Reward: -122.33, Step time: 0.758s\n",
            "[Step 1] VRMS: 18.77, THD: 0.783, Reward: -631.51, Step time: 1.104s\n",
            "[Step 2] VRMS: 33.97, THD: 0.297, Reward: -79.03, Step time: 1.105s\n",
            "[Step 3] VRMS: 27.83, THD: 0.434, Reward: -23.71, Step time: 1.024s\n",
            "[Step 4] VRMS: 18.34, THD: 0.892, Reward: -681.04, Step time: 0.780s\n",
            "[Step 5] VRMS: 9.67, THD: 3.287, Reward: -2077.82, Step time: 0.766s\n",
            "[Step 6] VRMS: 31.94, THD: 0.320, Reward: -18.87, Step time: 0.771s\n",
            "[Step 7] VRMS: 10.02, THD: 3.415, Reward: -2006.85, Step time: 0.772s\n",
            "[Step 8] VRMS: 20.98, THD: 0.496, Reward: -407.46, Step time: 0.768s\n",
            "[Step 9] VRMS: 27.75, THD: 0.453, Reward: -25.49, Step time: 0.759s\n",
            "[Step 10] VRMS: 29.81, THD: 0.401, Reward: -0.34, Step time: 0.819s\n",
            "[Step 11] VRMS: 10.01, THD: 12.710, Reward: -2158.63, Step time: 0.803s\n",
            "[Step 12] VRMS: 16.53, THD: 1.227, Reward: -908.37, Step time: 0.771s\n",
            "[Step 13] VRMS: 9.62, THD: 5.435, Reward: -2106.26, Step time: 0.768s\n",
            "[Step 14] VRMS: 9.60, THD: 3.003, Reward: -2090.10, Step time: 0.767s\n",
            "[Step 15] VRMS: 19.05, THD: 0.711, Reward: -600.25, Step time: 0.774s\n",
            "[Step 16] VRMS: 34.12, THD: 0.298, Reward: -84.84, Step time: 1.054s\n",
            "[Step 17] VRMS: 34.08, THD: 0.292, Reward: -83.32, Step time: 1.090s\n",
            "[Step 18] VRMS: 20.35, THD: 0.592, Reward: -466.36, Step time: 1.062s\n",
            "[Step 19] VRMS: 9.78, THD: 3.986, Reward: -2059.36, Step time: 0.768s\n",
            "[Step 20] VRMS: 34.24, THD: 0.292, Reward: -90.03, Step time: 0.764s\n",
            "[Step 21] VRMS: 26.04, THD: 0.487, Reward: -78.50, Step time: 0.787s\n",
            "[Step 22] VRMS: 10.01, THD: 5.593, Reward: -2028.31, Step time: 0.791s\n",
            "[Step 23] VRMS: 34.05, THD: 0.292, Reward: -82.08, Step time: 0.768s\n",
            "[Step 24] VRMS: 31.57, THD: 0.332, Reward: -12.46, Step time: 0.760s\n",
            "[Step 25] VRMS: 29.27, THD: 0.411, Reward: -2.87, Step time: 0.775s\n",
            "[Step 26] VRMS: 10.03, THD: 3.270, Reward: -2005.38, Step time: 0.748s\n",
            "[Step 27] VRMS: 17.76, THD: 0.930, Reward: -750.42, Step time: 0.759s\n",
            "[Step 28] VRMS: 9.65, THD: 7.641, Reward: -2129.90, Step time: 0.765s\n",
            "[Step 29] VRMS: 13.57, THD: 1.525, Reward: -1352.13, Step time: 0.784s\n",
            "[Step 30] VRMS: 34.53, THD: 0.278, Reward: -102.85, Step time: 0.782s\n",
            "[Step 31] VRMS: 34.76, THD: 0.276, Reward: -113.46, Step time: 0.912s\n",
            "[Step 32] VRMS: 33.32, THD: 0.300, Reward: -55.11, Step time: 1.076s\n",
            "[Step 33] VRMS: 34.98, THD: 0.272, Reward: -123.86, Step time: 1.164s\n",
            "[Step 34] VRMS: 10.60, THD: 3.346, Reward: -1893.87, Step time: 0.798s\n",
            "[Step 35] VRMS: 31.91, THD: 0.307, Reward: -18.36, Step time: 0.759s\n",
            "[Step 36] VRMS: 17.05, THD: 0.807, Reward: -838.71, Step time: 0.761s\n",
            "[Step 37] VRMS: 28.87, THD: 0.377, Reward: -6.55, Step time: 0.799s\n",
            "[Step 38] VRMS: 34.90, THD: 0.262, Reward: -120.24, Step time: 0.780s\n",
            "[Step 39] VRMS: 30.18, THD: 0.336, Reward: -0.27, Step time: 0.796s\n",
            "[Step 40] VRMS: 27.79, THD: 0.381, Reward: -24.46, Step time: 0.772s\n",
            "[Step 41] VRMS: 28.34, THD: 0.366, Reward: -13.95, Step time: 0.769s\n",
            "[Step 42] VRMS: 22.22, THD: 0.397, Reward: -302.78, Step time: 0.776s\n",
            "[Step 43] VRMS: 10.08, THD: 2.074, Reward: -1988.85, Step time: 0.782s\n",
            "[Step 44] VRMS: 28.22, THD: 0.355, Reward: -16.04, Step time: 0.755s\n",
            "[Step 45] VRMS: 15.80, THD: 0.748, Reward: -1009.34, Step time: 0.800s\n",
            "[Step 46] VRMS: 34.76, THD: 0.243, Reward: -113.41, Step time: 0.847s\n",
            "[Step 47] VRMS: 28.36, THD: 0.349, Reward: -13.60, Step time: 1.126s\n",
            "[Step 48] VRMS: 9.64, THD: 3.281, Reward: -2084.18, Step time: 1.149s\n",
            "[Step 49] VRMS: 16.94, THD: 0.617, Reward: -853.67, Step time: 0.878s\n",
            "[Step 50] VRMS: 27.26, THD: 0.341, Reward: -37.61, Step time: 0.761s\n",
            "[Step 51] VRMS: 34.92, THD: 0.230, Reward: -120.86, Step time: 0.747s\n",
            "[Step 52] VRMS: 34.87, THD: 0.229, Reward: -118.75, Step time: 0.756s\n",
            "[Step 53] VRMS: 19.12, THD: 0.531, Reward: -592.11, Step time: 0.759s\n",
            "[Step 54] VRMS: 10.02, THD: 10.956, Reward: -2115.86, Step time: 0.784s\n",
            "[Step 55] VRMS: 34.76, THD: 0.242, Reward: -113.55, Step time: 0.744s\n",
            "[Step 56] VRMS: 10.04, THD: 3.286, Reward: -2003.46, Step time: 0.759s\n",
            "[Step 57] VRMS: 34.74, THD: 0.248, Reward: -112.48, Step time: 0.781s\n",
            "[Step 58] VRMS: 10.25, THD: 3.616, Reward: -1963.70, Step time: 0.818s\n",
            "[Step 59] VRMS: 9.60, THD: 2.990, Reward: -2090.02, Step time: 0.763s\n",
            "[Step 60] VRMS: 31.57, THD: 0.298, Reward: -12.44, Step time: 0.773s\n",
            "[Step 61] VRMS: 10.09, THD: 3.308, Reward: -1993.39, Step time: 0.775s\n",
            "[Step 62] VRMS: 30.46, THD: 0.318, Reward: -1.18, Step time: 1.097s\n",
            "[Step 63] VRMS: 10.10, THD: 3.207, Reward: -1989.48, Step time: 1.143s\n",
            "[Step 64] VRMS: 34.90, THD: 0.265, Reward: -119.97, Step time: 1.085s\n",
            "[Step 65] VRMS: 10.85, THD: 10.828, Reward: -1951.54, Step time: 0.779s\n",
            "[Step 66] VRMS: 33.23, THD: 0.293, Reward: -52.28, Step time: 0.750s\n",
            "[Step 67] VRMS: 28.70, THD: 0.406, Reward: -8.65, Step time: 0.830s\n",
            "[Step 68] VRMS: 33.61, THD: 0.289, Reward: -65.41, Step time: 0.798s\n",
            "[Step 69] VRMS: 32.68, THD: 0.311, Reward: -35.95, Step time: 0.775s\n",
            "[Step 70] VRMS: 34.22, THD: 0.279, Reward: -89.29, Step time: 0.749s\n",
            "[Step 71] VRMS: 17.74, THD: 0.975, Reward: -752.43, Step time: 0.786s\n",
            "[Step 72] VRMS: 22.35, THD: 0.482, Reward: -292.51, Step time: 0.793s\n",
            "[Step 73] VRMS: 10.56, THD: 3.418, Reward: -1901.52, Step time: 0.798s\n",
            "[Step 74] VRMS: 19.28, THD: 0.628, Reward: -574.60, Step time: 0.791s\n",
            "[Step 75] VRMS: 10.00, THD: 3.219, Reward: -2010.76, Step time: 0.763s\n",
            "[Step 76] VRMS: 17.67, THD: 0.748, Reward: -760.25, Step time: 0.825s\n",
            "[Step 77] VRMS: 19.35, THD: 0.577, Reward: -567.08, Step time: 1.093s\n",
            "[Step 78] VRMS: 29.99, THD: 0.342, Reward: -0.12, Step time: 1.129s\n",
            "[Step 79] VRMS: 19.82, THD: 0.583, Reward: -518.48, Step time: 1.035s\n",
            "[Step 80] VRMS: 18.93, THD: 0.581, Reward: -613.22, Step time: 0.828s\n",
            "[Step 81] VRMS: 31.80, THD: 0.301, Reward: -16.38, Step time: 0.892s\n",
            "[Step 82] VRMS: 31.66, THD: 0.303, Reward: -13.85, Step time: 0.800s\n",
            "[Step 83] VRMS: 31.26, THD: 0.307, Reward: -8.01, Step time: 0.792s\n",
            "[Step 84] VRMS: 31.78, THD: 0.291, Reward: -16.01, Step time: 0.787s\n",
            "[Step 85] VRMS: 32.02, THD: 0.291, Reward: -20.40, Step time: 0.831s\n",
            "[Step 86] VRMS: 30.36, THD: 0.310, Reward: -0.73, Step time: 0.777s\n",
            "[Step 87] VRMS: 32.07, THD: 0.288, Reward: -21.51, Step time: 0.783s\n",
            "[Step 88] VRMS: 19.22, THD: 0.530, Reward: -581.74, Step time: 0.803s\n",
            "[Step 89] VRMS: 10.93, THD: 1.933, Reward: -1821.38, Step time: 0.804s\n",
            "[Step 90] VRMS: 9.61, THD: 3.950, Reward: -2094.57, Step time: 0.779s\n",
            "[Step 91] VRMS: 18.42, THD: 0.536, Reward: -670.87, Step time: 0.794s\n",
            "[Step 92] VRMS: 18.24, THD: 0.583, Reward: -691.36, Step time: 1.146s\n",
            "[Step 93] VRMS: 34.64, THD: 0.239, Reward: -107.59, Step time: 1.165s\n",
            "[Step 94] VRMS: 16.25, THD: 0.668, Reward: -945.71, Step time: 0.947s\n",
            "[Step 95] VRMS: 18.69, THD: 0.494, Reward: -639.73, Step time: 0.795s\n",
            "[Step 96] VRMS: 10.26, THD: 21.660, Reward: -2417.62, Step time: 0.854s\n",
            "[Step 97] VRMS: 35.21, THD: 0.213, Reward: -135.74, Step time: 0.820s\n",
            "[Step 98] VRMS: 13.59, THD: 0.721, Reward: -1347.38, Step time: 0.768s\n",
            "[Step 99] VRMS: 9.60, THD: 3.209, Reward: -2090.69, Step time: 0.757s\n",
            "[Step 100] VRMS: 27.67, THD: 0.293, Reward: -27.17, Step time: 0.807s\n",
            "[Step 1] VRMS: 18.19, THD: 0.739, Reward: -697.84, Step time: 0.802s\n",
            "[Step 2] VRMS: 9.58, THD: 3.845, Reward: -2099.82, Step time: 0.788s\n",
            "[Step 3] VRMS: 33.29, THD: 0.296, Reward: -54.30, Step time: 0.767s\n",
            "[Step 4] VRMS: 17.46, THD: 0.847, Reward: -787.14, Step time: 0.772s\n",
            "[Step 5] VRMS: 17.16, THD: 0.899, Reward: -825.21, Step time: 0.780s\n",
            "[Step 6] VRMS: 31.91, THD: 0.309, Reward: -18.38, Step time: 0.828s\n",
            "[Step 7] VRMS: 9.60, THD: 3.214, Reward: -2091.10, Step time: 1.188s\n",
            "[Step 8] VRMS: 26.02, THD: 0.459, Reward: -79.54, Step time: 1.134s\n",
            "[Step 9] VRMS: 33.32, THD: 0.298, Reward: -55.11, Step time: 0.944s\n",
            "[Step 10] VRMS: 30.77, THD: 0.323, Reward: -3.08, Step time: 0.772s\n",
            "[Step 11] VRMS: 33.44, THD: 0.290, Reward: -59.39, Step time: 0.801s\n",
            "[Step 12] VRMS: 19.36, THD: 0.601, Reward: -566.25, Step time: 0.758s\n",
            "[Step 13] VRMS: 18.61, THD: 0.676, Reward: -648.84, Step time: 0.765s\n",
            "[Step 14] VRMS: 18.60, THD: 0.682, Reward: -650.09, Step time: 0.765s\n",
            "[Step 15] VRMS: 19.68, THD: 0.561, Reward: -532.46, Step time: 0.787s\n",
            "[Step 16] VRMS: 25.44, THD: 0.480, Reward: -104.23, Step time: 0.779s\n",
            "[Step 17] VRMS: 32.68, THD: 0.302, Reward: -36.10, Step time: 0.803s\n",
            "[Step 18] VRMS: 26.29, THD: 0.453, Reward: -69.12, Step time: 0.767s\n",
            "[Step 19] VRMS: 19.49, THD: 0.586, Reward: -553.04, Step time: 0.880s\n",
            "[Step 20] VRMS: 17.44, THD: 0.854, Reward: -789.02, Step time: 0.930s\n",
            "[Step 21] VRMS: 30.15, THD: 0.346, Reward: -0.23, Step time: 1.184s\n",
            "[Step 22] VRMS: 33.43, THD: 0.286, Reward: -59.00, Step time: 2.746s\n",
            "[Step 23] VRMS: 33.39, THD: 0.288, Reward: -57.66, Step time: 1.546s\n",
            "[Step 24] VRMS: 33.21, THD: 0.293, Reward: -51.47, Step time: 1.806s\n",
            "[Step 25] VRMS: 9.81, THD: 5.006, Reward: -2062.99, Step time: 0.771s\n",
            "[Step 26] VRMS: 12.88, THD: 1.801, Reward: -1467.87, Step time: 0.796s\n",
            "[Step 27] VRMS: 30.42, THD: 0.336, Reward: -1.00, Step time: 0.777s\n",
            "[Step 28] VRMS: 19.34, THD: 0.589, Reward: -568.39, Step time: 0.814s\n",
            "[Step 29] VRMS: 17.93, THD: 0.762, Reward: -729.10, Step time: 0.798s\n",
            "[Step 30] VRMS: 33.90, THD: 0.276, Reward: -76.10, Step time: 0.836s\n",
            "[Step 31] VRMS: 34.06, THD: 0.275, Reward: -82.49, Step time: 0.818s\n",
            "[Step 32] VRMS: 34.08, THD: 0.274, Reward: -83.21, Step time: 0.781s\n",
            "[Step 33] VRMS: 34.26, THD: 0.273, Reward: -90.72, Step time: 0.776s\n",
            "[Step 34] VRMS: 18.67, THD: 0.651, Reward: -642.26, Step time: 1.111s\n",
            "[Step 35] VRMS: 34.35, THD: 0.267, Reward: -94.50, Step time: 1.103s\n",
            "[Step 36] VRMS: 31.83, THD: 0.302, Reward: -16.87, Step time: 1.158s\n",
            "[Step 37] VRMS: 9.86, THD: 3.442, Reward: -2040.26, Step time: 0.768s\n",
            "[Step 38] VRMS: 16.54, THD: 0.777, Reward: -907.09, Step time: 0.772s\n",
            "[Step 39] VRMS: 26.27, THD: 0.409, Reward: -69.67, Step time: 0.823s\n",
            "[Step 40] VRMS: 9.58, THD: 3.324, Reward: -2096.55, Step time: 0.785s\n",
            "[Step 41] VRMS: 17.70, THD: 0.632, Reward: -757.19, Step time: 0.748s\n",
            "[Step 42] VRMS: 9.80, THD: 1.319, Reward: -2041.27, Step time: 0.788s\n",
            "[Step 43] VRMS: 9.58, THD: 3.175, Reward: -2094.83, Step time: 0.766s\n",
            "[Step 44] VRMS: 34.51, THD: 0.246, Reward: -101.94, Step time: 0.779s\n",
            "[Step 45] VRMS: 9.91, THD: 1.300, Reward: -2018.87, Step time: 0.800s\n",
            "[Step 46] VRMS: 24.80, THD: 0.374, Reward: -135.38, Step time: 0.781s\n",
            "[Step 47] VRMS: 31.78, THD: 0.284, Reward: -15.91, Step time: 0.762s\n",
            "[Step 48] VRMS: 17.68, THD: 0.589, Reward: -759.21, Step time: 0.803s\n",
            "[Step 49] VRMS: 21.20, THD: 0.396, Reward: -387.10, Step time: 0.993s\n",
            "[Step 50] VRMS: 18.19, THD: 0.564, Reward: -697.48, Step time: 1.086s\n",
            "[Step 51] VRMS: 29.51, THD: 0.296, Reward: -1.31, Step time: 1.189s\n",
            "[Step 52] VRMS: 21.80, THD: 0.365, Reward: -336.64, Step time: 0.783s\n",
            "[Step 53] VRMS: 17.90, THD: 0.590, Reward: -732.09, Step time: 0.781s\n",
            "[Step 54] VRMS: 29.45, THD: 0.304, Reward: -1.58, Step time: 0.777s\n",
            "[Step 55] VRMS: 27.70, THD: 0.342, Reward: -26.47, Step time: 0.764s\n",
            "[Step 56] VRMS: 9.64, THD: 3.196, Reward: -2083.37, Step time: 0.764s\n",
            "[Step 57] VRMS: 30.09, THD: 0.301, Reward: -0.13, Step time: 0.769s\n",
            "[Step 58] VRMS: 19.00, THD: 0.535, Reward: -605.72, Step time: 0.773s\n",
            "[Step 59] VRMS: 29.83, THD: 0.311, Reward: -0.23, Step time: 0.787s\n",
            "[Step 60] VRMS: 34.30, THD: 0.257, Reward: -92.61, Step time: 0.764s\n",
            "[Step 61] VRMS: 9.99, THD: 5.041, Reward: -2026.51, Step time: 0.781s\n",
            "[Step 62] VRMS: 20.24, THD: 0.486, Reward: -476.16, Step time: 0.779s\n",
            "[Step 63] VRMS: 21.41, THD: 0.429, Reward: -369.32, Step time: 0.770s\n",
            "[Step 64] VRMS: 30.24, THD: 0.319, Reward: -0.39, Step time: 0.842s\n",
            "[Step 65] VRMS: 34.35, THD: 0.263, Reward: -94.88, Step time: 1.095s\n",
            "[Step 66] VRMS: 10.17, THD: 5.810, Reward: -2000.54, Step time: 1.214s\n",
            "[Step 67] VRMS: 28.93, THD: 0.365, Reward: -5.91, Step time: 0.820s\n",
            "[Step 68] VRMS: 18.16, THD: 0.739, Reward: -702.02, Step time: 0.782s\n",
            "[Step 69] VRMS: 10.86, THD: 1.737, Reward: -1834.26, Step time: 0.770s\n",
            "[Step 70] VRMS: 33.44, THD: 0.275, Reward: -59.27, Step time: 0.758s\n",
            "[Step 71] VRMS: 33.38, THD: 0.287, Reward: -57.14, Step time: 0.746s\n",
            "[Step 72] VRMS: 29.23, THD: 0.377, Reward: -3.09, Step time: 0.781s\n",
            "[Step 73] VRMS: 29.39, THD: 0.367, Reward: -2.02, Step time: 0.765s\n",
            "[Step 74] VRMS: 19.92, THD: 0.556, Reward: -508.54, Step time: 0.757s\n",
            "[Step 75] VRMS: 9.77, THD: 4.458, Reward: -2066.04, Step time: 0.760s\n",
            "[Step 76] VRMS: 9.58, THD: 3.001, Reward: -2093.53, Step time: 0.825s\n",
            "[Step 77] VRMS: 31.70, THD: 0.296, Reward: -14.48, Step time: 0.806s\n",
            "[Step 78] VRMS: 18.95, THD: 0.593, Reward: -610.66, Step time: 0.786s\n",
            "[Step 79] VRMS: 32.49, THD: 0.291, Reward: -31.16, Step time: 0.777s\n",
            "[Step 80] VRMS: 34.41, THD: 0.267, Reward: -97.16, Step time: 1.178s\n",
            "[Step 81] VRMS: 26.74, THD: 0.403, Reward: -53.43, Step time: 1.238s\n",
            "[Step 82] VRMS: 9.79, THD: 3.403, Reward: -2054.43, Step time: 0.925s\n",
            "[Step 83] VRMS: 17.16, THD: 0.679, Reward: -824.41, Step time: 0.839s\n",
            "[Step 84] VRMS: 15.47, THD: 0.806, Reward: -1055.82, Step time: 0.851s\n",
            "[Step 85] VRMS: 17.94, THD: 0.609, Reward: -728.01, Step time: 0.808s\n",
            "[Step 86] VRMS: 34.59, THD: 0.242, Reward: -105.53, Step time: 0.765s\n",
            "[Step 87] VRMS: 34.58, THD: 0.244, Reward: -104.81, Step time: 0.760s\n",
            "[Step 88] VRMS: 10.20, THD: 4.084, Reward: -1975.98, Step time: 0.837s\n",
            "[Step 89] VRMS: 34.73, THD: 0.230, Reward: -111.98, Step time: 0.793s\n",
            "[Step 90] VRMS: 34.55, THD: 0.235, Reward: -103.44, Step time: 0.781s\n",
            "[Step 91] VRMS: 10.21, THD: 3.901, Reward: -1972.95, Step time: 0.790s\n",
            "[Step 92] VRMS: 34.67, THD: 0.222, Reward: -109.20, Step time: 0.802s\n",
            "[Step 93] VRMS: 21.55, THD: 0.390, Reward: -357.39, Step time: 0.806s\n",
            "[Step 94] VRMS: 9.62, THD: 3.325, Reward: -2087.94, Step time: 0.852s\n",
            "[Step 95] VRMS: 18.30, THD: 0.509, Reward: -684.94, Step time: 1.151s\n",
            "[Step 96] VRMS: 17.83, THD: 0.517, Reward: -740.63, Step time: 1.174s\n",
            "[Step 97] VRMS: 22.75, THD: 0.307, Reward: -263.22, Step time: 0.836s\n",
            "[Step 98] VRMS: 34.70, THD: 0.206, Reward: -110.67, Step time: 0.773s\n",
            "[Step 99] VRMS: 30.02, THD: 0.277, Reward: -0.08, Step time: 0.787s\n",
            "[Step 100] VRMS: 10.32, THD: 0.645, Reward: -1937.47, Step time: 0.806s\n",
            "[Step 1] VRMS: 33.42, THD: 0.298, Reward: -58.74, Step time: 0.768s\n",
            "[Step 2] VRMS: 19.68, THD: 0.585, Reward: -532.71, Step time: 0.776s\n",
            "[Step 3] VRMS: 27.19, THD: 0.438, Reward: -39.60, Step time: 0.799s\n",
            "[Step 4] VRMS: 31.02, THD: 0.329, Reward: -5.36, Step time: 0.800s\n",
            "[Step 5] VRMS: 30.81, THD: 0.329, Reward: -3.36, Step time: 0.803s\n",
            "[Step 6] VRMS: 32.55, THD: 0.306, Reward: -32.48, Step time: 0.772s\n",
            "[Step 7] VRMS: 19.94, THD: 0.543, Reward: -506.27, Step time: 0.776s\n",
            "[Step 8] VRMS: 19.35, THD: 0.633, Reward: -567.60, Step time: 0.768s\n",
            "[Step 9] VRMS: 9.59, THD: 3.342, Reward: -2094.41, Step time: 0.881s\n",
            "[Step 10] VRMS: 9.59, THD: 3.002, Reward: -2092.16, Step time: 1.165s\n",
            "[Step 11] VRMS: 17.62, THD: 0.863, Reward: -767.11, Step time: 1.216s\n",
            "[Step 12] VRMS: 32.66, THD: 0.304, Reward: -35.60, Step time: 0.839s\n",
            "[Step 13] VRMS: 9.67, THD: 3.201, Reward: -2076.81, Step time: 0.777s\n",
            "[Step 14] VRMS: 9.59, THD: 3.003, Reward: -2092.19, Step time: 0.759s\n",
            "[Step 15] VRMS: 29.64, THD: 0.374, Reward: -0.79, Step time: 0.773s\n",
            "[Step 16] VRMS: 30.33, THD: 0.345, Reward: -0.67, Step time: 0.815s\n",
            "[Step 17] VRMS: 17.07, THD: 0.948, Reward: -836.96, Step time: 0.766s\n",
            "[Step 18] VRMS: 9.60, THD: 3.202, Reward: -2090.70, Step time: 0.769s\n",
            "[Step 19] VRMS: 9.59, THD: 3.003, Reward: -2092.19, Step time: 0.797s\n",
            "[Step 20] VRMS: 9.59, THD: 3.002, Reward: -2092.16, Step time: 0.815s\n",
            "[Step 21] VRMS: 9.59, THD: 3.000, Reward: -2092.15, Step time: 0.804s\n",
            "[Step 22] VRMS: 9.59, THD: 3.005, Reward: -2092.20, Step time: 0.761s\n",
            "[Step 23] VRMS: 33.13, THD: 0.298, Reward: -48.97, Step time: 0.773s\n",
            "[Step 24] VRMS: 9.89, THD: 16.258, Reward: -2286.14, Step time: 0.874s\n",
            "[Step 25] VRMS: 9.59, THD: 3.002, Reward: -2092.16, Step time: 1.124s\n",
            "[Step 26] VRMS: 9.38, THD: 2.554, Reward: -2132.76, Step time: 1.178s\n",
            "[Step 27] VRMS: 19.99, THD: 0.540, Reward: -501.30, Step time: 0.900s\n",
            "[Step 28] VRMS: 32.81, THD: 0.302, Reward: -39.50, Step time: 0.783s\n",
            "[Step 29] VRMS: 32.59, THD: 0.301, Reward: -33.71, Step time: 0.777s\n",
            "[Step 30] VRMS: 9.99, THD: 4.109, Reward: -2019.84, Step time: 0.774s\n",
            "[Step 31] VRMS: 9.59, THD: 3.000, Reward: -2092.15, Step time: 0.793s\n",
            "[Step 32] VRMS: 34.16, THD: 0.275, Reward: -86.53, Step time: 0.799s\n",
            "[Step 33] VRMS: 10.09, THD: 3.337, Reward: -1992.72, Step time: 0.790s\n",
            "[Step 34] VRMS: 18.27, THD: 0.643, Reward: -687.84, Step time: 0.790s\n",
            "[Step 35] VRMS: 9.58, THD: 3.226, Reward: -2096.11, Step time: 0.782s\n",
            "[Step 36] VRMS: 30.08, THD: 0.328, Reward: -0.14, Step time: 0.764s\n",
            "[Step 37] VRMS: 29.49, THD: 0.342, Reward: -1.42, Step time: 0.777s\n",
            "[Step 38] VRMS: 34.50, THD: 0.261, Reward: -101.16, Step time: 0.758s\n",
            "[Step 39] VRMS: 29.26, THD: 0.351, Reward: -2.84, Step time: 0.862s\n",
            "[Step 40] VRMS: 27.64, THD: 0.376, Reward: -27.91, Step time: 1.361s\n",
            "[Step 41] VRMS: 9.60, THD: 4.519, Reward: -2100.66, Step time: 1.374s\n",
            "[Step 42] VRMS: 29.12, THD: 0.328, Reward: -4.00, Step time: 1.534s\n",
            "[Step 43] VRMS: 34.45, THD: 0.253, Reward: -99.26, Step time: 0.987s\n",
            "[Step 44] VRMS: 34.69, THD: 0.247, Reward: -109.94, Step time: 0.826s\n",
            "[Step 45] VRMS: 30.73, THD: 0.298, Reward: -2.74, Step time: 0.781s\n",
            "[Step 46] VRMS: 34.42, THD: 0.246, Reward: -97.80, Step time: 0.775s\n",
            "[Step 47] VRMS: 19.02, THD: 0.526, Reward: -603.21, Step time: 0.781s\n",
            "[Step 48] VRMS: 31.56, THD: 0.284, Reward: -12.18, Step time: 0.751s\n",
            "[Step 49] VRMS: 28.71, THD: 0.329, Reward: -8.45, Step time: 0.752s\n",
            "[Step 50] VRMS: 10.01, THD: 0.794, Reward: -1999.28, Step time: 0.773s\n",
            "[Step 51] VRMS: 34.68, THD: 0.228, Reward: -109.58, Step time: 0.763s\n",
            "[Step 52] VRMS: 31.67, THD: 0.283, Reward: -14.02, Step time: 0.802s\n",
            "[Step 53] VRMS: 9.67, THD: 3.705, Reward: -2080.36, Step time: 0.773s\n",
            "[Step 54] VRMS: 34.58, THD: 0.239, Reward: -105.00, Step time: 0.808s\n",
            "[Step 55] VRMS: 10.23, THD: 1.079, Reward: -1956.07, Step time: 0.953s\n",
            "[Step 56] VRMS: 9.61, THD: 1.255, Reward: -2080.60, Step time: 1.138s\n",
            "[Step 57] VRMS: 9.59, THD: 3.618, Reward: -2096.00, Step time: 1.194s\n",
            "[Step 58] VRMS: 9.90, THD: 0.965, Reward: -2020.69, Step time: 0.797s\n",
            "[Step 59] VRMS: 26.33, THD: 0.390, Reward: -67.52, Step time: 0.757s\n",
            "[Step 60] VRMS: 18.20, THD: 0.620, Reward: -697.01, Step time: 0.769s\n",
            "[Step 61] VRMS: 34.51, THD: 0.259, Reward: -101.74, Step time: 0.782s\n",
            "[Step 62] VRMS: 34.67, THD: 0.262, Reward: -109.26, Step time: 0.767s\n",
            "[Step 63] VRMS: 18.40, THD: 0.628, Reward: -673.47, Step time: 0.786s\n",
            "[Step 64] VRMS: 17.24, THD: 0.715, Reward: -813.99, Step time: 0.788s\n",
            "[Step 65] VRMS: 9.61, THD: 3.330, Reward: -2090.18, Step time: 0.771s\n",
            "[Step 66] VRMS: 34.18, THD: 0.267, Reward: -87.40, Step time: 0.768s\n",
            "[Step 67] VRMS: 10.35, THD: 5.654, Reward: -1962.20, Step time: 0.768s\n",
            "[Step 68] VRMS: 20.85, THD: 0.483, Reward: -418.81, Step time: 0.756s\n",
            "[Step 69] VRMS: 29.71, THD: 0.351, Reward: -0.55, Step time: 0.748s\n",
            "[Step 70] VRMS: 17.42, THD: 0.900, Reward: -791.58, Step time: 0.831s\n",
            "[Step 71] VRMS: 33.36, THD: 0.282, Reward: -56.64, Step time: 1.115s\n",
            "[Step 72] VRMS: 18.46, THD: 0.784, Reward: -666.77, Step time: 1.163s\n",
            "[Step 73] VRMS: 17.28, THD: 0.858, Reward: -810.12, Step time: 0.881s\n",
            "[Step 74] VRMS: 9.61, THD: 3.391, Reward: -2090.63, Step time: 0.757s\n",
            "[Step 75] VRMS: 33.17, THD: 0.287, Reward: -50.31, Step time: 0.764s\n",
            "[Step 76] VRMS: 32.37, THD: 0.300, Reward: -28.19, Step time: 0.783s\n",
            "[Step 77] VRMS: 19.10, THD: 0.616, Reward: -594.47, Step time: 0.787s\n",
            "[Step 78] VRMS: 31.85, THD: 0.297, Reward: -17.24, Step time: 0.779s\n",
            "[Step 79] VRMS: 18.97, THD: 0.602, Reward: -609.08, Step time: 0.746s\n",
            "[Step 80] VRMS: 9.57, THD: 3.204, Reward: -2096.72, Step time: 0.763s\n",
            "[Step 81] VRMS: 18.91, THD: 0.557, Reward: -615.66, Step time: 0.802s\n",
            "[Step 82] VRMS: 18.16, THD: 0.605, Reward: -701.83, Step time: 0.777s\n",
            "[Step 83] VRMS: 17.89, THD: 0.638, Reward: -733.52, Step time: 0.762s\n",
            "[Step 84] VRMS: 26.23, THD: 0.382, Reward: -71.18, Step time: 0.759s\n",
            "[Step 85] VRMS: 28.05, THD: 0.357, Reward: -19.21, Step time: 0.763s\n",
            "[Step 86] VRMS: 34.47, THD: 0.243, Reward: -99.93, Step time: 1.097s\n",
            "[Step 87] VRMS: 21.01, THD: 0.454, Reward: -404.26, Step time: 1.100s\n",
            "[Step 88] VRMS: 34.81, THD: 0.237, Reward: -115.55, Step time: 1.018s\n",
            "[Step 89] VRMS: 19.96, THD: 0.465, Reward: -503.79, Step time: 0.797s\n",
            "[Step 90] VRMS: 13.45, THD: 0.798, Reward: -1370.68, Step time: 0.746s\n",
            "[Step 91] VRMS: 18.78, THD: 0.527, Reward: -629.17, Step time: 0.759s\n",
            "[Step 92] VRMS: 15.92, THD: 0.670, Reward: -991.75, Step time: 0.779s\n",
            "[Step 93] VRMS: 34.78, THD: 0.222, Reward: -114.53, Step time: 0.781s\n",
            "[Step 94] VRMS: 10.39, THD: 4.003, Reward: -1937.85, Step time: 0.758s\n",
            "[Step 95] VRMS: 34.91, THD: 0.214, Reward: -120.52, Step time: 0.769s\n",
            "[Step 96] VRMS: 34.80, THD: 0.216, Reward: -115.20, Step time: 0.785s\n",
            "[Step 97] VRMS: 19.86, THD: 0.452, Reward: -514.00, Step time: 0.789s\n",
            "[Step 98] VRMS: 9.93, THD: 3.778, Reward: -2029.14, Step time: 0.756s\n",
            "[Step 99] VRMS: 9.72, THD: 0.786, Reward: -2057.94, Step time: 0.778s\n",
            "[Step 100] VRMS: 9.61, THD: 4.048, Reward: -2095.38, Step time: 0.764s\n",
            "[Step 1] VRMS: 25.32, THD: 0.482, Reward: -109.84, Step time: 0.983s\n",
            "[Step 2] VRMS: 32.15, THD: 0.312, Reward: -23.18, Step time: 1.073s\n",
            "[Step 3] VRMS: 19.12, THD: 0.639, Reward: -591.86, Step time: 1.123s\n",
            "[Step 4] VRMS: 9.61, THD: 3.585, Reward: -2090.78, Step time: 0.735s\n",
            "[Step 5] VRMS: 32.45, THD: 0.304, Reward: -30.02, Step time: 0.768s\n",
            "[Step 6] VRMS: 19.22, THD: 0.629, Reward: -581.03, Step time: 0.778s\n",
            "[Step 7] VRMS: 33.46, THD: 0.296, Reward: -59.95, Step time: 0.768s\n",
            "[Step 8] VRMS: 24.30, THD: 0.497, Reward: -162.76, Step time: 0.733s\n",
            "[Step 9] VRMS: 20.19, THD: 0.531, Reward: -481.61, Step time: 0.777s\n",
            "[Step 10] VRMS: 9.73, THD: 3.200, Reward: -2065.26, Step time: 0.772s\n",
            "[Step 11] VRMS: 9.59, THD: 3.001, Reward: -2092.30, Step time: 0.766s\n",
            "[Step 12] VRMS: 33.17, THD: 0.301, Reward: -50.34, Step time: 0.758s\n",
            "[Step 13] VRMS: 9.68, THD: 3.253, Reward: -2074.35, Step time: 0.771s\n",
            "[Step 14] VRMS: 20.10, THD: 0.524, Reward: -490.69, Step time: 0.783s\n",
            "[Step 15] VRMS: 32.32, THD: 0.310, Reward: -27.01, Step time: 0.772s\n",
            "[Step 16] VRMS: 29.23, THD: 0.384, Reward: -3.10, Step time: 0.832s\n",
            "[Step 17] VRMS: 33.54, THD: 0.293, Reward: -62.82, Step time: 1.150s\n",
            "[Step 18] VRMS: 32.05, THD: 0.310, Reward: -21.09, Step time: 1.143s\n",
            "[Step 19] VRMS: 32.00, THD: 0.307, Reward: -20.09, Step time: 0.881s\n",
            "[Step 20] VRMS: 9.66, THD: 3.212, Reward: -2077.91, Step time: 0.769s\n",
            "[Step 21] VRMS: 19.55, THD: 0.596, Reward: -546.31, Step time: 0.763s\n",
            "[Step 22] VRMS: 33.63, THD: 0.288, Reward: -65.98, Step time: 0.778s\n",
            "[Step 23] VRMS: 17.48, THD: 0.891, Reward: -784.66, Step time: 0.763s\n",
            "[Step 24] VRMS: 15.38, THD: 1.292, Reward: -1070.70, Step time: 0.768s\n",
            "[Step 25] VRMS: 32.54, THD: 0.302, Reward: -32.25, Step time: 0.773s\n",
            "[Step 26] VRMS: 18.98, THD: 0.672, Reward: -607.70, Step time: 0.770s\n",
            "[Step 27] VRMS: 33.37, THD: 0.293, Reward: -56.89, Step time: 0.769s\n",
            "[Step 28] VRMS: 31.71, THD: 0.317, Reward: -14.81, Step time: 0.769s\n",
            "[Step 29] VRMS: 34.01, THD: 0.279, Reward: -80.46, Step time: 0.766s\n",
            "[Step 30] VRMS: 10.09, THD: 3.361, Reward: -1993.68, Step time: 0.765s\n",
            "[Step 31] VRMS: 34.13, THD: 0.275, Reward: -85.29, Step time: 0.793s\n",
            "[Step 32] VRMS: 34.26, THD: 0.275, Reward: -90.69, Step time: 1.061s\n",
            "[Step 33] VRMS: 10.07, THD: 3.333, Reward: -1996.33, Step time: 1.110s\n",
            "[Step 34] VRMS: 34.51, THD: 0.271, Reward: -101.70, Step time: 1.044s\n",
            "[Step 35] VRMS: 31.62, THD: 0.308, Reward: -13.27, Step time: 0.771s\n",
            "[Step 36] VRMS: 19.00, THD: 0.586, Reward: -605.61, Step time: 0.773s\n",
            "[Step 37] VRMS: 34.45, THD: 0.265, Reward: -98.92, Step time: 0.768s\n",
            "[Step 38] VRMS: 24.53, THD: 0.451, Reward: -149.60, Step time: 0.786s\n",
            "[Step 39] VRMS: 9.59, THD: 3.202, Reward: -2092.99, Step time: 0.766s\n",
            "[Step 40] VRMS: 9.59, THD: 3.001, Reward: -2092.31, Step time: 0.761s\n",
            "[Step 41] VRMS: 17.83, THD: 0.625, Reward: -740.78, Step time: 0.763s\n",
            "[Step 42] VRMS: 24.73, THD: 0.395, Reward: -138.89, Step time: 0.770s\n",
            "[Step 43] VRMS: 9.60, THD: 19.765, Reward: -2471.85, Step time: 0.775s\n",
            "[Step 44] VRMS: 17.60, THD: 0.636, Reward: -768.59, Step time: 0.778s\n",
            "[Step 45] VRMS: 27.75, THD: 0.359, Reward: -25.38, Step time: 0.738s\n",
            "[Step 46] VRMS: 9.63, THD: 5.364, Reward: -2104.30, Step time: 0.764s\n",
            "[Step 47] VRMS: 30.16, THD: 0.298, Reward: -0.21, Step time: 0.941s\n",
            "[Step 48] VRMS: 9.98, THD: 1.015, Reward: -2004.88, Step time: 1.082s\n",
            "[Step 49] VRMS: 31.74, THD: 0.283, Reward: -15.14, Step time: 1.212s\n",
            "[Step 50] VRMS: 9.67, THD: 3.360, Reward: -2077.01, Step time: 0.843s\n",
            "[Step 51] VRMS: 9.83, THD: 1.283, Reward: -2036.78, Step time: 0.847s\n",
            "[Step 52] VRMS: 18.75, THD: 0.512, Reward: -632.71, Step time: 0.804s\n",
            "[Step 53] VRMS: 34.73, THD: 0.232, Reward: -112.07, Step time: 0.857s\n",
            "[Step 54] VRMS: 9.65, THD: 2.313, Reward: -2075.78, Step time: 0.847s\n",
            "[Step 55] VRMS: 34.56, THD: 0.241, Reward: -104.01, Step time: 0.832s\n",
            "[Step 56] VRMS: 21.09, THD: 0.433, Reward: -397.33, Step time: 0.776s\n",
            "[Step 57] VRMS: 9.63, THD: 3.284, Reward: -2084.66, Step time: 0.796s\n",
            "[Step 58] VRMS: 31.63, THD: 0.293, Reward: -13.43, Step time: 0.806s\n",
            "[Step 59] VRMS: 9.87, THD: 3.299, Reward: -2036.91, Step time: 0.902s\n",
            "[Step 60] VRMS: 9.59, THD: 3.001, Reward: -2092.31, Step time: 0.947s\n",
            "[Step 61] VRMS: 31.25, THD: 0.299, Reward: -7.93, Step time: 1.089s\n",
            "[Step 62] VRMS: 26.81, THD: 0.406, Reward: -50.91, Step time: 1.210s\n",
            "[Step 63] VRMS: 9.86, THD: 3.237, Reward: -2038.31, Step time: 1.242s\n",
            "[Step 64] VRMS: 30.08, THD: 0.325, Reward: -0.14, Step time: 0.818s\n",
            "[Step 65] VRMS: 19.77, THD: 0.589, Reward: -523.23, Step time: 0.826s\n",
            "[Step 66] VRMS: 19.62, THD: 0.550, Reward: -538.89, Step time: 0.850s\n",
            "[Step 67] VRMS: 18.82, THD: 0.613, Reward: -624.96, Step time: 0.784s\n",
            "[Step 68] VRMS: 33.97, THD: 0.270, Reward: -78.95, Step time: 0.802s\n",
            "[Step 69] VRMS: 29.78, THD: 0.358, Reward: -0.37, Step time: 0.791s\n",
            "[Step 70] VRMS: 16.33, THD: 1.034, Reward: -935.68, Step time: 0.790s\n",
            "[Step 71] VRMS: 25.79, THD: 0.463, Reward: -88.78, Step time: 0.869s\n",
            "[Step 72] VRMS: 33.49, THD: 0.276, Reward: -61.09, Step time: 0.818s\n",
            "[Step 73] VRMS: 10.57, THD: 2.284, Reward: -1892.62, Step time: 0.797s\n",
            "[Step 74] VRMS: 33.63, THD: 0.273, Reward: -65.85, Step time: 0.794s\n",
            "[Step 75] VRMS: 10.33, THD: 4.911, Reward: -1958.74, Step time: 0.814s\n",
            "[Step 76] VRMS: 19.07, THD: 0.614, Reward: -598.24, Step time: 1.081s\n",
            "[Step 77] VRMS: 32.43, THD: 0.298, Reward: -29.62, Step time: 1.129s\n",
            "[Step 78] VRMS: 25.96, THD: 0.435, Reward: -81.66, Step time: 1.060s\n",
            "[Step 79] VRMS: 34.46, THD: 0.259, Reward: -99.37, Step time: 0.790s\n",
            "[Step 80] VRMS: 19.62, THD: 0.541, Reward: -538.94, Step time: 0.784s\n",
            "[Step 81] VRMS: 19.03, THD: 0.558, Reward: -602.09, Step time: 0.793s\n",
            "[Step 82] VRMS: 22.00, THD: 0.388, Reward: -320.29, Step time: 0.807s\n",
            "[Step 83] VRMS: 34.55, THD: 0.251, Reward: -103.45, Step time: 0.767s\n",
            "[Step 84] VRMS: 18.22, THD: 0.633, Reward: -694.18, Step time: 0.791s\n",
            "[Step 85] VRMS: 9.59, THD: 3.198, Reward: -2094.01, Step time: 0.800s\n",
            "[Step 86] VRMS: 14.60, THD: 0.820, Reward: -1185.72, Step time: 0.792s\n",
            "[Step 87] VRMS: 15.44, THD: 0.725, Reward: -1060.66, Step time: 0.804s\n",
            "[Step 88] VRMS: 25.74, THD: 0.374, Reward: -91.08, Step time: 0.766s\n",
            "[Step 89] VRMS: 22.28, THD: 0.355, Reward: -298.03, Step time: 0.779s\n",
            "[Step 90] VRMS: 13.93, THD: 0.783, Reward: -1291.57, Step time: 0.770s\n",
            "[Step 91] VRMS: 18.88, THD: 0.519, Reward: -619.01, Step time: 1.051s\n",
            "[Step 92] VRMS: 27.76, THD: 0.332, Reward: -25.29, Step time: 1.103s\n",
            "[Step 93] VRMS: 24.99, THD: 0.338, Reward: -125.82, Step time: 1.047s\n",
            "[Step 94] VRMS: 34.79, THD: 0.216, Reward: -114.76, Step time: 0.765s\n",
            "[Step 95] VRMS: 18.56, THD: 0.510, Reward: -654.81, Step time: 0.778s\n",
            "[Step 96] VRMS: 17.15, THD: 0.555, Reward: -826.55, Step time: 0.764s\n",
            "[Step 97] VRMS: 22.87, THD: 0.312, Reward: -254.54, Step time: 0.761s\n",
            "[Step 98] VRMS: 18.42, THD: 0.489, Reward: -671.12, Step time: 0.746s\n",
            "[Step 99] VRMS: 22.20, THD: 0.324, Reward: -304.07, Step time: 0.778s\n",
            "[Step 100] VRMS: 27.56, THD: 0.292, Reward: -29.85, Step time: 0.779s\n",
            "[Step 1] VRMS: 30.76, THD: 0.341, Reward: -3.02, Step time: 0.756s\n",
            "[Step 2] VRMS: 18.15, THD: 0.847, Reward: -703.10, Step time: 0.782s\n",
            "[Step 3] VRMS: 33.77, THD: 0.299, Reward: -71.18, Step time: 0.796s\n",
            "[Step 4] VRMS: 31.28, THD: 0.322, Reward: -8.27, Step time: 0.775s\n",
            "[Step 5] VRMS: 20.31, THD: 0.542, Reward: -469.85, Step time: 0.759s\n",
            "[Step 6] VRMS: 28.96, THD: 0.411, Reward: -5.55, Step time: 0.979s\n",
            "[Step 7] VRMS: 29.24, THD: 0.403, Reward: -3.01, Step time: 1.111s\n",
            "[Step 8] VRMS: 19.33, THD: 0.662, Reward: -569.22, Step time: 1.149s\n",
            "[Step 9] VRMS: 20.19, THD: 0.556, Reward: -481.89, Step time: 0.763s\n",
            "[Step 10] VRMS: 30.84, THD: 0.345, Reward: -3.66, Step time: 0.775s\n",
            "[Step 11] VRMS: 32.91, THD: 0.305, Reward: -42.57, Step time: 0.782s\n",
            "[Step 12] VRMS: 33.21, THD: 0.299, Reward: -51.57, Step time: 0.818s\n",
            "[Step 13] VRMS: 18.52, THD: 0.777, Reward: -659.59, Step time: 0.775s\n",
            "[Step 14] VRMS: 9.59, THD: 3.256, Reward: -2093.56, Step time: 0.794s\n",
            "[Step 15] VRMS: 30.36, THD: 0.360, Reward: -0.80, Step time: 0.776s\n",
            "[Step 16] VRMS: 9.84, THD: 3.317, Reward: -2043.78, Step time: 0.773s\n",
            "[Step 17] VRMS: 32.50, THD: 0.310, Reward: -31.47, Step time: 0.767s\n",
            "[Step 18] VRMS: 9.83, THD: 3.215, Reward: -2044.90, Step time: 0.768s\n",
            "[Step 19] VRMS: 9.59, THD: 3.005, Reward: -2090.93, Step time: 0.768s\n",
            "[Step 20] VRMS: 9.59, THD: 3.002, Reward: -2090.89, Step time: 0.782s\n",
            "[Step 21] VRMS: 33.40, THD: 0.299, Reward: -57.81, Step time: 0.944s\n",
            "[Step 22] VRMS: 10.01, THD: 4.879, Reward: -2021.89, Step time: 1.081s\n",
            "[Step 23] VRMS: 31.74, THD: 0.320, Reward: -15.24, Step time: 1.200s\n",
            "[Step 24] VRMS: 19.63, THD: 0.623, Reward: -538.05, Step time: 0.789s\n",
            "[Step 25] VRMS: 19.96, THD: 0.555, Reward: -504.45, Step time: 0.773s\n",
            "[Step 26] VRMS: 9.85, THD: 3.240, Reward: -2040.54, Step time: 0.780s\n",
            "[Step 27] VRMS: 9.59, THD: 3.004, Reward: -2090.93, Step time: 0.771s\n",
            "[Step 28] VRMS: 9.59, THD: 3.001, Reward: -2090.93, Step time: 0.760s\n",
            "[Step 29] VRMS: 9.59, THD: 3.005, Reward: -2090.93, Step time: 0.799s\n",
            "[Step 30] VRMS: 30.80, THD: 0.341, Reward: -3.30, Step time: 0.798s\n",
            "[Step 31] VRMS: 9.85, THD: 3.251, Reward: -2040.49, Step time: 0.815s\n",
            "[Step 32] VRMS: 9.59, THD: 3.004, Reward: -2090.93, Step time: 0.775s\n",
            "[Step 33] VRMS: 20.34, THD: 0.512, Reward: -466.73, Step time: 0.792s\n",
            "[Step 34] VRMS: 9.74, THD: 4.140, Reward: -2070.17, Step time: 0.837s\n",
            "[Step 35] VRMS: 9.59, THD: 3.002, Reward: -2090.89, Step time: 0.835s\n",
            "[Step 36] VRMS: 9.59, THD: 3.001, Reward: -2090.88, Step time: 0.964s\n",
            "[Step 37] VRMS: 9.59, THD: 3.004, Reward: -2090.93, Step time: 1.157s\n",
            "[Step 38] VRMS: 15.95, THD: 0.882, Reward: -987.59, Step time: 1.170s\n",
            "[Step 39] VRMS: 32.40, THD: 0.292, Reward: -28.77, Step time: 0.804s\n",
            "[Step 40] VRMS: 10.11, THD: 3.286, Reward: -1989.85, Step time: 0.782s\n",
            "[Step 41] VRMS: 34.66, THD: 0.256, Reward: -108.80, Step time: 0.784s\n",
            "[Step 42] VRMS: 9.99, THD: 3.204, Reward: -2012.34, Step time: 0.779s\n",
            "[Step 43] VRMS: 18.35, THD: 0.589, Reward: -679.16, Step time: 0.798s\n",
            "[Step 44] VRMS: 34.74, THD: 0.248, Reward: -112.60, Step time: 0.754s\n",
            "[Step 45] VRMS: 20.86, THD: 0.459, Reward: -417.76, Step time: 0.776s\n",
            "[Step 46] VRMS: 18.52, THD: 0.583, Reward: -659.50, Step time: 0.777s\n",
            "[Step 47] VRMS: 34.72, THD: 0.243, Reward: -111.61, Step time: 0.816s\n",
            "[Step 48] VRMS: 34.81, THD: 0.237, Reward: -115.77, Step time: 0.798s\n",
            "[Step 49] VRMS: 29.80, THD: 0.305, Reward: -0.29, Step time: 0.807s\n",
            "[Step 50] VRMS: 22.02, THD: 0.357, Reward: -318.39, Step time: 0.777s\n",
            "[Step 51] VRMS: 22.20, THD: 0.365, Reward: -304.00, Step time: 0.988s\n",
            "[Step 52] VRMS: 21.94, THD: 0.378, Reward: -324.86, Step time: 1.104s\n",
            "[Step 53] VRMS: 19.07, THD: 0.526, Reward: -597.07, Step time: 1.162s\n",
            "[Step 54] VRMS: 18.48, THD: 0.587, Reward: -663.59, Step time: 0.788s\n",
            "[Step 55] VRMS: 31.55, THD: 0.290, Reward: -12.06, Step time: 0.790s\n",
            "[Step 56] VRMS: 17.15, THD: 0.671, Reward: -825.96, Step time: 0.811s\n",
            "[Step 57] VRMS: 9.68, THD: 3.325, Reward: -2076.22, Step time: 0.838s\n",
            "[Step 58] VRMS: 9.59, THD: 3.001, Reward: -2090.93, Step time: 0.820s\n",
            "[Step 59] VRMS: 9.59, THD: 3.005, Reward: -2090.93, Step time: 0.784s\n",
            "[Step 60] VRMS: 27.91, THD: 0.369, Reward: -22.06, Step time: 0.763s\n",
            "[Step 61] VRMS: 9.70, THD: 3.230, Reward: -2069.89, Step time: 0.780s\n",
            "[Step 62] VRMS: 32.91, THD: 0.284, Reward: -42.48, Step time: 0.788s\n",
            "[Step 63] VRMS: 10.54, THD: 1.302, Reward: -1894.91, Step time: 0.808s\n",
            "[Step 64] VRMS: 18.15, THD: 0.636, Reward: -702.87, Step time: 0.757s\n",
            "[Step 65] VRMS: 33.66, THD: 0.278, Reward: -66.97, Step time: 0.782s\n",
            "[Step 66] VRMS: 10.45, THD: 5.122, Reward: -1937.19, Step time: 1.030s\n",
            "[Step 67] VRMS: 34.29, THD: 0.270, Reward: -92.12, Step time: 1.091s\n",
            "[Step 68] VRMS: 32.46, THD: 0.305, Reward: -30.27, Step time: 1.145s\n",
            "[Step 69] VRMS: 31.92, THD: 0.314, Reward: -18.52, Step time: 0.817s\n",
            "[Step 70] VRMS: 20.59, THD: 0.556, Reward: -443.45, Step time: 0.771s\n",
            "[Step 71] VRMS: 20.10, THD: 0.591, Reward: -490.11, Step time: 0.770s\n",
            "[Step 72] VRMS: 23.28, THD: 0.482, Reward: -225.76, Step time: 0.774s\n",
            "[Step 73] VRMS: 19.14, THD: 0.683, Reward: -589.80, Step time: 0.786s\n",
            "[Step 74] VRMS: 30.55, THD: 0.333, Reward: -1.63, Step time: 0.819s\n",
            "[Step 75] VRMS: 34.24, THD: 0.270, Reward: -89.89, Step time: 0.765s\n",
            "[Step 76] VRMS: 10.61, THD: 4.850, Reward: -1903.89, Step time: 0.779s\n",
            "[Step 77] VRMS: 31.94, THD: 0.303, Reward: -18.91, Step time: 0.800s\n",
            "[Step 78] VRMS: 10.60, THD: 5.506, Reward: -1912.08, Step time: 0.796s\n",
            "[Step 79] VRMS: 32.10, THD: 0.297, Reward: -22.23, Step time: 0.759s\n",
            "[Step 80] VRMS: 10.58, THD: 6.536, Reward: -1927.76, Step time: 0.784s\n",
            "[Step 81] VRMS: 34.96, THD: 0.258, Reward: -123.00, Step time: 1.045s\n",
            "[Step 82] VRMS: 17.15, THD: 0.779, Reward: -826.30, Step time: 1.119s\n",
            "[Step 83] VRMS: 27.05, THD: 0.392, Reward: -43.74, Step time: 1.193s\n",
            "[Step 84] VRMS: 18.76, THD: 0.573, Reward: -632.36, Step time: 0.812s\n",
            "[Step 85] VRMS: 27.58, THD: 0.370, Reward: -29.35, Step time: 0.797s\n",
            "[Step 86] VRMS: 34.59, THD: 0.243, Reward: -105.59, Step time: 0.819s\n",
            "[Step 87] VRMS: 31.62, THD: 0.289, Reward: -13.16, Step time: 0.754s\n",
            "[Step 88] VRMS: 19.02, THD: 0.531, Reward: -602.96, Step time: 0.791s\n",
            "[Step 89] VRMS: 10.04, THD: 3.205, Reward: -2003.25, Step time: 0.771s\n",
            "[Step 90] VRMS: 18.87, THD: 0.524, Reward: -619.30, Step time: 0.765s\n",
            "[Step 91] VRMS: 30.84, THD: 0.285, Reward: -3.64, Step time: 0.792s\n",
            "[Step 92] VRMS: 34.73, THD: 0.227, Reward: -111.78, Step time: 0.818s\n",
            "[Step 93] VRMS: 10.80, THD: 0.853, Reward: -1843.18, Step time: 0.807s\n",
            "[Step 94] VRMS: 34.60, THD: 0.227, Reward: -105.94, Step time: 0.798s\n",
            "[Step 95] VRMS: 10.66, THD: 6.347, Reward: -1911.40, Step time: 0.799s\n",
            "[Step 96] VRMS: 35.05, THD: 0.212, Reward: -127.37, Step time: 1.035s\n",
            "[Step 97] VRMS: 17.81, THD: 0.531, Reward: -743.18, Step time: 1.107s\n",
            "[Step 98] VRMS: 18.22, THD: 0.489, Reward: -694.20, Step time: 1.058s\n",
            "[Step 99] VRMS: 9.98, THD: 5.515, Reward: -2034.07, Step time: 0.784s\n",
            "[Step 100] VRMS: 16.02, THD: 0.558, Reward: -977.27, Step time: 0.787s\n",
            "[Step 1] VRMS: 9.63, THD: 9.429, Reward: -2163.15, Step time: 0.832s\n",
            "[Step 2] VRMS: 9.59, THD: 3.006, Reward: -2092.18, Step time: 0.828s\n",
            "[Step 3] VRMS: 30.01, THD: 0.354, Reward: -0.13, Step time: 0.830s\n",
            "[Step 4] VRMS: 28.41, THD: 0.416, Reward: -12.74, Step time: 0.828s\n",
            "[Step 5] VRMS: 9.72, THD: 3.380, Reward: -2066.98, Step time: 0.804s\n",
            "[Step 6] VRMS: 28.00, THD: 0.425, Reward: -20.21, Step time: 0.771s\n",
            "[Step 7] VRMS: 30.48, THD: 0.345, Reward: -1.27, Step time: 0.758s\n",
            "[Step 8] VRMS: 9.70, THD: 3.641, Reward: -2073.63, Step time: 0.771s\n",
            "[Step 9] VRMS: 31.95, THD: 0.311, Reward: -19.03, Step time: 0.773s\n",
            "[Step 10] VRMS: 17.88, THD: 0.823, Reward: -734.71, Step time: 0.778s\n",
            "[Step 11] VRMS: 15.26, THD: 1.346, Reward: -1088.48, Step time: 1.073s\n",
            "[Step 12] VRMS: 30.28, THD: 0.349, Reward: -0.51, Step time: 1.166s\n",
            "[Step 13] VRMS: 33.68, THD: 0.291, Reward: -67.73, Step time: 1.031s\n",
            "[Step 14] VRMS: 17.19, THD: 0.925, Reward: -820.87, Step time: 0.786s\n",
            "[Step 15] VRMS: 29.84, THD: 0.367, Reward: -0.27, Step time: 0.746s\n",
            "[Step 16] VRMS: 15.85, THD: 1.220, Reward: -1002.97, Step time: 0.801s\n",
            "[Step 17] VRMS: 19.67, THD: 0.586, Reward: -534.05, Step time: 0.804s\n",
            "[Step 18] VRMS: 9.63, THD: 15.229, Reward: -2305.83, Step time: 1.079s\n",
            "[Step 19] VRMS: 9.59, THD: 3.004, Reward: -2092.16, Step time: 1.132s\n",
            "[Step 20] VRMS: 25.85, THD: 0.474, Reward: -86.21, Step time: 1.012s\n",
            "[Step 21] VRMS: 9.71, THD: 7.843, Reward: -2119.64, Step time: 0.782s\n",
            "[Step 22] VRMS: 14.00, THD: 1.599, Reward: -1283.21, Step time: 0.787s\n",
            "[Step 23] VRMS: 9.59, THD: 4.367, Reward: -2102.32, Step time: 0.755s\n",
            "[Step 24] VRMS: 9.59, THD: 3.004, Reward: -2092.16, Step time: 0.751s\n",
            "[Step 25] VRMS: 9.59, THD: 3.001, Reward: -2092.12, Step time: 1.022s\n",
            "[Step 26] VRMS: 9.59, THD: 3.001, Reward: -2092.12, Step time: 1.107s\n",
            "[Step 27] VRMS: 27.89, THD: 0.437, Reward: -22.44, Step time: 1.086s\n",
            "[Step 28] VRMS: 9.68, THD: 3.247, Reward: -2074.16, Step time: 0.737s\n",
            "[Step 29] VRMS: 34.02, THD: 0.281, Reward: -80.76, Step time: 0.755s\n",
            "[Step 30] VRMS: 34.23, THD: 0.277, Reward: -89.44, Step time: 0.754s\n",
            "[Step 31] VRMS: 34.28, THD: 0.275, Reward: -91.46, Step time: 0.762s\n",
            "[Step 32] VRMS: 34.29, THD: 0.275, Reward: -92.02, Step time: 0.744s\n",
            "[Step 33] VRMS: 29.98, THD: 0.357, Reward: -0.13, Step time: 0.764s\n",
            "[Step 34] VRMS: 19.84, THD: 0.528, Reward: -515.97, Step time: 0.758s\n",
            "[Step 35] VRMS: 15.96, THD: 0.900, Reward: -987.07, Step time: 0.753s\n",
            "[Step 36] VRMS: 9.59, THD: 4.856, Reward: -2106.84, Step time: 0.752s\n",
            "[Step 37] VRMS: 34.46, THD: 0.265, Reward: -99.39, Step time: 0.756s\n",
            "[Step 38] VRMS: 31.32, THD: 0.307, Reward: -8.79, Step time: 0.771s\n",
            "[Step 39] VRMS: 16.16, THD: 0.842, Reward: -958.53, Step time: 0.754s\n",
            "[Step 40] VRMS: 16.26, THD: 0.795, Reward: -944.09, Step time: 0.823s\n",
            "[Step 41] VRMS: 9.61, THD: 3.242, Reward: -2089.45, Step time: 1.076s\n",
            "[Step 42] VRMS: 34.38, THD: 0.253, Reward: -95.98, Step time: 1.138s\n",
            "[Step 43] VRMS: 18.84, THD: 0.587, Reward: -623.54, Step time: 0.840s\n",
            "[Step 44] VRMS: 9.57, THD: 3.200, Reward: -2096.24, Step time: 0.770s\n",
            "[Step 45] VRMS: 34.55, THD: 0.245, Reward: -103.38, Step time: 0.748s\n",
            "[Step 46] VRMS: 34.64, THD: 0.243, Reward: -107.81, Step time: 0.749s\n",
            "[Step 47] VRMS: 9.77, THD: 3.230, Reward: -2056.92, Step time: 0.764s\n",
            "[Step 48] VRMS: 30.62, THD: 0.292, Reward: -2.01, Step time: 0.756s\n",
            "[Step 49] VRMS: 29.85, THD: 0.301, Reward: -0.21, Step time: 0.759s\n",
            "[Step 50] VRMS: 9.62, THD: 14.603, Reward: -2290.06, Step time: 0.771s\n",
            "[Step 51] VRMS: 9.59, THD: 3.001, Reward: -2092.12, Step time: 0.760s\n",
            "[Step 52] VRMS: 18.07, THD: 0.572, Reward: -711.64, Step time: 0.763s\n",
            "[Step 53] VRMS: 9.60, THD: 3.245, Reward: -2090.75, Step time: 0.751s\n",
            "[Step 54] VRMS: 17.09, THD: 0.611, Reward: -833.64, Step time: 0.759s\n",
            "[Step 55] VRMS: 17.57, THD: 0.620, Reward: -773.09, Step time: 0.763s\n",
            "[Step 56] VRMS: 15.45, THD: 0.752, Reward: -1059.53, Step time: 0.975s\n",
            "[Step 57] VRMS: 34.55, THD: 0.247, Reward: -103.62, Step time: 1.065s\n",
            "[Step 58] VRMS: 18.54, THD: 0.595, Reward: -657.51, Step time: 1.093s\n",
            "[Step 59] VRMS: 34.45, THD: 0.253, Reward: -99.28, Step time: 0.782s\n",
            "[Step 60] VRMS: 10.12, THD: 3.784, Reward: -1990.86, Step time: 0.750s\n",
            "[Step 61] VRMS: 28.69, THD: 0.350, Reward: -8.76, Step time: 0.751s\n",
            "[Step 62] VRMS: 15.73, THD: 0.902, Reward: -1019.60, Step time: 0.762s\n",
            "[Step 63] VRMS: 34.48, THD: 0.263, Reward: -100.41, Step time: 0.747s\n",
            "[Step 64] VRMS: 34.62, THD: 0.268, Reward: -106.63, Step time: 0.766s\n",
            "[Step 65] VRMS: 16.39, THD: 0.877, Reward: -927.17, Step time: 0.804s\n",
            "[Step 66] VRMS: 9.59, THD: 8.422, Reward: -2153.71, Step time: 0.768s\n",
            "[Step 67] VRMS: 34.08, THD: 0.269, Reward: -83.33, Step time: 0.746s\n",
            "[Step 68] VRMS: 32.43, THD: 0.301, Reward: -29.69, Step time: 0.748s\n",
            "[Step 69] VRMS: 10.29, THD: 6.621, Reward: -1986.51, Step time: 0.759s\n",
            "[Step 70] VRMS: 33.55, THD: 0.277, Reward: -63.03, Step time: 0.764s\n",
            "[Step 71] VRMS: 33.61, THD: 0.287, Reward: -65.20, Step time: 0.787s\n",
            "[Step 72] VRMS: 10.35, THD: 5.868, Reward: -1965.33, Step time: 1.080s\n",
            "[Step 73] VRMS: 31.76, THD: 0.305, Reward: -15.53, Step time: 1.145s\n",
            "[Step 74] VRMS: 26.94, THD: 0.443, Reward: -47.12, Step time: 0.889s\n",
            "[Step 75] VRMS: 29.96, THD: 0.350, Reward: -0.13, Step time: 0.771s\n",
            "[Step 76] VRMS: 10.10, THD: 3.509, Reward: -1992.81, Step time: 0.757s\n",
            "[Step 77] VRMS: 34.39, THD: 0.267, Reward: -96.58, Step time: 0.731s\n",
            "[Step 78] VRMS: 18.96, THD: 0.613, Reward: -609.94, Step time: 0.767s\n",
            "[Step 79] VRMS: 18.34, THD: 0.615, Reward: -680.63, Step time: 0.764s\n",
            "[Step 80] VRMS: 29.90, THD: 0.324, Reward: -0.15, Step time: 0.750s\n",
            "[Step 81] VRMS: 10.13, THD: 10.117, Reward: -2076.56, Step time: 0.733s\n",
            "[Step 82] VRMS: 34.69, THD: 0.256, Reward: -110.01, Step time: 0.760s\n",
            "[Step 83] VRMS: 34.05, THD: 0.264, Reward: -82.06, Step time: 0.755s\n",
            "[Step 84] VRMS: 19.20, THD: 0.535, Reward: -583.21, Step time: 0.755s\n",
            "[Step 85] VRMS: 9.49, THD: 1.586, Reward: -2105.62, Step time: 0.762s\n",
            "[Step 86] VRMS: 31.97, THD: 0.286, Reward: -19.46, Step time: 0.769s\n",
            "[Step 87] VRMS: 10.35, THD: 5.794, Reward: -1964.12, Step time: 0.967s\n",
            "[Step 88] VRMS: 19.24, THD: 0.487, Reward: -578.86, Step time: 1.105s\n",
            "[Step 89] VRMS: 28.08, THD: 0.345, Reward: -18.57, Step time: 1.121s\n",
            "[Step 90] VRMS: 32.98, THD: 0.255, Reward: -44.34, Step time: 0.753s\n",
            "[Step 91] VRMS: 34.68, THD: 0.232, Reward: -109.48, Step time: 0.776s\n",
            "[Step 92] VRMS: 28.15, THD: 0.329, Reward: -17.29, Step time: 0.746s\n",
            "[Step 93] VRMS: 9.98, THD: 3.525, Reward: -2016.58, Step time: 0.754s\n",
            "[Step 94] VRMS: 22.26, THD: 0.343, Reward: -299.49, Step time: 0.751s\n",
            "[Step 95] VRMS: 9.98, THD: 0.993, Reward: -2005.10, Step time: 0.745s\n",
            "[Step 96] VRMS: 17.71, THD: 0.523, Reward: -755.56, Step time: 0.764s\n",
            "[Step 97] VRMS: 14.06, THD: 0.734, Reward: -1271.14, Step time: 0.787s\n",
            "[Step 98] VRMS: 9.57, THD: 3.198, Reward: -2096.72, Step time: 0.759s\n",
            "[Step 99] VRMS: 30.77, THD: 0.265, Reward: -3.04, Step time: 0.745s\n",
            "[Step 100] VRMS: 14.75, THD: 0.642, Reward: -1162.48, Step time: 0.760s\n",
            "[Step 1] VRMS: 20.60, THD: 0.523, Reward: -441.80, Step time: 0.768s\n",
            "[Step 2] VRMS: 34.21, THD: 0.303, Reward: -88.74, Step time: 0.813s\n",
            "[Step 3] VRMS: 19.94, THD: 0.627, Reward: -506.24, Step time: 1.130s\n",
            "[Step 4] VRMS: 33.08, THD: 0.309, Reward: -47.38, Step time: 1.126s\n",
            "[Step 5] VRMS: 32.84, THD: 0.307, Reward: -40.41, Step time: 0.902s\n",
            "[Step 6] VRMS: 33.97, THD: 0.297, Reward: -78.77, Step time: 0.781s\n",
            "[Step 7] VRMS: 18.59, THD: 0.829, Reward: -652.07, Step time: 0.792s\n",
            "[Step 8] VRMS: 30.11, THD: 0.377, Reward: -0.20, Step time: 0.772s\n",
            "[Step 9] VRMS: 10.03, THD: 4.767, Reward: -2016.57, Step time: 0.779s\n",
            "[Step 10] VRMS: 34.13, THD: 0.298, Reward: -85.44, Step time: 0.760s\n",
            "[Step 11] VRMS: 34.24, THD: 0.290, Reward: -89.99, Step time: 0.766s\n",
            "[Step 12] VRMS: 34.25, THD: 0.290, Reward: -90.25, Step time: 0.752s\n",
            "[Step 13] VRMS: 20.46, THD: 0.558, Reward: -455.16, Step time: 0.762s\n",
            "[Step 14] VRMS: 20.62, THD: 0.525, Reward: -439.83, Step time: 0.775s\n",
            "[Step 15] VRMS: 20.40, THD: 0.605, Reward: -461.41, Step time: 0.774s\n",
            "[Step 16] VRMS: 33.51, THD: 0.302, Reward: -61.62, Step time: 0.751s\n",
            "[Step 17] VRMS: 29.25, THD: 0.411, Reward: -2.98, Step time: 0.732s\n",
            "[Step 18] VRMS: 34.37, THD: 0.295, Reward: -95.47, Step time: 1.010s\n",
            "[Step 19] VRMS: 10.12, THD: 3.464, Reward: -1988.36, Step time: 1.085s\n",
            "[Step 20] VRMS: 32.41, THD: 0.316, Reward: -29.18, Step time: 1.094s\n",
            "[Step 21] VRMS: 10.03, THD: 3.218, Reward: -2004.02, Step time: 0.767s\n",
            "[Step 22] VRMS: 34.20, THD: 0.291, Reward: -88.26, Step time: 0.768s\n",
            "[Step 23] VRMS: 20.30, THD: 0.611, Reward: -470.67, Step time: 0.762s\n",
            "[Step 24] VRMS: 19.91, THD: 0.626, Reward: -509.68, Step time: 0.757s\n",
            "[Step 25] VRMS: 9.71, THD: 3.228, Reward: -2068.00, Step time: 0.765s\n",
            "[Step 26] VRMS: 20.10, THD: 0.579, Reward: -490.35, Step time: 0.773s\n",
            "[Step 27] VRMS: 19.72, THD: 0.677, Reward: -528.90, Step time: 0.748s\n",
            "[Step 28] VRMS: 20.22, THD: 0.547, Reward: -478.95, Step time: 0.783s\n",
            "[Step 29] VRMS: 17.31, THD: 0.948, Reward: -806.54, Step time: 0.772s\n",
            "[Step 30] VRMS: 9.62, THD: 4.228, Reward: -2094.10, Step time: 0.747s\n",
            "[Step 31] VRMS: 33.11, THD: 0.301, Reward: -48.43, Step time: 0.721s\n",
            "[Step 32] VRMS: 10.34, THD: 6.304, Reward: -1971.90, Step time: 0.770s\n",
            "[Step 33] VRMS: 27.86, THD: 0.427, Reward: -23.12, Step time: 0.839s\n",
            "[Step 34] VRMS: 17.69, THD: 0.701, Reward: -757.95, Step time: 1.084s\n",
            "[Step 35] VRMS: 18.52, THD: 0.626, Reward: -659.02, Step time: 1.144s\n",
            "[Step 36] VRMS: 34.83, THD: 0.266, Reward: -116.70, Step time: 0.832s\n",
            "[Step 37] VRMS: 10.35, THD: 3.251, Reward: -1940.24, Step time: 0.736s\n",
            "[Step 38] VRMS: 13.91, THD: 1.012, Reward: -1296.15, Step time: 0.778s\n",
            "[Step 39] VRMS: 17.24, THD: 0.769, Reward: -814.81, Step time: 0.759s\n",
            "[Step 40] VRMS: 32.51, THD: 0.294, Reward: -31.61, Step time: 0.771s\n",
            "[Step 41] VRMS: 18.24, THD: 0.683, Reward: -692.15, Step time: 0.751s\n",
            "[Step 42] VRMS: 19.18, THD: 0.526, Reward: -586.02, Step time: 0.767s\n",
            "[Step 43] VRMS: 29.49, THD: 0.323, Reward: -1.40, Step time: 0.764s\n",
            "[Step 44] VRMS: 31.07, THD: 0.299, Reward: -5.86, Step time: 0.756s\n",
            "[Step 45] VRMS: 34.79, THD: 0.245, Reward: -114.99, Step time: 0.749s\n",
            "[Step 46] VRMS: 9.85, THD: 3.210, Reward: -2040.24, Step time: 0.780s\n",
            "[Step 47] VRMS: 9.60, THD: 3.003, Reward: -2090.02, Step time: 0.762s\n",
            "[Step 48] VRMS: 34.85, THD: 0.236, Reward: -117.70, Step time: 0.773s\n",
            "[Step 49] VRMS: 34.86, THD: 0.236, Reward: -118.20, Step time: 1.039s\n",
            "[Step 50] VRMS: 34.89, THD: 0.232, Reward: -119.48, Step time: 1.089s\n",
            "[Step 51] VRMS: 34.90, THD: 0.230, Reward: -120.22, Step time: 1.020s\n",
            "[Step 52] VRMS: 31.46, THD: 0.286, Reward: -10.80, Step time: 0.748s\n",
            "[Step 53] VRMS: 9.63, THD: 5.291, Reward: -2103.49, Step time: 0.761s\n",
            "[Step 54] VRMS: 34.77, THD: 0.240, Reward: -113.98, Step time: 0.768s\n",
            "[Step 55] VRMS: 15.98, THD: 0.752, Reward: -982.71, Step time: 0.752s\n",
            "[Step 56] VRMS: 34.04, THD: 0.256, Reward: -81.80, Step time: 0.781s\n",
            "[Step 57] VRMS: 10.14, THD: 3.398, Reward: -1984.13, Step time: 0.782s\n",
            "[Step 58] VRMS: 18.12, THD: 0.627, Reward: -705.93, Step time: 0.789s\n",
            "[Step 59] VRMS: 9.89, THD: 3.314, Reward: -2033.83, Step time: 0.797s\n",
            "[Step 60] VRMS: 25.33, THD: 0.408, Reward: -109.01, Step time: 0.771s\n",
            "[Step 61] VRMS: 20.00, THD: 0.488, Reward: -500.17, Step time: 0.776s\n",
            "[Step 62] VRMS: 31.28, THD: 0.300, Reward: -8.31, Step time: 0.790s\n",
            "[Step 63] VRMS: 31.94, THD: 0.305, Reward: -18.85, Step time: 0.782s\n",
            "[Step 64] VRMS: 17.78, THD: 0.723, Reward: -747.16, Step time: 0.967s\n",
            "[Step 65] VRMS: 9.62, THD: 3.415, Reward: -2088.59, Step time: 1.080s\n",
            "[Step 66] VRMS: 23.92, THD: 0.463, Reward: -184.78, Step time: 1.146s\n",
            "[Step 67] VRMS: 34.75, THD: 0.267, Reward: -113.11, Step time: 0.736s\n",
            "[Step 68] VRMS: 21.01, THD: 0.543, Reward: -404.37, Step time: 0.769s\n",
            "[Step 69] VRMS: 10.09, THD: 4.199, Reward: -2000.41, Step time: 0.763s\n",
            "[Step 70] VRMS: 9.60, THD: 3.002, Reward: -2090.00, Step time: 0.748s\n",
            "[Step 71] VRMS: 9.60, THD: 3.001, Reward: -2089.99, Step time: 0.786s\n",
            "[Step 72] VRMS: 33.99, THD: 0.282, Reward: -79.57, Step time: 0.767s\n",
            "[Step 73] VRMS: 11.32, THD: 2.390, Reward: -1751.09, Step time: 0.768s\n",
            "[Step 74] VRMS: 18.93, THD: 0.664, Reward: -613.26, Step time: 0.804s\n",
            "[Step 75] VRMS: 9.80, THD: 3.332, Reward: -2052.15, Step time: 0.772s\n",
            "[Step 76] VRMS: 19.87, THD: 0.575, Reward: -513.02, Step time: 0.783s\n",
            "[Step 77] VRMS: 9.98, THD: 3.358, Reward: -2015.55, Step time: 0.787s\n",
            "[Step 78] VRMS: 33.13, THD: 0.293, Reward: -48.94, Step time: 0.763s\n",
            "[Step 79] VRMS: 17.71, THD: 0.750, Reward: -755.30, Step time: 0.888s\n",
            "[Step 80] VRMS: 35.34, THD: 0.264, Reward: -142.68, Step time: 1.095s\n",
            "[Step 81] VRMS: 30.16, THD: 0.331, Reward: -0.24, Step time: 1.195s\n",
            "[Step 82] VRMS: 11.81, THD: 1.006, Reward: -1655.42, Step time: 0.844s\n",
            "[Step 83] VRMS: 31.32, THD: 0.299, Reward: -8.79, Step time: 0.781s\n",
            "[Step 84] VRMS: 19.70, THD: 0.539, Reward: -530.55, Step time: 0.767s\n",
            "[Step 85] VRMS: 9.64, THD: 3.206, Reward: -2083.37, Step time: 0.763s\n",
            "[Step 86] VRMS: 15.03, THD: 0.799, Reward: -1120.99, Step time: 0.762s\n",
            "[Step 87] VRMS: 30.83, THD: 0.298, Reward: -3.53, Step time: 0.767s\n",
            "[Step 88] VRMS: 10.82, THD: 10.589, Reward: -1951.23, Step time: 0.761s\n",
            "[Step 89] VRMS: 31.58, THD: 0.285, Reward: -12.50, Step time: 0.770s\n",
            "[Step 90] VRMS: 19.62, THD: 0.522, Reward: -539.27, Step time: 0.771s\n",
            "[Step 91] VRMS: 20.29, THD: 0.494, Reward: -471.58, Step time: 0.768s\n",
            "[Step 92] VRMS: 34.95, THD: 0.229, Reward: -122.55, Step time: 0.766s\n",
            "[Step 93] VRMS: 11.41, THD: 0.808, Reward: -1729.44, Step time: 0.758s\n",
            "[Step 94] VRMS: 30.39, THD: 0.294, Reward: -0.85, Step time: 0.768s\n",
            "[Step 95] VRMS: 34.93, THD: 0.215, Reward: -121.73, Step time: 1.076s\n",
            "[Step 96] VRMS: 21.58, THD: 0.406, Reward: -354.29, Step time: 1.100s\n",
            "[Step 97] VRMS: 17.85, THD: 0.516, Reward: -738.58, Step time: 0.979s\n",
            "[Step 98] VRMS: 9.57, THD: 1.877, Reward: -2091.46, Step time: 0.781s\n",
            "[Step 99] VRMS: 30.54, THD: 0.278, Reward: -1.51, Step time: 0.779s\n",
            "[Step 100] VRMS: 34.93, THD: 0.203, Reward: -121.61, Step time: 0.776s\n",
            "[Step 1] VRMS: 19.31, THD: 0.669, Reward: -571.33, Step time: 0.762s\n",
            "[Step 2] VRMS: 34.01, THD: 0.302, Reward: -80.33, Step time: 0.770s\n",
            "[Step 3] VRMS: 32.47, THD: 0.308, Reward: -30.60, Step time: 0.762s\n",
            "[Step 4] VRMS: 9.96, THD: 3.436, Reward: -2019.79, Step time: 0.748s\n",
            "[Step 5] VRMS: 16.51, THD: 1.212, Reward: -910.83, Step time: 0.766s\n",
            "[Step 6] VRMS: 27.94, THD: 0.439, Reward: -21.36, Step time: 0.779s\n",
            "[Step 7] VRMS: 9.97, THD: 3.241, Reward: -2016.26, Step time: 0.750s\n",
            "[Step 8] VRMS: 9.60, THD: 3.002, Reward: -2090.33, Step time: 0.790s\n",
            "[Step 9] VRMS: 33.94, THD: 0.299, Reward: -77.62, Step time: 0.757s\n",
            "[Step 10] VRMS: 9.94, THD: 3.212, Reward: -2022.78, Step time: 0.949s\n",
            "[Step 11] VRMS: 33.73, THD: 0.303, Reward: -69.79, Step time: 1.101s\n",
            "[Step 12] VRMS: 34.14, THD: 0.289, Reward: -85.88, Step time: 1.127s\n",
            "[Step 13] VRMS: 32.69, THD: 0.308, Reward: -36.36, Step time: 0.760s\n",
            "[Step 14] VRMS: 9.94, THD: 3.211, Reward: -2021.44, Step time: 0.743s\n",
            "[Step 15] VRMS: 33.90, THD: 0.297, Reward: -76.18, Step time: 0.763s\n",
            "[Step 16] VRMS: 17.76, THD: 0.927, Reward: -749.45, Step time: 0.765s\n",
            "[Step 17] VRMS: 34.01, THD: 0.297, Reward: -80.43, Step time: 0.765s\n",
            "[Step 18] VRMS: 20.66, THD: 0.517, Reward: -436.88, Step time: 0.789s\n",
            "[Step 19] VRMS: 16.74, THD: 1.159, Reward: -880.58, Step time: 0.789s\n",
            "[Step 20] VRMS: 16.72, THD: 1.091, Reward: -883.50, Step time: 0.768s\n",
            "[Step 21] VRMS: 9.59, THD: 3.305, Reward: -2093.10, Step time: 0.764s\n",
            "[Step 22] VRMS: 34.10, THD: 0.291, Reward: -84.25, Step time: 0.749s\n",
            "[Step 23] VRMS: 19.77, THD: 0.657, Reward: -523.96, Step time: 0.762s\n",
            "[Step 24] VRMS: 18.03, THD: 0.829, Reward: -717.01, Step time: 0.768s\n",
            "[Step 25] VRMS: 19.89, THD: 0.605, Reward: -511.44, Step time: 0.752s\n",
            "[Step 26] VRMS: 34.22, THD: 0.284, Reward: -89.15, Step time: 1.123s\n",
            "[Step 27] VRMS: 33.50, THD: 0.298, Reward: -61.32, Step time: 1.132s\n",
            "[Step 28] VRMS: 10.26, THD: 16.116, Reward: -2208.79, Step time: 0.962s\n",
            "[Step 29] VRMS: 9.60, THD: 3.011, Reward: -2090.37, Step time: 0.755s\n",
            "[Step 30] VRMS: 34.47, THD: 0.278, Reward: -100.02, Step time: 0.786s\n",
            "[Step 31] VRMS: 34.69, THD: 0.276, Reward: -110.22, Step time: 0.764s\n",
            "[Step 32] VRMS: 32.49, THD: 0.312, Reward: -30.99, Step time: 0.766s\n",
            "[Step 33] VRMS: 34.86, THD: 0.272, Reward: -118.29, Step time: 0.811s\n",
            "[Step 34] VRMS: 33.00, THD: 0.299, Reward: -44.96, Step time: 0.844s\n",
            "[Step 35] VRMS: 10.35, THD: 3.758, Reward: -1944.47, Step time: 0.779s\n",
            "[Step 36] VRMS: 9.60, THD: 2.999, Reward: -2090.27, Step time: 0.788s\n",
            "[Step 37] VRMS: 17.52, THD: 0.692, Reward: -779.42, Step time: 0.821s\n",
            "[Step 38] VRMS: 31.86, THD: 0.301, Reward: -17.39, Step time: 0.832s\n",
            "[Step 39] VRMS: 10.09, THD: 3.873, Reward: -1997.34, Step time: 0.776s\n",
            "[Step 40] VRMS: 9.60, THD: 2.999, Reward: -2090.27, Step time: 0.752s\n",
            "[Step 41] VRMS: 34.74, THD: 0.256, Reward: -112.43, Step time: 1.129s\n",
            "[Step 42] VRMS: 12.34, THD: 0.945, Reward: -1561.05, Step time: 1.161s\n",
            "[Step 43] VRMS: 34.61, THD: 0.254, Reward: -106.26, Step time: 0.919s\n",
            "[Step 44] VRMS: 10.05, THD: 3.210, Reward: -2000.50, Step time: 0.751s\n",
            "[Step 45] VRMS: 9.60, THD: 3.000, Reward: -2090.28, Step time: 0.760s\n",
            "[Step 46] VRMS: 17.23, THD: 0.637, Reward: -816.25, Step time: 0.799s\n",
            "[Step 47] VRMS: 10.30, THD: 1.253, Reward: -1941.20, Step time: 0.776s\n",
            "[Step 48] VRMS: 30.74, THD: 0.293, Reward: -2.83, Step time: 0.732s\n",
            "[Step 49] VRMS: 29.97, THD: 0.301, Reward: -0.10, Step time: 0.741s\n",
            "[Step 50] VRMS: 10.21, THD: 2.680, Reward: -1964.51, Step time: 0.778s\n",
            "[Step 51] VRMS: 31.58, THD: 0.283, Reward: -12.55, Step time: 0.766s\n",
            "[Step 52] VRMS: 9.63, THD: 4.674, Reward: -2097.23, Step time: 0.743s\n",
            "[Step 53] VRMS: 31.56, THD: 0.284, Reward: -12.24, Step time: 0.744s\n",
            "[Step 54] VRMS: 10.15, THD: 1.469, Reward: -1971.98, Step time: 0.766s\n",
            "[Step 55] VRMS: 34.74, THD: 0.242, Reward: -112.34, Step time: 0.751s\n",
            "[Step 56] VRMS: 30.95, THD: 0.296, Reward: -4.61, Step time: 0.983s\n",
            "[Step 57] VRMS: 21.95, THD: 0.398, Reward: -324.06, Step time: 1.082s\n",
            "[Step 58] VRMS: 34.73, THD: 0.249, Reward: -111.86, Step time: 1.096s\n",
            "[Step 59] VRMS: 34.70, THD: 0.255, Reward: -110.54, Step time: 0.790s\n",
            "[Step 60] VRMS: 14.40, THD: 0.948, Reward: -1217.53, Step time: 0.785s\n",
            "[Step 61] VRMS: 9.64, THD: 3.218, Reward: -2083.75, Step time: 0.775s\n",
            "[Step 62] VRMS: 17.10, THD: 0.776, Reward: -833.23, Step time: 0.763s\n",
            "[Step 63] VRMS: 26.00, THD: 0.420, Reward: -80.19, Step time: 0.783s\n",
            "[Step 64] VRMS: 34.90, THD: 0.263, Reward: -119.96, Step time: 0.774s\n",
            "[Step 65] VRMS: 26.92, THD: 0.428, Reward: -47.67, Step time: 0.791s\n",
            "[Step 66] VRMS: 19.74, THD: 0.601, Reward: -526.83, Step time: 0.749s\n",
            "[Step 67] VRMS: 32.87, THD: 0.300, Reward: -41.41, Step time: 0.767s\n",
            "[Step 68] VRMS: 10.65, THD: 13.875, Reward: -2064.82, Step time: 0.763s\n",
            "[Step 69] VRMS: 9.60, THD: 3.012, Reward: -2090.38, Step time: 0.807s\n",
            "[Step 70] VRMS: 9.60, THD: 3.002, Reward: -2090.28, Step time: 0.847s\n",
            "[Step 71] VRMS: 33.79, THD: 0.284, Reward: -71.84, Step time: 0.990s\n",
            "[Step 72] VRMS: 15.08, THD: 1.422, Reward: -1115.00, Step time: 1.135s\n",
            "[Step 73] VRMS: 19.55, THD: 0.617, Reward: -545.99, Step time: 1.258s\n",
            "[Step 74] VRMS: 33.97, THD: 0.274, Reward: -78.95, Step time: 0.771s\n",
            "[Step 75] VRMS: 10.77, THD: 7.811, Reward: -1909.93, Step time: 0.771s\n",
            "[Step 76] VRMS: 27.23, THD: 0.424, Reward: -38.45, Step time: 0.777s\n",
            "[Step 77] VRMS: 34.74, THD: 0.264, Reward: -112.64, Step time: 0.820s\n",
            "[Step 78] VRMS: 30.71, THD: 0.333, Reward: -2.66, Step time: 0.776s\n",
            "[Step 79] VRMS: 31.73, THD: 0.304, Reward: -15.13, Step time: 0.786s\n",
            "[Step 80] VRMS: 25.47, THD: 0.437, Reward: -102.79, Step time: 0.771s\n",
            "[Step 81] VRMS: 35.01, THD: 0.255, Reward: -125.53, Step time: 0.774s\n",
            "[Step 82] VRMS: 10.69, THD: 10.608, Reward: -1977.20, Step time: 0.753s\n",
            "[Step 83] VRMS: 18.11, THD: 0.645, Reward: -706.94, Step time: 0.802s\n",
            "[Step 84] VRMS: 20.78, THD: 0.435, Reward: -425.41, Step time: 0.777s\n",
            "[Step 85] VRMS: 18.24, THD: 0.617, Reward: -692.00, Step time: 0.795s\n",
            "[Step 86] VRMS: 31.67, THD: 0.291, Reward: -14.06, Step time: 0.908s\n",
            "[Step 87] VRMS: 18.68, THD: 0.621, Reward: -640.86, Step time: 1.062s\n",
            "[Step 88] VRMS: 18.83, THD: 0.515, Reward: -624.43, Step time: 1.175s\n",
            "[Step 89] VRMS: 10.77, THD: 0.850, Reward: -1849.15, Step time: 0.758s\n",
            "[Step 90] VRMS: 35.12, THD: 0.234, Reward: -131.29, Step time: 0.796s\n",
            "[Step 91] VRMS: 10.90, THD: 5.711, Reward: -1856.81, Step time: 0.774s\n",
            "[Step 92] VRMS: 17.83, THD: 0.554, Reward: -741.00, Step time: 0.761s\n",
            "[Step 93] VRMS: 31.94, THD: 0.276, Reward: -18.88, Step time: 0.789s\n",
            "[Step 94] VRMS: 29.21, THD: 0.314, Reward: -3.20, Step time: 0.799s\n",
            "[Step 95] VRMS: 33.74, THD: 0.242, Reward: -70.06, Step time: 0.774s\n",
            "[Step 96] VRMS: 10.73, THD: 5.927, Reward: -1892.71, Step time: 0.757s\n",
            "[Step 97] VRMS: 9.60, THD: 3.021, Reward: -2090.43, Step time: 0.787s\n",
            "[Step 98] VRMS: 18.30, THD: 0.485, Reward: -684.95, Step time: 0.765s\n",
            "[Step 99] VRMS: 34.98, THD: 0.205, Reward: -124.18, Step time: 0.788s\n",
            "[Step 100] VRMS: 35.05, THD: 0.206, Reward: -127.77, Step time: 0.750s\n",
            "[Step 1] VRMS: 9.68, THD: 17.886, Reward: -2385.02, Step time: 0.881s\n",
            "[Step 2] VRMS: 33.22, THD: 0.305, Reward: -52.05, Step time: 1.355s\n",
            "[Step 3] VRMS: 19.35, THD: 0.688, Reward: -567.49, Step time: 1.388s\n",
            "[Step 4] VRMS: 31.25, THD: 0.337, Reward: -7.94, Step time: 1.468s\n",
            "[Step 5] VRMS: 30.21, THD: 0.377, Reward: -0.37, Step time: 0.941s\n",
            "[Step 6] VRMS: 10.00, THD: 4.420, Reward: -2019.65, Step time: 0.791s\n",
            "[Step 7] VRMS: 17.72, THD: 0.927, Reward: -754.70, Step time: 0.808s\n",
            "[Step 8] VRMS: 19.73, THD: 0.642, Reward: -527.97, Step time: 0.753s\n",
            "[Step 9] VRMS: 31.68, THD: 0.323, Reward: -14.16, Step time: 0.784s\n",
            "[Step 10] VRMS: 20.48, THD: 0.548, Reward: -453.23, Step time: 0.773s\n",
            "[Step 11] VRMS: 19.85, THD: 0.644, Reward: -515.21, Step time: 0.811s\n",
            "[Step 12] VRMS: 9.71, THD: 3.438, Reward: -2069.82, Step time: 0.761s\n",
            "[Step 13] VRMS: 28.77, THD: 0.422, Reward: -7.73, Step time: 0.768s\n",
            "[Step 14] VRMS: 30.92, THD: 0.357, Reward: -4.39, Step time: 0.767s\n",
            "[Step 15] VRMS: 20.57, THD: 0.521, Reward: -444.62, Step time: 0.810s\n",
            "[Step 16] VRMS: 16.74, THD: 1.239, Reward: -880.45, Step time: 0.793s\n",
            "[Step 17] VRMS: 28.40, THD: 0.434, Reward: -12.91, Step time: 1.106s\n",
            "[Step 18] VRMS: 34.31, THD: 0.295, Reward: -92.86, Step time: 1.099s\n",
            "[Step 19] VRMS: 27.06, THD: 0.455, Reward: -43.37, Step time: 1.058s\n",
            "[Step 20] VRMS: 16.19, THD: 1.269, Reward: -954.91, Step time: 0.802s\n",
            "[Step 21] VRMS: 20.31, THD: 0.539, Reward: -470.03, Step time: 0.789s\n",
            "[Step 22] VRMS: 33.43, THD: 0.307, Reward: -58.92, Step time: 0.759s\n",
            "[Step 23] VRMS: 20.73, THD: 0.519, Reward: -429.58, Step time: 0.768s\n",
            "[Step 24] VRMS: 10.00, THD: 3.279, Reward: -2010.35, Step time: 0.783s\n",
            "[Step 25] VRMS: 34.27, THD: 0.287, Reward: -91.37, Step time: 0.768s\n",
            "[Step 26] VRMS: 32.90, THD: 0.311, Reward: -42.16, Step time: 0.767s\n",
            "[Step 27] VRMS: 10.07, THD: 3.349, Reward: -1997.87, Step time: 0.758s\n",
            "[Step 28] VRMS: 31.23, THD: 0.339, Reward: -7.63, Step time: 0.760s\n",
            "[Step 29] VRMS: 10.00, THD: 3.222, Reward: -2009.69, Step time: 0.773s\n",
            "[Step 30] VRMS: 34.49, THD: 0.279, Reward: -100.69, Step time: 0.770s\n",
            "[Step 31] VRMS: 24.60, THD: 0.503, Reward: -146.14, Step time: 0.781s\n",
            "[Step 32] VRMS: 31.61, THD: 0.322, Reward: -13.14, Step time: 1.014s\n",
            "[Step 33] VRMS: 18.26, THD: 0.677, Reward: -689.92, Step time: 1.093s\n",
            "[Step 34] VRMS: 9.60, THD: 3.471, Reward: -2093.12, Step time: 1.154s\n",
            "[Step 35] VRMS: 9.60, THD: 3.001, Reward: -2090.11, Step time: 0.835s\n",
            "[Step 36] VRMS: 29.15, THD: 0.370, Reward: -3.75, Step time: 0.820s\n",
            "[Step 37] VRMS: 28.83, THD: 0.372, Reward: -7.00, Step time: 0.781s\n",
            "[Step 38] VRMS: 9.83, THD: 3.247, Reward: -2044.33, Step time: 1.003s\n",
            "[Step 39] VRMS: 34.81, THD: 0.261, Reward: -115.89, Step time: 0.940s\n",
            "[Step 40] VRMS: 34.96, THD: 0.261, Reward: -123.11, Step time: 0.935s\n",
            "[Step 41] VRMS: 15.28, THD: 0.879, Reward: -1083.70, Step time: 0.965s\n",
            "[Step 42] VRMS: 9.62, THD: 3.295, Reward: -2087.31, Step time: 0.949s\n",
            "[Step 43] VRMS: 31.31, THD: 0.294, Reward: -8.69, Step time: 1.206s\n",
            "[Step 44] VRMS: 16.42, THD: 0.732, Reward: -923.26, Step time: 1.219s\n",
            "[Step 45] VRMS: 30.02, THD: 0.304, Reward: -0.09, Step time: 1.764s\n",
            "[Step 46] VRMS: 30.26, THD: 0.302, Reward: -0.43, Step time: 1.171s\n",
            "[Step 47] VRMS: 34.78, THD: 0.242, Reward: -114.41, Step time: 1.028s\n",
            "[Step 48] VRMS: 34.91, THD: 0.237, Reward: -120.48, Step time: 0.778s\n",
            "[Step 49] VRMS: 28.18, THD: 0.340, Reward: -16.75, Step time: 0.785s\n",
            "[Step 50] VRMS: 19.18, THD: 0.533, Reward: -585.50, Step time: 0.747s\n",
            "[Step 51] VRMS: 34.98, THD: 0.227, Reward: -124.18, Step time: 0.770s\n",
            "[Step 52] VRMS: 34.87, THD: 0.229, Reward: -118.40, Step time: 0.780s\n",
            "[Step 53] VRMS: 18.39, THD: 0.587, Reward: -674.45, Step time: 0.798s\n",
            "[Step 54] VRMS: 12.36, THD: 0.839, Reward: -1556.33, Step time: 0.764s\n",
            "[Step 55] VRMS: 9.63, THD: 20.205, Reward: -2483.58, Step time: 0.773s\n",
            "[Step 56] VRMS: 18.98, THD: 0.506, Reward: -607.69, Step time: 0.783s\n",
            "[Step 57] VRMS: 34.78, THD: 0.246, Reward: -114.24, Step time: 0.799s\n",
            "[Step 58] VRMS: 19.28, THD: 0.540, Reward: -575.25, Step time: 0.759s\n",
            "[Step 59] VRMS: 28.67, THD: 0.346, Reward: -8.96, Step time: 0.762s\n",
            "[Step 60] VRMS: 26.50, THD: 0.407, Reward: -61.25, Step time: 1.060s\n",
            "[Step 61] VRMS: 22.10, THD: 0.411, Reward: -312.15, Step time: 1.175s\n",
            "[Step 62] VRMS: 19.00, THD: 0.567, Reward: -605.87, Step time: 1.047s\n",
            "[Step 63] VRMS: 21.48, THD: 0.448, Reward: -362.98, Step time: 0.768s\n",
            "[Step 64] VRMS: 31.91, THD: 0.303, Reward: -18.25, Step time: 0.759s\n",
            "[Step 65] VRMS: 10.29, THD: 3.349, Reward: -1953.16, Step time: 0.820s\n",
            "[Step 66] VRMS: 26.93, THD: 0.427, Reward: -47.32, Step time: 0.788s\n",
            "[Step 67] VRMS: 26.78, THD: 0.441, Reward: -52.12, Step time: 0.801s\n",
            "[Step 68] VRMS: 16.42, THD: 0.988, Reward: -922.41, Step time: 0.793s\n",
            "[Step 69] VRMS: 9.59, THD: 3.205, Reward: -2092.82, Step time: 0.774s\n",
            "[Step 70] VRMS: 19.86, THD: 0.610, Reward: -514.67, Step time: 0.781s\n",
            "[Step 71] VRMS: 20.42, THD: 0.578, Reward: -458.88, Step time: 0.801s\n",
            "[Step 72] VRMS: 31.63, THD: 0.320, Reward: -13.36, Step time: 0.800s\n",
            "[Step 73] VRMS: 33.04, THD: 0.300, Reward: -46.36, Step time: 0.775s\n",
            "[Step 74] VRMS: 10.79, THD: 19.738, Reward: -2235.51, Step time: 0.777s\n",
            "[Step 75] VRMS: 31.94, THD: 0.306, Reward: -18.99, Step time: 1.040s\n",
            "[Step 76] VRMS: 20.61, THD: 0.558, Reward: -441.39, Step time: 1.109s\n",
            "[Step 77] VRMS: 16.26, THD: 0.904, Reward: -945.25, Step time: 1.047s\n",
            "[Step 78] VRMS: 20.74, THD: 0.468, Reward: -428.92, Step time: 0.753s\n",
            "[Step 79] VRMS: 31.41, THD: 0.306, Reward: -10.07, Step time: 0.755s\n",
            "[Step 80] VRMS: 20.19, THD: 0.537, Reward: -481.02, Step time: 0.759s\n",
            "[Step 81] VRMS: 28.08, THD: 0.377, Reward: -18.58, Step time: 0.760s\n",
            "[Step 82] VRMS: 34.76, THD: 0.255, Reward: -113.34, Step time: 0.768s\n",
            "[Step 83] VRMS: 34.92, THD: 0.258, Reward: -121.14, Step time: 0.784s\n",
            "[Step 84] VRMS: 16.41, THD: 0.798, Reward: -923.72, Step time: 0.786s\n",
            "[Step 85] VRMS: 32.31, THD: 0.287, Reward: -26.75, Step time: 0.813s\n",
            "[Step 86] VRMS: 34.72, THD: 0.249, Reward: -111.23, Step time: 0.790s\n",
            "[Step 87] VRMS: 30.88, THD: 0.299, Reward: -3.93, Step time: 0.771s\n",
            "[Step 88] VRMS: 34.95, THD: 0.241, Reward: -122.59, Step time: 0.765s\n",
            "[Step 89] VRMS: 10.93, THD: 5.367, Reward: -1846.59, Step time: 0.802s\n",
            "[Step 90] VRMS: 9.93, THD: 0.983, Reward: -2014.65, Step time: 0.947s\n",
            "[Step 91] VRMS: 34.73, THD: 0.236, Reward: -111.77, Step time: 1.112s\n",
            "[Step 92] VRMS: 28.67, THD: 0.325, Reward: -8.96, Step time: 1.196s\n",
            "[Step 93] VRMS: 10.25, THD: 3.384, Reward: -1961.40, Step time: 0.767s\n",
            "[Step 94] VRMS: 27.43, THD: 0.334, Reward: -33.25, Step time: 0.785s\n",
            "[Step 95] VRMS: 10.35, THD: 0.738, Reward: -1932.03, Step time: 0.777s\n",
            "[Step 96] VRMS: 9.71, THD: 3.339, Reward: -2069.70, Step time: 0.774s\n",
            "[Step 97] VRMS: 9.60, THD: 3.008, Reward: -2090.18, Step time: 0.773s\n",
            "[Step 98] VRMS: 30.83, THD: 0.275, Reward: -3.50, Step time: 0.796s\n",
            "[Step 99] VRMS: 18.06, THD: 0.523, Reward: -713.45, Step time: 0.745s\n",
            "[Step 100] VRMS: 30.02, THD: 0.280, Reward: -0.08, Step time: 0.771s\n",
            "[Step 1] VRMS: 9.61, THD: 6.178, Reward: -2116.03, Step time: 0.763s\n",
            "[Step 2] VRMS: 33.32, THD: 0.296, Reward: -55.30, Step time: 0.774s\n",
            "[Step 3] VRMS: 25.46, THD: 0.468, Reward: -103.44, Step time: 0.761s\n",
            "[Step 4] VRMS: 18.52, THD: 0.704, Reward: -659.51, Step time: 0.801s\n",
            "[Step 5] VRMS: 9.60, THD: 3.290, Reward: -2091.89, Step time: 0.862s\n",
            "[Step 6] VRMS: 27.56, THD: 0.430, Reward: -29.93, Step time: 1.105s\n",
            "[Step 7] VRMS: 33.33, THD: 0.297, Reward: -55.50, Step time: 1.206s\n",
            "[Step 8] VRMS: 19.82, THD: 0.536, Reward: -518.29, Step time: 0.843s\n",
            "[Step 9] VRMS: 13.88, THD: 1.737, Reward: -1302.81, Step time: 0.791s\n",
            "[Step 10] VRMS: 26.74, THD: 0.446, Reward: -53.40, Step time: 0.767s\n",
            "[Step 11] VRMS: 19.54, THD: 0.594, Reward: -547.60, Step time: 0.781s\n",
            "[Step 12] VRMS: 33.46, THD: 0.291, Reward: -59.90, Step time: 0.762s\n",
            "[Step 13] VRMS: 32.50, THD: 0.301, Reward: -31.25, Step time: 0.758s\n",
            "[Step 14] VRMS: 31.58, THD: 0.310, Reward: -12.55, Step time: 0.770s\n",
            "[Step 15] VRMS: 28.32, THD: 0.408, Reward: -14.30, Step time: 0.764s\n",
            "[Step 16] VRMS: 33.38, THD: 0.292, Reward: -57.07, Step time: 0.784s\n",
            "[Step 17] VRMS: 16.67, THD: 0.984, Reward: -889.14, Step time: 0.762s\n",
            "[Step 18] VRMS: 9.59, THD: 3.213, Reward: -2093.46, Step time: 0.770s\n",
            "[Step 19] VRMS: 19.85, THD: 0.539, Reward: -515.46, Step time: 0.817s\n",
            "[Step 20] VRMS: 9.68, THD: 3.194, Reward: -2075.49, Step time: 0.817s\n",
            "[Step 21] VRMS: 9.58, THD: 3.001, Reward: -2093.31, Step time: 1.182s\n",
            "[Step 22] VRMS: 19.08, THD: 0.637, Reward: -597.05, Step time: 1.191s\n",
            "[Step 23] VRMS: 33.37, THD: 0.289, Reward: -56.74, Step time: 0.945s\n",
            "[Step 24] VRMS: 19.79, THD: 0.560, Reward: -521.35, Step time: 0.788s\n",
            "[Step 25] VRMS: 9.68, THD: 3.194, Reward: -2075.60, Step time: 0.757s\n",
            "[Step 26] VRMS: 23.05, THD: 0.511, Reward: -241.83, Step time: 0.777s\n",
            "[Step 27] VRMS: 9.64, THD: 10.255, Reward: -2177.16, Step time: 0.778s\n",
            "[Step 28] VRMS: 33.48, THD: 0.285, Reward: -60.69, Step time: 0.800s\n",
            "[Step 29] VRMS: 27.03, THD: 0.458, Reward: -44.46, Step time: 0.757s\n",
            "[Step 30] VRMS: 31.25, THD: 0.312, Reward: -7.87, Step time: 0.791s\n",
            "[Step 31] VRMS: 18.05, THD: 0.713, Reward: -715.07, Step time: 0.798s\n",
            "[Step 32] VRMS: 9.59, THD: 5.160, Reward: -2109.56, Step time: 0.808s\n",
            "[Step 33] VRMS: 9.58, THD: 3.000, Reward: -2093.35, Step time: 0.771s\n",
            "[Step 34] VRMS: 9.58, THD: 3.005, Reward: -2093.36, Step time: 0.778s\n",
            "[Step 35] VRMS: 17.16, THD: 0.730, Reward: -824.88, Step time: 0.769s\n",
            "[Step 36] VRMS: 32.65, THD: 0.292, Reward: -35.19, Step time: 1.121s\n",
            "[Step 37] VRMS: 25.80, THD: 0.440, Reward: -88.46, Step time: 1.148s\n",
            "[Step 38] VRMS: 26.49, THD: 0.410, Reward: -61.80, Step time: 0.988s\n",
            "[Step 39] VRMS: 9.57, THD: 3.203, Reward: -2097.12, Step time: 0.791s\n",
            "[Step 40] VRMS: 18.88, THD: 0.554, Reward: -618.86, Step time: 0.765s\n",
            "[Step 41] VRMS: 13.75, THD: 0.932, Reward: -1320.65, Step time: 0.778s\n",
            "[Step 42] VRMS: 34.31, THD: 0.252, Reward: -92.83, Step time: 0.761s\n",
            "[Step 43] VRMS: 20.98, THD: 0.456, Reward: -406.65, Step time: 0.762s\n",
            "[Step 44] VRMS: 24.43, THD: 0.387, Reward: -155.23, Step time: 0.749s\n",
            "[Step 45] VRMS: 9.71, THD: 1.173, Reward: -2059.58, Step time: 0.767s\n",
            "[Step 46] VRMS: 16.97, THD: 0.638, Reward: -848.89, Step time: 0.819s\n",
            "[Step 47] VRMS: 18.57, THD: 0.556, Reward: -653.42, Step time: 0.786s\n",
            "[Step 48] VRMS: 20.09, THD: 0.451, Reward: -491.16, Step time: 0.823s\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -7.66e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1            |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 1745         |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047468334 |\n",
            "|    clip_fraction        | 0.00996      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -4.05e-06    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.53e+07     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00901     |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 1.35e+08     |\n",
            "------------------------------------------\n",
            "\n",
            "--- Training Complete in 1745.81 seconds ---\n",
            "\n",
            "--- Evaluating Trained Agent ---\n",
            "\n",
            "Environment using device: cpu\n",
            "[Step 1] VRMS: 19.39, THD: 0.567, Reward: -563.19, Step time: 0.810s\n",
            "[Step 2] VRMS: 19.77, THD: 0.526, Reward: -523.76, Step time: 1.158s\n",
            "[Step 3] VRMS: 19.76, THD: 0.532, Reward: -524.65, Step time: 1.179s\n",
            "[Step 4] VRMS: 19.76, THD: 0.532, Reward: -524.73, Step time: 1.194s\n",
            "[Step 5] VRMS: 19.76, THD: 0.532, Reward: -524.71, Step time: 0.791s\n",
            "[Step 6] VRMS: 19.76, THD: 0.532, Reward: -524.70, Step time: 0.819s\n",
            "[Step 7] VRMS: 19.76, THD: 0.532, Reward: -524.70, Step time: 0.873s\n",
            "[Step 8] VRMS: 19.76, THD: 0.532, Reward: -524.70, Step time: 0.788s\n",
            "[Step 9] VRMS: 19.78, THD: 0.530, Reward: -522.12, Step time: 0.795s\n",
            "[Step 10] VRMS: 19.78, THD: 0.530, Reward: -522.11, Step time: 0.811s\n",
            "[Step 11] VRMS: 19.78, THD: 0.530, Reward: -522.10, Step time: 0.813s\n",
            "[Step 12] VRMS: 19.78, THD: 0.530, Reward: -522.09, Step time: 0.825s\n",
            "[Step 13] VRMS: 19.78, THD: 0.530, Reward: -522.09, Step time: 0.778s\n",
            "[Step 14] VRMS: 19.76, THD: 0.532, Reward: -524.64, Step time: 0.782s\n",
            "[Step 15] VRMS: 19.81, THD: 0.529, Reward: -519.35, Step time: 0.790s\n",
            "[Step 16] VRMS: 19.78, THD: 0.529, Reward: -522.23, Step time: 0.816s\n",
            "[Step 17] VRMS: 19.78, THD: 0.530, Reward: -522.06, Step time: 1.154s\n",
            "[Step 18] VRMS: 19.81, THD: 0.529, Reward: -519.30, Step time: 1.132s\n",
            "[Step 19] VRMS: 19.78, THD: 0.529, Reward: -522.26, Step time: 0.925s\n",
            "[Step 20] VRMS: 19.78, THD: 0.530, Reward: -522.04, Step time: 0.767s\n",
            "[Step 21] VRMS: 19.78, THD: 0.530, Reward: -522.04, Step time: 0.793s\n",
            "[Step 22] VRMS: 19.77, THD: 0.531, Reward: -523.26, Step time: 0.794s\n",
            "[Step 23] VRMS: 19.78, THD: 0.529, Reward: -522.28, Step time: 0.819s\n",
            "[Step 24] VRMS: 19.75, THD: 0.532, Reward: -526.07, Step time: 0.745s\n",
            "[Step 25] VRMS: 19.75, THD: 0.532, Reward: -526.06, Step time: 0.788s\n",
            "[Step 26] VRMS: 19.75, THD: 0.532, Reward: -526.06, Step time: 0.772s\n",
            "[Step 27] VRMS: 19.76, THD: 0.531, Reward: -524.48, Step time: 0.801s\n",
            "[Step 28] VRMS: 19.82, THD: 0.528, Reward: -518.22, Step time: 0.780s\n",
            "[Step 29] VRMS: 19.78, THD: 0.526, Reward: -522.97, Step time: 0.812s\n",
            "[Step 30] VRMS: 20.12, THD: 0.504, Reward: -488.25, Step time: 0.788s\n",
            "[Step 31] VRMS: 20.06, THD: 0.498, Reward: -494.16, Step time: 0.819s\n",
            "[Step 32] VRMS: 20.45, THD: 0.484, Reward: -455.98, Step time: 1.166s\n",
            "[Step 33] VRMS: 20.35, THD: 0.485, Reward: -465.40, Step time: 1.167s\n",
            "[Step 34] VRMS: 20.53, THD: 0.474, Reward: -448.51, Step time: 0.951s\n",
            "[Step 35] VRMS: 20.64, THD: 0.472, Reward: -438.45, Step time: 0.800s\n",
            "[Step 36] VRMS: 20.71, THD: 0.466, Reward: -431.45, Step time: 0.759s\n",
            "[Step 37] VRMS: 20.73, THD: 0.462, Reward: -430.30, Step time: 0.791s\n",
            "[Step 38] VRMS: 20.75, THD: 0.460, Reward: -427.76, Step time: 0.775s\n",
            "[Step 39] VRMS: 20.85, THD: 0.449, Reward: -419.19, Step time: 0.819s\n",
            "[Step 40] VRMS: 20.82, THD: 0.445, Reward: -421.56, Step time: 0.781s\n",
            "[Step 41] VRMS: 20.89, THD: 0.437, Reward: -415.17, Step time: 0.801s\n",
            "[Step 42] VRMS: 21.02, THD: 0.429, Reward: -403.05, Step time: 0.777s\n",
            "[Step 43] VRMS: 20.81, THD: 0.429, Reward: -422.69, Step time: 0.805s\n",
            "[Step 44] VRMS: 21.05, THD: 0.422, Reward: -401.13, Step time: 0.787s\n",
            "[Step 45] VRMS: 20.89, THD: 0.413, Reward: -415.25, Step time: 0.829s\n",
            "[Step 46] VRMS: 20.95, THD: 0.413, Reward: -409.84, Step time: 0.883s\n",
            "[Step 47] VRMS: 21.12, THD: 0.403, Reward: -394.36, Step time: 1.118s\n",
            "[Step 48] VRMS: 21.04, THD: 0.401, Reward: -401.55, Step time: 1.162s\n",
            "[Step 49] VRMS: 21.10, THD: 0.395, Reward: -396.22, Step time: 0.883s\n",
            "[Step 50] VRMS: 21.20, THD: 0.382, Reward: -387.67, Step time: 0.780s\n",
            "[Step 51] VRMS: 21.18, THD: 0.383, Reward: -388.90, Step time: 0.776s\n",
            "[Step 52] VRMS: 21.22, THD: 0.389, Reward: -385.75, Step time: 0.773s\n",
            "[Step 53] VRMS: 21.13, THD: 0.393, Reward: -393.87, Step time: 0.801s\n",
            "[Step 54] VRMS: 21.09, THD: 0.399, Reward: -397.07, Step time: 0.775s\n",
            "[Step 55] VRMS: 21.08, THD: 0.408, Reward: -397.95, Step time: 0.779s\n",
            "[Step 56] VRMS: 20.96, THD: 0.423, Reward: -408.99, Step time: 0.759s\n",
            "[Step 57] VRMS: 20.95, THD: 0.424, Reward: -409.91, Step time: 0.788s\n",
            "[Step 58] VRMS: 20.90, THD: 0.432, Reward: -414.59, Step time: 0.799s\n",
            "[Step 59] VRMS: 20.81, THD: 0.445, Reward: -422.73, Step time: 0.822s\n",
            "[Step 60] VRMS: 20.72, THD: 0.441, Reward: -430.82, Step time: 0.800s\n",
            "[Step 61] VRMS: 20.67, THD: 0.450, Reward: -435.65, Step time: 0.820s\n",
            "[Step 62] VRMS: 20.68, THD: 0.454, Reward: -434.81, Step time: 1.142s\n",
            "[Step 63] VRMS: 20.59, THD: 0.463, Reward: -442.69, Step time: 1.194s\n",
            "[Step 64] VRMS: 20.53, THD: 0.468, Reward: -448.46, Step time: 0.915s\n",
            "[Step 65] VRMS: 20.61, THD: 0.475, Reward: -441.23, Step time: 0.785s\n",
            "[Step 66] VRMS: 20.32, THD: 0.481, Reward: -468.76, Step time: 0.778s\n",
            "[Step 67] VRMS: 20.10, THD: 0.494, Reward: -489.88, Step time: 0.787s\n",
            "[Step 68] VRMS: 19.97, THD: 0.501, Reward: -502.99, Step time: 0.810s\n",
            "[Step 69] VRMS: 19.82, THD: 0.517, Reward: -518.24, Step time: 0.786s\n",
            "[Step 70] VRMS: 19.81, THD: 0.521, Reward: -518.96, Step time: 0.794s\n",
            "[Step 71] VRMS: 19.86, THD: 0.519, Reward: -514.53, Step time: 0.778s\n",
            "[Step 72] VRMS: 19.80, THD: 0.528, Reward: -520.38, Step time: 0.809s\n",
            "[Step 73] VRMS: 19.79, THD: 0.523, Reward: -521.22, Step time: 0.808s\n",
            "[Step 74] VRMS: 19.94, THD: 0.507, Reward: -506.07, Step time: 0.797s\n",
            "[Step 75] VRMS: 19.93, THD: 0.505, Reward: -507.28, Step time: 0.801s\n",
            "[Step 76] VRMS: 20.22, THD: 0.483, Reward: -478.07, Step time: 0.834s\n",
            "[Step 77] VRMS: 20.68, THD: 0.475, Reward: -434.27, Step time: 1.165s\n",
            "[Step 78] VRMS: 20.54, THD: 0.473, Reward: -448.11, Step time: 1.268s\n",
            "[Step 79] VRMS: 20.41, THD: 0.469, Reward: -460.27, Step time: 0.891s\n",
            "[Step 80] VRMS: 20.54, THD: 0.456, Reward: -447.82, Step time: 0.829s\n",
            "[Step 81] VRMS: 20.77, THD: 0.448, Reward: -426.50, Step time: 0.825s\n",
            "[Step 82] VRMS: 20.65, THD: 0.446, Reward: -436.96, Step time: 0.794s\n",
            "[Step 83] VRMS: 20.77, THD: 0.439, Reward: -425.83, Step time: 0.783s\n",
            "[Step 84] VRMS: 20.88, THD: 0.430, Reward: -416.04, Step time: 0.768s\n",
            "[Step 85] VRMS: 21.05, THD: 0.422, Reward: -401.09, Step time: 0.759s\n",
            "[Step 86] VRMS: 20.99, THD: 0.424, Reward: -406.42, Step time: 0.772s\n",
            "[Step 87] VRMS: 20.98, THD: 0.421, Reward: -407.29, Step time: 0.761s\n",
            "[Step 88] VRMS: 20.97, THD: 0.409, Reward: -407.73, Step time: 0.749s\n",
            "[Step 89] VRMS: 21.07, THD: 0.398, Reward: -398.92, Step time: 0.779s\n",
            "[Step 90] VRMS: 21.06, THD: 0.396, Reward: -399.73, Step time: 0.770s\n",
            "[Step 91] VRMS: 21.27, THD: 0.387, Reward: -381.15, Step time: 0.751s\n",
            "[Step 92] VRMS: 21.23, THD: 0.389, Reward: -384.89, Step time: 1.129s\n",
            "[Step 93] VRMS: 21.29, THD: 0.380, Reward: -379.30, Step time: 1.121s\n",
            "[Step 94] VRMS: 21.28, THD: 0.376, Reward: -380.76, Step time: 0.958s\n",
            "[Step 95] VRMS: 21.33, THD: 0.364, Reward: -376.24, Step time: 0.790s\n",
            "[Step 96] VRMS: 21.41, THD: 0.362, Reward: -368.90, Step time: 0.795s\n",
            "[Step 97] VRMS: 21.52, THD: 0.355, Reward: -359.37, Step time: 0.771s\n",
            "[Step 98] VRMS: 21.47, THD: 0.352, Reward: -363.73, Step time: 0.758s\n",
            "[Step 99] VRMS: 21.56, THD: 0.343, Reward: -356.17, Step time: 0.806s\n",
            "[Step 100] VRMS: 21.41, THD: 0.338, Reward: -368.66, Step time: 0.797s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# STEP 1: Install Required Packages (Uncomment if running in Colab)\n",
        "# ========================================================================\n",
        "# !pip install gymnasium stable-baselines3[extra] torch matplotlib -q\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "# ========================================================================\n",
        "# STEP 2: Define the GPU-Accelerated Inverter Model\n",
        "# ========================================================================\n",
        "class InverterModelGPU:\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device)\n",
        "        self.L = torch.tensor(1.5e-3, device=device)\n",
        "        self.C = torch.tensor(10e-6, device=device)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "\n",
        "        self.state = torch.zeros(2, device=device)\n",
        "        self.sim_time = torch.tensor(0.0, device=device)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    def batch_step_rk4(self, modulation_index, r_load, num_steps, dt=1e-5):\n",
        "        t_steps = self.sim_time + torch.arange(num_steps, device=self.device) * dt\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * t_steps)\n",
        "        carrier = 2 * (torch.abs(2 * ((t_steps / self.pwm_period) - torch.floor(0.5 + t_steps / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "\n",
        "        y = self.state.clone()\n",
        "        outputs = torch.zeros(num_steps, 2, device=self.device)\n",
        "\n",
        "        for i in range(num_steps):\n",
        "            v_inv_step = v_inverter[i] - torch.sign(v_inverter[i]) * y[0] * self.Rds_on\n",
        "            k1 = self._diffeq(y, v_inv_step, r_load)\n",
        "            k2 = self._diffeq(y + 0.5 * dt * k1, v_inv_step, r_load)\n",
        "            k3 = self._diffeq(y + 0.5 * dt * k2, v_inv_step, r_load)\n",
        "            k4 = self._diffeq(y + dt * k3, v_inv_step, r_load)\n",
        "            y = y + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "            outputs[i] = y\n",
        "\n",
        "        self.state = outputs[-1]\n",
        "        self.sim_time += num_steps * dt\n",
        "        return outputs\n",
        "\n",
        "# ========================================================================\n",
        "# STEP 3: Define the Gym-Compatible RL Environment\n",
        "# ========================================================================\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Environment using device: {self.device}\")\n",
        "        self.inverter = InverterModelGPU(device=self.device)\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, history_gpu):\n",
        "        v_history_gpu, i_history_gpu = history_gpu[:, 1], history_gpu[:, 0]\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        harmonics = torch.abs(fft[1:11])\n",
        "        fundamental = harmonics[0]\n",
        "        higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "        thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        return torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device)\n",
        "        return np.zeros(5, dtype=np.float32), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        start = time.time()\n",
        "\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device)\n",
        "        history_gpu = self.inverter.batch_step_rk4(modulation_index, self.load_resistance, self.sim_steps_per_cycle)\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(history_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        print(f\"[Step {self.current_step}] VRMS: {v_rms:.2f}, THD: {thd:.3f}, Reward: {reward:.2f}, Step time: {time.time() - start:.3f}s\")\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}\n",
        "\n",
        "# ========================================================================\n",
        "# STEP 4: Train the PPO Agent on GPU\n",
        "# ========================================================================\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\n--- Starting GPU-Based Inverter RL Training ---\\n\")\n",
        "\n",
        "    env = InverterEnvGPU()\n",
        "\n",
        "    model = PPO(\n",
        "        \"MlpPolicy\",\n",
        "        env,\n",
        "        verbose=1,\n",
        "        device=\"cuda\",\n",
        "        n_steps=1024,\n",
        "        batch_size=64,\n",
        "        tensorboard_log=\"./ppo_inverter_tensorboard/\"\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.learn(total_timesteps=2000)  # QUICK TEST\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f\"\\n--- Training Complete in {end_time - start_time:.2f} seconds ---\")\n",
        "    model.save(\"ppo_inverter_model\")\n",
        "    env.close()\n",
        "\n",
        "    # ================= Evaluate and Plot =================\n",
        "    print(\"\\n--- Evaluating Trained Agent ---\\n\")\n",
        "    env = InverterEnvGPU()\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    rewards = []\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, _, _ = env.step(action)\n",
        "        rewards.append(reward)\n",
        "\n",
        "    plt.plot(rewards)\n",
        "    plt.title(\"Reward per Step (Trained Agent)\")\n",
        "    plt.xlabel(\"Step\")\n",
        "    plt.ylabel(\"Reward\")\n",
        "    plt.grid()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwEX7nbWyhWe"
      },
      "source": [
        "# ***After Debugging***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA_aVlIZj0uM",
        "outputId": "c1b255cb-ccd6-4bf0-885e-64d60f294220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install gym\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f0-Z34fxtTw",
        "outputId": "99da9dfe-d1dc-4406-efac-8fc994f5e5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.7.0)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.3.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3[extra] gym numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wUJQAK24xtko"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "\n",
        "class InverterEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(InverterEnv, self).__init__()\n",
        "        self.V_REF = 34.0  # Target VRMS\n",
        "        self.THD_REF = 0.3 # Acceptable THD level\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=np.array([0, 0]), high=np.array([100, 100]), dtype=np.float32)\n",
        "\n",
        "        self.step_count = 0\n",
        "        self.max_steps = 200\n",
        "\n",
        "    def step(self, action):\n",
        "        pulse_width = float(action[0]) * 10 + 50  # Simulated PWM (40 to 60)\n",
        "\n",
        "        vrms = self.V_REF + np.random.randn() * 5 - 0.2 * abs(pulse_width - 50)\n",
        "        thd = self.THD_REF + np.random.randn() * 0.1 + 0.05 * abs(pulse_width - 50)\n",
        "\n",
        "        reward = - (abs(vrms - self.V_REF) + 100 * thd)\n",
        "\n",
        "        self.step_count += 1\n",
        "        done = self.step_count >= self.max_steps\n",
        "        info = {'vrms': vrms, 'thd': thd}\n",
        "\n",
        "        return np.array([vrms, thd], dtype=np.float32), reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        self.step_count = 0\n",
        "        return np.array([self.V_REF, self.THD_REF], dtype=np.float32)\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aEg4ZvU9x8Ts"
      },
      "outputs": [],
      "source": [
        "!pip install gym shimmy stable-baselines3[extra] torch --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEHOdDC2xwEE",
        "outputId": "b0fdabc2-255e-473f-dce9-2277a9c0f497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Using cpu device\n",
            "Logging to ./ppo_inverter_tensorboard/PPO_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1022 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 2    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 768          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059186695 |\n",
            "|    clip_fraction        | 0.0332       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -4.77e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.15e+05     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.0036      |\n",
            "|    std                  | 0.989        |\n",
            "|    value_loss           | 1.04e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 746          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 8            |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038300331 |\n",
            "|    clip_fraction        | 0.0223       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | -1.55e-06    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.12e+05     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00251     |\n",
            "|    std                  | 0.976        |\n",
            "|    value_loss           | 1.03e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 731          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018828779 |\n",
            "|    clip_fraction        | 0.00479      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.82e+05     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.000974    |\n",
            "|    std                  | 0.956        |\n",
            "|    value_loss           | 1.03e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 699         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 14          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004839648 |\n",
            "|    clip_fraction        | 0.0186      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | -4.77e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.23e+05    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00174    |\n",
            "|    std                  | 0.947       |\n",
            "|    value_loss           | 1.02e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 701         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 17          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002498228 |\n",
            "|    clip_fraction        | 0.00937     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.13e+05    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00108    |\n",
            "|    std                  | 0.934       |\n",
            "|    value_loss           | 1.02e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 702          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014281274 |\n",
            "|    clip_fraction        | 0.00161      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.99e+05     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000937    |\n",
            "|    std                  | 0.912        |\n",
            "|    value_loss           | 1.04e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 699          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022472332 |\n",
            "|    clip_fraction        | 0.0022       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.32        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.32e+05     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.000387    |\n",
            "|    std                  | 0.902        |\n",
            "|    value_loss           | 1e+06        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 682          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 27           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017197451 |\n",
            "|    clip_fraction        | 0.00293      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.83e+05     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00044     |\n",
            "|    std                  | 0.889        |\n",
            "|    value_loss           | 9.94e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 687          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062458995 |\n",
            "|    clip_fraction        | 0.0516       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.83e+05     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00546     |\n",
            "|    std                  | 0.862        |\n",
            "|    value_loss           | 9.55e+05     |\n",
            "------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import DummyVecEnv\n",
        "import torch\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Wrap env\n",
        "env = DummyVecEnv([lambda: InverterEnv()])\n",
        "\n",
        "# Define PPO agent\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./ppo_inverter_tensorboard/\", device=device)\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=20000)\n",
        "model.save(\"ppo_inverter_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YElvvruxxql",
        "outputId": "7ed2369e-e91f-441c-ba0e-4e2be7dc037d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation ---\n",
            "[Step 1] VRMS: 36.72, THD: 0.332, Reward: -35.88\n",
            "[Step 2] VRMS: 29.99, THD: 0.078, Reward: -11.76\n",
            "[Step 3] VRMS: 34.70, THD: 0.218, Reward: -22.46\n",
            "[Step 4] VRMS: 33.26, THD: 0.321, Reward: -32.85\n",
            "[Step 5] VRMS: 37.83, THD: 0.224, Reward: -26.26\n",
            "[Step 6] VRMS: 28.98, THD: 0.312, Reward: -36.18\n",
            "[Step 7] VRMS: 24.51, THD: 0.195, Reward: -29.00\n",
            "[Step 8] VRMS: 27.64, THD: 0.571, Reward: -63.42\n",
            "[Step 9] VRMS: 27.59, THD: 0.525, Reward: -58.88\n",
            "[Step 10] VRMS: 36.66, THD: 0.351, Reward: -37.80\n",
            "[Step 11] VRMS: 36.25, THD: 0.463, Reward: -48.51\n",
            "[Step 12] VRMS: 29.69, THD: 0.293, Reward: -33.62\n",
            "[Step 13] VRMS: 34.57, THD: 0.217, Reward: -22.31\n",
            "[Step 14] VRMS: 36.61, THD: 0.116, Reward: -14.17\n",
            "[Step 15] VRMS: 31.57, THD: 0.221, Reward: -24.50\n",
            "[Step 16] VRMS: 31.97, THD: 0.207, Reward: -22.68\n",
            "[Step 17] VRMS: 29.62, THD: 0.342, Reward: -38.55\n",
            "[Step 18] VRMS: 34.64, THD: 0.317, Reward: -32.30\n",
            "[Step 19] VRMS: 41.21, THD: 0.399, Reward: -47.08\n",
            "[Step 20] VRMS: 38.83, THD: 0.071, Reward: -11.89\n",
            "\n",
            "Total Evaluation Reward: -650.07\n"
          ]
        }
      ],
      "source": [
        "env = InverterEnv()\n",
        "obs = env.reset()\n",
        "total_reward = 0\n",
        "\n",
        "print(\"\\n--- Evaluation ---\")\n",
        "for step in range(20):\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    total_reward += reward\n",
        "    print(f\"[Step {step+1}] VRMS: {info['vrms']:.2f}, THD: {info['thd']:.3f}, Reward: {reward:.2f}\")\n",
        "    if done:\n",
        "        break\n",
        "\n",
        "print(f\"\\nTotal Evaluation Reward: {total_reward:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xaSHwLi7yD_J"
      },
      "outputs": [],
      "source": [
        "class InverterEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = gym.spaces.Box(low=np.array([0, 0]), high=np.array([100, 100]), dtype=np.float32)\n",
        "        self.state = np.array([0.0, 0.0], dtype=np.float32)\n",
        "        self.step_count = 0\n",
        "        self.max_steps = 200\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        super().reset(seed=seed)  # optional but recommended\n",
        "        self.step_count = 0\n",
        "        self.state = np.array([50.0 + np.random.randn(), 0.1 + 0.05 * np.random.randn()], dtype=np.float32)\n",
        "        return self.state, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        self.step_count += 1\n",
        "        modulation = np.clip(action[0], -1, 1)\n",
        "\n",
        "        vrms = 50 + 10 * modulation + np.random.randn()\n",
        "        thd = max(0.1, 1.0 - modulation + 0.1 * np.random.randn())\n",
        "\n",
        "        self.state = np.array([vrms, thd], dtype=np.float32)\n",
        "        reward = -thd - 0.2 * abs(vrms - 50)\n",
        "        done = self.step_count >= self.max_steps\n",
        "\n",
        "        return self.state, reward, done, False, {}\n",
        "\n",
        "    def render(self):\n",
        "        print(f\"VRMS: {self.state[0]:.2f}, THD: {self.state[1]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es3QPkZ0yeUr",
        "outputId": "67ddaec1-1266-47e9-f081-3a1d7cdbce49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 100       |\n",
            "|    ep_rew_mean     | -4.13e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 1512      |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 1         |\n",
            "|    total_timesteps | 2048      |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -2.9e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1029        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007774613 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 2.68e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.39e+05    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0116     |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.47e+06    |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=5000, episode_reward=-0.58 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.585      |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 5000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008698413 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | -0.002      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.24e+04    |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0169     |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.41e+05    |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 100       |\n",
            "|    ep_rew_mean     | -2.22e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 798       |\n",
            "|    iterations      | 3         |\n",
            "|    time_elapsed    | 7         |\n",
            "|    total_timesteps | 6144      |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -1.76e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 790         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009590582 |\n",
            "|    clip_fraction        | 0.117       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | -0.00465    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.14e+04    |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0179     |\n",
            "|    std                  | 0.981       |\n",
            "|    value_loss           | 6.15e+04    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=-0.01 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.00661    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 10000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011279607 |\n",
            "|    clip_fraction        | 0.15        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | -0.000155   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.46e+03    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0213     |\n",
            "|    std                  | 0.938       |\n",
            "|    value_loss           | 3.03e+03    |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 100       |\n",
            "|    ep_rew_mean     | -1.38e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 764       |\n",
            "|    iterations      | 5         |\n",
            "|    time_elapsed    | 13        |\n",
            "|    total_timesteps | 10240     |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -599        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 762         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014596418 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | -4.39e-05   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 217         |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0161     |\n",
            "|    std                  | 0.86        |\n",
            "|    value_loss           | 497         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -338        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 740         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009354814 |\n",
            "|    clip_fraction        | 0.0742      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.22       |\n",
            "|    explained_variance   | 1.5e-05     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 92.6        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0102     |\n",
            "|    std                  | 0.803       |\n",
            "|    value_loss           | 246         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=15000, episode_reward=-0.72 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.717       |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 15000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045885863 |\n",
            "|    clip_fraction        | 0.061        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.16        |\n",
            "|    explained_variance   | 0.000102     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 89.8         |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00765     |\n",
            "|    std                  | 0.76         |\n",
            "|    value_loss           | 206          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -162     |\n",
            "| time/              |          |\n",
            "|    fps             | 726      |\n",
            "|    iterations      | 8        |\n",
            "|    time_elapsed    | 22       |\n",
            "|    total_timesteps | 16384    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -107         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 725          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042117196 |\n",
            "|    clip_fraction        | 0.0355       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.12        |\n",
            "|    explained_variance   | -2.87e-05    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 92.6         |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.0045      |\n",
            "|    std                  | 0.737        |\n",
            "|    value_loss           | 164          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=-0.01 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.00823     |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 20000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032691937 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | -0.000161    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 120          |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00343     |\n",
            "|    std                  | 0.709        |\n",
            "|    value_loss           | 146          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -86.1    |\n",
            "| time/              |          |\n",
            "|    fps             | 715      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 28       |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "\n",
            "--- Training complete ---\n",
            "\n",
            "Step 0: State=-0.021482102572917938, Reward=-0.00046148072578944266\n",
            "Step 1: State=-0.026983465999364853, Reward=-0.0007281074649654329\n",
            "Step 2: State=-0.02839162014424801, Reward=-0.0008060840773396194\n",
            "Step 3: State=-0.028752032667398453, Reward=-0.000826679402962327\n",
            "Step 4: State=-0.028844278305768967, Reward=-0.0008319923654198647\n",
            "Step 5: State=-0.02886788733303547, Reward=-0.0008333548903465271\n",
            "Step 6: State=-0.028873929753899574, Reward=-0.0008337038452737033\n",
            "Step 7: State=-0.028875475749373436, Reward=-0.0008337930776178837\n",
            "Step 8: State=-0.028875872492790222, Reward=-0.0008338160114362836\n",
            "Step 9: State=-0.02887597307562828, Reward=-0.0008338218322023749\n",
            "Step 10: State=-0.02887599915266037, Reward=-0.0008338233456015587\n",
            "Step 11: State=-0.028876004740595818, Reward=-0.0008338236366398633\n",
            "Step 12: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 13: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 14: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 15: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 16: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 17: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 18: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 19: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 20: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 21: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 22: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 23: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 24: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 25: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 26: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 27: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 28: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 29: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 30: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 31: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 32: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 33: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 34: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 35: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 36: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 37: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 38: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 39: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 40: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 41: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 42: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 43: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 44: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 45: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 46: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 47: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 48: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 49: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 50: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 51: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 52: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 53: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 54: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 55: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 56: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 57: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 58: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 59: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 60: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 61: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 62: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 63: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 64: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 65: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 66: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 67: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 68: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 69: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 70: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 71: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 72: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 73: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 74: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 75: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 76: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 77: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 78: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 79: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 80: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 81: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 82: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 83: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 84: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 85: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 86: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 87: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 88: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 89: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 90: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 91: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 92: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 93: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 94: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 95: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 96: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 97: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 98: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "Step 99: State=-0.028876006603240967, Reward=-0.0008338237530551851\n",
            "\n",
            "Total Reward after 100 steps: -0.08286700397729874\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "# --- Custom Inverter Environment ---\n",
        "class InverterEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(InverterEnv, self).__init__()\n",
        "        self.observation_space = spaces.Box(low=-100.0, high=100.0, shape=(1,), dtype=np.float32)\n",
        "        self.action_space = spaces.Box(low=-10.0, high=10.0, shape=(1,), dtype=np.float32)\n",
        "        self.state = np.array([0.0], dtype=np.float32)\n",
        "        self.step_count = 0\n",
        "        self.max_steps = 100\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.state = np.array([0.0], dtype=np.float32)\n",
        "        self.step_count = 0\n",
        "        return self.state, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        self.step_count += 1\n",
        "        # Simple state update: add action to current state\n",
        "        self.state = self.state + action\n",
        "        # Example reward: negative squared state (try to keep near zero)\n",
        "        reward = -np.sum(np.square(self.state))\n",
        "        done = self.step_count >= self.max_steps\n",
        "        truncated = False  # no truncation logic for now\n",
        "        info = {}\n",
        "        return self.state, reward, done, truncated, info\n",
        "\n",
        "    def render(self):\n",
        "        print(f\"Step: {self.step_count}, State: {self.state}\")\n",
        "\n",
        "# --- Setup Environment and Model ---\n",
        "env = InverterEnv()\n",
        "eval_env = InverterEnv()\n",
        "\n",
        "# Evaluation callback to evaluate the agent every 5000 steps\n",
        "eval_callback = EvalCallback(eval_env, best_model_save_path='./logs/',\n",
        "                             log_path='./logs/', eval_freq=5000,\n",
        "                             deterministic=True, render=False)\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1, device=\"cuda\")\n",
        "\n",
        "# --- Train the model ---\n",
        "total_timesteps = 20_000  # Adjust timesteps as needed\n",
        "model.learn(total_timesteps=total_timesteps, callback=eval_callback)\n",
        "\n",
        "print(\"\\n--- Training complete ---\\n\")\n",
        "\n",
        "# --- Run a demo episode ---\n",
        "obs, info = env.reset()\n",
        "done = False\n",
        "truncated = False\n",
        "step = 0\n",
        "total_reward = 0\n",
        "\n",
        "while not (done or truncated):\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "    print(f\"Step {step}: State={obs[0]}, Reward={reward}\")\n",
        "    total_reward += reward\n",
        "    step += 1\n",
        "    if step > 100:  # safety break\n",
        "        break\n",
        "\n",
        "print(f\"\\nTotal Reward after {step} steps: {total_reward}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioeqMufGzEoN",
        "outputId": "c44a93d4-52bb-400f-a42a-9978e0f7d1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "model.save(\"ppo_inverter\")\n",
        "# later\n",
        "model = PPO.load(\"ppo_inverter\", env=env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Qt8555Qx0ktN",
        "outputId": "0d055a11-847c-42d4-fe57-bc93244ca23b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average reward over 10 episodes: -0.0829\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate over multiple episodes\n",
        "num_eval_episodes = 10\n",
        "all_rewards = []\n",
        "\n",
        "for ep in range(num_eval_episodes):\n",
        "    obs, _ = env.reset() # Modified line: extract only the observation\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    states = []\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        # The step method in the custom environment should return (observation, reward, done, truncated, info)\n",
        "        obs, reward, done, truncated, info = env.step(action) # Modified line: Unpack all return values from step\n",
        "        total_reward += reward\n",
        "        states.append(obs[0])  # Adjust indexing if needed\n",
        "    all_rewards.append(total_reward)\n",
        "    plt.plot(states, label=f\"Episode {ep+1}\")\n",
        "\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"State\")\n",
        "plt.title(\"State trajectories during evaluation episodes\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Average reward over {num_eval_episodes} episodes: {np.mean(all_rewards):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTB2wIzd1PkD",
        "outputId": "561d5760-ca0f-4023-f870-011eb05cd321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "model.save(\"ppo_trained_model\")\n",
        "print(\"Model saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HKCV7D-1Rid",
        "outputId": "a351826e-c65c-4fbc-ee89-34d26434443b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Average reward over 10 episodes: -0.0829 +/- 0.0000\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Load your saved model (optional, if you already have it in memory)\n",
        "model = PPO.load(\"ppo_trained_model\", env=env)\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "print(f\"Average reward over 10 episodes: {mean_reward:.4f} +/- {std_reward:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWhX7p_k1UK0",
        "outputId": "6d72e313-e69a-4210-9069-51de0e43c1a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Eval num_timesteps=1000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | 0        |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1000     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=2000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | 0        |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2000     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 100       |\n",
            "|    ep_rew_mean     | -4.41e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 931       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 2         |\n",
            "|    total_timesteps | 2048      |\n",
            "----------------------------------\n",
            "Eval num_timesteps=3000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.000401    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3000         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074627325 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -0.000158    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.58e+05     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.012       |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 1.12e+06     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 100       |\n",
            "|    mean_reward     | -0.000401 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 4000      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 100       |\n",
            "|    ep_rew_mean     | -3.21e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 726       |\n",
            "|    iterations      | 2         |\n",
            "|    time_elapsed    | 5         |\n",
            "|    total_timesteps | 4096      |\n",
            "----------------------------------\n",
            "Eval num_timesteps=5000, episode_reward=-0.03 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.0324     |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 5000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011033308 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | -0.00842    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.15e+05    |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0165     |\n",
            "|    std                  | 0.997       |\n",
            "|    value_loss           | 3.12e+05    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=6000, episode_reward=-0.03 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.0324  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 6000     |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 100       |\n",
            "|    ep_rew_mean     | -2.29e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 670       |\n",
            "|    iterations      | 3         |\n",
            "|    time_elapsed    | 9         |\n",
            "|    total_timesteps | 6144      |\n",
            "----------------------------------\n",
            "Eval num_timesteps=7000, episode_reward=-0.22 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.22       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 7000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011415541 |\n",
            "|    clip_fraction        | 0.119       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.39       |\n",
            "|    explained_variance   | -0.00255    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.72e+03    |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0175     |\n",
            "|    std                  | 0.957       |\n",
            "|    value_loss           | 1.6e+04     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=8000, episode_reward=-0.22 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.22    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 8000     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -1.8e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 613      |\n",
            "|    iterations      | 4        |\n",
            "|    time_elapsed    | 13       |\n",
            "|    total_timesteps | 8192     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=9000, episode_reward=-0.02 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.0176     |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 9000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012869293 |\n",
            "|    clip_fraction        | 0.163       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | -0.000481   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 774         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0222     |\n",
            "|    std                  | 0.91        |\n",
            "|    value_loss           | 2.03e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=-0.02 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.0176  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 100       |\n",
            "|    ep_rew_mean     | -1.44e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 611       |\n",
            "|    iterations      | 5         |\n",
            "|    time_elapsed    | 16        |\n",
            "|    total_timesteps | 10240     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=11000, episode_reward=-0.17 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.172      |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 11000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013726341 |\n",
            "|    clip_fraction        | 0.135       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | -0.000406   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 107         |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0175     |\n",
            "|    std                  | 0.865       |\n",
            "|    value_loss           | 491         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=12000, episode_reward=-0.17 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.172   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 12000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -612     |\n",
            "| time/              |          |\n",
            "|    fps             | 612      |\n",
            "|    iterations      | 6        |\n",
            "|    time_elapsed    | 20       |\n",
            "|    total_timesteps | 12288    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=13000, episode_reward=-0.01 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.0149     |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 13000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008992299 |\n",
            "|    clip_fraction        | 0.128       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | -4.33e-05   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 97.7        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    std                  | 0.798       |\n",
            "|    value_loss           | 231         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=14000, episode_reward=-0.01 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.0149  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 14000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -226     |\n",
            "| time/              |          |\n",
            "|    fps             | 613      |\n",
            "|    iterations      | 7        |\n",
            "|    time_elapsed    | 23       |\n",
            "|    total_timesteps | 14336    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=15000, episode_reward=-0.14 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.137      |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 15000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008828027 |\n",
            "|    clip_fraction        | 0.0826      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | -9.06e-06   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 98.9        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00779    |\n",
            "|    std                  | 0.769       |\n",
            "|    value_loss           | 180         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=16000, episode_reward=-0.14 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.137   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 16000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -148     |\n",
            "| time/              |          |\n",
            "|    fps             | 596      |\n",
            "|    iterations      | 8        |\n",
            "|    time_elapsed    | 27       |\n",
            "|    total_timesteps | 16384    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=17000, episode_reward=-0.03 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.0338      |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 17000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034573409 |\n",
            "|    clip_fraction        | 0.0312       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | -8.74e-05    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 53.3         |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00277     |\n",
            "|    std                  | 0.746        |\n",
            "|    value_loss           | 132          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=18000, episode_reward=-0.03 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.0338  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 18000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -102     |\n",
            "| time/              |          |\n",
            "|    fps             | 600      |\n",
            "|    iterations      | 9        |\n",
            "|    time_elapsed    | 30       |\n",
            "|    total_timesteps | 18432    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=19000, episode_reward=-0.18 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.184       |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 19000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029982112 |\n",
            "|    clip_fraction        | 0.0169       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.11        |\n",
            "|    explained_variance   | 4.94e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 60.4         |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00235     |\n",
            "|    std                  | 0.721        |\n",
            "|    value_loss           | 117          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=-0.18 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.184   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -80.9    |\n",
            "| time/              |          |\n",
            "|    fps             | 603      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 33       |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=21000, episode_reward=-0.01 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.0102      |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 21000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041027376 |\n",
            "|    clip_fraction        | 0.0238       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.08        |\n",
            "|    explained_variance   | -0.000414    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 60.7         |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00312     |\n",
            "|    std                  | 0.7          |\n",
            "|    value_loss           | 105          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=22000, episode_reward=-0.01 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.0102  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 22000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -67.3    |\n",
            "| time/              |          |\n",
            "|    fps             | 599      |\n",
            "|    iterations      | 11       |\n",
            "|    time_elapsed    | 37       |\n",
            "|    total_timesteps | 22528    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=23000, episode_reward=-0.29 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.288       |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 23000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034126146 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.05        |\n",
            "|    explained_variance   | -0.000113    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 35.7         |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    std                  | 0.679        |\n",
            "|    value_loss           | 89.8         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=24000, episode_reward=-0.29 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.288   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 24000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -60      |\n",
            "| time/              |          |\n",
            "|    fps             | 595      |\n",
            "|    iterations      | 12       |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 24576    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=25000, episode_reward=-0.24 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.242      |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 25000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002835372 |\n",
            "|    clip_fraction        | 0.0298      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.02       |\n",
            "|    explained_variance   | -0.00311    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 25.8        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00228    |\n",
            "|    std                  | 0.663       |\n",
            "|    value_loss           | 69.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=26000, episode_reward=-0.24 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.242   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 26000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.2    |\n",
            "| time/              |          |\n",
            "|    fps             | 598      |\n",
            "|    iterations      | 13       |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total_timesteps | 26624    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=27000, episode_reward=-0.03 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.029      |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 27000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003615528 |\n",
            "|    clip_fraction        | 0.0379      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.994      |\n",
            "|    explained_variance   | -0.00012    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 25.9        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00598    |\n",
            "|    std                  | 0.644       |\n",
            "|    value_loss           | 66.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=28000, episode_reward=-0.03 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.029   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 28000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -51.5    |\n",
            "| time/              |          |\n",
            "|    fps             | 599      |\n",
            "|    iterations      | 14       |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 28672    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=29000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.00303     |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 29000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018428189 |\n",
            "|    clip_fraction        | 0.00571      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.96        |\n",
            "|    explained_variance   | -3.09e-05    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 26.1         |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.0022      |\n",
            "|    std                  | 0.62         |\n",
            "|    value_loss           | 55           |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.00303 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -47      |\n",
            "| time/              |          |\n",
            "|    fps             | 591      |\n",
            "|    iterations      | 15       |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 30720    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=31000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.000492    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 31000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023531844 |\n",
            "|    clip_fraction        | 0.0154       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.924       |\n",
            "|    explained_variance   | 0.000323     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 38.7         |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00246     |\n",
            "|    std                  | 0.601        |\n",
            "|    value_loss           | 47.8         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=32000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 100       |\n",
            "|    mean_reward     | -0.000492 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 32000     |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -43.8    |\n",
            "| time/              |          |\n",
            "|    fps             | 593      |\n",
            "|    iterations      | 16       |\n",
            "|    time_elapsed    | 55       |\n",
            "|    total_timesteps | 32768    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=33000, episode_reward=-0.04 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 100         |\n",
            "|    mean_reward          | -0.0401     |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 33000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002905928 |\n",
            "|    clip_fraction        | 0.0121      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.894      |\n",
            "|    explained_variance   | -0.0026     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14.4        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00226    |\n",
            "|    std                  | 0.581       |\n",
            "|    value_loss           | 39.6        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=34000, episode_reward=-0.04 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.0401  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 34000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -40.3    |\n",
            "| time/              |          |\n",
            "|    fps             | 594      |\n",
            "|    iterations      | 17       |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 34816    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=35000, episode_reward=-0.02 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.0205      |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 35000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012286501 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.86        |\n",
            "|    explained_variance   | -0.000438    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 20.5         |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    std                  | 0.562        |\n",
            "|    value_loss           | 33.6         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=36000, episode_reward=-0.02 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.0205  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 36000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -37.4    |\n",
            "| time/              |          |\n",
            "|    fps             | 592      |\n",
            "|    iterations      | 18       |\n",
            "|    time_elapsed    | 62       |\n",
            "|    total_timesteps | 36864    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=37000, episode_reward=-0.13 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.126       |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 37000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027710441 |\n",
            "|    clip_fraction        | 0.026        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.826       |\n",
            "|    explained_variance   | -5.54e-05    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 17.2         |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00269     |\n",
            "|    std                  | 0.543        |\n",
            "|    value_loss           | 26.5         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=38000, episode_reward=-0.13 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.126   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 38000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -34.5    |\n",
            "| time/              |          |\n",
            "|    fps             | 587      |\n",
            "|    iterations      | 19       |\n",
            "|    time_elapsed    | 66       |\n",
            "|    total_timesteps | 38912    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=39000, episode_reward=-0.40 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.405       |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 39000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030164404 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.79        |\n",
            "|    explained_variance   | 0.000261     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.24         |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00167     |\n",
            "|    std                  | 0.526        |\n",
            "|    value_loss           | 24.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=-0.40 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.405   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -32.7    |\n",
            "| time/              |          |\n",
            "|    fps             | 588      |\n",
            "|    iterations      | 20       |\n",
            "|    time_elapsed    | 69       |\n",
            "|    total_timesteps | 40960    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=41000, episode_reward=-0.48 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.482       |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 41000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010542991 |\n",
            "|    clip_fraction        | 0.0125       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.763       |\n",
            "|    explained_variance   | 1.36e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9            |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.000604    |\n",
            "|    std                  | 0.513        |\n",
            "|    value_loss           | 20.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=42000, episode_reward=-0.48 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.482   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 42000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=43000, episode_reward=-0.48 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.482   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 43000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -30.7    |\n",
            "| time/              |          |\n",
            "|    fps             | 588      |\n",
            "|    iterations      | 21       |\n",
            "|    time_elapsed    | 73       |\n",
            "|    total_timesteps | 43008    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=44000, episode_reward=-0.58 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.579       |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 44000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019031821 |\n",
            "|    clip_fraction        | 0.0148       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.734       |\n",
            "|    explained_variance   | 0.000949     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.47         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    std                  | 0.498        |\n",
            "|    value_loss           | 19.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=45000, episode_reward=-0.58 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.579   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 45000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -29.2    |\n",
            "| time/              |          |\n",
            "|    fps             | 582      |\n",
            "|    iterations      | 22       |\n",
            "|    time_elapsed    | 77       |\n",
            "|    total_timesteps | 45056    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=46000, episode_reward=-0.93 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.93        |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 46000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018197657 |\n",
            "|    clip_fraction        | 0.00815      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.704       |\n",
            "|    explained_variance   | -0.000692    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.06         |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    std                  | 0.481        |\n",
            "|    value_loss           | 16.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=47000, episode_reward=-0.93 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.93    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 47000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -27.9    |\n",
            "| time/              |          |\n",
            "|    fps             | 580      |\n",
            "|    iterations      | 23       |\n",
            "|    time_elapsed    | 81       |\n",
            "|    total_timesteps | 47104    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=48000, episode_reward=-0.96 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.96        |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 48000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023640408 |\n",
            "|    clip_fraction        | 0.0118       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.669       |\n",
            "|    explained_variance   | -0.000824    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.75         |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    std                  | 0.466        |\n",
            "|    value_loss           | 14.7         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=49000, episode_reward=-0.96 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.96    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 49000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -26      |\n",
            "| time/              |          |\n",
            "|    fps             | 579      |\n",
            "|    iterations      | 24       |\n",
            "|    time_elapsed    | 84       |\n",
            "|    total_timesteps | 49152    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=-0.40 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 100          |\n",
            "|    mean_reward          | -0.398       |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 50000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038932106 |\n",
            "|    clip_fraction        | 0.0339       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.634       |\n",
            "|    explained_variance   | -0.000191    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.18         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00384     |\n",
            "|    std                  | 0.451        |\n",
            "|    value_loss           | 12.9         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=51000, episode_reward=-0.40 +/- 0.00\n",
            "Episode length: 100.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 100      |\n",
            "|    mean_reward     | -0.398   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 51000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -24.2    |\n",
            "| time/              |          |\n",
            "|    fps             | 576      |\n",
            "|    iterations      | 25       |\n",
            "|    time_elapsed    | 88       |\n",
            "|    total_timesteps | 51200    |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7a6f00811850>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
        "                             log_path='./logs/', eval_freq=1000,\n",
        "                             n_eval_episodes=5, deterministic=True, render=False)\n",
        "\n",
        "model = PPO('MlpPolicy', env, verbose=1)\n",
        "model.learn(total_timesteps=50000, callback=eval_callback)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2wyUN621Uml",
        "outputId": "00063021-0828-41d9-edb7-6346e6f7cb19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -18.9    |\n",
            "| time/              |          |\n",
            "|    fps             | 1381     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -18.1        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 942          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 4            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034191618 |\n",
            "|    clip_fraction        | 0.0142       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.559       |\n",
            "|    explained_variance   | -0.000466    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.08         |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00182     |\n",
            "|    std                  | 0.416        |\n",
            "|    value_loss           | 9.69         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -17.7        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 860          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018448132 |\n",
            "|    clip_fraction        | 0.0288       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.521       |\n",
            "|    explained_variance   | 5.32e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.71         |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00344     |\n",
            "|    std                  | 0.402        |\n",
            "|    value_loss           | 8.26         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -17.2       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 782         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002543941 |\n",
            "|    clip_fraction        | 0.0128      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.488      |\n",
            "|    explained_variance   | -0.000817   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.77        |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.00242    |\n",
            "|    std                  | 0.386       |\n",
            "|    value_loss           | 7.5         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -16.5       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 746         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004918791 |\n",
            "|    clip_fraction        | 0.0346      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.451      |\n",
            "|    explained_variance   | -0.0018     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.66        |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.00413    |\n",
            "|    std                  | 0.374       |\n",
            "|    value_loss           | 6.5         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -15.3        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 734          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015731587 |\n",
            "|    clip_fraction        | 0.00747      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.419       |\n",
            "|    explained_variance   | -0.000641    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.89         |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00073     |\n",
            "|    std                  | 0.362        |\n",
            "|    value_loss           | 5.46         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -14.2        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 728          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018676665 |\n",
            "|    clip_fraction        | 0.00986      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.38        |\n",
            "|    explained_variance   | -0.000743    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.6          |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    std                  | 0.347        |\n",
            "|    value_loss           | 4.62         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -13.3        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 711          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018117542 |\n",
            "|    clip_fraction        | 0.0162       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.338       |\n",
            "|    explained_variance   | -0.000248    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.74         |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00178     |\n",
            "|    std                  | 0.334        |\n",
            "|    value_loss           | 4.09         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -12.2        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 698          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 26           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058793626 |\n",
            "|    clip_fraction        | 0.036        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.294       |\n",
            "|    explained_variance   | 0.000493     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.81         |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00379     |\n",
            "|    std                  | 0.317        |\n",
            "|    value_loss           | 3.65         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -11.3        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 700          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022584843 |\n",
            "|    clip_fraction        | 0.0145       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.248       |\n",
            "|    explained_variance   | -0.000191    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.88         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00144     |\n",
            "|    std                  | 0.304        |\n",
            "|    value_loss           | 3.1          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -10.5        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 703          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033611124 |\n",
            "|    clip_fraction        | 0.0323       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.215       |\n",
            "|    explained_variance   | -0.00106     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.943        |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00208     |\n",
            "|    std                  | 0.298        |\n",
            "|    value_loss           | 2.36         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -9.69        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 691          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 35           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044885697 |\n",
            "|    clip_fraction        | 0.0354       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.193       |\n",
            "|    explained_variance   | 0.000295     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.968        |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00341     |\n",
            "|    std                  | 0.29         |\n",
            "|    value_loss           | 2.07         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -8.83       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 685         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002032112 |\n",
            "|    clip_fraction        | 0.0112      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.156      |\n",
            "|    explained_variance   | -0.00098    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.949       |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.00158    |\n",
            "|    std                  | 0.278       |\n",
            "|    value_loss           | 1.84        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -8.23       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 686         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003159163 |\n",
            "|    clip_fraction        | 0.0304      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.11       |\n",
            "|    explained_variance   | 9.75e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.687       |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.0035     |\n",
            "|    std                  | 0.265       |\n",
            "|    value_loss           | 1.62        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -7.62       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 689         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 44          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004283259 |\n",
            "|    clip_fraction        | 0.0403      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0658     |\n",
            "|    explained_variance   | -0.00171    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.513       |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.00322    |\n",
            "|    std                  | 0.254       |\n",
            "|    value_loss           | 1.32        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -7.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 687          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 47           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043036654 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0264      |\n",
            "|    explained_variance   | -0.000597    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.435        |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00293     |\n",
            "|    std                  | 0.244        |\n",
            "|    value_loss           | 1.16         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -6.57       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 679         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005546852 |\n",
            "|    clip_fraction        | 0.0372      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.00876     |\n",
            "|    explained_variance   | 0.00023     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.256       |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00323    |\n",
            "|    std                  | 0.237       |\n",
            "|    value_loss           | 0.948       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -6.12        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 682          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 54           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024802636 |\n",
            "|    clip_fraction        | 0.0213       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.0433       |\n",
            "|    explained_variance   | 0.000368     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.541        |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00316     |\n",
            "|    std                  | 0.228        |\n",
            "|    value_loss           | 0.955        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -5.66        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 685          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 56           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033192905 |\n",
            "|    clip_fraction        | 0.0324       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.0807       |\n",
            "|    explained_variance   | -0.000939    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.332        |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.00307     |\n",
            "|    std                  | 0.22         |\n",
            "|    value_loss           | 0.753        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -5.29        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 686          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 59           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022177491 |\n",
            "|    clip_fraction        | 0.0119       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.12         |\n",
            "|    explained_variance   | -0.00106     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.343        |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.00167     |\n",
            "|    std                  | 0.211        |\n",
            "|    value_loss           | 0.625        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -4.92        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 678          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 63           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020944658 |\n",
            "|    clip_fraction        | 0.0143       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.16         |\n",
            "|    explained_variance   | -0.000412    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.24         |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    std                  | 0.203        |\n",
            "|    value_loss           | 0.538        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -4.53       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 677         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 66          |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002808155 |\n",
            "|    clip_fraction        | 0.0184      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.2         |\n",
            "|    explained_variance   | -0.00144    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.185       |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.0017     |\n",
            "|    std                  | 0.194       |\n",
            "|    value_loss           | 0.472       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -4.14        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 678          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 69           |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037247855 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.244        |\n",
            "|    explained_variance   | -0.00384     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.161        |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00285     |\n",
            "|    std                  | 0.185        |\n",
            "|    value_loss           | 0.404        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -3.77        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 679          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025585657 |\n",
            "|    clip_fraction        | 0.0136       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.286        |\n",
            "|    explained_variance   | -0.000168    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.16         |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    std                  | 0.179        |\n",
            "|    value_loss           | 0.34         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 100          |\n",
            "|    ep_rew_mean          | -3.52        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 671          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 76           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042426502 |\n",
            "|    clip_fraction        | 0.033        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.327        |\n",
            "|    explained_variance   | 0.0005       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.126        |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.00424     |\n",
            "|    std                  | 0.171        |\n",
            "|    value_loss           | 0.284        |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7a6f00811850>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model.learn(total_timesteps=50000)  # or more like 100000 for better results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9351wc7z1XbY",
        "outputId": "95ce0a13-0f1d-45b9-edc9-eff36be65555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 1, State: [0.00037559]\n",
            "Step: 2, State: [0.00034185]\n",
            "Step: 3, State: [0.00034488]\n",
            "Step: 4, State: [0.00034461]\n",
            "Step: 5, State: [0.00034463]\n",
            "Step: 6, State: [0.00034463]\n",
            "Step: 7, State: [0.00034463]\n",
            "Step: 8, State: [0.00034463]\n",
            "Step: 9, State: [0.00034463]\n",
            "Step: 10, State: [0.00034463]\n",
            "Step: 11, State: [0.00034463]\n",
            "Step: 12, State: [0.00034463]\n",
            "Step: 13, State: [0.00034463]\n",
            "Step: 14, State: [0.00034463]\n",
            "Step: 15, State: [0.00034463]\n",
            "Step: 16, State: [0.00034463]\n",
            "Step: 17, State: [0.00034463]\n",
            "Step: 18, State: [0.00034463]\n",
            "Step: 19, State: [0.00034463]\n",
            "Step: 20, State: [0.00034463]\n",
            "Step: 21, State: [0.00034463]\n",
            "Step: 22, State: [0.00034463]\n",
            "Step: 23, State: [0.00034463]\n",
            "Step: 24, State: [0.00034463]\n",
            "Step: 25, State: [0.00034463]\n",
            "Step: 26, State: [0.00034463]\n",
            "Step: 27, State: [0.00034463]\n",
            "Step: 28, State: [0.00034463]\n",
            "Step: 29, State: [0.00034463]\n",
            "Step: 30, State: [0.00034463]\n",
            "Step: 31, State: [0.00034463]\n",
            "Step: 32, State: [0.00034463]\n",
            "Step: 33, State: [0.00034463]\n",
            "Step: 34, State: [0.00034463]\n",
            "Step: 35, State: [0.00034463]\n",
            "Step: 36, State: [0.00034463]\n",
            "Step: 37, State: [0.00034463]\n",
            "Step: 38, State: [0.00034463]\n",
            "Step: 39, State: [0.00034463]\n",
            "Step: 40, State: [0.00034463]\n",
            "Step: 41, State: [0.00034463]\n",
            "Step: 42, State: [0.00034463]\n",
            "Step: 43, State: [0.00034463]\n",
            "Step: 44, State: [0.00034463]\n",
            "Step: 45, State: [0.00034463]\n",
            "Step: 46, State: [0.00034463]\n",
            "Step: 47, State: [0.00034463]\n",
            "Step: 48, State: [0.00034463]\n",
            "Step: 49, State: [0.00034463]\n",
            "Step: 50, State: [0.00034463]\n",
            "Step: 51, State: [0.00034463]\n",
            "Step: 52, State: [0.00034463]\n",
            "Step: 53, State: [0.00034463]\n",
            "Step: 54, State: [0.00034463]\n",
            "Step: 55, State: [0.00034463]\n",
            "Step: 56, State: [0.00034463]\n",
            "Step: 57, State: [0.00034463]\n",
            "Step: 58, State: [0.00034463]\n",
            "Step: 59, State: [0.00034463]\n",
            "Step: 60, State: [0.00034463]\n",
            "Step: 61, State: [0.00034463]\n",
            "Step: 62, State: [0.00034463]\n",
            "Step: 63, State: [0.00034463]\n",
            "Step: 64, State: [0.00034463]\n",
            "Step: 65, State: [0.00034463]\n",
            "Step: 66, State: [0.00034463]\n",
            "Step: 67, State: [0.00034463]\n",
            "Step: 68, State: [0.00034463]\n",
            "Step: 69, State: [0.00034463]\n",
            "Step: 70, State: [0.00034463]\n",
            "Step: 71, State: [0.00034463]\n",
            "Step: 72, State: [0.00034463]\n",
            "Step: 73, State: [0.00034463]\n",
            "Step: 74, State: [0.00034463]\n",
            "Step: 75, State: [0.00034463]\n",
            "Step: 76, State: [0.00034463]\n",
            "Step: 77, State: [0.00034463]\n",
            "Step: 78, State: [0.00034463]\n",
            "Step: 79, State: [0.00034463]\n",
            "Step: 80, State: [0.00034463]\n",
            "Step: 81, State: [0.00034463]\n",
            "Step: 82, State: [0.00034463]\n",
            "Step: 83, State: [0.00034463]\n",
            "Step: 84, State: [0.00034463]\n",
            "Step: 85, State: [0.00034463]\n",
            "Step: 86, State: [0.00034463]\n",
            "Step: 87, State: [0.00034463]\n",
            "Step: 88, State: [0.00034463]\n",
            "Step: 89, State: [0.00034463]\n",
            "Step: 90, State: [0.00034463]\n",
            "Step: 91, State: [0.00034463]\n",
            "Step: 92, State: [0.00034463]\n",
            "Step: 93, State: [0.00034463]\n",
            "Step: 94, State: [0.00034463]\n",
            "Step: 95, State: [0.00034463]\n",
            "Step: 96, State: [0.00034463]\n",
            "Step: 97, State: [0.00034463]\n",
            "Step: 98, State: [0.00034463]\n",
            "Step: 99, State: [0.00034463]\n",
            "Step: 100, State: [0.00034463]\n"
          ]
        }
      ],
      "source": [
        "obs, _ = env.reset()\n",
        "for step in range(100):\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, truncated, info = env.step(action) # Unpack all return values\n",
        "    env.render()  # If your environment supports rendering\n",
        "    if done:\n",
        "        obs, _ = env.reset() # Modified line: extract only the observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccB6JvEN1aep",
        "outputId": "241c320a-d6e5-4ec0-c439-591a3e4497ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward: -0.0000 +/- 0.0000\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=20)\n",
        "print(f\"Mean reward: {mean_reward:.4f} +/- {std_reward:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "AnTXIIhp3QtW"
      },
      "outputs": [],
      "source": [
        "model.save(\"ppo_final_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvJSAhDa3UTr",
        "outputId": "26fac024-f00a-4642-f474-0e0b7858eac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'LunarLander-v2', 'LunarLanderContinuous-v2', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v2', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'Reacher-v2', 'Reacher-v4', 'Pusher-v2', 'Pusher-v4', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'HumanoidStandup-v2', 'HumanoidStandup-v4']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/envs/registration.py:421: UserWarning: \u001b[33mWARN: The `registry.all` method is deprecated. Please use `registry.values` instead.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "\n",
        "# List all available environments\n",
        "envs = gym.envs.registry.all()\n",
        "env_names = [env.id for env in envs]\n",
        "print(env_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWJszS-Y4T94",
        "outputId": "51debfb6-0fd6-4c09-d5b3-a98af7b87ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.11/dist-packages (2.7.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.2.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install stable-baselines3 gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e607fc01",
        "outputId": "20562a3f-5a76-4fdc-b64a-7757196e0c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.11/dist-packages (2.7.0)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3 gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MexENrC44l-2",
        "outputId": "d747205d-4e0f-46ff-b81f-d396d32a37ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead\n",
            "  warnings.warn(\"get_schedule_fn() is deprecated, please use FloatSchedule() instead\")\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead\n",
            "  warnings.warn(\"constant_fn() is deprecated, please use ConstantSchedule() instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 22.2     |\n",
            "|    ep_rew_mean     | 22.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 1162     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.6        |\n",
            "|    ep_rew_mean          | 27.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 817         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 5           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009818489 |\n",
            "|    clip_fraction        | 0.103       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.686      |\n",
            "|    explained_variance   | -0.000661   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.94        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0139     |\n",
            "|    value_loss           | 54.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 35.8        |\n",
            "|    ep_rew_mean          | 35.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 690         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008598639 |\n",
            "|    clip_fraction        | 0.0586      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.672      |\n",
            "|    explained_variance   | 0.0823      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 16.3        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.017      |\n",
            "|    value_loss           | 38.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 46.3        |\n",
            "|    ep_rew_mean          | 46.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 677         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012383519 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.636      |\n",
            "|    explained_variance   | 0.251       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 24          |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0201     |\n",
            "|    value_loss           | 52.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=337.40 +/- 137.37\n",
            "Episode length: 337.40 +/- 137.37\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 337         |\n",
            "|    mean_reward          | 337         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 10000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008739783 |\n",
            "|    clip_fraction        | 0.0651      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.61       |\n",
            "|    explained_variance   | 0.341       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 20.8        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0149     |\n",
            "|    value_loss           | 62.4        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 63.3     |\n",
            "|    ep_rew_mean     | 63.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 588      |\n",
            "|    iterations      | 5        |\n",
            "|    time_elapsed    | 17       |\n",
            "|    total_timesteps | 10240    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 79.5         |\n",
            "|    ep_rew_mean          | 79.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 21           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062330323 |\n",
            "|    clip_fraction        | 0.0389       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.609       |\n",
            "|    explained_variance   | 0.343        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.23         |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.011       |\n",
            "|    value_loss           | 56.4         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 96.1        |\n",
            "|    ep_rew_mean          | 96.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 575         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005648424 |\n",
            "|    clip_fraction        | 0.0502      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.597      |\n",
            "|    explained_variance   | 0.453       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.69        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00883    |\n",
            "|    value_loss           | 55.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 113         |\n",
            "|    ep_rew_mean          | 113         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 577         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002974216 |\n",
            "|    clip_fraction        | 0.0171      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.58       |\n",
            "|    explained_variance   | 0.327       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.6        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00529    |\n",
            "|    value_loss           | 81.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 130         |\n",
            "|    ep_rew_mean          | 130         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 576         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009641762 |\n",
            "|    clip_fraction        | 0.0877      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.579      |\n",
            "|    explained_variance   | 0.756       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.1         |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 43.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=490.50 +/- 28.50\n",
            "Episode length: 490.50 +/- 28.50\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 490         |\n",
            "|    mean_reward          | 490         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 20000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004802878 |\n",
            "|    clip_fraction        | 0.0648      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.574      |\n",
            "|    explained_variance   | 0.869       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.61        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00919    |\n",
            "|    value_loss           | 29.4        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 145      |\n",
            "|    ep_rew_mean     | 145      |\n",
            "| time/              |          |\n",
            "|    fps             | 534      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 38       |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 163         |\n",
            "|    ep_rew_mean          | 163         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008000087 |\n",
            "|    clip_fraction        | 0.0951      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.575      |\n",
            "|    explained_variance   | 0.886       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.3        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0112     |\n",
            "|    value_loss           | 28.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 182         |\n",
            "|    ep_rew_mean          | 182         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 545         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 45          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011867955 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.564      |\n",
            "|    explained_variance   | 0.898       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.06        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0146     |\n",
            "|    value_loss           | 13.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 202         |\n",
            "|    ep_rew_mean          | 202         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 550         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 48          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009557782 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.542      |\n",
            "|    explained_variance   | 0.791       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.63        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00936    |\n",
            "|    value_loss           | 31.6        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 219          |\n",
            "|    ep_rew_mean          | 219          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 557          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 51           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028593577 |\n",
            "|    clip_fraction        | 0.0573       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.545       |\n",
            "|    explained_variance   | 0.941        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.743        |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.0056      |\n",
            "|    value_loss           | 6.25         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 30000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045783725 |\n",
            "|    clip_fraction        | 0.0636       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.526       |\n",
            "|    explained_variance   | 0.0207       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0292       |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00569     |\n",
            "|    value_loss           | 2.14         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 237      |\n",
            "|    ep_rew_mean     | 237      |\n",
            "| time/              |          |\n",
            "|    fps             | 529      |\n",
            "|    iterations      | 15       |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 30720    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 253         |\n",
            "|    ep_rew_mean          | 253         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 534         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005712957 |\n",
            "|    clip_fraction        | 0.0404      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.525      |\n",
            "|    explained_variance   | 0.0688      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.11        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00212    |\n",
            "|    value_loss           | 1.46        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 271         |\n",
            "|    ep_rew_mean          | 271         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 537         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 64          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004090146 |\n",
            "|    clip_fraction        | 0.0322      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.525      |\n",
            "|    explained_variance   | 0.00368     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0577      |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0014     |\n",
            "|    value_loss           | 0.926       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 288          |\n",
            "|    ep_rew_mean          | 288          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 542          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050561456 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.517       |\n",
            "|    explained_variance   | -0.00352     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0404       |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.000242    |\n",
            "|    value_loss           | 0.577        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 305          |\n",
            "|    ep_rew_mean          | 305          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 541          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 71           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036091306 |\n",
            "|    clip_fraction        | 0.0262       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.526       |\n",
            "|    explained_variance   | 0.0653       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0221       |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.0032      |\n",
            "|    value_loss           | 0.372        |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 500         |\n",
            "|    mean_reward          | 500         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003901447 |\n",
            "|    clip_fraction        | 0.0177      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.512      |\n",
            "|    explained_variance   | 0.0321      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00275    |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.00143    |\n",
            "|    value_loss           | 0.236       |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 318      |\n",
            "|    ep_rew_mean     | 318      |\n",
            "| time/              |          |\n",
            "|    fps             | 525      |\n",
            "|    iterations      | 20       |\n",
            "|    time_elapsed    | 77       |\n",
            "|    total_timesteps | 40960    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 330          |\n",
            "|    ep_rew_mean          | 330          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 530          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 81           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026728301 |\n",
            "|    clip_fraction        | 0.0118       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.524       |\n",
            "|    explained_variance   | 0.000984     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0252       |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00115     |\n",
            "|    value_loss           | 0.147        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 344          |\n",
            "|    ep_rew_mean          | 344          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 529          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046445844 |\n",
            "|    clip_fraction        | 0.0263       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.51        |\n",
            "|    explained_variance   | -0.0174      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0104      |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00121     |\n",
            "|    value_loss           | 0.0936       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 355          |\n",
            "|    ep_rew_mean          | 355          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 533          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 88           |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049312874 |\n",
            "|    clip_fraction        | 0.0221       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.515       |\n",
            "|    explained_variance   | 0.00401      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00288      |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.0011      |\n",
            "|    value_loss           | 0.0587       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 370          |\n",
            "|    ep_rew_mean          | 370          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 537          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 91           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064355684 |\n",
            "|    clip_fraction        | 0.0418       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.511       |\n",
            "|    explained_variance   | -0.000921    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00816      |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00169     |\n",
            "|    value_loss           | 0.0372       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 50000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024808862 |\n",
            "|    clip_fraction        | 0.0248       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.489       |\n",
            "|    explained_variance   | 0.0175       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0137      |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00157     |\n",
            "|    value_loss           | 0.0234       |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 385      |\n",
            "|    ep_rew_mean     | 385      |\n",
            "| time/              |          |\n",
            "|    fps             | 521      |\n",
            "|    iterations      | 25       |\n",
            "|    time_elapsed    | 98       |\n",
            "|    total_timesteps | 51200    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 397         |\n",
            "|    ep_rew_mean          | 397         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 525         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 101         |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004141722 |\n",
            "|    clip_fraction        | 0.0333      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.474      |\n",
            "|    explained_variance   | 0.0295      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0056      |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00226    |\n",
            "|    value_loss           | 0.0145      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 410        |\n",
            "|    ep_rew_mean          | 410        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 529        |\n",
            "|    iterations           | 27         |\n",
            "|    time_elapsed         | 104        |\n",
            "|    total_timesteps      | 55296      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00207623 |\n",
            "|    clip_fraction        | 0.0113     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.484     |\n",
            "|    explained_variance   | 0.00434    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.00378    |\n",
            "|    n_updates            | 260        |\n",
            "|    policy_gradient_loss | 3.49e-05   |\n",
            "|    value_loss           | 0.00928    |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 423          |\n",
            "|    ep_rew_mean          | 423          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 531          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 107          |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014206143 |\n",
            "|    clip_fraction        | 0.0109       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.489       |\n",
            "|    explained_variance   | 0.0117       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00407      |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.000405    |\n",
            "|    value_loss           | 0.00628      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 434          |\n",
            "|    ep_rew_mean          | 434          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 533          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 111          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034369128 |\n",
            "|    clip_fraction        | 0.00879      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.471       |\n",
            "|    explained_variance   | -0.0111      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00243     |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.000326    |\n",
            "|    value_loss           | 0.00408      |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 60000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018118293 |\n",
            "|    clip_fraction        | 0.0111       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.477       |\n",
            "|    explained_variance   | -0.0227      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.000613    |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | 0.000214     |\n",
            "|    value_loss           | 0.0027       |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 446      |\n",
            "|    ep_rew_mean     | 446      |\n",
            "| time/              |          |\n",
            "|    fps             | 522      |\n",
            "|    iterations      | 30       |\n",
            "|    time_elapsed    | 117      |\n",
            "|    total_timesteps | 61440    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 457          |\n",
            "|    ep_rew_mean          | 457          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 523          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 121          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024653724 |\n",
            "|    clip_fraction        | 0.0355       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.475       |\n",
            "|    explained_variance   | 0.00886      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0176      |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00268     |\n",
            "|    value_loss           | 0.00192      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 469          |\n",
            "|    ep_rew_mean          | 469          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 526          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 124          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027024148 |\n",
            "|    clip_fraction        | 0.0162       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.474       |\n",
            "|    explained_variance   | 0.0236       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00777     |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    value_loss           | 0.00128      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 481          |\n",
            "|    ep_rew_mean          | 481          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 529          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 127          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035538592 |\n",
            "|    clip_fraction        | 0.0357       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.471       |\n",
            "|    explained_variance   | 0.0679       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00142      |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00359     |\n",
            "|    value_loss           | 0.000858     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 493         |\n",
            "|    ep_rew_mean          | 493         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 533         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 130         |\n",
            "|    total_timesteps      | 69632       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005414927 |\n",
            "|    clip_fraction        | 0.0347      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.453      |\n",
            "|    explained_variance   | -0.00674    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00604     |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.00283    |\n",
            "|    value_loss           | 0.000587    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 70000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026221788 |\n",
            "|    clip_fraction        | 0.0322       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.441       |\n",
            "|    explained_variance   | -0.000138    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00337     |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00196     |\n",
            "|    value_loss           | 0.000466     |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 494      |\n",
            "|    ep_rew_mean     | 494      |\n",
            "| time/              |          |\n",
            "|    fps             | 521      |\n",
            "|    iterations      | 35       |\n",
            "|    time_elapsed    | 137      |\n",
            "|    total_timesteps | 71680    |\n",
            "---------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 496           |\n",
            "|    ep_rew_mean          | 496           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 524           |\n",
            "|    iterations           | 36            |\n",
            "|    time_elapsed         | 140           |\n",
            "|    total_timesteps      | 73728         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00073356373 |\n",
            "|    clip_fraction        | 0.00781       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.459        |\n",
            "|    explained_variance   | -0.0403       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.000838      |\n",
            "|    n_updates            | 350           |\n",
            "|    policy_gradient_loss | -8.79e-05     |\n",
            "|    value_loss           | 0.000301      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 498          |\n",
            "|    ep_rew_mean          | 498          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 527          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 143          |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019612426 |\n",
            "|    clip_fraction        | 0.0085       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.475       |\n",
            "|    explained_variance   | -0.0312      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00877     |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | 9.23e-05     |\n",
            "|    value_loss           | 0.000197     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 527          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 147          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031775613 |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.459       |\n",
            "|    explained_variance   | -0.0203      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.005       |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00234     |\n",
            "|    value_loss           | 0.000155     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 530          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 150          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036946083 |\n",
            "|    clip_fraction        | 0.0238       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.444       |\n",
            "|    explained_variance   | -0.0231      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0161      |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00164     |\n",
            "|    value_loss           | 0.000104     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 80000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046018325 |\n",
            "|    clip_fraction        | 0.0521       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.445       |\n",
            "|    explained_variance   | -0.0241      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00306     |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.0011      |\n",
            "|    value_loss           | 7.23e-05     |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 522      |\n",
            "|    iterations      | 40       |\n",
            "|    time_elapsed    | 156      |\n",
            "|    total_timesteps | 81920    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 522         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 160         |\n",
            "|    total_timesteps      | 83968       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006004675 |\n",
            "|    clip_fraction        | 0.0325      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.438      |\n",
            "|    explained_variance   | -0.0122     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0146      |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.00205    |\n",
            "|    value_loss           | 5.13e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 525          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 163          |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026299693 |\n",
            "|    clip_fraction        | 0.0325       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.446       |\n",
            "|    explained_variance   | -0.0105      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00612     |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    value_loss           | 3.9e-05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 527         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 166         |\n",
            "|    total_timesteps      | 88064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002000419 |\n",
            "|    clip_fraction        | 0.041       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.432      |\n",
            "|    explained_variance   | -0.0773     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00503     |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.00141    |\n",
            "|    value_loss           | 3.05e-05    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 500        |\n",
            "|    mean_reward          | 500        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 90000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00520844 |\n",
            "|    clip_fraction        | 0.0294     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.435     |\n",
            "|    explained_variance   | -0.164     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0102     |\n",
            "|    n_updates            | 430        |\n",
            "|    policy_gradient_loss | -0.000293  |\n",
            "|    value_loss           | 2.11e-05   |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 518      |\n",
            "|    iterations      | 44       |\n",
            "|    time_elapsed    | 173      |\n",
            "|    total_timesteps | 90112    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 520         |\n",
            "|    iterations           | 45          |\n",
            "|    time_elapsed         | 176         |\n",
            "|    total_timesteps      | 92160       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009502444 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.423      |\n",
            "|    explained_variance   | -0.281      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0064      |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | -0.0052     |\n",
            "|    value_loss           | 1.81e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 523         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 180         |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003956141 |\n",
            "|    clip_fraction        | 0.0188      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.438      |\n",
            "|    explained_variance   | -0.222      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00932    |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.00149    |\n",
            "|    value_loss           | 1.09e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 524          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 183          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027745257 |\n",
            "|    clip_fraction        | 0.0282       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.407       |\n",
            "|    explained_variance   | -0.479       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.000396    |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00237     |\n",
            "|    value_loss           | 8.07e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 525          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 187          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012670843 |\n",
            "|    clip_fraction        | 0.017        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.396       |\n",
            "|    explained_variance   | -0.345       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00659     |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.000514    |\n",
            "|    value_loss           | 5.96e-06     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 100000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037110876 |\n",
            "|    clip_fraction        | 0.0832       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.391       |\n",
            "|    explained_variance   | -0.61        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00677     |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00329     |\n",
            "|    value_loss           | 3.98e-06     |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 519      |\n",
            "|    iterations      | 49       |\n",
            "|    time_elapsed    | 193      |\n",
            "|    total_timesteps | 100352   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 520          |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 196          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038069398 |\n",
            "|    clip_fraction        | 0.0265       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.368       |\n",
            "|    explained_variance   | -0.54        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00274      |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    value_loss           | 3.78e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 520          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 200          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027578645 |\n",
            "|    clip_fraction        | 0.0253       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.344       |\n",
            "|    explained_variance   | -0.728       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00808     |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00251     |\n",
            "|    value_loss           | 3.61e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 522          |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 203          |\n",
            "|    total_timesteps      | 106496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019918277 |\n",
            "|    clip_fraction        | 0.0146       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.338       |\n",
            "|    explained_variance   | -0.867       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.000934    |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.000217    |\n",
            "|    value_loss           | 2.81e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 524         |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 207         |\n",
            "|    total_timesteps      | 108544      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004214769 |\n",
            "|    clip_fraction        | 0.0351      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.332      |\n",
            "|    explained_variance   | -1.45       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00646     |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -0.00275    |\n",
            "|    value_loss           | 2.32e-06    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=110000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 500         |\n",
            "|    mean_reward          | 500         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 110000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003667761 |\n",
            "|    clip_fraction        | 0.0231      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.309      |\n",
            "|    explained_variance   | -1.52       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.000398    |\n",
            "|    n_updates            | 530         |\n",
            "|    policy_gradient_loss | -0.00141    |\n",
            "|    value_loss           | 1.62e-06    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 516      |\n",
            "|    iterations      | 54       |\n",
            "|    time_elapsed    | 214      |\n",
            "|    total_timesteps | 110592   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 518          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 217          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018185212 |\n",
            "|    clip_fraction        | 0.0272       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.295       |\n",
            "|    explained_variance   | -1.6         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00575     |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00121     |\n",
            "|    value_loss           | 2.74e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 518          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 221          |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029943038 |\n",
            "|    clip_fraction        | 0.0231       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.288       |\n",
            "|    explained_variance   | -0.732       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.001       |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    value_loss           | 1.23e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 519         |\n",
            "|    iterations           | 57          |\n",
            "|    time_elapsed         | 224         |\n",
            "|    total_timesteps      | 116736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003963571 |\n",
            "|    clip_fraction        | 0.0491      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.302      |\n",
            "|    explained_variance   | -2.02       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00166     |\n",
            "|    n_updates            | 560         |\n",
            "|    policy_gradient_loss | -0.000655   |\n",
            "|    value_loss           | 1.52e-06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 500        |\n",
            "|    ep_rew_mean          | 500        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 521        |\n",
            "|    iterations           | 58         |\n",
            "|    time_elapsed         | 227        |\n",
            "|    total_timesteps      | 118784     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00208534 |\n",
            "|    clip_fraction        | 0.0147     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.288     |\n",
            "|    explained_variance   | -4.13      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.00139    |\n",
            "|    n_updates            | 570        |\n",
            "|    policy_gradient_loss | -0.000121  |\n",
            "|    value_loss           | 1.84e-06   |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 120000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023700446 |\n",
            "|    clip_fraction        | 0.019        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.28        |\n",
            "|    explained_variance   | -1.88        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00585      |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    value_loss           | 3.59e-06     |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 515      |\n",
            "|    iterations      | 59       |\n",
            "|    time_elapsed    | 234      |\n",
            "|    total_timesteps | 120832   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 516          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 237          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024543556 |\n",
            "|    clip_fraction        | 0.0311       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.281       |\n",
            "|    explained_variance   | -3.41        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00406     |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    value_loss           | 3.32e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 518          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 241          |\n",
            "|    total_timesteps      | 124928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024736933 |\n",
            "|    clip_fraction        | 0.027        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.275       |\n",
            "|    explained_variance   | -5.44        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00303      |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | -3.83e-05    |\n",
            "|    value_loss           | 3.34e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 520         |\n",
            "|    iterations           | 62          |\n",
            "|    time_elapsed         | 244         |\n",
            "|    total_timesteps      | 126976      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005352676 |\n",
            "|    clip_fraction        | 0.063       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.27       |\n",
            "|    explained_variance   | -3.64       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.000207    |\n",
            "|    n_updates            | 610         |\n",
            "|    policy_gradient_loss | -0.00219    |\n",
            "|    value_loss           | 1.71e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 520         |\n",
            "|    iterations           | 63          |\n",
            "|    time_elapsed         | 247         |\n",
            "|    total_timesteps      | 129024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003675539 |\n",
            "|    clip_fraction        | 0.0485      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.278      |\n",
            "|    explained_variance   | -7.42       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00133    |\n",
            "|    n_updates            | 620         |\n",
            "|    policy_gradient_loss | -0.000793   |\n",
            "|    value_loss           | 1.26e-05    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=130000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 130000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024231237 |\n",
            "|    clip_fraction        | 0.0306       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.283       |\n",
            "|    explained_variance   | -5.88        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0151       |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00137     |\n",
            "|    value_loss           | 4.89e-07     |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 515      |\n",
            "|    iterations      | 64       |\n",
            "|    time_elapsed    | 254      |\n",
            "|    total_timesteps | 131072   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 517          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 257          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020204817 |\n",
            "|    clip_fraction        | 0.035        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.276       |\n",
            "|    explained_variance   | -7.99        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00142      |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.000644    |\n",
            "|    value_loss           | 3.7e-07      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 517          |\n",
            "|    iterations           | 66           |\n",
            "|    time_elapsed         | 261          |\n",
            "|    total_timesteps      | 135168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048342333 |\n",
            "|    clip_fraction        | 0.053        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.267       |\n",
            "|    explained_variance   | -4.48        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.011       |\n",
            "|    n_updates            | 650          |\n",
            "|    policy_gradient_loss | -0.0042      |\n",
            "|    value_loss           | 4.43e-07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 500           |\n",
            "|    ep_rew_mean          | 500           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 519           |\n",
            "|    iterations           | 67            |\n",
            "|    time_elapsed         | 264           |\n",
            "|    total_timesteps      | 137216        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00060290704 |\n",
            "|    clip_fraction        | 0.0158        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.274        |\n",
            "|    explained_variance   | -3.44         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.00101       |\n",
            "|    n_updates            | 660           |\n",
            "|    policy_gradient_loss | 0.000298      |\n",
            "|    value_loss           | 2.09e-06      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 521         |\n",
            "|    iterations           | 68          |\n",
            "|    time_elapsed         | 267         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004218269 |\n",
            "|    clip_fraction        | 0.0489      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.288      |\n",
            "|    explained_variance   | -10.3       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00943    |\n",
            "|    n_updates            | 670         |\n",
            "|    policy_gradient_loss | -0.00222    |\n",
            "|    value_loss           | 5.82e-06    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=140000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 140000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016883505 |\n",
            "|    clip_fraction        | 0.0171       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.264       |\n",
            "|    explained_variance   | -7.82        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00322     |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -0.00086     |\n",
            "|    value_loss           | 8.3e-07      |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 515      |\n",
            "|    iterations      | 69       |\n",
            "|    time_elapsed    | 273      |\n",
            "|    total_timesteps | 141312   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 517          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 277          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013314681 |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.245       |\n",
            "|    explained_variance   | -8.73        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00263     |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    value_loss           | 3.75e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 518          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 280          |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034042334 |\n",
            "|    clip_fraction        | 0.0292       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.27        |\n",
            "|    explained_variance   | -8.57        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00063      |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -6.24e-05    |\n",
            "|    value_loss           | 1.4e-05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 520         |\n",
            "|    iterations           | 72          |\n",
            "|    time_elapsed         | 283         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003052322 |\n",
            "|    clip_fraction        | 0.0313      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.253      |\n",
            "|    explained_variance   | -9.35       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00778    |\n",
            "|    n_updates            | 710         |\n",
            "|    policy_gradient_loss | -0.00278    |\n",
            "|    value_loss           | 3.4e-07     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 520          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 287          |\n",
            "|    total_timesteps      | 149504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007078645 |\n",
            "|    clip_fraction        | 0.0199       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.255       |\n",
            "|    explained_variance   | -8.75        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00507     |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | 5.67e-05     |\n",
            "|    value_loss           | 1.08e-06     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=150000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 150000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029557925 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.236       |\n",
            "|    explained_variance   | -9.62        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00403      |\n",
            "|    n_updates            | 730          |\n",
            "|    policy_gradient_loss | -0.00151     |\n",
            "|    value_loss           | 8.2e-07      |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 516      |\n",
            "|    iterations      | 74       |\n",
            "|    time_elapsed    | 293      |\n",
            "|    total_timesteps | 151552   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 517          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 296          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031413955 |\n",
            "|    clip_fraction        | 0.037        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.243       |\n",
            "|    explained_variance   | -7.05        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00164      |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.00148     |\n",
            "|    value_loss           | 1.48e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 517          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 300          |\n",
            "|    total_timesteps      | 155648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037527177 |\n",
            "|    clip_fraction        | 0.0411       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.261       |\n",
            "|    explained_variance   | -5.08        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0148      |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.000484    |\n",
            "|    value_loss           | 1.97e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 519          |\n",
            "|    iterations           | 77           |\n",
            "|    time_elapsed         | 303          |\n",
            "|    total_timesteps      | 157696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029520313 |\n",
            "|    clip_fraction        | 0.0178       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.268       |\n",
            "|    explained_variance   | -7.42        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0087      |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | -0.000981    |\n",
            "|    value_loss           | 2.25e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 520          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 306          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009472843 |\n",
            "|    clip_fraction        | 0.0359       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.257       |\n",
            "|    explained_variance   | -9.6         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00439      |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.000866    |\n",
            "|    value_loss           | 1.11e-06     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 500         |\n",
            "|    mean_reward          | 500         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 160000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003732545 |\n",
            "|    clip_fraction        | 0.0355      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.248      |\n",
            "|    explained_variance   | -14.1       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00191     |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | -0.00184    |\n",
            "|    value_loss           | 6.71e-07    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 516      |\n",
            "|    iterations      | 79       |\n",
            "|    time_elapsed    | 313      |\n",
            "|    total_timesteps | 161792   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 517          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 316          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040308274 |\n",
            "|    clip_fraction        | 0.0389       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.264       |\n",
            "|    explained_variance   | -12.4        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00671     |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.000646    |\n",
            "|    value_loss           | 3.13e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 518         |\n",
            "|    iterations           | 81          |\n",
            "|    time_elapsed         | 319         |\n",
            "|    total_timesteps      | 165888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002133849 |\n",
            "|    clip_fraction        | 0.0111      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.255      |\n",
            "|    explained_variance   | -10.2       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00234    |\n",
            "|    n_updates            | 800         |\n",
            "|    policy_gradient_loss | -2.67e-05   |\n",
            "|    value_loss           | 1.23e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 518         |\n",
            "|    iterations           | 82          |\n",
            "|    time_elapsed         | 323         |\n",
            "|    total_timesteps      | 167936      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002665517 |\n",
            "|    clip_fraction        | 0.0305      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.239      |\n",
            "|    explained_variance   | -12.6       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00818    |\n",
            "|    n_updates            | 810         |\n",
            "|    policy_gradient_loss | -0.00198    |\n",
            "|    value_loss           | 4.64e-07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 519          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 327          |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012648652 |\n",
            "|    clip_fraction        | 0.0144       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.247       |\n",
            "|    explained_variance   | -13.8        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0011      |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | 0.000116     |\n",
            "|    value_loss           | 3.76e-07     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=170000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 500         |\n",
            "|    mean_reward          | 500         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 170000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002247124 |\n",
            "|    clip_fraction        | 0.0194      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.248      |\n",
            "|    explained_variance   | -14.4       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.000968   |\n",
            "|    n_updates            | 830         |\n",
            "|    policy_gradient_loss | -0.000964   |\n",
            "|    value_loss           | 8.08e-06    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 515      |\n",
            "|    iterations      | 84       |\n",
            "|    time_elapsed    | 333      |\n",
            "|    total_timesteps | 172032   |\n",
            "---------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 500           |\n",
            "|    ep_rew_mean          | 500           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 515           |\n",
            "|    iterations           | 85            |\n",
            "|    time_elapsed         | 337           |\n",
            "|    total_timesteps      | 174080        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00038395933 |\n",
            "|    clip_fraction        | 0.0225        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.263        |\n",
            "|    explained_variance   | -1.78         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.000123     |\n",
            "|    n_updates            | 840           |\n",
            "|    policy_gradient_loss | 0.000156      |\n",
            "|    value_loss           | 1.56e-06      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 517          |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 340          |\n",
            "|    total_timesteps      | 176128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021652807 |\n",
            "|    clip_fraction        | 0.0146       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.253       |\n",
            "|    explained_variance   | -1.86        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0086      |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | 6.2e-05      |\n",
            "|    value_loss           | 1.71e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 518         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 343         |\n",
            "|    total_timesteps      | 178176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003970571 |\n",
            "|    clip_fraction        | 0.0304      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.256      |\n",
            "|    explained_variance   | -1.02       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.000654    |\n",
            "|    n_updates            | 860         |\n",
            "|    policy_gradient_loss | -1.5e-05    |\n",
            "|    value_loss           | 2.22e-07    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=180000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 500         |\n",
            "|    mean_reward          | 500         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 180000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006869084 |\n",
            "|    clip_fraction        | 0.0563      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.254      |\n",
            "|    explained_variance   | -2.95       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.000532    |\n",
            "|    n_updates            | 870         |\n",
            "|    policy_gradient_loss | -0.00222    |\n",
            "|    value_loss           | 2.17e-07    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 513      |\n",
            "|    iterations      | 88       |\n",
            "|    time_elapsed    | 350      |\n",
            "|    total_timesteps | 180224   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 514         |\n",
            "|    iterations           | 89          |\n",
            "|    time_elapsed         | 353         |\n",
            "|    total_timesteps      | 182272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004371307 |\n",
            "|    clip_fraction        | 0.0521      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.273      |\n",
            "|    explained_variance   | -10.9       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00214     |\n",
            "|    n_updates            | 880         |\n",
            "|    policy_gradient_loss | -0.0028     |\n",
            "|    value_loss           | 1.92e-07    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 500        |\n",
            "|    ep_rew_mean          | 500        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 516        |\n",
            "|    iterations           | 90         |\n",
            "|    time_elapsed         | 357        |\n",
            "|    total_timesteps      | 184320     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00636883 |\n",
            "|    clip_fraction        | 0.0351     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.264     |\n",
            "|    explained_variance   | -2.44      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.044      |\n",
            "|    n_updates            | 890        |\n",
            "|    policy_gradient_loss | -0.00187   |\n",
            "|    value_loss           | 1.49e-06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 517          |\n",
            "|    iterations           | 91           |\n",
            "|    time_elapsed         | 360          |\n",
            "|    total_timesteps      | 186368       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034534712 |\n",
            "|    clip_fraction        | 0.0332       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.274       |\n",
            "|    explained_variance   | -4.98        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00688      |\n",
            "|    n_updates            | 900          |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    value_loss           | 1.47e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 517          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 364          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014979782 |\n",
            "|    clip_fraction        | 0.0148       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.27        |\n",
            "|    explained_variance   | -6.76        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00348     |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.000974    |\n",
            "|    value_loss           | 2.08e-07     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=190000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 500        |\n",
            "|    mean_reward          | 500        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 190000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00320845 |\n",
            "|    clip_fraction        | 0.0245     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.272     |\n",
            "|    explained_variance   | -9.18      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0113     |\n",
            "|    n_updates            | 920        |\n",
            "|    policy_gradient_loss | -0.00148   |\n",
            "|    value_loss           | 2.48e-07   |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 513      |\n",
            "|    iterations      | 93       |\n",
            "|    time_elapsed    | 370      |\n",
            "|    total_timesteps | 190464   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 514          |\n",
            "|    iterations           | 94           |\n",
            "|    time_elapsed         | 374          |\n",
            "|    total_timesteps      | 192512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019560163 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.28        |\n",
            "|    explained_variance   | -11.5        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0144      |\n",
            "|    n_updates            | 930          |\n",
            "|    policy_gradient_loss | -0.00097     |\n",
            "|    value_loss           | 1.33e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 515          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 377          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008648712 |\n",
            "|    clip_fraction        | 0.0105       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.269       |\n",
            "|    explained_variance   | -12.5        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00122     |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -6e-05       |\n",
            "|    value_loss           | 1.36e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 516          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 380          |\n",
            "|    total_timesteps      | 196608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068509365 |\n",
            "|    clip_fraction        | 0.0673       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.277       |\n",
            "|    explained_variance   | -14.4        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.000923    |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | -0.00236     |\n",
            "|    value_loss           | 1.26e-07     |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 500       |\n",
            "|    ep_rew_mean          | 500       |\n",
            "| time/                   |           |\n",
            "|    fps                  | 517       |\n",
            "|    iterations           | 97        |\n",
            "|    time_elapsed         | 383       |\n",
            "|    total_timesteps      | 198656    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0033382 |\n",
            "|    clip_fraction        | 0.032     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.283    |\n",
            "|    explained_variance   | -11.5     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -0.00535  |\n",
            "|    n_updates            | 960       |\n",
            "|    policy_gradient_loss | -0.00134  |\n",
            "|    value_loss           | 2.42e-06  |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 500          |\n",
            "|    mean_reward          | 500          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 200000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015500193 |\n",
            "|    clip_fraction        | 0.0168       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.274       |\n",
            "|    explained_variance   | -7.03        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00398     |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | -0.000937    |\n",
            "|    value_loss           | 2.2e-05      |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 514      |\n",
            "|    iterations      | 98       |\n",
            "|    time_elapsed    | 390      |\n",
            "|    total_timesteps | 200704   |\n",
            "---------------------------------\n",
            "Mean reward over 20 episodes: 500.0000 +/- 0.0000\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym # Import gymnasium\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "# from stable_baselines3.common.evaluation import evaluate_policy # Removed evaluate_policy\n",
        "from stable_baselines3.common.utils import get_schedule_fn\n",
        "import numpy as np # Import numpy for mean and std\n",
        "\n",
        "# Create environment wrapped with Monitor\n",
        "def make_env():\n",
        "    env = gym.make('CartPole-v1', render_mode=\"rgb_array\")  # Use gymnasium.make and add render_mode for rendering\n",
        "    env = Monitor(env)\n",
        "    return env\n",
        "\n",
        "# Create a vectorized environment\n",
        "env = DummyVecEnv([make_env])\n",
        "eval_env = DummyVecEnv([make_env])  # Wrap eval env as well\n",
        "\n",
        "# Define learning rate schedule (decay from 3e-4 to 1e-5 linearly)\n",
        "learning_rate_schedule = get_schedule_fn(3e-4)\n",
        "\n",
        "# Setup EvalCallback for periodic evaluation and saving best model\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path='./logs/best_model',\n",
        "    log_path='./logs/',\n",
        "    eval_freq=10000,  # Evaluate every 10k steps\n",
        "    n_eval_episodes=10,\n",
        "    deterministic=True,\n",
        "    render=False\n",
        ")\n",
        "\n",
        "# Create PPO model with learning rate schedule and verbose output\n",
        "model = PPO('MlpPolicy', env, verbose=1, learning_rate=learning_rate_schedule)\n",
        "\n",
        "# Train the model for 200,000 timesteps with evaluation callback\n",
        "model.learn(total_timesteps=200000, callback=eval_callback)\n",
        "\n",
        "# Save final model\n",
        "model.save(\"ppo_final_model\")\n",
        "\n",
        "# Evaluate model after training for 20 episodes using a manual loop\n",
        "num_eval_episodes = 20\n",
        "all_episode_rewards = []\n",
        "\n",
        "for episode in range(num_eval_episodes):\n",
        "    obs = eval_env.reset()\n",
        "    done = False\n",
        "    truncated = False\n",
        "    episode_reward = 0\n",
        "    while not (done or truncated):\n",
        "        action, _states = model.predict(obs, deterministic=True)\n",
        "        # Dynamically unpack based on the number of elements returned by step\n",
        "        step_return = eval_env.step(action)\n",
        "        if len(step_return) == 5:\n",
        "            obs, reward, terminated, truncated, info = step_return\n",
        "            done = terminated or truncated # Combine terminated and truncated for loop condition\n",
        "        elif len(step_return) == 4: # For older Gym environments\n",
        "            obs, reward, done, info = step_return\n",
        "            truncated = False # Assume no truncation in older Gym\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected number of values returned by env.step(): {len(step_return)}\")\n",
        "\n",
        "        episode_reward += reward[0] # Accumulate reward (reward is an array in vectorized env)\n",
        "\n",
        "    all_episode_rewards.append(episode_reward)\n",
        "\n",
        "mean_reward = np.mean(all_episode_rewards)\n",
        "std_reward = np.std(all_episode_rewards)\n",
        "\n",
        "print(f\"Mean reward over {num_eval_episodes} episodes: {mean_reward:.4f} +/- {std_reward:.4f}\")\n",
        "\n",
        "\n",
        "# Optional: Run and render the trained model for 100 steps\n",
        "# Removing rendering due to persistent errors\n",
        "# obs = eval_env.reset()\n",
        "# for step in range(100):\n",
        "#     action, _states = model.predict(obs, deterministic=True)\n",
        "#     step_return = eval_env.step(action)\n",
        "#     if len(step_return) == 5:\n",
        "#         obs, reward, terminated, truncated, info = step_return\n",
        "#         done = terminated or truncated\n",
        "#     elif len(step_return) == 4:\n",
        "#         obs, reward, done, info = step_return\n",
        "#         truncated = False\n",
        "#     else:\n",
        "#         raise ValueError(f\"Unexpected number of values returned by env.step(): {len(step_return)}\")\n",
        "#\n",
        "#     # Removed rendering call\n",
        "#     # eval_env.envs[0].env.render(mode=\"rgb_array\")\n",
        "#     if done or truncated:\n",
        "#         obs = eval_env.reset()\n",
        "\n",
        "# Close environments\n",
        "env.close()\n",
        "eval_env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_xlXUjbnt5s",
        "outputId": "475c6301-be14-4823-8f3d-82775338bda0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 500      |\n",
            "|    ep_rew_mean     | 500      |\n",
            "| time/              |          |\n",
            "|    fps             | 932      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 719          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013440524 |\n",
            "|    clip_fraction        | 0.014        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.233       |\n",
            "|    explained_variance   | -7.31        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00189     |\n",
            "|    n_updates            | 990          |\n",
            "|    policy_gradient_loss | -0.000168    |\n",
            "|    value_loss           | 1.96e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 692          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 8            |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045431852 |\n",
            "|    clip_fraction        | 0.0513       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.242       |\n",
            "|    explained_variance   | -9.63        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.022        |\n",
            "|    n_updates            | 1000         |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    value_loss           | 1.19e-07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 680         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009845708 |\n",
            "|    clip_fraction        | 0.0797      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.282      |\n",
            "|    explained_variance   | -9.88       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00166    |\n",
            "|    n_updates            | 1010        |\n",
            "|    policy_gradient_loss | -0.00447    |\n",
            "|    value_loss           | 2.98e-07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 640          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 15           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032632235 |\n",
            "|    clip_fraction        | 0.0326       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.27        |\n",
            "|    explained_variance   | -6.89        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00637      |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.00299     |\n",
            "|    value_loss           | 3.26e-07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 643         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002890017 |\n",
            "|    clip_fraction        | 0.026       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.269      |\n",
            "|    explained_variance   | -7.41       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00603     |\n",
            "|    n_updates            | 1030        |\n",
            "|    policy_gradient_loss | -0.00143    |\n",
            "|    value_loss           | 8.79e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 649          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011185663 |\n",
            "|    clip_fraction        | 0.0179       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.249       |\n",
            "|    explained_variance   | -8.51        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00288     |\n",
            "|    n_updates            | 1040         |\n",
            "|    policy_gradient_loss | -2.49e-05    |\n",
            "|    value_loss           | 6.44e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 652          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012684576 |\n",
            "|    clip_fraction        | 0.0153       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.245       |\n",
            "|    explained_variance   | -8.74        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00128      |\n",
            "|    n_updates            | 1050         |\n",
            "|    policy_gradient_loss | -0.000756    |\n",
            "|    value_loss           | 6.52e-07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 635         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001019688 |\n",
            "|    clip_fraction        | 0.0206      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.24       |\n",
            "|    explained_variance   | -15.5       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00225     |\n",
            "|    n_updates            | 1060        |\n",
            "|    policy_gradient_loss | -0.000463   |\n",
            "|    value_loss           | 5.34e-07    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 500           |\n",
            "|    ep_rew_mean          | 500           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 640           |\n",
            "|    iterations           | 10            |\n",
            "|    time_elapsed         | 31            |\n",
            "|    total_timesteps      | 20480         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00087221037 |\n",
            "|    clip_fraction        | 0.0122        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.261        |\n",
            "|    explained_variance   | -14.5         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.00075       |\n",
            "|    n_updates            | 1070          |\n",
            "|    policy_gradient_loss | 0.000652      |\n",
            "|    value_loss           | 3.2e-06       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 644          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 34           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021612155 |\n",
            "|    clip_fraction        | 0.0215       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.256       |\n",
            "|    explained_variance   | -18.2        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00144      |\n",
            "|    n_updates            | 1080         |\n",
            "|    policy_gradient_loss | -0.000999    |\n",
            "|    value_loss           | 3.9e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 647          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013059652 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.252       |\n",
            "|    explained_variance   | -10.8        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0135      |\n",
            "|    n_updates            | 1090         |\n",
            "|    policy_gradient_loss | -0.00171     |\n",
            "|    value_loss           | 9.03e-08     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 636         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001773577 |\n",
            "|    clip_fraction        | 0.022       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.259      |\n",
            "|    explained_variance   | -15.5       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00155    |\n",
            "|    n_updates            | 1100        |\n",
            "|    policy_gradient_loss | -0.000186   |\n",
            "|    value_loss           | 1.1e-07     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 638          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 44           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023155753 |\n",
            "|    clip_fraction        | 0.0463       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.267       |\n",
            "|    explained_variance   | -14.1        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.000476    |\n",
            "|    n_updates            | 1110         |\n",
            "|    policy_gradient_loss | -0.000469    |\n",
            "|    value_loss           | 2.49e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 633          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012243361 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.254       |\n",
            "|    explained_variance   | -9.1         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00467      |\n",
            "|    n_updates            | 1120         |\n",
            "|    policy_gradient_loss | -0.000306    |\n",
            "|    value_loss           | 3.19e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 627          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 52           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028344458 |\n",
            "|    clip_fraction        | 0.0175       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.24        |\n",
            "|    explained_variance   | -11.2        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00654     |\n",
            "|    n_updates            | 1130         |\n",
            "|    policy_gradient_loss | -0.00042     |\n",
            "|    value_loss           | 1.28e-07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 623         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 55          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004158276 |\n",
            "|    clip_fraction        | 0.0417      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.243      |\n",
            "|    explained_variance   | -13         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0188     |\n",
            "|    n_updates            | 1140        |\n",
            "|    policy_gradient_loss | -0.00169    |\n",
            "|    value_loss           | 1.73e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 625          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022954794 |\n",
            "|    clip_fraction        | 0.028        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.237       |\n",
            "|    explained_variance   | -11          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0194       |\n",
            "|    n_updates            | 1150         |\n",
            "|    policy_gradient_loss | -0.000812    |\n",
            "|    value_loss           | 1.09e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 628         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003957742 |\n",
            "|    clip_fraction        | 0.0208      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.255      |\n",
            "|    explained_variance   | -5.1        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.000136    |\n",
            "|    n_updates            | 1160        |\n",
            "|    policy_gradient_loss | 0.000668    |\n",
            "|    value_loss           | 3.27e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 626          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 65           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035731706 |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.257       |\n",
            "|    explained_variance   | -6.63        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00184     |\n",
            "|    n_updates            | 1170         |\n",
            "|    policy_gradient_loss | -0.000327    |\n",
            "|    value_loss           | 1.77e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 624          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 68           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028251715 |\n",
            "|    clip_fraction        | 0.0295       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.277       |\n",
            "|    explained_variance   | -12.2        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00129     |\n",
            "|    n_updates            | 1180         |\n",
            "|    policy_gradient_loss | -0.000961    |\n",
            "|    value_loss           | 2.35e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 626          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 71           |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015322067 |\n",
            "|    clip_fraction        | 0.0182       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.255       |\n",
            "|    explained_variance   | -18.1        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.000339     |\n",
            "|    n_updates            | 1190         |\n",
            "|    policy_gradient_loss | -0.000191    |\n",
            "|    value_loss           | 1.74e-07     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 500        |\n",
            "|    ep_rew_mean          | 500        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 628        |\n",
            "|    iterations           | 23         |\n",
            "|    time_elapsed         | 74         |\n",
            "|    total_timesteps      | 47104      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00676431 |\n",
            "|    clip_fraction        | 0.0507     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.269     |\n",
            "|    explained_variance   | -18.4      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.00573   |\n",
            "|    n_updates            | 1200       |\n",
            "|    policy_gradient_loss | -0.00173   |\n",
            "|    value_loss           | 4.31e-06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 623          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 78           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024955552 |\n",
            "|    clip_fraction        | 0.0107       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.269       |\n",
            "|    explained_variance   | -18.6        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00337      |\n",
            "|    n_updates            | 1210         |\n",
            "|    policy_gradient_loss | -0.000139    |\n",
            "|    value_loss           | 1.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 624          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 81           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018330084 |\n",
            "|    clip_fraction        | 0.0103       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.281       |\n",
            "|    explained_variance   | -14.5        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0143       |\n",
            "|    n_updates            | 1220         |\n",
            "|    policy_gradient_loss | 0.000524     |\n",
            "|    value_loss           | 7.9e-08      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 626          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015480928 |\n",
            "|    clip_fraction        | 0.0144       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.264       |\n",
            "|    explained_variance   | -16.4        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00131     |\n",
            "|    n_updates            | 1230         |\n",
            "|    policy_gradient_loss | -0.000292    |\n",
            "|    value_loss           | 1.34e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 627          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 88           |\n",
            "|    total_timesteps      | 55296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023626601 |\n",
            "|    clip_fraction        | 0.0346       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.259       |\n",
            "|    explained_variance   | -14.7        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00825     |\n",
            "|    n_updates            | 1240         |\n",
            "|    policy_gradient_loss | -0.00097     |\n",
            "|    value_loss           | 3.25e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 623          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 91           |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013581086 |\n",
            "|    clip_fraction        | 0.0175       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.261       |\n",
            "|    explained_variance   | -13.4        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.000245     |\n",
            "|    n_updates            | 1250         |\n",
            "|    policy_gradient_loss | -0.0005      |\n",
            "|    value_loss           | 1.57e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 625          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012043173 |\n",
            "|    clip_fraction        | 0.00913      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.239       |\n",
            "|    explained_variance   | -18.1        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.000151     |\n",
            "|    n_updates            | 1260         |\n",
            "|    policy_gradient_loss | -0.000785    |\n",
            "|    value_loss           | 0.000117     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 626          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 98           |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047147884 |\n",
            "|    clip_fraction        | 0.0232       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.243       |\n",
            "|    explained_variance   | -16.1        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00235      |\n",
            "|    n_updates            | 1270         |\n",
            "|    policy_gradient_loss | -0.000267    |\n",
            "|    value_loss           | 1.19e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 627          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 101          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056968215 |\n",
            "|    clip_fraction        | 0.0669       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.275       |\n",
            "|    explained_variance   | -11.1        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0103      |\n",
            "|    n_updates            | 1280         |\n",
            "|    policy_gradient_loss | -0.00437     |\n",
            "|    value_loss           | 6.41e-08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 623          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 105          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020943864 |\n",
            "|    clip_fraction        | 0.0146       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.267       |\n",
            "|    explained_variance   | -13.8        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00126      |\n",
            "|    n_updates            | 1290         |\n",
            "|    policy_gradient_loss | -0.000956    |\n",
            "|    value_loss           | 7.4e-08      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 625          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 108          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027121748 |\n",
            "|    clip_fraction        | 0.0204       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.249       |\n",
            "|    explained_variance   | -12.3        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00594     |\n",
            "|    n_updates            | 1300         |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    value_loss           | 8.07e-08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 626          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 111          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023106989 |\n",
            "|    clip_fraction        | 0.0148       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.247       |\n",
            "|    explained_variance   | -11.3        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0021      |\n",
            "|    n_updates            | 1310         |\n",
            "|    policy_gradient_loss | 0.000152     |\n",
            "|    value_loss           | 9.62e-08     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 500        |\n",
            "|    ep_rew_mean          | 500        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 627        |\n",
            "|    iterations           | 35         |\n",
            "|    time_elapsed         | 114        |\n",
            "|    total_timesteps      | 71680      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00209055 |\n",
            "|    clip_fraction        | 0.0263     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.254     |\n",
            "|    explained_variance   | -15.2      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.00832   |\n",
            "|    n_updates            | 1320       |\n",
            "|    policy_gradient_loss | 0.000343   |\n",
            "|    value_loss           | 1.04e-07   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 623          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 118          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033466727 |\n",
            "|    clip_fraction        | 0.0671       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.26        |\n",
            "|    explained_variance   | -14.7        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.03        |\n",
            "|    n_updates            | 1330         |\n",
            "|    policy_gradient_loss | -0.00303     |\n",
            "|    value_loss           | 4.18e-07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 624         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 121         |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002148357 |\n",
            "|    clip_fraction        | 0.0143      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.235      |\n",
            "|    explained_variance   | -11.2       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00445    |\n",
            "|    n_updates            | 1340        |\n",
            "|    policy_gradient_loss | -0.000949   |\n",
            "|    value_loss           | 2.11e-07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 625          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 124          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026994569 |\n",
            "|    clip_fraction        | 0.0314       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.271       |\n",
            "|    explained_variance   | -21.4        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00269     |\n",
            "|    n_updates            | 1350         |\n",
            "|    policy_gradient_loss | -0.000904    |\n",
            "|    value_loss           | 5.13e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 624          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 127          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011064953 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.255       |\n",
            "|    explained_variance   | -22.2        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.000563     |\n",
            "|    n_updates            | 1360         |\n",
            "|    policy_gradient_loss | 0.000523     |\n",
            "|    value_loss           | 1.63e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 622          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 131          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037769012 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.264       |\n",
            "|    explained_variance   | -11.9        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00262      |\n",
            "|    n_updates            | 1370         |\n",
            "|    policy_gradient_loss | 0.000233     |\n",
            "|    value_loss           | 2.88e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 624          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 134          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015891539 |\n",
            "|    clip_fraction        | 0.0234       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.253       |\n",
            "|    explained_variance   | -1.98        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00136     |\n",
            "|    n_updates            | 1380         |\n",
            "|    policy_gradient_loss | -0.000478    |\n",
            "|    value_loss           | 2.01e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 625         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 137         |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002065312 |\n",
            "|    clip_fraction        | 0.0179      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.263      |\n",
            "|    explained_variance   | -2.52       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0198     |\n",
            "|    n_updates            | 1390        |\n",
            "|    policy_gradient_loss | -0.00113    |\n",
            "|    value_loss           | 1.34e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 623         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 141         |\n",
            "|    total_timesteps      | 88064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002501408 |\n",
            "|    clip_fraction        | 0.0143      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.254      |\n",
            "|    explained_variance   | -4.22       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00265     |\n",
            "|    n_updates            | 1400        |\n",
            "|    policy_gradient_loss | -0.000871   |\n",
            "|    value_loss           | 1.12e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 622          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 144          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028529956 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.259       |\n",
            "|    explained_variance   | -5.06        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00118      |\n",
            "|    n_updates            | 1410         |\n",
            "|    policy_gradient_loss | -0.000412    |\n",
            "|    value_loss           | 1.3e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 622          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 147          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023449436 |\n",
            "|    clip_fraction        | 0.0198       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.26        |\n",
            "|    explained_variance   | -7.55        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00136      |\n",
            "|    n_updates            | 1420         |\n",
            "|    policy_gradient_loss | -0.000284    |\n",
            "|    value_loss           | 1.68e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 623          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 151          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021798979 |\n",
            "|    clip_fraction        | 0.0312       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.255       |\n",
            "|    explained_variance   | -3.02        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00136      |\n",
            "|    n_updates            | 1430         |\n",
            "|    policy_gradient_loss | -0.00119     |\n",
            "|    value_loss           | 2.24e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 620          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 155          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055653565 |\n",
            "|    clip_fraction        | 0.032        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.269       |\n",
            "|    explained_variance   | -6.8         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0073      |\n",
            "|    n_updates            | 1440         |\n",
            "|    policy_gradient_loss | -0.000242    |\n",
            "|    value_loss           | 2.43e-07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 620         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 158         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002149319 |\n",
            "|    clip_fraction        | 0.0178      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.256      |\n",
            "|    explained_variance   | -9.95       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0031     |\n",
            "|    n_updates            | 1450        |\n",
            "|    policy_gradient_loss | -0.00104    |\n",
            "|    value_loss           | 2.25e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 620          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 161          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031265612 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.258       |\n",
            "|    explained_variance   | -8.07        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00753      |\n",
            "|    n_updates            | 1460         |\n",
            "|    policy_gradient_loss | -0.00196     |\n",
            "|    value_loss           | 7.09e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 620          |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 165          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060569625 |\n",
            "|    clip_fraction        | 0.0561       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.27        |\n",
            "|    explained_variance   | -13.7        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0167      |\n",
            "|    n_updates            | 1470         |\n",
            "|    policy_gradient_loss | -0.00221     |\n",
            "|    value_loss           | 2.93e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 617          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 169          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034152349 |\n",
            "|    clip_fraction        | 0.0251       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.263       |\n",
            "|    explained_variance   | -14.1        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00519     |\n",
            "|    n_updates            | 1480         |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    value_loss           | 3.98e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 618          |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 172          |\n",
            "|    total_timesteps      | 106496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015843587 |\n",
            "|    clip_fraction        | 0.0141       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.249       |\n",
            "|    explained_variance   | -8.88        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00255     |\n",
            "|    n_updates            | 1490         |\n",
            "|    policy_gradient_loss | -0.000555    |\n",
            "|    value_loss           | 2.25e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 618          |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 175          |\n",
            "|    total_timesteps      | 108544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019014215 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.254       |\n",
            "|    explained_variance   | -7.65        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00272      |\n",
            "|    n_updates            | 1500         |\n",
            "|    policy_gradient_loss | -0.000705    |\n",
            "|    value_loss           | 2.96e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 617         |\n",
            "|    iterations           | 54          |\n",
            "|    time_elapsed         | 179         |\n",
            "|    total_timesteps      | 110592      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003186766 |\n",
            "|    clip_fraction        | 0.0344      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.249      |\n",
            "|    explained_variance   | -12.8       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00402     |\n",
            "|    n_updates            | 1510        |\n",
            "|    policy_gradient_loss | -0.00099    |\n",
            "|    value_loss           | 8.9e-08     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 616          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 182          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011144502 |\n",
            "|    clip_fraction        | 0.0119       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.25        |\n",
            "|    explained_variance   | -4.33        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00228     |\n",
            "|    n_updates            | 1520         |\n",
            "|    policy_gradient_loss | -0.000297    |\n",
            "|    value_loss           | 9.34e-08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 617          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 185          |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006732805 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.265       |\n",
            "|    explained_variance   | -13          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00241     |\n",
            "|    n_updates            | 1530         |\n",
            "|    policy_gradient_loss | 0.000566     |\n",
            "|    value_loss           | 3.5e-07      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 617          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 189          |\n",
            "|    total_timesteps      | 116736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017332885 |\n",
            "|    clip_fraction        | 0.0197       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.247       |\n",
            "|    explained_variance   | -21.3        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00492     |\n",
            "|    n_updates            | 1540         |\n",
            "|    policy_gradient_loss | -6.55e-05    |\n",
            "|    value_loss           | 8.34e-07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 614         |\n",
            "|    iterations           | 58          |\n",
            "|    time_elapsed         | 193         |\n",
            "|    total_timesteps      | 118784      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000929797 |\n",
            "|    clip_fraction        | 0.0103      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.235      |\n",
            "|    explained_variance   | -8.57       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.000324   |\n",
            "|    n_updates            | 1550        |\n",
            "|    policy_gradient_loss | -8.72e-05   |\n",
            "|    value_loss           | 5.86e-07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 615          |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 196          |\n",
            "|    total_timesteps      | 120832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076977224 |\n",
            "|    clip_fraction        | 0.0746       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.263       |\n",
            "|    explained_variance   | -4.48        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00728     |\n",
            "|    n_updates            | 1560         |\n",
            "|    policy_gradient_loss | -0.00371     |\n",
            "|    value_loss           | 6.11e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 615          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 199          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028369955 |\n",
            "|    clip_fraction        | 0.0274       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.254       |\n",
            "|    explained_variance   | -8.13        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0047      |\n",
            "|    n_updates            | 1570         |\n",
            "|    policy_gradient_loss | -0.00116     |\n",
            "|    value_loss           | 6.33e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 616          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 202          |\n",
            "|    total_timesteps      | 124928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035944716 |\n",
            "|    clip_fraction        | 0.0482       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.252       |\n",
            "|    explained_variance   | -2.03        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0039       |\n",
            "|    n_updates            | 1580         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    value_loss           | 2.14e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 613          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 206          |\n",
            "|    total_timesteps      | 126976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046438696 |\n",
            "|    clip_fraction        | 0.0531       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.273       |\n",
            "|    explained_variance   | -5.03        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0018      |\n",
            "|    n_updates            | 1590         |\n",
            "|    policy_gradient_loss | -0.00371     |\n",
            "|    value_loss           | 1.68e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 613          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 210          |\n",
            "|    total_timesteps      | 129024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022832628 |\n",
            "|    clip_fraction        | 0.0359       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.27        |\n",
            "|    explained_variance   | -5.51        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00856      |\n",
            "|    n_updates            | 1600         |\n",
            "|    policy_gradient_loss | -0.000285    |\n",
            "|    value_loss           | 1.82e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 612          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 213          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012023828 |\n",
            "|    clip_fraction        | 0.0127       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.28        |\n",
            "|    explained_variance   | -6.47        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0141       |\n",
            "|    n_updates            | 1610         |\n",
            "|    policy_gradient_loss | 0.000255     |\n",
            "|    value_loss           | 1.19e-06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 500        |\n",
            "|    ep_rew_mean          | 500        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 609        |\n",
            "|    iterations           | 65         |\n",
            "|    time_elapsed         | 218        |\n",
            "|    total_timesteps      | 133120     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00205411 |\n",
            "|    clip_fraction        | 0.0354     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.272     |\n",
            "|    explained_variance   | -11.1      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0195    |\n",
            "|    n_updates            | 1620       |\n",
            "|    policy_gradient_loss | -0.00132   |\n",
            "|    value_loss           | 3.21e-06   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 609         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 221         |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003988473 |\n",
            "|    clip_fraction        | 0.0264      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.27       |\n",
            "|    explained_variance   | -7.46       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00575     |\n",
            "|    n_updates            | 1630        |\n",
            "|    policy_gradient_loss | -0.000205   |\n",
            "|    value_loss           | 1.28e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 610         |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 224         |\n",
            "|    total_timesteps      | 137216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002367853 |\n",
            "|    clip_fraction        | 0.0347      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.255      |\n",
            "|    explained_variance   | -16.6       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00799     |\n",
            "|    n_updates            | 1640        |\n",
            "|    policy_gradient_loss | 0.000197    |\n",
            "|    value_loss           | 3.78e-07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 610         |\n",
            "|    iterations           | 68          |\n",
            "|    time_elapsed         | 228         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004624688 |\n",
            "|    clip_fraction        | 0.0502      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.277      |\n",
            "|    explained_variance   | -16         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0172     |\n",
            "|    n_updates            | 1650        |\n",
            "|    policy_gradient_loss | -0.00318    |\n",
            "|    value_loss           | 7.48e-08    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 608          |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 232          |\n",
            "|    total_timesteps      | 141312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015266596 |\n",
            "|    clip_fraction        | 0.0166       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.251       |\n",
            "|    explained_variance   | -11.2        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0045      |\n",
            "|    n_updates            | 1660         |\n",
            "|    policy_gradient_loss | -0.000504    |\n",
            "|    value_loss           | 2.71e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 609          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 235          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017216641 |\n",
            "|    clip_fraction        | 0.0127       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.245       |\n",
            "|    explained_variance   | -14.2        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00114     |\n",
            "|    n_updates            | 1670         |\n",
            "|    policy_gradient_loss | -0.000511    |\n",
            "|    value_loss           | 1.58e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 609          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 238          |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021848863 |\n",
            "|    clip_fraction        | 0.0154       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.259       |\n",
            "|    explained_variance   | -10.7        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00221      |\n",
            "|    n_updates            | 1680         |\n",
            "|    policy_gradient_loss | 0.000794     |\n",
            "|    value_loss           | 1.98e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 609          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 241          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013015412 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.261       |\n",
            "|    explained_variance   | -11.1        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.013        |\n",
            "|    n_updates            | 1690         |\n",
            "|    policy_gradient_loss | -0.00117     |\n",
            "|    value_loss           | 1.08e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 608          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 245          |\n",
            "|    total_timesteps      | 149504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024398542 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.251       |\n",
            "|    explained_variance   | -25.7        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00507      |\n",
            "|    n_updates            | 1700         |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    value_loss           | 4.22e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 608          |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 248          |\n",
            "|    total_timesteps      | 151552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028684605 |\n",
            "|    clip_fraction        | 0.0424       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.271       |\n",
            "|    explained_variance   | -0.602       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00456     |\n",
            "|    n_updates            | 1710         |\n",
            "|    policy_gradient_loss | -0.00122     |\n",
            "|    value_loss           | 5.25e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 608          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 252          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039875507 |\n",
            "|    clip_fraction        | 0.0421       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.248       |\n",
            "|    explained_variance   | -6.12        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0114       |\n",
            "|    n_updates            | 1720         |\n",
            "|    policy_gradient_loss | -0.00286     |\n",
            "|    value_loss           | 3.24e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 607          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 256          |\n",
            "|    total_timesteps      | 155648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029038617 |\n",
            "|    clip_fraction        | 0.0304       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.252       |\n",
            "|    explained_variance   | -10.3        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00335      |\n",
            "|    n_updates            | 1730         |\n",
            "|    policy_gradient_loss | -0.00168     |\n",
            "|    value_loss           | 1.25e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 607          |\n",
            "|    iterations           | 77           |\n",
            "|    time_elapsed         | 259          |\n",
            "|    total_timesteps      | 157696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036787817 |\n",
            "|    clip_fraction        | 0.0312       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.272       |\n",
            "|    explained_variance   | -18.1        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0263       |\n",
            "|    n_updates            | 1740         |\n",
            "|    policy_gradient_loss | -0.000715    |\n",
            "|    value_loss           | 7.15e-07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 608          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 262          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020818398 |\n",
            "|    clip_fraction        | 0.016        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.268       |\n",
            "|    explained_variance   | -14.3        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0122      |\n",
            "|    n_updates            | 1750         |\n",
            "|    policy_gradient_loss | -0.00032     |\n",
            "|    value_loss           | 1.72e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 608          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 265          |\n",
            "|    total_timesteps      | 161792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020539502 |\n",
            "|    clip_fraction        | 0.0186       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.245       |\n",
            "|    explained_variance   | -12          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00554      |\n",
            "|    n_updates            | 1760         |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    value_loss           | 7.88e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 606          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 269          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029801629 |\n",
            "|    clip_fraction        | 0.0233       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.259       |\n",
            "|    explained_variance   | -35.1        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00221      |\n",
            "|    n_updates            | 1770         |\n",
            "|    policy_gradient_loss | -0.00075     |\n",
            "|    value_loss           | 2.99e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 607         |\n",
            "|    iterations           | 81          |\n",
            "|    time_elapsed         | 273         |\n",
            "|    total_timesteps      | 165888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002339133 |\n",
            "|    clip_fraction        | 0.0185      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.243      |\n",
            "|    explained_variance   | -10.7       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.000116   |\n",
            "|    n_updates            | 1780        |\n",
            "|    policy_gradient_loss | -0.00114    |\n",
            "|    value_loss           | 1.3e-07     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 606         |\n",
            "|    iterations           | 82          |\n",
            "|    time_elapsed         | 277         |\n",
            "|    total_timesteps      | 167936      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005248529 |\n",
            "|    clip_fraction        | 0.0447      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.27       |\n",
            "|    explained_variance   | -8.74       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0083     |\n",
            "|    n_updates            | 1790        |\n",
            "|    policy_gradient_loss | -0.00212    |\n",
            "|    value_loss           | 8.41e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 605         |\n",
            "|    iterations           | 83          |\n",
            "|    time_elapsed         | 280         |\n",
            "|    total_timesteps      | 169984      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002280911 |\n",
            "|    clip_fraction        | 0.018       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.262      |\n",
            "|    explained_variance   | -8.81       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.000356    |\n",
            "|    n_updates            | 1800        |\n",
            "|    policy_gradient_loss | -0.00114    |\n",
            "|    value_loss           | 5.94e-07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 605          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 284          |\n",
            "|    total_timesteps      | 172032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021448918 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.27        |\n",
            "|    explained_variance   | -12.3        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00533     |\n",
            "|    n_updates            | 1810         |\n",
            "|    policy_gradient_loss | 0.000941     |\n",
            "|    value_loss           | 3.87e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 605         |\n",
            "|    iterations           | 85          |\n",
            "|    time_elapsed         | 287         |\n",
            "|    total_timesteps      | 174080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001899554 |\n",
            "|    clip_fraction        | 0.0141      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.26       |\n",
            "|    explained_variance   | -5.02       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0111     |\n",
            "|    n_updates            | 1820        |\n",
            "|    policy_gradient_loss | -0.00209    |\n",
            "|    value_loss           | 4.37e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 605         |\n",
            "|    iterations           | 86          |\n",
            "|    time_elapsed         | 290         |\n",
            "|    total_timesteps      | 176128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005972759 |\n",
            "|    clip_fraction        | 0.056       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.27       |\n",
            "|    explained_variance   | -2.67       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00494    |\n",
            "|    n_updates            | 1830        |\n",
            "|    policy_gradient_loss | -0.00252    |\n",
            "|    value_loss           | 1.49e-07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 603         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 295         |\n",
            "|    total_timesteps      | 178176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001334873 |\n",
            "|    clip_fraction        | 0.0286      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.259      |\n",
            "|    explained_variance   | -5.86       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0117      |\n",
            "|    n_updates            | 1840        |\n",
            "|    policy_gradient_loss | -0.00108    |\n",
            "|    value_loss           | 5.83e-08    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 603          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 298          |\n",
            "|    total_timesteps      | 180224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013445804 |\n",
            "|    clip_fraction        | 0.0117       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.245       |\n",
            "|    explained_variance   | -6.53        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0086      |\n",
            "|    n_updates            | 1850         |\n",
            "|    policy_gradient_loss | -0.00108     |\n",
            "|    value_loss           | 8.89e-08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 604          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 301          |\n",
            "|    total_timesteps      | 182272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027557642 |\n",
            "|    clip_fraction        | 0.0153       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.252       |\n",
            "|    explained_variance   | -14.9        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00748      |\n",
            "|    n_updates            | 1860         |\n",
            "|    policy_gradient_loss | -0.000291    |\n",
            "|    value_loss           | 2.41e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 604          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 305          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015861792 |\n",
            "|    clip_fraction        | 0.048        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.262       |\n",
            "|    explained_variance   | -13.5        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00597     |\n",
            "|    n_updates            | 1870         |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    value_loss           | 1.19e-07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 603         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 308         |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004117645 |\n",
            "|    clip_fraction        | 0.0246      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.266      |\n",
            "|    explained_variance   | -8.42       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00819     |\n",
            "|    n_updates            | 1880        |\n",
            "|    policy_gradient_loss | -0.000186   |\n",
            "|    value_loss           | 1.05e-07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 603         |\n",
            "|    iterations           | 92          |\n",
            "|    time_elapsed         | 312         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002447312 |\n",
            "|    clip_fraction        | 0.0254      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.265      |\n",
            "|    explained_variance   | -10.2       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00186    |\n",
            "|    n_updates            | 1890        |\n",
            "|    policy_gradient_loss | -0.000444   |\n",
            "|    value_loss           | 9.58e-07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 604          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 315          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016194857 |\n",
            "|    clip_fraction        | 0.00928      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.249       |\n",
            "|    explained_variance   | -7.52        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00264      |\n",
            "|    n_updates            | 1900         |\n",
            "|    policy_gradient_loss | -7.17e-08    |\n",
            "|    value_loss           | 1.8e-06      |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 500           |\n",
            "|    ep_rew_mean          | 500           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 603           |\n",
            "|    iterations           | 94            |\n",
            "|    time_elapsed         | 318           |\n",
            "|    total_timesteps      | 192512        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00073901785 |\n",
            "|    clip_fraction        | 0.0242        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.269        |\n",
            "|    explained_variance   | -6.05         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.00405       |\n",
            "|    n_updates            | 1910          |\n",
            "|    policy_gradient_loss | 0.00054       |\n",
            "|    value_loss           | 1.22e-05      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 603         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 322         |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005155719 |\n",
            "|    clip_fraction        | 0.057       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.277      |\n",
            "|    explained_variance   | -8.33       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00729    |\n",
            "|    n_updates            | 1920        |\n",
            "|    policy_gradient_loss | -0.00243    |\n",
            "|    value_loss           | 3.33e-07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 500         |\n",
            "|    ep_rew_mean          | 500         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 603         |\n",
            "|    iterations           | 96          |\n",
            "|    time_elapsed         | 325         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002190696 |\n",
            "|    clip_fraction        | 0.0174      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.245      |\n",
            "|    explained_variance   | -16.2       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00094    |\n",
            "|    n_updates            | 1930        |\n",
            "|    policy_gradient_loss | -0.00168    |\n",
            "|    value_loss           | 1.15e-07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 603          |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 329          |\n",
            "|    total_timesteps      | 198656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024216904 |\n",
            "|    clip_fraction        | 0.0205       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.252       |\n",
            "|    explained_variance   | -22.7        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.000755     |\n",
            "|    n_updates            | 1940         |\n",
            "|    policy_gradient_loss | -0.00029     |\n",
            "|    value_loss           | 8.9e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 500          |\n",
            "|    ep_rew_mean          | 500          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 602          |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 333          |\n",
            "|    total_timesteps      | 200704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010677169 |\n",
            "|    clip_fraction        | 0.0131       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.239       |\n",
            "|    explained_variance   | -13          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00301     |\n",
            "|    n_updates            | 1950         |\n",
            "|    policy_gradient_loss | -0.00045     |\n",
            "|    value_loss           | 8.08e-08     |\n",
            "------------------------------------------\n",
            "Model saved!\n"
          ]
        }
      ],
      "source": [
        "# Your existing training code\n",
        "model.learn(total_timesteps=200000)\n",
        "\n",
        "# ==> ADD THIS LINE <==\n",
        "model.save(\"ppo_my_model\")\n",
        "print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b303d2ba",
        "outputId": "20dcb967-6df2-429e-e8b0-e5137091fd14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing inverter_model_gpu.py\n"
          ]
        }
      ],
      "source": [
        "# Save the InverterModelGPU class to a Python file\n",
        "%%writefile inverter_model_gpu.py\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.integrate import solve_ivp # Although not directly used in the GPU version, it's good practice to keep imports if they are part of the original design.\n",
        "\n",
        "class InverterModelGPU:\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device)\n",
        "        self.L = torch.tensor(1.5e-3, device=device)\n",
        "        self.C = torch.tensor(10e-6, device=device)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "\n",
        "        self.state = torch.zeros(2, device=device)\n",
        "        self.sim_time = torch.tensor(0.0, device=device)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    def batch_step_rk4(self, modulation_index, r_load, num_steps, dt=1e-5):\n",
        "        t_steps = self.sim_time + torch.arange(num_steps, device=self.device) * dt\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * t_steps)\n",
        "        carrier = 2 * (torch.abs(2 * ((t_steps / self.pwm_period) - torch.floor(0.5 + t_steps / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "\n",
        "        y = self.state.clone()\n",
        "        outputs = torch.zeros(num_steps, 2, device=self.device)\n",
        "\n",
        "        for i in range(num_steps):\n",
        "            v_inv_step = v_inverter[i] - torch.sign(v_inverter[i]) * y[0] * self.Rds_on\n",
        "            k1 = self._diffeq(y, v_inv_step, r_load)\n",
        "            k2 = self._diffeq(y + 0.5 * dt * k1, v_inv_step, r_load)\n",
        "            k3 = self._diffeq(y + 0.5 * dt * k2, v_inv_step, r_load)\n",
        "            k4 = self._diffeq(y + dt * k3, v_inv_step, r_load)\n",
        "            y = y + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "            outputs[i] = y\n",
        "\n",
        "        self.state = outputs[-1]\n",
        "        self.sim_time += num_steps * dt\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nV-o2-hZ4wrZ",
        "outputId": "297e7623-e12f-49bc-a505-100b47053a0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Installing Dependencies ---\n",
            "\n",
            "--- Dependencies Installed Successfully! ---\n",
            "--- Step 2: Defining All Required Classes ---\n",
            "--- All classes defined successfully! ---\n",
            "\n",
            "--- Running simulation for: SPWM Controller ---\n",
            "Simulation finished in 11.50 seconds.\n",
            "\n",
            "--- Running simulation for: PI Controller ---\n",
            "Simulation finished in 12.02 seconds.\n",
            "\n",
            "--- Running simulation for: RL Controller (Proposed) ---\n",
            "Simulation finished in 24.89 seconds.\n",
            "\n",
            "--- Analyzing results and generating plots... ---\n",
            "\n",
            "--- Plots generated and saved as 'final_comparison_results.png' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Part 1: Install Dependencies\n",
        "# ==============================================================================\n",
        "print(\"--- Step 1: Installing Dependencies ---\")\n",
        "!pip install gymnasium stable-baselines3[extra] torch torchdiffeq -q\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "from gymnasium import spaces # Import spaces for defining observation space\n",
        "\n",
        "print(\"\\n--- Dependencies Installed Successfully! ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 2: Define All Classes Directly in the Notebook\n",
        "# ==============================================================================\n",
        "print(\"--- Step 2: Defining All Required Classes ---\")\n",
        "\n",
        "# --- From inverter_model_gpu.py ---\n",
        "class InverterModelGPU:\n",
        "    \"\"\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # Custom RK4 Solver Step\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state\n",
        "\n",
        "# Define InverterEnvGPU within this cell (kept for potential future use or clarity, but not used in run_simulation)\n",
        "class InverterEnvGPU:\n",
        "    \"\"\"A custom Gymnasium environment for the RL-controlled inverter (GPU version).\"\"\"\n",
        "    def __init__(self, device):\n",
        "        # Using InverterModelGPU defined within this same cell\n",
        "        self.inverter = InverterModelGPU(device=device)\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item() # Use .item() for scalar tensor\n",
        "        self.dt = 1e-5 # Simulation time step\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / self.dt)\n",
        "\n",
        "        # Action: A single continuous value for modulation index [-1, 1]\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "\n",
        "        # Observation: [V_rms, I_rms, Power, THD] - Shape (4,)\n",
        "        # Explicitly set observation space shape to (4,)\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(4,), dtype=np.float32)\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.max_cycles = 200 # An episode will last 200 AC cycles\n",
        "\n",
        "        self.device = device # Store device\n",
        "\n",
        "    def _get_obs(self, v_history_tensor, i_history_tensor):\n",
        "        if v_history_tensor.numel() < 2: # Use numel() for tensor\n",
        "            return torch.zeros(4, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_tensor**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_tensor**2))\n",
        "        power = torch.mean(v_history_tensor * i_history_tensor)\n",
        "\n",
        "        # Calculate THD (Total Harmonic Distortion)\n",
        "        thd = torch.tensor(0.0, device=self.device, dtype=torch.float32)\n",
        "        if v_history_tensor.numel() > 1:\n",
        "            fft = torch.fft.fft(v_history_tensor)\n",
        "            # Avoid calculating THD if fundamental is zero or near zero\n",
        "            if torch.abs(fft[int(self.inverter.ac_freq.item() / (1.0/v_history_tensor.numel()/self.dt)) + 1]).item() > 1e-6: # Corrected fundamental index\n",
        "               # Get magnitudes of harmonics (excluding DC component)\n",
        "               harmonics_abs = torch.abs(fft[1:int(self.inverter.ac_freq.item() / (1.0/v_history_tensor.numel()/self.dt)) + 11]) # Consider more harmonics\n",
        "               fundamental_abs = harmonics_abs[int(self.inverter.ac_freq.item() / (1.0/v_history_tensor.numel()/self.dt))]\n",
        "               # Sum of squares of higher harmonics magnitudes\n",
        "               higher_harmonics_sum_sq = torch.sqrt(torch.sum(harmonics_abs[int(self.inverter.ac_freq.item() / (1.0/v_history_tensor.numel()/self.dt)) + 1:]**2))\n",
        "               # THD calculation: sqrt(sum(harmonics[2:]^2)) / fundamental\n",
        "               thd = higher_harmonics_sum_sq / (fundamental_abs + 1e-6)\n",
        "            else:\n",
        "                thd = torch.tensor(1.0, device=self.device, dtype=torch.float32) # Assume high distortion if fundamental is zero\n",
        "\n",
        "\n",
        "        # Ensure obs is a tensor of shape (4,)\n",
        "        obs = torch.stack([v_rms, i_rms, power, thd]) # Stack only 4 elements\n",
        "        # Replace non-finite values with 0\n",
        "        obs[~torch.isfinite(obs)] = 0.0\n",
        "\n",
        "        return obs\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        # Randomize load on reset, keep it on the same device\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        # Initial observation (zeros as no history yet), ensure it's on the correct device and shape (4,)\n",
        "        obs = torch.zeros(4, device=self.device, dtype=torch.float32) # Initialize with 4 zeros\n",
        "        return obs.cpu().numpy(), {} # Return numpy array for SB3 compatibility\n",
        "\n",
        "    def step(self, action):\n",
        "        # Action is a numpy array from SB3, convert to tensor\n",
        "        action_tensor = torch.tensor(action[0], device=self.device, dtype=torch.float32)\n",
        "        modulation_index = (action_tensor + 1.0) / 2.0 # De-normalize action from [-1, 1] to [0, 1]\n",
        "\n",
        "        v_history_tensor = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "        i_history_tensor = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "             # Pass load_resistance as a scalar tensor\n",
        "            state, _ = self.inverter.step(modulation_index.item(), self.load_resistance.item(), self.dt)\n",
        "            i_history_tensor[i] = state[0]\n",
        "            v_history_tensor[i] = state[1]\n",
        "\n",
        "        # Get observation (tensor) - Will be shape (4,) now\n",
        "        obs_tensor = self._get_obs(v_history_tensor, i_history_tensor)\n",
        "        v_rms, i_rms, power, thd = obs_tensor # Unpack 4 elements\n",
        "\n",
        "        # --- Multi-Objective Reward Function ---\n",
        "        target_v_rms = 30.0 # Target voltage in our low-voltage simulation\n",
        "\n",
        "        # 1. Voltage Error Penalty\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward_voltage = - (voltage_error**2)\n",
        "\n",
        "        # 2. THD Penalty\n",
        "        reward_thd = - (thd**2) if thd < 0.5 else torch.tensor(-10.0, device=self.device, dtype=torch.float32) # Heavily penalize high distortion\n",
        "\n",
        "        # 3. Stability Reward\n",
        "        reward_stability = torch.tensor(5.0, device=self.device, dtype=torch.float32) if voltage_error < 1.0 and thd < 0.1 else torch.tensor(0.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        reward = reward_voltage + reward_thd + reward_stability\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_cycles\n",
        "        truncated = False # Or define truncation conditions\n",
        "\n",
        "        # Return numpy array observation (shape 4,) and scalar reward (as expected by SB3 DummyVecEnv)\n",
        "        return obs_tensor.cpu().numpy(), reward.item(), done, truncated, {}\n",
        "\n",
        "# --- From controllers.py ---\n",
        "class SPWMController:\n",
        "    def __init__(self, modulation_index=0.8, ac_freq=50.0):\n",
        "        self.m = modulation_index\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "class PIController:\n",
        "    def __init__(self, Kp, Ki, target_rms, ac_freq=50.0):\n",
        "        self.Kp = Kp\n",
        "        self.Ki = Ki\n",
        "        self.target_rms = target_rms\n",
        "        self.ac_period = 1.0 / ac_freq\n",
        "        self.integral_error = 0.0\n",
        "        self.m = 0.8\n",
        "    def update_modulation_index(self, v_c_history_tensor):\n",
        "        if v_c_history_tensor.numel() == 0: return\n",
        "        measured_rms = torch.sqrt(torch.mean(v_c_history_tensor**2))\n",
        "        error = self.target_rms - measured_rms.item()\n",
        "        self.integral_error += error * self.ac_period\n",
        "        self.integral_error = np.clip(self.integral_error, -10.0, 10.0)\n",
        "        self.m = (self.Kp * error) + (self.Ki * self.integral_error)\n",
        "        self.m = np.clip(self.m, 0.0, 1.0)\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "\n",
        "print(\"--- All classes defined successfully! ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 3: The Master Simulation Function\n",
        "# ==============================================================================\n",
        "\n",
        "def run_simulation(controller_type, model_path=None, duration=0.2, dt=1e-5):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    if controller_type == \"RL\":\n",
        "        try:\n",
        "            # Load the model onto the correct device\n",
        "            sim_controller = PPO.load(model_path, device=device)\n",
        "            controller_name = \"RL Controller (Proposed)\"\n",
        "        except FileNotFoundError:\n",
        "            print(f\"\\nFATAL ERROR: Model file not found at '{model_path}'\")\n",
        "            return None\n",
        "    elif controller_type == \"PI\":\n",
        "        sim_controller = PIController(Kp=0.05, Ki=2.5, target_rms=30.0)\n",
        "        controller_name = \"PI Controller\"\n",
        "    elif controller_type == \"SPWM\":\n",
        "        sim_controller = SPWMController(modulation_index=0.65)\n",
        "        controller_name = \"SPWM Controller\"\n",
        "    else:\n",
        "        raise ValueError(\"Unknown controller type.\")\n",
        "\n",
        "    print(f\"\\n--- Running simulation for: {controller_name} ---\")\n",
        "\n",
        "    # Instantiate the GPU Inverter Model (used for all controllers now)\n",
        "    inverter = InverterModelGPU(device=device)\n",
        "    num_steps = int(duration / dt)\n",
        "\n",
        "    time_hist = np.zeros(num_steps)\n",
        "    v_c_hist = np.zeros(num_steps)\n",
        "    i_l_hist = np.zeros(num_steps)\n",
        "\n",
        "    ac_period_steps = int((1.0 / inverter.ac_freq.item()) / dt)\n",
        "\n",
        "    # Initialize observation for RL controller (shape (4,))\n",
        "    obs = np.zeros(4, dtype=np.float32) # Initialize with 4 zeros\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in range(num_steps):\n",
        "        t = i * dt\n",
        "\n",
        "        # Load scheduling (applied directly in the simulation step)\n",
        "        r_load_val = 50.0\n",
        "        if 0.08 <= t < 0.16:\n",
        "            r_load_val = 25.0\n",
        "        r_load_tensor = torch.tensor(r_load_val, device=device, dtype=torch.float32)\n",
        "\n",
        "        if controller_type == \"RL\":\n",
        "            # Get action from the RL controller\n",
        "            # Pass the observation with an added batch dimension (expected by SB3 models trained on VecEnvs)\n",
        "            action, _ = sim_controller.predict(np.expand_dims(obs, axis=0), deterministic=True)\n",
        "            # De-normalize action from [-1, 1] to [0, 1]. action is a batch, take the first element.\n",
        "            m_numpy = (action[0] + 1.0) / 2.0\n",
        "\n",
        "        else: # PI and SPWM controllers\n",
        "            if isinstance(sim_controller, PIController) and i > 0 and i % ac_period_steps == 0:\n",
        "                 # PI update logic (using history collected so far)\n",
        "                 v_cycle_tensor = torch.from_numpy(v_c_hist[max(0, i - ac_period_steps):i]).to(device)\n",
        "                 sim_controller.update_modulation_index(v_cycle_tensor)\n",
        "\n",
        "            m_numpy = sim_controller.get_modulation_index(t)\n",
        "\n",
        "        # Step the *inverter model* directly for all controllers\n",
        "        modulation_index = torch.tensor(m_numpy, device=device)\n",
        "        state_gpu = inverter.step(modulation_index, r_load_tensor, dt)\n",
        "        state_cpu = state_gpu.cpu().numpy()\n",
        "\n",
        "        # Store history\n",
        "        time_hist[i], v_c_hist[i], i_l_hist[i] = t, state_cpu[1], state_cpu[0]\n",
        "\n",
        "        # Update the observation for the next step if using the RL controller and at the end of a cycle\n",
        "        if controller_type == \"RL\" and (i + 1) % ac_period_steps == 0:\n",
        "            v_cycle = torch.from_numpy(v_c_hist[max(0, i-ac_period_steps+1):i+1]).to(device)\n",
        "            i_cycle = torch.from_numpy(i_l_hist[max(0, i-ac_period_steps+1):i+1]).to(device)\n",
        "\n",
        "            # Calculate the 4-element observation vector (V_rms, I_rms, Power, THD)\n",
        "            v_rms = torch.sqrt(torch.mean(v_cycle**2))\n",
        "            i_rms = torch.sqrt(torch.mean(i_cycle**2))\n",
        "            power = torch.mean(v_cycle * i_cycle)\n",
        "\n",
        "            thd = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "            if len(v_cycle) > 1:\n",
        "                fft = torch.fft.fft(v_cycle)\n",
        "                # Attempt to find the fundamental frequency index based on the number of points in the cycle\n",
        "                freq_resolution = (1.0 / (len(v_cycle) * dt))\n",
        "                fundamental_freq_idx = int(inverter.ac_freq.item() / freq_resolution)\n",
        "                if fundamental_freq_idx < len(fft) and torch.abs(fft[fundamental_freq_idx]).item() > 1e-6:\n",
        "                   harmonics_abs = torch.abs(fft[1: fundamental_freq_idx + 11]) # Consider fundamental + 10 harmonics\n",
        "                   fundamental_abs = harmonics_abs[fundamental_freq_idx -1] # Adjust index based on slice\n",
        "                   # Sum of squares of higher harmonics magnitudes\n",
        "                   higher_harmonics_sum_sq = torch.sum(harmonics_abs[fundamental_freq_idx : ]**2) # Sum from fundamental onwards\n",
        "                   thd = torch.sqrt(higher_harmonics_sum_sq) / (fundamental_abs + 1e-6)\n",
        "                else:\n",
        "                    thd = torch.tensor(1.0, device=device, dtype=torch.float32) # Assume high distortion if fundamental is zero\n",
        "\n",
        "            # Construct obs as a NumPy array of shape (4,)\n",
        "            obs = torch.stack([v_rms, i_rms, power, thd]).cpu().numpy()\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Simulation finished in {end_time - start_time:.2f} seconds.\")\n",
        "    return time_hist, v_c_hist, i_l_hist\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 4: Analysis and Plotting Function\n",
        "# ==============================================================================\n",
        "\n",
        "def analyze_and_plot(results):\n",
        "    print(\"\\n--- Analyzing results and generating plots... ---\")\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(12, 12), dpi=150)\n",
        "\n",
        "    ax = axes[0]\n",
        "    for name, data in results.items():\n",
        "        time, v_c, _ = data\n",
        "        dt = time[1] - time[0]\n",
        "        window_size = int(0.02 / dt)\n",
        "        # Ensure we have enough data points for the sliding window\n",
        "        if len(v_c) >= window_size:\n",
        "            rms_voltage = [np.sqrt(np.mean(v_c[i-window_size:i]**2)) for i in range(window_size, len(v_c))]\n",
        "            ax.plot(time[window_size:], rms_voltage, label=name, linewidth=2.5)\n",
        "        else:\n",
        "            print(f\"Warning: Not enough data for RMS calculation for {name}\")\n",
        "\n",
        "\n",
        "    ax.set_title('Dynamic Voltage Response to Load Step', fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel('Time (s)', fontsize=12)\n",
        "    ax.set_ylabel('RMS Voltage (V)', fontsize=12)\n",
        "    ax.axvspan(0.08, 0.16, color='gray', alpha=0.2, label='Heavy Load Applied')\n",
        "    ax.legend(fontsize=12); ax.grid(True, which='both', linestyle='--')\n",
        "\n",
        "    thd_values = {}\n",
        "    for name, data in results.items():\n",
        "        time, v_c, _ = data\n",
        "        # Select a portion of the steady-state waveform for THD calculation\n",
        "        steady_state_mask = (time >= 0.1) & (time < 0.16)\n",
        "        v_steady = v_c[steady_state_mask]\n",
        "\n",
        "        thd = 0.0\n",
        "        if len(v_steady) > 1:\n",
        "            fft = np.fft.fft(v_steady)\n",
        "             # Avoid calculating THD if fundamental is zero or near zero\n",
        "            if np.abs(fft[1]).item() > 1e-6:\n",
        "                harmonics = np.abs(fft[1:11])\n",
        "                fundamental = harmonics[0]\n",
        "                thd = np.sqrt(np.sum(harmonics[1:]**2)) / fundamental\n",
        "            else:\n",
        "                thd = 1.0 # Assume high distortion if fundamental is zero\n",
        "\n",
        "        thd_values[name] = thd * 100\n",
        "\n",
        "    ax = axes[1]\n",
        "    colors = ['gray', 'cornflowerblue', 'crimson']\n",
        "    # Ensure the number of colors matches the number of bars\n",
        "    num_bars = len(thd_values)\n",
        "    bars = ax.bar(list(thd_values.keys()), list(thd_values.values()), color=colors[:num_bars])\n",
        "    ax.set_title('Power Quality: Total Harmonic Distortion (THD)', fontsize=16, fontweight='bold')\n",
        "    ax.set_ylabel('THD (%)', fontsize=12)\n",
        "    ax.bar_label(bars, fmt='%.2f%%')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"final_comparison_results.png\")\n",
        "    print(\"\\n--- Plots generated and saved as 'final_comparison_results.png' ---\")\n",
        "    plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 5: Main Execution Block\n",
        "# ==============================================================================\n",
        "if __name__ == '__main__':\n",
        "    results = {}\n",
        "\n",
        "    # !!! IMPORTANT !!!\n",
        "    # Make sure this name matches the name of your best trained model file!\n",
        "    # For example, \"ppo_final_model.zip\" or \"ppo_my_model.zip\"\n",
        "    rl_model_filename = \"ppo_my_model.zip\" # <--- Replace with your model filename\n",
        "\n",
        "    # Run the simulation for each controller\n",
        "    results[\"SPWM Controller\"] = run_simulation(controller_type=\"SPWM\")\n",
        "    results[\"PI Controller\"] = run_simulation(controller_type=\"PI\")\n",
        "    results[\"RL Controller (Proposed)\"] = run_simulation(controller_type=\"RL\", model_path=rl_model_filename)\n",
        "\n",
        "    # Check if all simulations were successful before plotting\n",
        "    if all(res is not None for res in results.values()):\n",
        "        analyze_and_plot(results)\n",
        "    else:\n",
        "        print(\"\\n--- Skipping analysis due to a simulation failure. ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wLuYd5aqA--s"
      },
      "outputs": [],
      "source": [
        "# File: inverter_model_gpu.py\n",
        "import torch\n",
        "\n",
        "class InverterODE(torch.nn.Module):\n",
        "    \"\"\"Defines the system of differential equations for the inverter's LC filter.\"\"\"\n",
        "    def __init__(self, r_esr_l, r_esr_c, l, c):\n",
        "        super().__init__()\n",
        "        self.R_esr_L = r_esr_l\n",
        "        self.R_esr_C = r_esr_c\n",
        "        self.L = l\n",
        "        self.C = c\n",
        "\n",
        "    def forward(self, t, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \"\"\"A high-fidelity, GPU-accelerated model of a single-phase H-bridge inverter.\"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "\n",
        "        self.ode_func = InverterODE(\n",
        "            r_esr_l=torch.tensor(0.1, device=device, dtype=torch.float32),\n",
        "            r_esr_c=torch.tensor(0.05, device=device, dtype=torch.float32),\n",
        "            l=torch.tensor(1.5e-3, device=device, dtype=torch.float32),\n",
        "            c=torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        ).to(device)\n",
        "\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # Custom RK4 Solver Step for speed\n",
        "        k1 = self.ode_func.forward(0, self.state, v_inverter_eff, r_load)\n",
        "        k2 = self.ode_func.forward(0, self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self.ode_func.forward(0, self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self.ode_func.forward(0, self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "sOypB8ZdA_Zn"
      },
      "outputs": [],
      "source": [
        "# File: controllers.py\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class SPWMController:\n",
        "    \"\"\"A simple open-loop controller with a fixed modulation index.\"\"\"\n",
        "    def __init__(self, modulation_index=0.8):\n",
        "        self.m = modulation_index\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "class PIController:\n",
        "    \"\"\"A standard Proportional-Integral (PI) controller.\"\"\"\n",
        "    def __init__(self, Kp, Ki, target_rms, ac_freq=50.0):\n",
        "        self.Kp = Kp\n",
        "        self.Ki = Ki\n",
        "        self.target_rms = target_rms\n",
        "        self.ac_period = 1.0 / ac_freq\n",
        "        self.integral_error = 0.0\n",
        "        self.m = 0.8 # Initial modulation index\n",
        "\n",
        "    def update_modulation_index(self, v_c_history_tensor):\n",
        "        if v_c_history_tensor.numel() < 2: return\n",
        "        measured_rms = torch.sqrt(torch.mean(v_c_history_tensor**2))\n",
        "        error = self.target_rms - measured_rms.item()\n",
        "        self.integral_error += error * self.ac_period\n",
        "        self.integral_error = np.clip(self.integral_error, -10.0, 10.0)\n",
        "        self.m = (self.Kp * error) + (self.Ki * self.integral_error)\n",
        "        self.m = np.clip(self.m, 0.0, 1.0)\n",
        "\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "xY6yp449BMQh"
      },
      "outputs": [],
      "source": [
        "# File: rl_environment_gpu.py\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import torch\n",
        "from inverter_model_gpu import InverterModelGPU\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    \"\"\"A GPU-accelerated Gymnasium environment for the inverter.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.inverter = InverterModelGPU(device=self.device)\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        harmonics = torch.abs(fft[1:11])\n",
        "        fundamental = harmonics[0]\n",
        "        higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "        thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        return torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        return np.zeros(5, dtype=np.float32), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance)\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "MstYz0diBQM7",
        "outputId": "dc81915d-5075-4893-fa5e-0d027b65c879"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unmatched ')' (ipython-input-3361684725.py, line 415)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3361684725.py\"\u001b[0;36m, line \u001b[0;32m415\u001b[0m\n\u001b[0;31m    fft = torch.fft.fft(torch.from_numpy(v_steady).to(\"cuda\" if torch.cuda.is_available() else \"cpu\"))) # Convert to tensor for FFT\u001b[0m\n\u001b[0m                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# FINAL MASTER SCRIPT: TRAIN, COMPARE, AND GENERATE ALL PLOTS\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Part 1: Installation ---\n",
        "print(\"--- Installing Dependencies ---\")\n",
        "!pip install gymnasium stable-baselines3[extra] torch tensorboard -q\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "from gymnasium import spaces # Import spaces for defining observation space\n",
        "\n",
        "\n",
        "# Save the controller classes to a Python file\n",
        "%%writefile controllers.py\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class SPWMController:\n",
        "    \"\"\"A simple open-loop controller with a fixed modulation index.\"\"\"\n",
        "    def __init__(self, modulation_index=0.8):\n",
        "        self.m = modulation_index\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "class PIController:\n",
        "    \"\"\"A standard Proportional-Integral (PI) controller.\"\"\"\n",
        "    def __init__(self, Kp, Ki, target_rms, ac_freq=50.0):\n",
        "        self.Kp = Kp\n",
        "        self.Ki = Ki\n",
        "        self.target_rms = target_rms\n",
        "        self.ac_period = 1.0 / ac_freq\n",
        "        self.integral_error = 0.0\n",
        "        self.m = 0.8 # Initial modulation index\n",
        "\n",
        "    def update_modulation_index(self, v_c_history_tensor):\n",
        "        if v_c_history_tensor.numel() < 2: return\n",
        "        measured_rms = torch.sqrt(torch.mean(v_c_history_tensor**2))\n",
        "        error = self.target_rms - measured_rms.item()\n",
        "        self.integral_error += error * self.ac_period\n",
        "        self.integral_error = np.clip(self.integral_error, -10.0, 10.0)\n",
        "        self.m = (self.Kp * error) + (self.Ki * self.integral_error)\n",
        "        self.m = np.clip(self.m, 0.0, 1.0)\n",
        "\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "# Save the InverterModelGPU class to a Python file\n",
        "%%writefile inverter_model_gpu.py\n",
        "import numpy as np\n",
        "import torch\n",
        "# Removed solve_ivp as it's not used in this version and might cause import issues\n",
        "# from scipy.integrate import solve_ivp\n",
        "\n",
        "class InverterModelGPU:\n",
        "    \"\"\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    # Using a simple step function instead of batch_step_rk4 for this script's structure\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # Custom RK4 Solver Step\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state\n",
        "\n",
        "\n",
        "# Save the InverterEnvGPU class to a Python file\n",
        "%%writefile rl_environment_gpu.py\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import torch\n",
        "from inverter_model_gpu import InverterModelGPU # Import from the file saved above\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    \"\"\"A GPU-accelerated Gymnasium environment for the inverter.\"\"\"\n",
        "    def __init__(self, device): # Accept device here\n",
        "        super().__init__()\n",
        "        self.device = device # Use the passed device\n",
        "        self.inverter = InverterModelGPU(device=self.device) # Use the class defined above\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        # Observation: [V_rms, I_rms, Power, PF, THD] - Shape (5,)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        if v_history_gpu.numel() < 2:\n",
        "            return torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        # Handle case where fft might be short\n",
        "        if fft.numel() > 10:\n",
        "            harmonics = torch.abs(fft[1:11]) # Look at fundamental + 10 harmonics\n",
        "            fundamental = harmonics[0]\n",
        "            higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "            thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        else:\n",
        "            thd = torch.tensor(1.0, device=self.device, dtype=torch.float32) # Assume high distortion\n",
        "\n",
        "\n",
        "        obs = torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "        obs[~torch.isfinite(obs)] = 0.0\n",
        "        # Ensure obs is shape (5,)\n",
        "        if obs.shape != (5,):\n",
        "             # Pad with zeros if necessary (shouldn't happen with correct stacking)\n",
        "             padded_obs = torch.zeros(5, device=self.device, dtype=torch.float32)\n",
        "             padded_obs[:obs.numel()] = obs\n",
        "             obs = padded_obs\n",
        "\n",
        "\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        # Initial observation (zeros as no history yet), ensure it's on the correct device and shape (5,)\n",
        "        obs = torch.zeros(5, device=self.device, dtype=torch.float32) # Initialize with 5 zeros\n",
        "        return obs.cpu().numpy(), {} # Return numpy array for SB3 compatibility\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            # Pass load_resistance as a scalar tensor\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance, 1e-5) # Use constant dt\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu # Unpack 5 elements\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}\n",
        "\n",
        "\n",
        "# --- Part 2: Import Your Custom Modules ---\n",
        "try:\n",
        "    # Import from the files saved above\n",
        "    from rl_environment_gpu import InverterEnvGPU\n",
        "    from inverter_model_gpu import InverterModelGPU\n",
        "    from controllers import SPWMController, PIController\n",
        "    print(\"--- All custom modules imported successfully! ---\")\n",
        "except ImportError as e:\n",
        "    print(f\"\\n--- ERROR: Could not import a required file. ---\")\n",
        "    print(\"Please make sure all .py files are uploaded to this Colab session.\")\n",
        "    raise\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 3: Train the RL Agent\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Starting RL Agent Training ---\")\n",
        "if __name__ == '__main__':\n",
        "    num_cpu = max(1, os.cpu_count() - 1)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    log_dir = \"./ppo_inverter_tensorboard/\" # Define log directory\n",
        "    print(f\"Creating {num_cpu} parallel environments. Using device: {device}\")\n",
        "\n",
        "    # Use the InverterEnvGPU defined in this cell, passing the device\n",
        "    # The fix for TypeError: InverterEnvGPU.__init__() missing 1 required positional argument: 'device'\n",
        "    env = make_vec_env(lambda: InverterEnvGPU(device=device), n_envs=num_cpu) # Pass device to constructor\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=1, device=device, n_steps=1024, batch_size=64, tensorboard_log=log_dir)\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.learn(total_timesteps=100000)\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(\"--- Training Complete ---\")\n",
        "    print(f\"Total Training Time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    rl_model_filename = \"ppo_inverter_final_model.zip\"\n",
        "    model.save(rl_model_filename)\n",
        "    print(f\"--- Model Saved as {rl_model_filename} ---\")\n",
        "    env.close()\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 4: Generate RL Learning Curve Plot (IMMEDIATELY AFTER TRAINING)\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Generating RL Performance Plots ---\")\n",
        "\n",
        "def get_learning_curve(log_path):\n",
        "    try:\n",
        "        ea = event_accumulator.EventAccumulator(log_path, size_guidance={event_accumulator.SCALARS: 0})\n",
        "        ea.Reload()\n",
        "        if 'rollout/ep_rew_mean' in ea.Tags()['scalars']:\n",
        "            reward_data = ea.Scalars('rollout/ep_rew_mean')\n",
        "            return [e.step for e in reward_data], [e.value for e in reward_data]\n",
        "        return None, None\n",
        "    except Exception: return None, None\n",
        "\n",
        "subdirs = [os.path.join(log_dir, d) for d in os.listdir(log_dir)]\n",
        "latest_log_dir = max(subdirs, key=os.path.getmtime)\n",
        "steps, rewards = get_learning_curve(latest_log_dir)\n",
        "\n",
        "if steps and rewards:\n",
        "    plt.figure(figsize=(12, 8), dpi=100)\n",
        "    plt.plot(steps, rewards, color='darkgreen')\n",
        "    plt.title('Reinforcement Learning Curve', fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Training Timesteps'); plt.ylabel('Mean Reward per Episode')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"rl_learning_curve.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Could not generate learning curve. Log file might be missing or corrupted.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 5: Run the Head-to-Head Comparison\n",
        "# ==============================================================================\n",
        "\n",
        "def run_simulation(controller_type, model_path=None, duration=0.2, dt=1e-5):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    if controller_type == \"RL\":\n",
        "        try:\n",
        "            # Load the model onto the correct device\n",
        "            sim_controller = PPO.load(model_path, device=device)\n",
        "            controller_name = \"RL Controller (Proposed)\"\n",
        "        except FileNotFoundError:\n",
        "            print(f\"\\nFATAL ERROR: Model file not found at '{model_path}'\")\n",
        "            print(\"Please make sure your trained model .zip file is uploaded and the name is correct.\")\n",
        "            return None\n",
        "    elif controller_type == \"PI\":\n",
        "        sim_controller = PIController(Kp=0.05, Ki=2.5, target_rms=30.0)\n",
        "        controller_name = \"PI Controller\"\n",
        "    elif controller_type == \"SPWM\":\n",
        "        sim_controller = SPWMController(modulation_index=0.65)\n",
        "        controller_name = \"SPWM Controller\"\n",
        "    else:\n",
        "        raise ValueError(\"Unknown controller type.\")\n",
        "\n",
        "    print(f\"\\n--- Running simulation for: {controller_name} ---\")\n",
        "\n",
        "    # Instantiate the GPU Inverter Model (used for all controllers now)\n",
        "    inverter = InverterModelGPU(device=device)\n",
        "    num_steps = int(duration / dt)\n",
        "\n",
        "    time_hist = np.zeros(num_steps)\n",
        "    v_c_hist = np.zeros(num_steps)\n",
        "    i_l_hist = np.zeros(num_steps)\n",
        "\n",
        "    ac_period_steps = int((1.0 / inverter.ac_freq.item()) / dt)\n",
        "\n",
        "    # Initialize observation for RL controller (shape (5,)) to match the env used for training\n",
        "    obs = np.zeros(5, dtype=np.float32) # Initialize with 5 zeros\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in range(num_steps):\n",
        "        t = i * dt\n",
        "\n",
        "        # Load scheduling (applied directly in the simulation step)\n",
        "        r_load_val = 50.0\n",
        "        if 0.08 <= t < 0.16:\n",
        "            r_load_val = 25.0\n",
        "        r_load_tensor = torch.tensor(r_load_val, device=device, dtype=torch.float32)\n",
        "\n",
        "        if controller_type == \"RL\":\n",
        "            # Get action from the RL controller\n",
        "            # Pass the observation with an added batch dimension (expected by SB3 models trained on VecEnvs)\n",
        "            action, _ = sim_controller.predict(np.expand_dims(obs, axis=0), deterministic=True)\n",
        "            m_numpy = (action[0][0] + 1.0) / 2.0\n",
        "\n",
        "        else: # PI and SPWM controllers\n",
        "            if isinstance(sim_controller, PIController) and i > 0 and i % ac_period_steps == 0:\n",
        "                 # PI update logic (using history collected so far)\n",
        "                 v_cycle_tensor = torch.from_numpy(v_c_hist[max(0, i - ac_period_steps):i]).to(device)\n",
        "                 sim_controller.update_modulation_index(v_cycle_tensor)\n",
        "\n",
        "            m_numpy = sim_controller.get_modulation_index(t)\n",
        "\n",
        "        # Step the *inverter model* directly for all controllers\n",
        "        modulation_index = torch.tensor(m_numpy, device=device)\n",
        "        state_gpu = inverter.step(modulation_index, r_load_tensor, dt)\n",
        "        state_cpu = state_gpu.cpu().numpy()\n",
        "\n",
        "        # Store history\n",
        "        time_hist[i], v_c_hist[i], i_l_hist[i] = t, state_cpu[1], state_cpu[0]\n",
        "\n",
        "        # Update the observation for the next step if using the RL controller and at the end of a cycle\n",
        "        if controller_type == \"RL\" and (i + 1) % ac_period_steps == 0:\n",
        "            v_cycle = torch.from_numpy(v_c_hist[max(0, i-ac_period_steps+1):i+1]).to(device)\n",
        "            i_cycle = torch.from_numpy(i_l_hist[max(0, i-ac_period_steps+1):i+1]).to(device)\n",
        "\n",
        "            # Calculate the 5-element observation vector (V_rms, I_rms, Power, PF, THD)\n",
        "            v_rms = torch.sqrt(torch.mean(v_cycle**2))\n",
        "            i_rms = torch.sqrt(torch.mean(i_cycle**2))\n",
        "            power = torch.mean(v_cycle * i_cycle)\n",
        "            pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "            thd = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "            if len(v_cycle) > 1:\n",
        "                fft = torch.fft.fft(v_cycle)\n",
        "                # Attempt to find the fundamental frequency index based on the number of points in the cycle\n",
        "                freq_resolution = (1.0 / (len(v_cycle) * dt))\n",
        "                fundamental_freq_idx = int(inverter.ac_freq.item() / freq_resolution)\n",
        "                if fundamental_freq_idx > 0 and fundamental_freq_idx < len(fft) and torch.abs(fft[fundamental_freq_idx]).item() > 1e-6:\n",
        "                   harmonics_abs = torch.abs(fft[1: fundamental_freq_idx + 11]) # Consider fundamental + 10 harmonics\n",
        "                   # Adjust fundamental index based on slice\n",
        "                   fundamental_in_slice_idx = fundamental_freq_idx - 1\n",
        "                   if fundamental_in_slice_idx < len(harmonics_abs):\n",
        "                       fundamental_abs = harmonics_abs[fundamental_in_slice_idx]\n",
        "                       # Sum of squares of higher harmonics magnitudes from the fundamental onwards in the slice\n",
        "                       if fundamental_in_slice_idx + 1 < len(harmonics_abs):\n",
        "                           higher_harmonics_sum_sq = torch.sum(harmonics_abs[fundamental_in_slice_idx + 1 :]**2)\n",
        "                           thd = torch.sqrt(higher_harmonics_sum_sq) / (fundamental_abs + 1e-6)\n",
        "                       else:\n",
        "                           thd = torch.tensor(0.0, device=device, dtype=torch.float32) # No higher harmonics in slice\n",
        "                   else:\n",
        "                       thd = torch.tensor(0.0, device=device, dtype=torch.float32) # Fundamental index outside slice\n",
        "\n",
        "                else:\n",
        "                    thd = torch.tensor(1.0, device=device, dtype=torch.float32) # Assume high distortion if fundamental is zero or not found\n",
        "\n",
        "            # Construct obs as a NumPy array of shape (5,)\n",
        "            obs = torch.stack([v_rms, i_rms, power, pf, thd]).cpu().numpy()\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Simulation finished in {end_time - start_time:.2f} seconds.\")\n",
        "    return time_hist, v_c_hist, i_l_hist\n",
        "\n",
        "def analyze_and_plot(results):\n",
        "    print(\"\\n--- Analyzing results and generating plots... ---\")\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(12, 12), dpi=150)\n",
        "\n",
        "    ax = axes[0]\n",
        "    for name, data in results.items():\n",
        "        time, v_c, _ = data\n",
        "        dt = time[1] - time[0]\n",
        "        window_size = int(0.02 / dt)\n",
        "        # Ensure we have enough data points for the sliding window\n",
        "        if len(v_c) >= window_size:\n",
        "            rms_voltage = [np.sqrt(np.mean(v_c[i-window_size:i]**2)) for i in range(window_size, len(v_c))]\n",
        "            ax.plot(time[window_size:], rms_voltage, label=name, linewidth=2.5)\n",
        "        else:\n",
        "            print(f\"Warning: Not enough data for RMS calculation for {name}\")\n",
        "\n",
        "\n",
        "    ax.set_title('Dynamic Voltage Response to Load Step', fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel('Time (s)', fontsize=12)\n",
        "    ax.set_ylabel('RMS Voltage (V)', fontsize=12)\n",
        "    ax.axvspan(0.08, 0.16, color='gray', alpha=0.2, label='Heavy Load Applied')\n",
        "    ax.legend(fontsize=12); ax.grid(True, which='both', linestyle='--')\n",
        "\n",
        "    thd_values = {}\n",
        "    for name, data in results.items():\n",
        "        time, v_c, _ = data\n",
        "        # Select a portion of the steady-state waveform for THD calculation\n",
        "        steady_state_mask = (time >= 0.1) & (time < 0.16)\n",
        "        v_steady = v_c[steady_state_mask]\n",
        "\n",
        "        thd = torch.tensor(0.0, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", dtype=torch.float32)\n",
        "        if len(v_steady) > 1:\n",
        "            fft = torch.fft.fft(torch.from_numpy(v_steady).to(\"cuda\" if torch.cuda.is_available() else \"cpu\"))) # Convert to tensor for FFT\n",
        "            # Attempt to find the fundamental frequency index based on the number of points\n",
        "            # Assuming a 50Hz fundamental and a sample rate derived from dt\n",
        "            sample_rate = 1.0 / dt\n",
        "            fundamental_freq_idx = int(50.0 / (sample_rate / len(v_steady))) # Correct fundamental index calc\n",
        "            # Ensure index is within bounds and fundamental is not zero\n",
        "            if fundamental_freq_idx > 0 and fundamental_freq_idx < len(fft) and torch.abs(fft[fundamental_freq_idx]).item() > 1e-6:\n",
        "               # Get magnitudes of harmonics (excluding DC component)\n",
        "               harmonics_abs = torch.abs(fft[1:fundamental_freq_idx + 11]) # Consider fundamental + 10 harmonics\n",
        "               # Adjust fundamental index based on slice (1-based indexing from 1 to 10+fundamental)\n",
        "               fundamental_in_slice_idx = fundamental_freq_idx - 1\n",
        "               if fundamental_in_slice_idx < len(harmonics_abs):\n",
        "                   fundamental_abs = harmonics_abs[fundamental_in_slice_idx]\n",
        "                   # Sum of squares of higher harmonics magnitudes from the fundamental onwards in the slice\n",
        "                   if fundamental_in_slice_idx + 1 < len(harmonics_abs):\n",
        "                       higher_harmonics_sum_sq = torch.sum(harmonics_abs[fundamental_in_slice_idx + 1 :]**2)\n",
        "                       thd = torch.sqrt(higher_harmonics_sum_sq) / (fundamental_abs + 1e-6)\n",
        "                   else:\n",
        "                       thd = torch.tensor(0.0, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", dtype=torch.float32) # No higher harmonics in slice\n",
        "               else:\n",
        "                   thd = torch.tensor(0.0, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", dtype=torch.float32) # Fundamental index outside slice\n",
        "\n",
        "            else:\n",
        "                thd = torch.tensor(1.0, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", dtype=torch.float32) # Assume high distortion if fundamental is zero or not found\n",
        "\n",
        "        thd_values[name] = thd.item() * 100 # Convert tensor to scalar\n",
        "\n",
        "    ax = axes[1]\n",
        "    colors = ['gray', 'cornflowerblue', 'crimson']\n",
        "    # Ensure the number of colors matches the number of bars\n",
        "    num_bars = len(thd_values)\n",
        "    bars = ax.bar(list(thd_values.keys()), list(thd_values.values()), color=colors[:num_bars])\n",
        "    ax.set_title('Power Quality: Total Harmonic Distortion (THD)', fontsize=16, fontweight='bold')\n",
        "    ax.set_ylabel('THD (%)', fontsize=12)\n",
        "    ax.bar_label(bars, fmt='%.2f%%')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"final_comparison_results.png\")\n",
        "    print(\"\\n--- Plots generated and saved as 'final_comparison_results.png' ---\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Part 6: Main Execution Block ---\n",
        "if __name__ == '__main__':\n",
        "    results = {}\n",
        "    # !!! IMPORTANT !!!\n",
        "    # Make sure this name matches the name of your best trained model file!\n",
        "    # For example, \"ppo_final_model.zip\" or \"ppo_my_model.zip\"\n",
        "    rl_model_filename = \"ppo_inverter_final_model.zip\" # This is the filename used in Part 3\n",
        "\n",
        "    results[\"SPWM Controller\"] = run_simulation(controller_type=\"SPWM\")\n",
        "    results[\"PI Controller\"] = run_simulation(controller_type=\"PI\")\n",
        "    results[\"RL Controller (Proposed)\"] = run_simulation(controller_type=\"RL\", model_path=rl_model_filename)\n",
        "\n",
        "    # Check if all simulations were successful before plotting\n",
        "    if all(res is not None for res in results.values()):\n",
        "        analyze_and_plot(results)\n",
        "    else:\n",
        "        print(\"\\n--- Skipping analysis due to a simulation failure. ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a1a3f2c"
      },
      "outputs": [],
      "source": [
        "# Save the InverterEnvGPU class to a Python file\n",
        "%%writefile rl_environment_gpu.py\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import torch\n",
        "from inverter_model_gpu import InverterModelGPU\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    \"\"\"A GPU-accelerated Gymnasium environment for the inverter.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.inverter = InverterModelGPU(device=self.device)\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "\n",
        "        self.max_steps = 100\n",
        "        self.current_step = 0\n",
        "\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu)\n",
        "        pf = power / (v_rms * i_rms + 1e-6)\n",
        "\n",
        "        fft = torch.fft.fft(v_history_gpu)\n",
        "        harmonics = torch.abs(fft[1:11])\n",
        "        fundamental = harmonics[0]\n",
        "        higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "        thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        return torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        return np.zeros(5, dtype=np.float32), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance)\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu\n",
        "\n",
        "        target_v_rms = 30.0\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3pULAjLCaqP"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Part 1: Install Dependencies\n",
        "# ==============================================================================\n",
        "print(\"--- Step 1: Installing Dependencies ---\")\n",
        "!pip install gymnasium stable-baselines3[extra] torch torchdiffeq -q\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "from gymnasium import spaces # Import spaces for defining observation space\n",
        "\n",
        "print(\"\\n--- Dependencies Installed Successfully! ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 2: Define All Classes Directly in the Notebook\n",
        "# ==============================================================================\n",
        "print(\"--- Step 2: Defining All Required Classes ---\")\n",
        "\n",
        "# --- From inverter_model_gpu.py ---\n",
        "class InverterModelGPU:\n",
        "    \"\"\"\n",
        "    A high-fidelity, FULLY GPU-ACCELERATED model of a single-phase H-bridge inverter.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device\n",
        "        self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq\n",
        "        self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state.zero_()\n",
        "        self.sim_time.zero_()\n",
        "\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]\n",
        "        i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "\n",
        "        # Custom RK4 Solver Step\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "        self.sim_time += dt\n",
        "        return self.state\n",
        "\n",
        "# Define InverterEnvGPU within this cell to ensure consistency\n",
        "class InverterEnvGPU:\n",
        "    \"\"\"A custom Gymnasium environment for the RL-controlled inverter (GPU version).\"\"\"\n",
        "    def __init__(self, device):\n",
        "        # Using InverterModelGPU defined within this same cell\n",
        "        self.inverter = InverterModelGPU(device=device)\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item() # Use .item() for scalar tensor\n",
        "        self.dt = 1e-5 # Simulation time step\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / self.dt)\n",
        "\n",
        "        # Action: A single continuous value for modulation index [-1, 1]\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "\n",
        "        # Observation: [V_rms, I_rms, Power, THD] - Shape (4,)\n",
        "        # Explicitly set observation space shape to (4,)\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(4,), dtype=np.float32)\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.max_cycles = 200 # An episode will last 200 AC cycles\n",
        "\n",
        "        self.device = device # Store device\n",
        "\n",
        "    def _get_obs(self, v_history_tensor, i_history_tensor):\n",
        "        if v_history_tensor.numel() < 2: # Use numel() for tensor\n",
        "            return torch.zeros(4, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_tensor**2))\n",
        "        i_rms = torch.sqrt(torch.mean(i_history_tensor**2))\n",
        "        power = torch.mean(v_history_tensor * i_history_tensor)\n",
        "\n",
        "        # Calculate THD (Total Harmonic Distortion)\n",
        "        thd = torch.tensor(0.0, device=self.device, dtype=torch.float32)\n",
        "        if v_history_tensor.numel() > 1:\n",
        "            fft = torch.fft.fft(v_history_tensor)\n",
        "            # Attempt to find the fundamental frequency index based on the number of points in the cycle\n",
        "            freq_resolution = (1.0 / (len(v_history_tensor) * self.dt)) # Use len(v_history_tensor) for correct window size\n",
        "            fundamental_freq_idx = int(self.inverter.ac_freq.item() / freq_resolution)\n",
        "            # Ensure index is within bounds and fundamental is not zero\n",
        "            if fundamental_freq_idx > 0 and fundamental_freq_idx < len(fft) and torch.abs(fft[fundamental_freq_idx]).item() > 1e-6:\n",
        "               # Get magnitudes of harmonics (excluding DC component)\n",
        "               harmonics_abs = torch.abs(fft[1:fundamental_freq_idx + 11]) # Consider fundamental + 10 harmonics\n",
        "               fundamental_abs = harmonics_abs[fundamental_freq_idx - 1] # Adjust index based on slice\n",
        "\n",
        "               # Sum of squares of higher harmonics magnitudes\n",
        "               # Sum from the fundamental harmonic onwards in the 'harmonics_abs' slice\n",
        "               if fundamental_freq_idx < len(harmonics_abs):\n",
        "                  higher_harmonics_sum_sq = torch.sum(harmonics_abs[fundamental_freq_idx :]**2)\n",
        "                  thd = torch.sqrt(higher_harmonics_sum_sq) / (fundamental_abs + 1e-6)\n",
        "               else:\n",
        "                  thd = torch.tensor(0.0, device=self.device, dtype=torch.float32) # No higher harmonics in slice\n",
        "\n",
        "            else:\n",
        "                thd = torch.tensor(1.0, device=self.device, dtype=torch.float32) # Assume high distortion if fundamental is zero or not found\n",
        "\n",
        "        # Ensure obs is a tensor of shape (4,)\n",
        "        obs = torch.stack([v_rms, i_rms, power, thd]) # Stack only 4 elements\n",
        "        # Replace non-finite values with 0\n",
        "        obs[~torch.isfinite(obs)] = 0.0\n",
        "\n",
        "        return obs\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.inverter.reset()\n",
        "        self.current_step = 0\n",
        "        # Randomize load on reset, keep it on the same device\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        # Initial observation (zeros as no history yet), ensure it's on the correct device and shape (4,)\n",
        "        obs = torch.zeros(4, device=self.device, dtype=torch.float32) # Initialize with 4 zeros\n",
        "        return obs.cpu().numpy(), {} # Return numpy array for SB3 compatibility\n",
        "\n",
        "    def step(self, action):\n",
        "        # Action is a numpy array from SB3, convert to tensor\n",
        "        action_tensor = torch.tensor(action[0], device=self.device, dtype=torch.float32)\n",
        "        modulation_index = (action_tensor + 1.0) / 2.0 # De-normalize action from [-1, 1] to [0, 1]\n",
        "\n",
        "        v_history_tensor = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "        i_history_tensor = torch.zeros(self.sim_steps_per_cycle, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "             # Pass load_resistance as a scalar tensor\n",
        "            state = self.inverter.step(modulation_index.item(), self.load_resistance.item(), self.dt)\n",
        "            i_history_tensor[i] = state[0]\n",
        "            v_history_tensor[i] = state[1]\n",
        "\n",
        "        # Get observation (tensor) - Will be shape (4,) now\n",
        "        obs_tensor = self._get_obs(v_history_tensor, i_history_tensor)\n",
        "        v_rms, i_rms, power, thd = obs_tensor # Unpack 4 elements\n",
        "\n",
        "        # --- Multi-Objective Reward Function ---\n",
        "        target_v_rms = 30.0 # Target voltage in our low-voltage simulation\n",
        "\n",
        "        # 1. Voltage Error Penalty\n",
        "        voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward_voltage = - (voltage_error**2)\n",
        "\n",
        "        # 2. THD Penalty\n",
        "        reward_thd = - (thd**2) if thd < 0.5 else torch.tensor(-10.0, device=self.device, dtype=torch.float32) # Heavily penalize high distortion\n",
        "\n",
        "        # 3. Stability Reward\n",
        "        reward_stability = torch.tensor(5.0, device=self.device, dtype=torch.float32) if voltage_error < 1.0 and thd < 0.1 else torch.tensor(0.0, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        reward = reward_voltage + reward_thd + reward_stability\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_cycles\n",
        "        truncated = False # Or define truncation conditions\n",
        "\n",
        "        # Return numpy array observation (shape 4,) and scalar reward (as expected by SB3 DummyVecEnv)\n",
        "        return obs_tensor.cpu().numpy(), reward.item(), done, truncated, {}\n",
        "\n",
        "# --- From controllers.py ---\n",
        "class SPWMController:\n",
        "    def __init__(self, modulation_index=0.8, ac_freq=50.0):\n",
        "        self.m = modulation_index\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "class PIController:\n",
        "    def __init__(self, Kp, Ki, target_rms, ac_freq=50.0):\n",
        "        self.Kp = Kp\n",
        "        self.Ki = Ki\n",
        "        self.target_rms = target_rms\n",
        "        self.ac_period = 1.0 / ac_freq\n",
        "        self.integral_error = 0.0\n",
        "        self.m = 0.8\n",
        "    def update_modulation_index(self, v_c_history_tensor):\n",
        "        if v_c_history_tensor.numel() == 0: return\n",
        "        measured_rms = torch.sqrt(torch.mean(v_c_history_tensor**2))\n",
        "        error = self.target_rms - measured_rms.item()\n",
        "        self.integral_error += error * self.ac_period\n",
        "        self.integral_error = np.clip(self.integral_error, -10.0, 10.0)\n",
        "        self.m = (self.Kp * error) + (self.Ki * self.integral_error)\n",
        "        self.m = np.clip(self.m, 0.0, 1.0)\n",
        "    def get_modulation_index(self, t):\n",
        "        return self.m\n",
        "\n",
        "\n",
        "print(\"--- All classes defined successfully! ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 3: The Master Simulation Function\n",
        "# ==============================================================================\n",
        "\n",
        "def run_simulation(controller_type, model_path=None, duration=0.2, dt=1e-5):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    if controller_type == \"RL\":\n",
        "        try:\n",
        "            # Load the model onto the correct device\n",
        "            sim_controller = PPO.load(model_path, device=device)\n",
        "            controller_name = \"RL Controller (Proposed)\"\n",
        "        except FileNotFoundError:\n",
        "            print(f\"\\nFATAL ERROR: Model file not found at '{model_path}'\")\n",
        "            print(\"Please make sure your trained model .zip file is uploaded and the name is correct.\")\n",
        "            return None\n",
        "    elif controller_type == \"PI\":\n",
        "        sim_controller = PIController(Kp=0.05, Ki=2.5, target_rms=30.0)\n",
        "        controller_name = \"PI Controller\"\n",
        "    elif controller_type == \"SPWM\":\n",
        "        sim_controller = SPWMController(modulation_index=0.65)\n",
        "        controller_name = \"SPWM Controller\"\n",
        "    else:\n",
        "        raise ValueError(\"Unknown controller type.\")\n",
        "\n",
        "    print(f\"\\n--- Running simulation for: {controller_name} ---\")\n",
        "\n",
        "    # Instantiate the GPU Inverter Model (used for all controllers now)\n",
        "    inverter = InverterModelGPU(device=device)\n",
        "    num_steps = int(duration / dt)\n",
        "\n",
        "    time_hist = np.zeros(num_steps)\n",
        "    v_c_hist = np.zeros(num_steps)\n",
        "    i_l_hist = np.zeros(num_steps)\n",
        "\n",
        "    ac_period_steps = int((1.0 / inverter.ac_freq.item()) / dt)\n",
        "\n",
        "    # Initialize observation for RL controller (shape (4,))\n",
        "    obs = np.zeros(4, dtype=np.float32) # Initialize with 4 zeros\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in range(num_steps):\n",
        "        t = i * dt\n",
        "\n",
        "        # Load scheduling (applied directly in the simulation step)\n",
        "        r_load_val = 50.0\n",
        "        if 0.08 <= t < 0.16:\n",
        "            r_load_val = 25.0\n",
        "        r_load_tensor = torch.tensor(r_load_val, device=device, dtype=torch.float32)\n",
        "\n",
        "        if controller_type == \"RL\":\n",
        "            # Get action from the RL controller\n",
        "            # Pass the observation with an added batch dimension (expected by SB3 models trained on VecEnvs)\n",
        "            action, _ = sim_controller.predict(np.expand_dims(obs, axis=0), deterministic=True)\n",
        "            # De-normalize action from [-1, 1] to [0, 1]. action is a batch, so take the first element.\n",
        "            # Use .flatten() to handle potential (1,1) shape and get the scalar action\n",
        "            m_numpy = (action.flatten()[0] + 1.0) / 2.0\n",
        "\n",
        "        else: # PI and SPWM controllers\n",
        "            if isinstance(sim_controller, PIController) and i > 0 and i % ac_period_steps == 0:\n",
        "                 # PI update logic (using history collected so far)\n",
        "                 v_cycle_tensor = torch.from_numpy(v_c_hist[max(0, i - ac_period_steps):i]).to(device)\n",
        "                 sim_controller.update_modulation_index(v_cycle_tensor)\n",
        "\n",
        "            m_numpy = sim_controller.get_modulation_index(t)\n",
        "\n",
        "        # Step the *inverter model* directly for all controllers\n",
        "        modulation_index = torch.tensor(m_numpy, device=device)\n",
        "        state_gpu = inverter.step(modulation_index, r_load_tensor, dt)\n",
        "        state_cpu = state_gpu.cpu().numpy()\n",
        "\n",
        "        # Store history\n",
        "        time_hist[i], v_c_hist[i], i_l_hist[i] = t, state_cpu[1], state_cpu[0]\n",
        "\n",
        "        # Update the observation for the next step if using the RL controller and at the end of a cycle\n",
        "        if controller_type == \"RL\" and (i + 1) % ac_period_steps == 0:\n",
        "            v_cycle = torch.from_numpy(v_c_hist[max(0, i-ac_period_steps+1):i+1]).to(device)\n",
        "            i_cycle = torch.from_numpy(i_l_hist[max(0, i-ac_period_steps+1):i+1]).to(device)\n",
        "\n",
        "            # Calculate the 4-element observation vector (V_rms, I_rms, Power, THD)\n",
        "            v_rms = torch.sqrt(torch.mean(v_cycle**2))\n",
        "            i_rms = torch.sqrt(torch.mean(i_cycle**2))\n",
        "            power = torch.mean(v_cycle * i_cycle)\n",
        "\n",
        "            thd = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "            if len(v_cycle) > 1:\n",
        "                fft = torch.fft.fft(v_cycle)\n",
        "                # Attempt to find the fundamental frequency index based on the number of points in the cycle\n",
        "                freq_resolution = (1.0 / (len(v_cycle) * dt))\n",
        "                fundamental_freq_idx = int(inverter.ac_freq.item() / freq_resolution)\n",
        "                if fundamental_freq_idx > 0 and fundamental_freq_idx < len(fft) and torch.abs(fft[fundamental_freq_idx]).item() > 1e-6:\n",
        "                   harmonics_abs = torch.abs(fft[1: fundamental_freq_idx + 11]) # Consider fundamental + 10 harmonics\n",
        "                   # Adjust fundamental index based on slice\n",
        "                   fundamental_in_slice_idx = fundamental_freq_idx - 1\n",
        "                   if fundamental_in_slice_idx < len(harmonics_abs):\n",
        "                       fundamental_abs = harmonics_abs[fundamental_in_slice_idx]\n",
        "                       # Sum of squares of higher harmonics magnitudes from the fundamental onwards in the slice\n",
        "                       if fundamental_in_slice_idx + 1 < len(harmonics_abs):\n",
        "                           higher_harmonics_sum_sq = torch.sum(harmonics_abs[fundamental_in_slice_idx + 1 :]**2)\n",
        "                           thd = torch.sqrt(higher_harmonics_sum_sq) / (fundamental_abs + 1e-6)\n",
        "                       else:\n",
        "                           thd = torch.tensor(0.0, device=device, dtype=torch.float32) # No higher harmonics in slice\n",
        "                   else:\n",
        "                       thd = torch.tensor(0.0, device=device, dtype=torch.float32) # Fundamental index outside slice\n",
        "\n",
        "                else:\n",
        "                    thd = torch.tensor(1.0, device=device, dtype=torch.float32) # Assume high distortion if fundamental is zero or not found\n",
        "\n",
        "            # Construct obs as a NumPy array of shape (4,)\n",
        "            obs = torch.stack([v_rms, i_rms, power, thd]).cpu().numpy()\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Simulation finished in {end_time - start_time:.2f} seconds.\")\n",
        "    return time_hist, v_c_hist, i_l_hist\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 4: Analysis and Plotting Function\n",
        "# ==============================================================================\n",
        "\n",
        "def analyze_and_plot(results):\n",
        "    print(\"\\n--- Analyzing results and generating plots... ---\")\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(12, 12), dpi=150)\n",
        "\n",
        "    ax = axes[0]\n",
        "    for name, data in results.items():\n",
        "        time, v_c, _ = data\n",
        "        dt = time[1] - time[0]\n",
        "        window_size = int(0.02 / dt)\n",
        "        # Ensure we have enough data points for the sliding window\n",
        "        if len(v_c) >= window_size:\n",
        "            rms_voltage = [np.sqrt(np.mean(v_c[i-window_size:i]**2)) for i in range(window_size, len(v_c))]\n",
        "            ax.plot(time[window_size:], rms_voltage, label=name, linewidth=2.5)\n",
        "        else:\n",
        "            print(f\"Warning: Not enough data for RMS calculation for {name}\")\n",
        "\n",
        "\n",
        "    ax.set_title('Dynamic Voltage Response to Load Step', fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel('Time (s)', fontsize=12)\n",
        "    ax.set_ylabel('RMS Voltage (V)', fontsize=12)\n",
        "    ax.axvspan(0.08, 0.16, color='gray', alpha=0.2, label='Heavy Load Applied')\n",
        "    ax.legend(fontsize=12); ax.grid(True, which='both', linestyle='--')\n",
        "\n",
        "    thd_values = {}\n",
        "    for name, data in results.items():\n",
        "        time, v_c, _ = data\n",
        "        # Select a portion of the steady-state waveform for THD calculation\n",
        "        steady_state_mask = (time >= 0.1) & (time < 0.16)\n",
        "        v_steady = v_c[steady_state_mask]\n",
        "\n",
        "        thd = 0.0\n",
        "        if len(v_steady) > 1:\n",
        "            fft = np.fft.fft(v_steady)\n",
        "             # Avoid calculating THD if fundamental is zero or near zero\n",
        "            if np.abs(fft[1]).item() > 1e-6:\n",
        "                harmonics = np.abs(fft[1:11])\n",
        "                fundamental = harmonics[0]\n",
        "                thd = np.sqrt(np.sum(harmonics[1:]**2)) / fundamental\n",
        "            else:\n",
        "                thd = 1.0 # Assume high distortion if fundamental is zero\n",
        "\n",
        "        thd_values[name] = thd * 100\n",
        "\n",
        "    ax = axes[1]\n",
        "    colors = ['gray', 'cornflowerblue', 'crimson']\n",
        "    # Ensure the number of colors matches the number of bars\n",
        "    num_bars = len(thd_values)\n",
        "    bars = ax.bar(list(thd_values.keys()), list(thd_values.values()), color=colors[:num_bars])\n",
        "    ax.set_title('Power Quality: Total Harmonic Distortion (THD)', fontsize=16, fontweight='bold')\n",
        "    ax.set_ylabel('THD (%)', fontsize=12)\n",
        "    ax.bar_label(bars, fmt='%.2f%%')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"final_comparison_results.png\")\n",
        "    print(\"\\n--- Plots generated and saved as 'final_comparison_results.png' ---\")\n",
        "    plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 5: Main Execution Block\n",
        "# ==============================================================================\n",
        "if __name__ == '__main__':\n",
        "    results = {}\n",
        "\n",
        "    # !!! IMPORTANT !!!\n",
        "    # Make sure this name matches the name of your best trained model file!\n",
        "    # For example, \"ppo_final_model.zip\" or \"ppo_my_model.zip\"\n",
        "    rl_model_filename = \"ppo_my_model.zip\" # <--- Replace with your model filename\n",
        "\n",
        "    # Run the simulation for each controller\n",
        "    results[\"SPWM Controller\"] = run_simulation(controller_type=\"SPWM\")\n",
        "    results[\"PI Controller\"] = run_simulation(controller_type=\"PI\")\n",
        "    results[\"RL Controller (Proposed)\"] = run_simulation(controller_type=\"RL\", model_path=rl_model_filename)\n",
        "\n",
        "    # Check if all simulations were successful before plotting\n",
        "    if all(res is not None for res in results.values()):\n",
        "        analyze_and_plot(results)\n",
        "    else:\n",
        "        print(\"\\n--- Skipping analysis due to a simulation failure. ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTJtKSSDFZQn"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# SCRIPT 2: SPWM MECHANISM VISUALIZATION\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Running Script 2: Generating SPWM Mechanism Plot ---\")\n",
        "\n",
        "# --- Generate the waves ---\n",
        "t = np.linspace(0, 0.02, 1000) # One cycle at 50Hz\n",
        "# Sine wave (the reference signal)\n",
        "sine_wave = 0.8 * np.sin(2 * np.pi * 50 * t)\n",
        "# Triangle wave (the carrier signal)\n",
        "triangle_wave = 2 * np.abs(2 * (t * 2000 - np.floor(t * 2000 + 0.5))) - 1\n",
        "# The resulting PWM signal\n",
        "pwm_signal = np.where(sine_wave > triangle_wave, 1, -1)\n",
        "\n",
        "# --- Plot the results ---\n",
        "plt.figure(figsize=(12, 8), dpi=100)\n",
        "plt.plot(t, sine_wave, label='Sinusoidal Reference', linewidth=3)\n",
        "plt.plot(t, triangle_wave, label='Triangular Carrier', color='gray', linestyle='--')\n",
        "plt.plot(t, pwm_signal, label='Resulting PWM Output', color='red', alpha=0.8)\n",
        "plt.title('Mechanism of Sinusoidal PWM (SPWM) Generation', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Time (s)', fontsize=12)\n",
        "plt.ylabel('Amplitude', fontsize=12)\n",
        "plt.ylim(-1.2, 1.2)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.savefig(\"spwm_mechanism.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02415c51"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install gymnasium stable-baselines3[extra] torch tensorboard -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9TpsxrDHSyZ"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# FINAL MASTER SCRIPT: TRAIN, COMPARE, AND GENERATE ALL PLOTS\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Part 1: Installation ---\n",
        "print(\"--- Step 1: Installing Dependencies ---\")\n",
        "!pip install gymnasium stable-baselines3[extra] torch tensorboard -q\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "print(\"\\n--- Dependencies Installed Successfully! ---\")\n",
        "\n",
        "# --- Part 2: Define All Required Classes ---\n",
        "print(\"--- Step 2: Defining All Required Classes ---\")\n",
        "\n",
        "class InverterModelGPU:\n",
        "    def __init__(self, device, v_dc=48.0, rds_on=0.08, pwm_freq=20000, ac_freq=50.0):\n",
        "        self.device = device; self.V_dc = torch.tensor(v_dc, device=device, dtype=torch.float32)\n",
        "        self.Rds_on = torch.tensor(rds_on, device=device, dtype=torch.float32)\n",
        "        self.pwm_freq = torch.tensor(pwm_freq, device=device, dtype=torch.float32)\n",
        "        self.ac_freq = torch.tensor(ac_freq, device=device, dtype=torch.float32)\n",
        "        self.R_esr_L = torch.tensor(0.1, device=device, dtype=torch.float32)\n",
        "        self.R_esr_C = torch.tensor(0.05, device=device, dtype=torch.float32)\n",
        "        self.L = torch.tensor(1.5e-3, device=device, dtype=torch.float32)\n",
        "        self.C = torch.tensor(10e-6, device=device, dtype=torch.float32)\n",
        "        self.pwm_period = 1.0 / self.pwm_freq; self.state = torch.zeros(2, device=device, dtype=torch.float32)\n",
        "        self.sim_time = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "    def reset(self): self.state.zero_(); self.sim_time.zero_()\n",
        "    def _diffeq(self, y, v_inverter, r_load):\n",
        "        i_L, v_C = y[0], y[1]; i_load_branch = v_C / (r_load + self.R_esr_C)\n",
        "        diL_dt = (1 / self.L) * (v_inverter - v_C - i_L * self.R_esr_L)\n",
        "        dvC_dt = (1 / self.C) * (i_L - i_load_branch)\n",
        "        return torch.stack([diL_dt, dvC_dt])\n",
        "    def step(self, modulation_index, r_load, dt=1e-5):\n",
        "        sine_ref = modulation_index * torch.sin(2 * torch.pi * self.ac_freq * self.sim_time)\n",
        "        carrier = 2 * (torch.abs(2 * ((self.sim_time / self.pwm_period) - torch.floor(0.5 + self.sim_time / self.pwm_period)))) - 1\n",
        "        v_inverter = torch.where(sine_ref > carrier, self.V_dc, -self.V_dc)\n",
        "        v_inverter_eff = v_inverter - torch.sign(v_inverter) * self.state[0] * self.Rds_on\n",
        "        k1 = self._diffeq(self.state, v_inverter_eff, r_load)\n",
        "        k2 = self._diffeq(self.state + 0.5 * dt * k1, v_inverter_eff, r_load)\n",
        "        k3 = self._diffeq(self.state + 0.5 * dt * k2, v_inverter_eff, r_load)\n",
        "        k4 = self._diffeq(self.state + dt * k3, v_inverter_eff, r_load)\n",
        "        self.state = self.state + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "        self.sim_time += dt\n",
        "        return self.state\n",
        "\n",
        "class InverterEnvGPU(gym.Env):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.inverter = InverterModelGPU(device=self.device)\n",
        "        self.ac_period = 1.0 / self.inverter.ac_freq.item()\n",
        "        self.sim_steps_per_cycle = int(self.ac_period / 1e-5)\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-500.0, high=500.0, shape=(5,), dtype=np.float32)\n",
        "        self.max_steps = 100; self.current_step = 0\n",
        "    def _get_obs_from_gpu(self, v_history_gpu, i_history_gpu):\n",
        "        v_rms = torch.sqrt(torch.mean(v_history_gpu**2)); i_rms = torch.sqrt(torch.mean(i_history_gpu**2))\n",
        "        power = torch.mean(v_history_gpu * i_history_gpu); pf = power / (v_rms * i_rms + 1e-6)\n",
        "        fft = torch.fft.fft(v_history_gpu); harmonics = torch.abs(fft[1:11])\n",
        "        fundamental = harmonics[0]; higher_harmonics = torch.sqrt(torch.sum(harmonics[1:]**2))\n",
        "        thd = higher_harmonics / (fundamental + 1e-6)\n",
        "        return torch.stack([v_rms, i_rms, power, pf, thd])\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed); self.inverter.reset(); self.current_step = 0\n",
        "        self.load_resistance = torch.tensor(np.random.uniform(20, 80), device=self.device, dtype=torch.float32)\n",
        "        return np.zeros(5, dtype=np.float32), {}\n",
        "    def step(self, action):\n",
        "        modulation_index = torch.tensor((action[0] + 1.0) / 2.0, device=self.device, dtype=torch.float32)\n",
        "        v_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "        i_hist_gpu = torch.zeros(self.sim_steps_per_cycle, device=self.device)\n",
        "        for i in range(self.sim_steps_per_cycle):\n",
        "            state_gpu = self.inverter.step(modulation_index, self.load_resistance)\n",
        "            i_hist_gpu[i], v_hist_gpu[i] = state_gpu[0], state_gpu[1]\n",
        "        obs_gpu = self._get_obs_from_gpu(v_hist_gpu, i_hist_gpu)\n",
        "        v_rms, _, _, _, thd = obs_gpu\n",
        "        target_v_rms = 30.0; voltage_error = torch.abs(target_v_rms - v_rms)\n",
        "        reward = -(voltage_error**2) * 5.0 - (thd**2)\n",
        "        self.current_step += 1; done = self.current_step >= self.max_steps\n",
        "        return obs_gpu.cpu().numpy(), reward.item(), done, False, {}\n",
        "\n",
        "class SPWMController:\n",
        "    def __init__(self, modulation_index=0.8): self.m = modulation_index\n",
        "    def get_modulation_index(self, t): return self.m\n",
        "\n",
        "class PIController:\n",
        "    def __init__(self, Kp, Ki, target_rms, ac_freq=50.0):\n",
        "        self.Kp = Kp; self.Ki = Ki; self.target_rms = target_rms\n",
        "        self.ac_period = 1.0 / ac_freq; self.integral_error = 0.0; self.m = 0.8\n",
        "    def update_modulation_index(self, v_c_history_tensor):\n",
        "        if v_c_history_tensor.numel() < 2: return\n",
        "        measured_rms = torch.sqrt(torch.mean(v_c_history_tensor**2))\n",
        "        error = self.target_rms - measured_rms.item()\n",
        "        self.integral_error += error * self.ac_period\n",
        "        self.integral_error = np.clip(self.integral_error, -10.0, 10.0)\n",
        "        self.m = (self.Kp * error) + (self.Ki * self.integral_error)\n",
        "        self.m = np.clip(self.m, 0.0, 1.0)\n",
        "    def get_modulation_index(self, t): return self.m\n",
        "\n",
        "print(\"--- All classes defined successfully! ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 3: Train the RL Agent\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Starting RL Agent Training ---\")\n",
        "if __name__ == '__main__':\n",
        "    num_cpu = max(1, os.cpu_count() - 1)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    log_dir = \"./ppo_inverter_tensorboard/\"\n",
        "    print(f\"Creating {num_cpu} parallel environments. Using device: {device}\")\n",
        "\n",
        "    env = make_vec_env(InverterEnvGPU, n_envs=num_cpu)\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=1, device=device, n_steps=1024, batch_size=64, tensorboard_log=log_dir)\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.learn(total_timesteps=100000)\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(\"--- Training Complete ---\")\n",
        "    print(f\"Total Training Time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    rl_model_filename = \"ppo_inverter_final_model.zip\"\n",
        "    model.save(rl_model_filename)\n",
        "    print(f\"--- Model Saved as {rl_model_filename} ---\")\n",
        "    env.close()\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 4: Generate RL Learning Curve Plot\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Generating RL Performance Plots ---\")\n",
        "def get_learning_curve(log_path):\n",
        "    try:\n",
        "        ea = event_accumulator.EventAccumulator(log_path, size_guidance={event_accumulator.SCALARS: 0})\n",
        "        ea.Reload()\n",
        "        if 'rollout/ep_rew_mean' in ea.Tags()['scalars']:\n",
        "            reward_data = ea.Scalars('rollout/ep_rew_mean')\n",
        "            return [e.step for e in reward_data], [e.value for e in reward_data]\n",
        "        return None, None\n",
        "    except Exception: return None, None\n",
        "\n",
        "subdirs = [os.path.join(log_dir, d) for d in os.listdir(log_dir)]\n",
        "latest_log_dir = max(subdirs, key=os.path.getmtime)\n",
        "steps, rewards = get_learning_curve(latest_log_dir)\n",
        "\n",
        "if steps and rewards:\n",
        "    plt.figure(figsize=(12, 8), dpi=100)\n",
        "    plt.plot(steps, rewards, color='darkgreen')\n",
        "    plt.title('Reinforcement Learning Curve', fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Training Timesteps'); plt.ylabel('Mean Reward per Episode')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"rl_learning_curve.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Could not generate learning curve. Log file might be missing or corrupted.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 5: Run the Head-to-Head Comparison\n",
        "# ==============================================================================\n",
        "def run_simulation(controller_type, model_path=None, duration=0.2, dt=1e-5):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    if controller_type == \"RL\":\n",
        "        sim_controller = PPO.load(model_path, device=device)\n",
        "        controller_name = \"RL Controller (Proposed)\"\n",
        "    elif controller_type == \"PI\":\n",
        "        sim_controller = PIController(Kp=0.05, Ki=2.5, target_rms=30.0)\n",
        "        controller_name = \"PI Controller\"\n",
        "    else: # SPWM\n",
        "        sim_controller = SPWMController(modulation_index=0.65)\n",
        "        controller_name = \"SPWM Controller\"\n",
        "    print(f\"\\n--- Running simulation for: {controller_name} ---\")\n",
        "    inverter = InverterModelGPU(device=device)\n",
        "    num_steps = int(duration / dt)\n",
        "    time_hist=np.zeros(num_steps); v_c_hist=np.zeros(num_steps); i_l_hist=np.zeros(num_steps)\n",
        "    ac_period_steps = int((1.0 / inverter.ac_freq.item()) / dt)\n",
        "    obs = np.zeros(5, dtype=np.float32)\n",
        "    start_time = time.time()\n",
        "    for i in range(num_steps):\n",
        "        t = i * dt\n",
        "        r_load = torch.tensor(25.0 if 0.08 <= t < 0.16 else 50.0, device=device)\n",
        "        if controller_type == \"RL\":\n",
        "            action, _ = sim_controller.predict([obs], deterministic=True)\n",
        "            m_numpy = (action[0][0] + 1.0) / 2.0\n",
        "        else:\n",
        "            if isinstance(sim_controller, PIController) and i > 0 and i % ac_period_steps == 0:\n",
        "                v_cycle = torch.from_numpy(v_c_hist[max(0, i - ac_period_steps):i]).to(device)\n",
        "                sim_controller.update_modulation_index(v_cycle)\n",
        "            m_numpy = sim_controller.get_modulation_index(t)\n",
        "        modulation_index = torch.tensor(m_numpy, device=device)\n",
        "        state_gpu = inverter.step(modulation_index, r_load, dt)\n",
        "        state_cpu = state_gpu.cpu().numpy()\n",
        "        time_hist[i], v_c_hist[i], i_l_hist[i] = t, state_cpu[1], state_cpu[0]\n",
        "        if (i + 1) % ac_period_steps == 0 and controller_type == \"RL\":\n",
        "            v_cycle = torch.from_numpy(v_c_hist[i-ac_period_steps+1:i+1]).to(device)\n",
        "            i_cycle = torch.from_numpy(i_l_hist[i-ac_period_steps+1:i+1]).to(device)\n",
        "            obs_tensor = InverterEnvGPU()._get_obs_from_gpu(v_cycle, i_cycle)\n",
        "            obs = obs_tensor.cpu().numpy()\n",
        "    print(f\"Simulation finished in {time.time() - start_time:.2f} seconds.\")\n",
        "    return time_hist, v_c_hist, i_l_hist\n",
        "\n",
        "def analyze_and_plot(results):\n",
        "    print(\"\\n--- Analyzing results and generating plots... ---\")\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(12, 12), dpi=150)\n",
        "    ax = axes[0]\n",
        "    for name, data in results.items():\n",
        "        time, v_c, _ = data\n",
        "        dt = time[1] - time[0]; window_size = int(0.02 / dt)\n",
        "        rms_voltage = [np.sqrt(np.mean(v_c[i-window_size:i]**2)) for i in range(window_size, len(v_c))]\n",
        "        ax.plot(time[window_size:], rms_voltage, label=name, linewidth=2.5)\n",
        "    ax.set_title('Dynamic Voltage Response to Load Step', fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel('Time (s)'); ax.set_ylabel('RMS Voltage (V)')\n",
        "    ax.axvspan(0.08, 0.16, color='gray', alpha=0.2, label='Heavy Load Applied')\n",
        "    ax.legend(fontsize=12); ax.grid(True, which='both', linestyle='--')\n",
        "    thd_values = {}\n",
        "    for name, data in results.items():\n",
        "        time, v_c, _ = data\n",
        "        mask = (time >= 0.1) & (time < 0.16)\n",
        "        v_steady = v_c[mask]\n",
        "        fft = np.fft.fft(v_steady)\n",
        "        harmonics = np.abs(fft[1:11])\n",
        "        thd = np.sqrt(np.sum(harmonics[1:]**2)) / harmonics[0] if harmonics[0] > 1e-6 else 1.0\n",
        "        thd_values[name] = thd * 100\n",
        "    ax = axes[1]\n",
        "    colors = ['gray', 'cornflowerblue', 'crimson']\n",
        "    bars = ax.bar(thd_values.keys(), thd_values.values(), color=colors)\n",
        "    ax.set_title('Power Quality: Total Harmonic Distortion (THD)', fontsize=16, fontweight='bold')\n",
        "    ax.set_ylabel('THD (%)', fontsize=12)\n",
        "    ax.bar_label(bars, fmt='%.2f%%')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"final_comparison_results.png\")\n",
        "    print(\"\\n--- Plots generated and saved as 'final_comparison_results.png' ---\")\n",
        "    plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 6: Main Execution Block\n",
        "# ==============================================================================\n",
        "if __name__ == '__main__':\n",
        "    results = {}\n",
        "    results[\"SPWM Controller\"] = run_simulation(controller_type=\"SPWM\")\n",
        "    results[\"PI Controller\"] = run_simulation(controller_type=\"PI\")\n",
        "    results[\"RL Controller (Proposed)\"] = run_simulation(controller_type=\"RL\", model_path=rl_model_filename)\n",
        "    analyze_and_plot(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOd3NrXMUCuRWkbx2FjGfq6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}